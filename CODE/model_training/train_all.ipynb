{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\szymo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\szymo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: [WinError 127] Nie można odnaleźć określonej procedury\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "from model_training import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scripts.essentials import *\n",
    "from scripts.plots import *\n",
    "from scripts.train_utilities import *\n",
    "from neuralforecast.losses.pytorch import RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(744, 54)\n",
      "(40, 54)\n",
      "(60, 54)\n"
     ]
    }
   ],
   "source": [
    "prefix = \"NFLX\"\n",
    "FINAL_COLUMNS = ['mean_future', 'mean_influential','mean_trustworthy', 'mean_clickbait','norm_rsi_14', 'norm_rsi_gspc_14', 'norm_slowk_14']\n",
    "df_without_weekends = pd.read_csv(\"csv/\"+prefix+'_without_weekends.csv')\n",
    "df_without_weekends['DateGen'] = pd.date_range(start='2021-01-01', end='2023-11-26', freq='D')[:len(df_without_weekends)]\n",
    "max_date = df_without_weekends['DateGen'].max()\n",
    "test_start_date = max_date - pd.DateOffset(days=59)\n",
    "val_start_date = test_start_date - pd.DateOffset(days=40)\n",
    "train_set, val_set, test_set = split_data(df_without_weekends, 'DateGen', val_start_date, test_start_date, start_date_train = '2021-01-01')\n",
    "print(train_set.shape)\n",
    "print(val_set.shape)\n",
    "print(test_set.shape)\n",
    "\n",
    "cols_min_max = ['^GSPC_Volume', 'NFLX_Volume',\n",
    "'daily_variation', 'high_close_pressure', 'low_open_pressure',\n",
    "'low_norm', 'close_norm', 'high_norm', 'open_norm']\n",
    "\n",
    "train_set, scaler_min_max = min_max_scale(train_set,'Date', cols_min_max, train_data=True, scaler=None)\n",
    "val_set = min_max_scale(val_set,'Date', cols_min_max, train_data=False, scaler=scaler_min_max)\n",
    "test_set = min_max_scale(test_set,'Date', cols_min_max, train_data=False, scaler=scaler_min_max)\n",
    "\n",
    "train_set = train_set[['DateGen', f'{prefix}_Close'] + FINAL_COLUMNS]\n",
    "val_set = val_set[['DateGen', f'{prefix}_Close'] + FINAL_COLUMNS]\n",
    "test_set = test_set[['DateGen', f'{prefix}_Close'] + FINAL_COLUMNS]\n",
    "train_set.rename(columns={'DateGen':'ds', f'{prefix}_Close':'y'}, inplace=True)\n",
    "val_set.rename(columns={'DateGen':'ds', f'{prefix}_Close':'y'}, inplace=True)\n",
    "test_set.rename(columns={'DateGen':'ds', f'{prefix}_Close':'y'}, inplace=True)\n",
    "train_set['unique_id'] = prefix\n",
    "val_set['unique_id'] = prefix\n",
    "test_set['unique_id'] = prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-18 21:51:27,717] A new study created in memory with name: no-name-c3b6beb1-58a4-4f05-90b7-b913a87e6010\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "744 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 16.98it/s, v_num=1916, train_loss_step=3.570, train_loss_epoch=3.570]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 147.76it/s]\n",
      "749 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 18.92it/s, v_num=1918, train_loss_step=3.600, train_loss_epoch=3.600]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 76.89it/s]\n",
      "754 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 17.64it/s, v_num=1920, train_loss_step=3.620, train_loss_epoch=3.620]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 52.70it/s]\n",
      "759 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 18.92it/s, v_num=1922, train_loss_step=3.580, train_loss_epoch=3.580]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 56.65it/s]\n",
      "764 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 22.32it/s, v_num=1924, train_loss_step=3.450, train_loss_epoch=3.450]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 215.48it/s]\n",
      "769 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 16.19it/s, v_num=1926, train_loss_step=3.440, train_loss_epoch=3.440]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 209.63it/s]\n",
      "774 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 17.98it/s, v_num=1928, train_loss_step=3.530, train_loss_epoch=3.530]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 76.11it/s]\n",
      "779 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 19.83it/s, v_num=1930, train_loss_step=3.520, train_loss_epoch=3.520]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 119.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-18 21:51:35,986] Trial 0 finished with value: 166.28039769905178 and parameters: {'input_size': 7, 'n_blocks_season': 3, 'n_blocks_trend': 2, 'n_blocks_ident': 2, 'mlp_units': 32, 'num_hidden': 3, 'n_harmonics': 1, 'n_polynomials': 5, 'learning_rate': 0.05208060292448183}. Best is trial 0 with value: 166.28039769905178.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "744 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 18.11it/s, v_num=1932, train_loss_step=5.360, train_loss_epoch=5.360]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 131.75it/s]\n",
      "749 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 15.58it/s, v_num=1934, train_loss_step=5.340, train_loss_epoch=5.340]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 55.06it/s]\n",
      "754 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 15.68it/s, v_num=1936, train_loss_step=5.210, train_loss_epoch=5.210]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 322.29it/s]\n",
      "759 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 19.42it/s, v_num=1938, train_loss_step=5.130, train_loss_epoch=5.130]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 189.53it/s]\n",
      "764 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 20.14it/s, v_num=1940, train_loss_step=5.200, train_loss_epoch=5.200]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "769 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 16.97it/s, v_num=1942, train_loss_step=5.350, train_loss_epoch=5.350]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 296.52it/s]\n",
      "774 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 10.66it/s, v_num=1944, train_loss_step=5.450, train_loss_epoch=5.450]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 55.05it/s]\n",
      "779 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 14.47it/s, v_num=1946, train_loss_step=5.330, train_loss_epoch=5.330]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 97.39it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-18 21:51:42,863] Trial 1 finished with value: 216.0770509076308 and parameters: {'input_size': 4, 'n_blocks_season': 2, 'n_blocks_trend': 3, 'n_blocks_ident': 3, 'mlp_units': 64, 'num_hidden': 3, 'n_harmonics': 1, 'n_polynomials': 2, 'learning_rate': 0.04313409983625165}. Best is trial 0 with value: 166.28039769905178.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "744 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 16.66it/s, v_num=1948, train_loss_step=3.570, train_loss_epoch=3.570]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 133.19it/s]\n",
      "749 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 17.41it/s, v_num=1950, train_loss_step=3.600, train_loss_epoch=3.600]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 139.23it/s]\n",
      "754 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 15.78it/s, v_num=1952, train_loss_step=3.620, train_loss_epoch=3.620]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 208.65it/s]\n",
      "759 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 20.33it/s, v_num=1954, train_loss_step=3.580, train_loss_epoch=3.580]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 65.51it/s]\n",
      "764 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 16.88it/s, v_num=1956, train_loss_step=3.450, train_loss_epoch=3.450]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 105.62it/s]\n",
      "769 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 14.26it/s, v_num=1958, train_loss_step=3.440, train_loss_epoch=3.440]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 508.89it/s]\n",
      "774 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 16.32it/s, v_num=1960, train_loss_step=3.530, train_loss_epoch=3.530]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 992.26it/s]\n",
      "779 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 14.84it/s, v_num=1962, train_loss_step=3.520, train_loss_epoch=3.520]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 116.36it/s]\n",
      "784 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 19.81it/s, v_num=1964, train_loss_step=3.600, train_loss_epoch=3.600]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 87.74it/s] \n",
      "789 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 20.27it/s, v_num=1966, train_loss_step=3.490, train_loss_epoch=3.490]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 97.61it/s] \n",
      "794 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 17.04it/s, v_num=1968, train_loss_step=3.530, train_loss_epoch=3.530]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 65.40it/s]\n",
      "799 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 21.59it/s, v_num=1970, train_loss_step=3.570, train_loss_epoch=3.570]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "804 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 19.11it/s, v_num=1972, train_loss_step=3.550, train_loss_epoch=3.550]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 153.82it/s]\n",
      "809 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 20.29it/s, v_num=1974, train_loss_step=3.370, train_loss_epoch=3.370]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 83.99it/s]\n",
      "814 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 20.12it/s, v_num=1976, train_loss_step=3.160, train_loss_epoch=3.160]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 280.18it/s]\n",
      "819 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 22.44it/s, v_num=1978, train_loss_step=3.120, train_loss_epoch=3.120]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 204.32it/s]\n",
      "824 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 21.34it/s, v_num=1980, train_loss_step=3.210, train_loss_epoch=3.210]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 398.81it/s]\n",
      "829 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 20.35it/s, v_num=1982, train_loss_step=3.220, train_loss_epoch=3.220]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 237.53it/s]\n",
      "834 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 21.06it/s, v_num=1984, train_loss_step=3.220, train_loss_epoch=3.220]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 229.40it/s]\n",
      "839 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 20.19it/s, v_num=1986, train_loss_step=3.230, train_loss_epoch=3.230]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 321.40it/s]\n"
     ]
    }
   ],
   "source": [
    "############### NBEATS #################\n",
    "horizon = 5\n",
    "model_name = 'NBEATS'\n",
    "max_steps = 10\n",
    "random_seed = 1\n",
    "loss_func = mean_squared_error\n",
    "stack_types = ['seasonality', 'trend', 'identity']\n",
    "scaler_type = 'standard'\n",
    "loss=RMSE()\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(partial(objective, train_set=train_set, val_set=val_set, loss=loss, model_name=model_name, horizon=horizon, hist_exog_list=FINAL_COLUMNS, max_steps=max_steps, random_seed=random_seed, loss_func=loss_func, scaler_type=scaler_type), n_trials=2)\n",
    "prms = study.best_trial.params\n",
    "# Predykcja na podstawie najlepszych hiperparametrów\n",
    "n_blocks = [prms['n_blocks_season'], prms['n_blocks_trend'], prms['n_blocks_ident']]\n",
    "mlp_units=[[prms['mlp_units'], prms['mlp_units']]]*prms['num_hidden']\n",
    "models = [NBEATS(\n",
    "                 h=horizon,\n",
    "                 loss=loss,\n",
    "                 max_steps=max_steps,\n",
    "                 hist_exog_list=FINAL_COLUMNS,\n",
    "                 input_size=prms['input_size'],\n",
    "                 stack_types=stack_types,\n",
    "                 mlp_units=mlp_units,\n",
    "                 n_blocks=n_blocks,\n",
    "                 learning_rate=prms['learning_rate'],\n",
    "                 n_harmonics=prms['n_harmonics'],\n",
    "                 n_polynomials=prms['n_polynomials'],\n",
    "                 scaler_type=scaler_type,\n",
    "                random_seed=random_seed\n",
    "                 )]\n",
    "\n",
    "# Pipeline, który robi predykcję batchami co ileś dni, ustalane przez horizon\n",
    "loss_val, predictions_val = pipeline_train_predict(models, train_set, val_set, horizon, mean_squared_error, model_name)\n",
    "# Merge train and val sets\n",
    "train_val_set = pd.concat([train_set, val_set])\n",
    "loss_test, predictions_test = pipeline_train_predict(models, train_val_set, test_set, horizon, mean_squared_error, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166.28039769905178"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-18 21:52:27,570] A new study created in memory with name: no-name-8a2fa2eb-b67d-49d5-8032-6478006e4204\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "744 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 10.92it/s, v_num=1988, train_loss_step=1.640, train_loss_epoch=1.640]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 105.45it/s]\n",
      "749 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 15.81it/s, v_num=1990, train_loss_step=1.610, train_loss_epoch=1.610]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 387.11it/s]\n",
      "754 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 13.06it/s, v_num=1992, train_loss_step=1.570, train_loss_epoch=1.570]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 317.94it/s]\n",
      "759 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 14.63it/s, v_num=1994, train_loss_step=1.560, train_loss_epoch=1.560]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 52.28it/s]\n",
      "764 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 15.11it/s, v_num=1996, train_loss_step=1.530, train_loss_epoch=1.530]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "769 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 14.50it/s, v_num=1998, train_loss_step=1.530, train_loss_epoch=1.530]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 221.51it/s]\n",
      "774 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 14.87it/s, v_num=2000, train_loss_step=1.530, train_loss_epoch=1.530]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 53.51it/s]\n",
      "779 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 13.52it/s, v_num=2002, train_loss_step=1.490, train_loss_epoch=1.490]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 135.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-18 21:52:36,190] Trial 0 finished with value: 173.88642383848813 and parameters: {'input_size': 19, 'n_blocks1': 1, 'n_blocks2': 2, 'n_blocks3': 1, 'mlp_units': 128, 'n_pool_kernel_size1': 1, 'n_pool_kernel_size2': 1, 'n_pool_kernel_size3': 3, 'n_freq_downsample1': 4, 'n_freq_downsample2': 4, 'n_freq_downsample3': 3, 'learning_rate': 0.009341722913469208, 'dropout_prob_theta': 0.27485758098995744}. Best is trial 0 with value: 173.88642383848813.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "744 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 14.73it/s, v_num=2004, train_loss_step=1.590, train_loss_epoch=1.590]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "749 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 17.59it/s, v_num=2006, train_loss_step=1.590, train_loss_epoch=1.590]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "754 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 11.40it/s, v_num=2008, train_loss_step=1.580, train_loss_epoch=1.580]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 85.50it/s] \n",
      "759 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 16.37it/s, v_num=2010, train_loss_step=1.570, train_loss_epoch=1.570]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "764 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 12.62it/s, v_num=2012, train_loss_step=1.590, train_loss_epoch=1.590]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 189.62it/s]\n",
      "769 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 17.37it/s, v_num=2014, train_loss_step=1.580, train_loss_epoch=1.580]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "774 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 16.47it/s, v_num=2016, train_loss_step=1.570, train_loss_epoch=1.570]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.33it/s]\n",
      "779 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 14.41it/s, v_num=2018, train_loss_step=1.570, train_loss_epoch=1.570]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 772.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-18 21:52:44,049] Trial 1 finished with value: 159.87073754039616 and parameters: {'input_size': 17, 'n_blocks1': 1, 'n_blocks2': 2, 'n_blocks3': 3, 'mlp_units': 64, 'n_pool_kernel_size1': 1, 'n_pool_kernel_size2': 1, 'n_pool_kernel_size3': 2, 'n_freq_downsample1': 4, 'n_freq_downsample2': 2, 'n_freq_downsample3': 4, 'learning_rate': 7.790845054376245e-05, 'dropout_prob_theta': 0.4100162291293383}. Best is trial 1 with value: 159.87073754039616.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "744 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 14.15it/s, v_num=2020, train_loss_step=1.590, train_loss_epoch=1.590]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 59.35it/s]\n",
      "749 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 16.37it/s, v_num=2022, train_loss_step=1.590, train_loss_epoch=1.590]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "754 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 14.43it/s, v_num=2024, train_loss_step=1.580, train_loss_epoch=1.580]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "759 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 12.12it/s, v_num=2026, train_loss_step=1.570, train_loss_epoch=1.570]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "764 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 11.87it/s, v_num=2028, train_loss_step=1.590, train_loss_epoch=1.590]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 120.17it/s]\n",
      "769 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 13.87it/s, v_num=2030, train_loss_step=1.580, train_loss_epoch=1.580]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "774 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 16.76it/s, v_num=2032, train_loss_step=1.570, train_loss_epoch=1.570]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 93.23it/s]\n",
      "779 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 15.32it/s, v_num=2034, train_loss_step=1.570, train_loss_epoch=1.570]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 138.17it/s]\n",
      "784 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 15.81it/s, v_num=2036, train_loss_step=1.550, train_loss_epoch=1.550]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "789 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s, v_num=2038, train_loss_step=1.580, train_loss_epoch=1.580]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "794 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 12.52it/s, v_num=2040, train_loss_step=1.540, train_loss_epoch=1.540]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "799 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 11.89it/s, v_num=2042, train_loss_step=1.530, train_loss_epoch=1.530]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 85.07it/s] \n",
      "804 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  9.91it/s, v_num=2044, train_loss_step=1.520, train_loss_epoch=1.520]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 99.33it/s] \n",
      "809 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 13.88it/s, v_num=2046, train_loss_step=1.510, train_loss_epoch=1.510]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 312.45it/s]\n",
      "814 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 14.24it/s, v_num=2048, train_loss_step=1.520, train_loss_epoch=1.520]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 286.48it/s]\n",
      "819 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 14.74it/s, v_num=2050, train_loss_step=1.530, train_loss_epoch=1.530]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 276.03it/s]\n",
      "824 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 11.71it/s, v_num=2052, train_loss_step=1.540, train_loss_epoch=1.540]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 127.34it/s]\n",
      "829 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.80it/s, v_num=2054, train_loss_step=1.540, train_loss_epoch=1.540]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 122.97it/s]\n",
      "834 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 15.01it/s, v_num=2056, train_loss_step=1.520, train_loss_epoch=1.520]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 145.50it/s]\n",
      "839 5\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 14.04it/s, v_num=2058, train_loss_step=1.540, train_loss_epoch=1.540]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 67.78it/s]\n"
     ]
    }
   ],
   "source": [
    "############### NHITS #################\n",
    "horizon = 5\n",
    "model_name = 'NHITS'\n",
    "max_steps = 10\n",
    "random_seed = 1\n",
    "loss_func = mean_squared_error\n",
    "stack_types = ['identity', 'identity', 'identity']\n",
    "scaler_type = 'standard'\n",
    "loss=RMSE()\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(partial(objective, train_set=train_set, val_set=val_set, loss=loss, model_name=model_name, horizon=horizon, hist_exog_list=FINAL_COLUMNS, max_steps=max_steps, random_seed=random_seed, loss_func=loss_func, scaler_type=scaler_type), n_trials=2)\n",
    "prms = study.best_trial.params\n",
    "# Predykcja na podstawie najlepszych hiperparametrów\n",
    "n_blocks = [prms['n_blocks1'], prms['n_blocks2'], prms['n_blocks3']]\n",
    "mlp_units=[[prms['mlp_units'], prms['mlp_units']]]*3\n",
    "n_pool_kernel_size = [prms['n_pool_kernel_size1'], prms['n_pool_kernel_size2'], prms['n_pool_kernel_size3']]\n",
    "n_freq_downsample = [prms['n_freq_downsample1'], prms['n_freq_downsample2'], prms['n_freq_downsample3']]\n",
    "models = [NHITS(\n",
    "                 h=horizon,\n",
    "                 loss=loss,\n",
    "                 max_steps=max_steps,\n",
    "                 hist_exog_list=FINAL_COLUMNS,\n",
    "                 input_size=prms['input_size'],\n",
    "                 stack_types=stack_types,\n",
    "                 mlp_units=mlp_units,\n",
    "                 n_blocks=n_blocks,\n",
    "                 learning_rate=prms['learning_rate'],\n",
    "                 n_pool_kernel_size=n_pool_kernel_size,\n",
    "                 n_freq_downsample=n_freq_downsample,\n",
    "                 dropout_prob_theta=prms['dropout_prob_theta'],\n",
    "                 scaler_type=scaler_type,\n",
    "                random_seed=random_seed\n",
    "                 )]\n",
    "\n",
    "# Pipeline, który robi predykcję batchami co ileś dni, ustalane przez horizon\n",
    "loss_val, predictions_val = pipeline_train_predict(models, train_set, val_set, horizon, mean_squared_error, model_name)\n",
    "# Merge train and val sets\n",
    "train_val_set = pd.concat([train_set, val_set])\n",
    "loss_test, predictions_test = pipeline_train_predict(models, train_val_set, test_set, horizon, mean_squared_error, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159.87073754039616"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-18 21:57:46,837] A new study created in memory with name: no-name-cb0c3339-c13e-451c-9bc2-270de00e36d0\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.27it/s, v_num=2108, train_loss_step=30.10, train_loss_epoch=30.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 58.57it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.90it/s, v_num=2110, train_loss_step=30.20, train_loss_epoch=30.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.47it/s, v_num=2112, train_loss_step=30.20, train_loss_epoch=30.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 108.23it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.49it/s, v_num=2114, train_loss_step=30.10, train_loss_epoch=30.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.87it/s, v_num=2116, train_loss_step=30.20, train_loss_epoch=30.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 97.84it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s, v_num=2118, train_loss_step=30.20, train_loss_epoch=30.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.50it/s, v_num=2120, train_loss_step=30.30, train_loss_epoch=30.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 97.19it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.56it/s, v_num=2122, train_loss_step=30.20, train_loss_epoch=30.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 84.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-18 21:58:00,041] Trial 0 finished with value: 375.66886641590395 and parameters: {'input_size': 3, 'learning_rate': 1.4619019934073393e-05, 'hidden_size': 12, 'dropout': 0.18289535556885061, 'attn_dropout': 0.447507788311037}. Best is trial 0 with value: 375.66886641590395.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.09it/s, v_num=2124, train_loss_step=2.780, train_loss_epoch=2.780]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 87.63it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.79it/s, v_num=2126, train_loss_step=2.770, train_loss_epoch=2.770]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 113.00it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.07it/s, v_num=2128, train_loss_step=2.880, train_loss_epoch=2.880]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 403.41it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.00it/s, v_num=2130, train_loss_step=2.880, train_loss_epoch=2.880]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 260.92it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  2.71it/s, v_num=2132, train_loss_step=2.880, train_loss_epoch=2.880]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 80.58it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.82it/s, v_num=2134, train_loss_step=2.890, train_loss_epoch=2.890]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 51.32it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.98it/s, v_num=2136, train_loss_step=3.030, train_loss_epoch=3.030]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 115.25it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.01it/s, v_num=2138, train_loss_step=3.050, train_loss_epoch=3.050]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 232.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-18 21:58:23,367] Trial 1 finished with value: 229.69487190034735 and parameters: {'input_size': 8, 'learning_rate': 0.0032831202948453196, 'hidden_size': 20, 'dropout': 0.32601738794520446, 'attn_dropout': 0.3124408660151364}. Best is trial 1 with value: 229.69487190034735.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.06it/s, v_num=2140, train_loss_step=2.780, train_loss_epoch=2.780]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 206.83it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.02it/s, v_num=2142, train_loss_step=2.770, train_loss_epoch=2.770]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 118.15it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.56it/s, v_num=2144, train_loss_step=2.880, train_loss_epoch=2.880]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 117.81it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.07it/s, v_num=2146, train_loss_step=2.880, train_loss_epoch=2.880]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 71.96it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s, v_num=2148, train_loss_step=2.880, train_loss_epoch=2.880]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 208.65it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.66it/s, v_num=2150, train_loss_step=2.890, train_loss_epoch=2.890]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 41.63it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.73it/s, v_num=2152, train_loss_step=3.030, train_loss_epoch=3.030]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 172.37it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.97it/s, v_num=2154, train_loss_step=3.050, train_loss_epoch=3.050]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 304.95it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.72it/s, v_num=2156, train_loss_step=3.080, train_loss_epoch=3.080]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 66.60it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.72it/s, v_num=2158, train_loss_step=2.980, train_loss_epoch=2.980]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 104.30it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.66it/s, v_num=2160, train_loss_step=2.980, train_loss_epoch=2.980]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 70.00it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.75it/s, v_num=2162, train_loss_step=3.030, train_loss_epoch=3.030]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 79.09it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.74it/s, v_num=2164, train_loss_step=3.030, train_loss_epoch=3.030]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 72.03it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.89it/s, v_num=2166, train_loss_step=3.030, train_loss_epoch=3.030]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 86.56it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.76it/s, v_num=2168, train_loss_step=2.960, train_loss_epoch=2.960]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 98.98it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.71it/s, v_num=2170, train_loss_step=2.940, train_loss_epoch=2.940]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 211.20it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.78it/s, v_num=2172, train_loss_step=3.150, train_loss_epoch=3.150]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 65.85it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.74it/s, v_num=2174, train_loss_step=3.150, train_loss_epoch=3.150]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 65.40it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.57it/s, v_num=2176, train_loss_step=3.120, train_loss_epoch=3.120]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 49.26it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.72it/s, v_num=2178, train_loss_step=3.020, train_loss_epoch=3.020]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 114.41it/s]\n"
     ]
    }
   ],
   "source": [
    "############### TFT #################\n",
    "horizon = 5\n",
    "model_name = 'TFT'\n",
    "max_steps = 10\n",
    "random_seed = 1\n",
    "loss_func = mean_squared_error\n",
    "stack_types = ['identity', 'identity', 'identity']\n",
    "scaler_type = 'standard'\n",
    "loss=RMSE()\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(partial(objective, train_set=train_set, val_set=val_set, loss=loss, model_name=model_name, horizon=horizon, hist_exog_list=FINAL_COLUMNS, max_steps=max_steps, random_seed=random_seed, loss_func=loss_func, scaler_type=scaler_type), n_trials=2)\n",
    "prms = study.best_trial.params\n",
    "# Predykcja na podstawie najlepszych hiperparametrów\n",
    "models = [TFT(\n",
    "                 h=horizon,\n",
    "                 loss=loss,\n",
    "                 max_steps=max_steps,\n",
    "                 hist_exog_list=FINAL_COLUMNS,\n",
    "                 input_size=prms['input_size'],\n",
    "                 learning_rate=prms['learning_rate'],\n",
    "                 hidden_size=prms['hidden_size'],\n",
    "                 dropout=prms['dropout'],\n",
    "                 attn_dropout=prms['attn_dropout'],\n",
    "                 scaler_type=scaler_type,\n",
    "                random_seed=random_seed\n",
    "                 )]\n",
    "\n",
    "# Pipeline, który robi predykcję batchami co ileś dni, ustalane przez horizon\n",
    "loss_val, predictions_val = pipeline_train_predict(models, train_set, val_set, horizon, mean_squared_error, model_name)\n",
    "# Merge train and val sets\n",
    "train_val_set = pd.concat([train_set, val_set])\n",
    "loss_test, predictions_test = pipeline_train_predict(models, train_val_set, test_set, horizon, mean_squared_error, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "229.69487190034735"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.22it/s, v_num=1914, train_loss_step=0.612, train_loss_epoch=0.612]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 13.67it/s]\n"
     ]
    }
   ],
   "source": [
    "from neuralforecast.models import DilatedRNN\n",
    "\n",
    "models = [DilatedRNN(\n",
    "                 h=horizon,\n",
    "                 loss=loss,\n",
    "                 max_steps=max_steps,\n",
    "                 hist_exog_list=FINAL_COLUMNS,\n",
    "                 input_size=10,\n",
    "                 #stack_types=stack_types,\n",
    "                 #mlp_units=mlp_units,\n",
    "                 #n_blocks=n_blocks,\n",
    "                 #learning_rate=prms['learning_rate'],\n",
    "                 #n_harmonics=prms['n_harmonics'],\n",
    "                 #n_polynomials=prms['n_polynomials'],\n",
    "                 scaler_type=scaler_type,\n",
    "                random_seed=random_seed\n",
    "                 )]\n",
    "model = NeuralForecast(models=models, freq='D')\n",
    "model.fit(train_set)\n",
    "p =  model.predict().reset_index()\n",
    "p = p.merge(val_set[['ds','unique_id', 'y']].reset_index(), on=['ds', 'unique_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 6, 6, 6]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[6]*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>DilatedRNN</th>\n",
       "      <th>index</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2023-01-15</td>\n",
       "      <td>438.156189</td>\n",
       "      <td>0</td>\n",
       "      <td>441.709991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2023-01-16</td>\n",
       "      <td>439.109467</td>\n",
       "      <td>1</td>\n",
       "      <td>440.209991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2023-01-17</td>\n",
       "      <td>439.157562</td>\n",
       "      <td>2</td>\n",
       "      <td>444.049988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2023-01-18</td>\n",
       "      <td>440.515656</td>\n",
       "      <td>3</td>\n",
       "      <td>450.380005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2023-01-19</td>\n",
       "      <td>440.727509</td>\n",
       "      <td>4</td>\n",
       "      <td>441.910004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  unique_id         ds  DilatedRNN  index           y\n",
       "0      NFLX 2023-01-15  438.156189      0  441.709991\n",
       "1      NFLX 2023-01-16  439.109467      1  440.209991\n",
       "2      NFLX 2023-01-17  439.157562      2  444.049988\n",
       "3      NFLX 2023-01-18  440.515656      3  450.380005\n",
       "4      NFLX 2023-01-19  440.727509      4  441.910004"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = pd.read_csv('csv/BA/train_set_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['future', 'influential', 'trustworthy', 'not clickbait',\n",
       "       'finbert_Score', 'bart_Score', 'vader_Score', 'future_finbert',\n",
       "       'future_bart', 'future_vader', 'influential_finbert',\n",
       "       'influential_bart', 'influential_vader', 'trustworthy_finbert',\n",
       "       'trustworthy_bart', 'trustworthy_vader', 'clickbait_finbert',\n",
       "       'clickbait_bart', 'clickbait_vader', 'Date', 'EURUSD=X_Close',\n",
       "       'mean_future', 'mean_influential', 'mean_trustworthy', 'mean_clickbait',\n",
       "       'norm_rsi_14', 'norm_rsi_gspc_14', 'norm_slowk_14', 'norm_roc_14',\n",
       "       'log_return_1', 'log_return_5', 'log_return_10', 'log_return_20',\n",
       "       'log_return_gspc_1', 'log_return_gspc_5', 'log_return_gspc_10',\n",
       "       'log_return_gspc_20', 'target_1', 'target_5', 'target_10', 'target_20',\n",
       "       'minmax_^GSPC_Volume', 'minmax_BA_Volume', 'minmax_daily_variation',\n",
       "       'minmax_high_close_pressure', 'minmax_low_open_pressure',\n",
       "       'minmax_low_norm', 'minmax_close_norm', 'minmax_high_norm',\n",
       "       'minmax_open_norm'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same finansowe, same newsy, finansowe + newsy\n",
    "# Do zapisu: model nauczony na treningu, na treningu i walidacji\n",
    "# predykcja na walidacyjnym\n",
    "# predykcja na testowym\n",
    "# loss na walidacyjnym\n",
    "# loss na testowym\n",
    "# Dla każdego znacznika: json['financial'/'news'/'financial_and_news']['TFT'/'NBEATS'/'NHITS']['params'/'loss'] - zapis\n",
    "# json['BA']['financial']['loss']['val'/'test']\n",
    "# Dla każdego znacznika: zapis val_pred.csv oraz test_pred.csv results/BA/financial/TFT/val_pred.csv\n",
    "horizon = 5\n",
    "model_name = 'TFT'\n",
    "max_steps = 10\n",
    "random_seed = 1\n",
    "loss_func = mean_squared_error\n",
    "stack_types = ['identity', 'identity', 'identity']\n",
    "scaler_type = 'standard'\n",
    "loss=RMSE()\n",
    "\n",
    "def train_all(indicator, model_names, max_steps, random_seed, FINAL_COLUMNS, scaler_type='standard', loss=RMSE()):\n",
    "    \n",
    "    # Prepare data\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"NFLX\"\n",
    "FINAL_COLUMNS = ['mean_future', 'mean_influential','mean_trustworthy', 'mean_clickbait','norm_rsi_14', 'norm_rsi_gspc_14', 'norm_slowk_14']\n",
    "df_without_weekends = pd.read_csv(\"csv/\"+prefix+'_without_weekends.csv')\n",
    "df_without_weekends['DateGen'] = pd.date_range(start='2021-01-01', end='2023-11-26', freq='D')[:len(df_without_weekends)]\n",
    "max_date = df_without_weekends['DateGen'].max()\n",
    "test_start_date = max_date - pd.DateOffset(days=59)\n",
    "val_start_date = test_start_date - pd.DateOffset(days=40)\n",
    "train_set, val_set, test_set = split_data(df_without_weekends, 'DateGen', val_start_date, test_start_date, start_date_train = '2021-01-01')\n",
    "print(train_set.shape)\n",
    "print(val_set.shape)\n",
    "print(test_set.shape)\n",
    "\n",
    "cols_min_max = ['^GSPC_Volume', 'NFLX_Volume',\n",
    "'daily_variation', 'high_close_pressure', 'low_open_pressure',\n",
    "'low_norm', 'close_norm', 'high_norm', 'open_norm']\n",
    "\n",
    "train_set, scaler_min_max = min_max_scale(train_set,'Date', cols_min_max, train_data=True, scaler=None)\n",
    "val_set = min_max_scale(val_set,'Date', cols_min_max, train_data=False, scaler=scaler_min_max)\n",
    "test_set = min_max_scale(test_set,'Date', cols_min_max, train_data=False, scaler=scaler_min_max)\n",
    "\n",
    "train_set = train_set[['DateGen', f'{prefix}_Close'] + FINAL_COLUMNS]\n",
    "val_set = val_set[['DateGen', f'{prefix}_Close'] + FINAL_COLUMNS]\n",
    "test_set = test_set[['DateGen', f'{prefix}_Close'] + FINAL_COLUMNS]\n",
    "train_set.rename(columns={'DateGen':'ds', f'{prefix}_Close':'y'}, inplace=True)\n",
    "val_set.rename(columns={'DateGen':'ds', f'{prefix}_Close':'y'}, inplace=True)\n",
    "test_set.rename(columns={'DateGen':'ds', f'{prefix}_Close':'y'}, inplace=True)\n",
    "train_set['unique_id'] = prefix\n",
    "val_set['unique_id'] = prefix\n",
    "test_set['unique_id'] = prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.000000\n",
       "1     -0.033606\n",
       "2     -0.003948\n",
       "3     -0.039778\n",
       "4      0.016644\n",
       "         ...   \n",
       "651    0.002154\n",
       "652    0.000000\n",
       "653    0.010053\n",
       "654   -0.015960\n",
       "655   -0.001688\n",
       "Name: log_return_1, Length: 656, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('csv/'+prefix+'/train_set_full.csv')['log_return_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\szymo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\szymo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: [WinError 127] Nie można odnaleźć określonej procedury\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "from model_training import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scripts.essentials import *\n",
    "from scripts.plots import *\n",
    "from scripts.train_utilities import *\n",
    "from neuralforecast.losses.pytorch import MQLoss, MSE\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import torch\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    csm = count_signs_matrix(y_true.reset_index(drop=True), y_pred.reset_index(drop=True))\n",
    "    return (3*csm[1][1]/(csm[1][0]+csm[1][1]) + 2*csm[1][1]/(csm[0][1]+csm[1][1]))/5\n",
    "\n",
    "def MQLoss2(y_pred, y_test):\n",
    "    # Reshape tensors to 1D\n",
    "    y_pred_ = torch.tensor(y_pred.values)\n",
    "    y_pred_ = y_pred_.view(-1)\n",
    "    y_test_ = torch.tensor(y_test.values)\n",
    "    y_test_ = y_test_.view(-1)\n",
    "    # print(y_pred_.shape)\n",
    "    # print(y_test_.shape)\n",
    "    #print(MQLoss()(y_test, y_pred_).item())\n",
    "    print(y_test_)\n",
    "    print(y_pred_)\n",
    "    return MQLoss()(y_test_, y_pred_).item()\n",
    "    # return MQLoss(y_test_, y_pred_)\n",
    "\n",
    "class HorizonTrainer:\n",
    "    def __init__(self, prefix, mode, model_type, final_columns, train_set_all, val_set_all, test_set_all, horizon, max_steps, scaler_type, loss_func, loss, n_trials, random_seed, timestamp, target):\n",
    "        self.prefix = prefix\n",
    "        self.model_type = model_type\n",
    "        self.mode = mode\n",
    "        self.final_columns = final_columns\n",
    "        self.train_set_all = train_set_all\n",
    "        self.train_set = train_set_all\n",
    "        self.val_set_all = val_set_all\n",
    "        self.val_set = val_set_all\n",
    "        self.test_set_all = test_set_all\n",
    "        self.test_set = test_set_all\n",
    "        self.horizon = horizon\n",
    "        self.max_steps = max_steps\n",
    "        self.scaler_type = scaler_type\n",
    "        self.loss_func = loss_func\n",
    "        self.loss = loss\n",
    "        self.n_trials = n_trials\n",
    "        self.random_seed = random_seed\n",
    "        self.timestamp = timestamp\n",
    "        self.target = target\n",
    "\n",
    "    def __prepare_sets__(self):\n",
    "\n",
    "        self.train_set_all['DateGen'] = pd.date_range(start='2021-01-01', end='2023-11-26', freq='D')[:len(self.train_set)]\n",
    "        valid_start_date = self.train_set['DateGen'].max() + pd.DateOffset(days=1)\n",
    "        self.val_set_all['DateGen'] = pd.date_range(start=valid_start_date, end='2023-11-26', freq='D')[:len(self.val_set)]\n",
    "        test_start_date = self.val_set['DateGen'].max() + pd.DateOffset(days=1)\n",
    "        self.test_set_all['DateGen'] = pd.date_range(start=test_start_date, end='2023-11-26', freq='D')[:len(self.test_set)]\n",
    "        # self.train_set = self.train_set_all[['DateGen', f'{self.prefix}_Close'] + self.final_columns]\n",
    "        # self.val_set = self.val_set_all[['DateGen', f'{self.prefix}_Close'] + self.final_columns]\n",
    "        # self.test_set = self.test_set_all[['DateGen', f'{self.prefix}_Close'] + self.final_columns]\n",
    "        # self.train_set.rename(columns={'DateGen':'ds', f'{self.prefix}_Close':'y'}, inplace=True)\n",
    "        # self.val_set.rename(columns={'DateGen':'ds', f'{self.prefix}_Close':'y'}, inplace=True)\n",
    "        # self.test_set.rename(columns={'DateGen':'ds', f'{self.prefix}_Close':'y'}, inplace=True)\n",
    "        self.train_set = self.train_set_all[['DateGen', f'{self.target}'] + self.final_columns]\n",
    "        self.val_set = self.val_set_all[['DateGen', f'{self.target}'] + self.final_columns]\n",
    "        self.test_set = self.test_set_all[['DateGen', f'{self.target}'] + self.final_columns]\n",
    "        self.train_set.rename(columns={'DateGen':'ds', f'{self.target}':'y'}, inplace=True)\n",
    "        self.val_set.rename(columns={'DateGen':'ds', f'{self.target}':'y'}, inplace=True)\n",
    "        self.test_set.rename(columns={'DateGen':'ds', f'{self.target}':'y'}, inplace=True)\n",
    "        self.train_set['unique_id'] = self.prefix\n",
    "        self.val_set['unique_id'] = self.prefix\n",
    "        self.test_set['unique_id'] = self.prefix\n",
    "\n",
    "    def train(self):\n",
    "        self.__prepare_sets__()\n",
    "        if self.loss_func == f1_score:\n",
    "            study = optuna.create_study(direction='maximize')\n",
    "        else:\n",
    "            study = optuna.create_study(direction='minimize')\n",
    "        study.optimize(partial(objective, train_set=self.train_set, val_set=self.val_set, loss=self.loss, model_name=self.model_type, horizon=self.horizon, hist_exog_list=self.final_columns, max_steps=self.max_steps, random_seed=self.random_seed, loss_func=self.loss_func, scaler_type=self.scaler_type), n_trials=self.n_trials)\n",
    "        prms = study.best_trial.params\n",
    "\n",
    "        if self.model_type == 'NBEATS':\n",
    "            n_blocks = [prms['n_blocks_season'], prms['n_blocks_trend'], prms['n_blocks_ident']]\n",
    "            mlp_units=[[prms['mlp_units'], prms['mlp_units']]]*prms['num_hidden']\n",
    "            params = {\n",
    "                'h': self.horizon,\n",
    "                'loss': self.loss,\n",
    "                'max_steps': self.max_steps,\n",
    "                'hist_exog_list': self.final_columns,\n",
    "                'input_size': 2*self.horizon,\n",
    "                'stack_types': ['seasonality', 'trend', 'identity'],\n",
    "                'mlp_units': mlp_units,\n",
    "                'n_blocks': n_blocks,\n",
    "                'learning_rate': prms['learning_rate'],\n",
    "                'n_harmonics': prms['n_harmonics'],\n",
    "                'n_polynomials': prms['n_polynomials'],\n",
    "                'scaler_type': self.scaler_type,\n",
    "                'random_seed': self.random_seed\n",
    "            }\n",
    "            models = [NBEATS(**params)]\n",
    "\n",
    "        elif self.model_type == 'NHITS':\n",
    "            n_blocks = [prms['n_blocks1'], prms['n_blocks2'], prms['n_blocks3']]\n",
    "            mlp_units=[[prms['mlp_units'], prms['mlp_units']]]*3\n",
    "            n_pool_kernel_size = [prms['n_pool_kernel_size1'], prms['n_pool_kernel_size2'], prms['n_pool_kernel_size3']]\n",
    "            #n_freq_downsample = [prms['n_freq_downsample1'], prms['n_freq_downsample2'], prms['n_freq_downsample3']]\n",
    "            params = {\n",
    "                'h': self.horizon,\n",
    "                'loss': self.loss,\n",
    "                'max_steps': self.max_steps,\n",
    "                'hist_exog_list': self.final_columns,\n",
    "                'input_size': 2*self.horizon,\n",
    "                'stack_types': ['identity', 'identity', 'identity'],\n",
    "                'mlp_units': mlp_units,\n",
    "                'n_blocks': n_blocks,\n",
    "                'learning_rate': prms['learning_rate'],\n",
    "                'n_pool_kernel_size': n_pool_kernel_size,\n",
    "                #'n_freq_downsample': n_freq_downsample,\n",
    "                #'dropout_prob_theta': prms['dropout_prob_theta'],\n",
    "                'scaler_type': self.scaler_type,\n",
    "                'random_seed': self.random_seed\n",
    "            }\n",
    "            models = [NHITS(**params)]\n",
    "\n",
    "        elif self.model_type == 'TFT':\n",
    "            params = {\n",
    "                'h': self.horizon,\n",
    "                'loss': self.loss,\n",
    "                'max_steps': self.max_steps,\n",
    "                'hist_exog_list': self.final_columns,\n",
    "                'input_size': 2*self.horizon,\n",
    "                'learning_rate': prms['learning_rate'],\n",
    "                'hidden_size': prms['hidden_size'],\n",
    "                #'dropout': prms['dropout'],\n",
    "                #'attn_dropout': prms['attn_dropout'],\n",
    "                'scaler_type': self.scaler_type,\n",
    "                'random_seed': self.random_seed\n",
    "            }\n",
    "            models = [TFT(**params)]\n",
    "\n",
    "        else:\n",
    "            raise ValueError('Wrong model type!')\n",
    "        \n",
    "        params['loss'] = str(params['loss'])\n",
    "        \n",
    "            \n",
    "        loss_val, predictions_val = pipeline_train_predict(models, self.train_set, self.val_set, self.horizon, self.loss_func, self.model_type)\n",
    "        predictions_val = pd.concat([predictions_val, self.val_set_all[['Date']]], axis=1)\n",
    "        \n",
    "        train_val_set = pd.concat([self.train_set, self.val_set])\n",
    "        loss_test, predictions_test = pipeline_train_predict(models, train_val_set, self.test_set, self.horizon, self.loss_func, self.model_type)\n",
    "        predictions_test = pd.concat([predictions_test, self.test_set_all[['Date']]], axis=1)\n",
    "        \n",
    "        # create directiories if not exist\n",
    "    \n",
    "        if not os.path.exists(f'results/{self.prefix}'):\n",
    "            os.mkdir(f'results/{self.prefix}')\n",
    "        if not os.path.exists(f'results/{self.prefix}/{self.mode}'):\n",
    "            os.mkdir(f'results/{self.prefix}/{self.mode}')\n",
    "        if not os.path.exists(f'results/{self.prefix}/{self.mode}/{self.model_type}'):\n",
    "            os.mkdir(f'results/{self.prefix}/{self.mode}/{self.model_type}')\n",
    "        # All saves\n",
    "        # Save params as json\n",
    "        with open(f'results/{self.prefix}/{self.mode}/{self.model_type}/params_{self.timestamp}.json', 'w') as f:\n",
    "            json.dump(params, f)\n",
    "        # Save predictions_val and predictions_test as csv\n",
    "        predictions_val.to_csv(f'results/{self.prefix}/{self.mode}/{self.model_type}/val_pred_{self.timestamp}.csv', index=False)\n",
    "        predictions_test.to_csv(f'results/{self.prefix}/{self.mode}/{self.model_type}/test_pred_{self.timestamp}.csv', index=False)\n",
    "        # Save loss_val and loss_test as json\n",
    "        scores = {\n",
    "            'val': loss_val,\n",
    "            'test': loss_test\n",
    "        }\n",
    "        with open(f'results/{self.prefix}/{self.mode}/{self.model_type}/loss_{self.timestamp}.json', 'w') as f:\n",
    "            json.dump(scores, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 15:17:41,699] A new study created in memory with name: no-name-f40805ca-4a66-4196-ac4c-4296211d349b\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prefix: NFLX | mode: financial_and_news | model_type: NBEATS\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 24.35it/s, v_num=17820, train_loss_step=4.220, train_loss_epoch=4.220]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 261.62it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 26.79it/s, v_num=17822, train_loss_step=3.790, train_loss_epoch=3.790]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 220.64it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 27.50it/s, v_num=17824, train_loss_step=4.290, train_loss_epoch=4.290]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 84.29it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 30.16it/s, v_num=17826, train_loss_step=3.950, train_loss_epoch=3.950]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 159.24it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 28.78it/s, v_num=17828, train_loss_step=4.010, train_loss_epoch=4.010]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 200.56it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 24.04it/s, v_num=17830, train_loss_step=4.090, train_loss_epoch=4.090]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 107.56it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 35.69it/s, v_num=17832, train_loss_step=4.150, train_loss_epoch=4.150]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 287.97it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 28.54it/s, v_num=17834, train_loss_step=4.250, train_loss_epoch=4.250]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 163.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 15:18:07,882] Trial 0 finished with value: 0.772258064516129 and parameters: {'n_blocks_trend': 3, 'n_blocks_ident': 1, 'mlp_units': 32, 'num_hidden': 2, 'n_harmonics': 1, 'n_polynomials': 4, 'learning_rate': 0.05063159193743755}. Best is trial 0 with value: 0.772258064516129.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 20.33it/s, v_num=17836, train_loss_step=4.920, train_loss_epoch=4.920]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 94.60it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 21.18it/s, v_num=17838, train_loss_step=4.620, train_loss_epoch=4.620]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 182.16it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.31it/s, v_num=17840, train_loss_step=4.980, train_loss_epoch=4.980]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 239.03it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 21.41it/s, v_num=17842, train_loss_step=4.680, train_loss_epoch=4.680]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 288.27it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 22.49it/s, v_num=17844, train_loss_step=4.830, train_loss_epoch=4.830]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 262.60it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.65it/s, v_num=17846, train_loss_step=4.840, train_loss_epoch=4.840]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 316.58it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 23.76it/s, v_num=17848, train_loss_step=5.100, train_loss_epoch=5.100]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.66it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 22.85it/s, v_num=17850, train_loss_step=5.250, train_loss_epoch=5.250]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 225.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 15:18:36,491] Trial 1 finished with value: 0.6958823529411765 and parameters: {'n_blocks_trend': 2, 'n_blocks_ident': 3, 'mlp_units': 128, 'num_hidden': 1, 'n_harmonics': 4, 'n_polynomials': 2, 'learning_rate': 2.0122753311683894e-05}. Best is trial 0 with value: 0.772258064516129.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.73it/s, v_num=17852, train_loss_step=4.500, train_loss_epoch=4.500] \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 204.25it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 28.04it/s, v_num=17854, train_loss_step=4.230, train_loss_epoch=4.230]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 165.68it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 27.57it/s, v_num=17856, train_loss_step=4.560, train_loss_epoch=4.560]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 257.79it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 27.25it/s, v_num=17858, train_loss_step=4.220, train_loss_epoch=4.220] \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 184.82it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 21.16it/s, v_num=17860, train_loss_step=4.380, train_loss_epoch=4.380]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 141.92it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 21.32it/s, v_num=17862, train_loss_step=4.370, train_loss_epoch=4.370]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 128.14it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 21.34it/s, v_num=17864, train_loss_step=4.580, train_loss_epoch=4.580]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 24.98it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.73it/s, v_num=17866, train_loss_step=4.710, train_loss_epoch=4.710]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 15:19:07,143] Trial 2 finished with value: 0.7582608695652173 and parameters: {'n_blocks_trend': 1, 'n_blocks_ident': 2, 'mlp_units': 64, 'num_hidden': 2, 'n_harmonics': 5, 'n_polynomials': 1, 'learning_rate': 0.0004776288195451216}. Best is trial 0 with value: 0.772258064516129.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 20.03it/s, v_num=17868, train_loss_step=4.220, train_loss_epoch=4.220]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 143.26it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.47it/s, v_num=17870, train_loss_step=3.790, train_loss_epoch=3.790]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 21.34it/s, v_num=17872, train_loss_step=4.290, train_loss_epoch=4.290]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 1841.22it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 22.59it/s, v_num=17874, train_loss_step=3.950, train_loss_epoch=3.950]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 21.16it/s, v_num=17876, train_loss_step=4.010, train_loss_epoch=4.010]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 21.16it/s, v_num=17878, train_loss_step=4.090, train_loss_epoch=4.090]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.02it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.65it/s, v_num=17880, train_loss_step=4.150, train_loss_epoch=4.150]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 20.09it/s, v_num=17882, train_loss_step=4.250, train_loss_epoch=4.250]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 205.40it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 20.26it/s, v_num=17884, train_loss_step=3.750, train_loss_epoch=3.750]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 117.45it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.95it/s, v_num=17886, train_loss_step=3.660, train_loss_epoch=3.660]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 124.47it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 21.34it/s, v_num=17888, train_loss_step=4.100, train_loss_epoch=4.100]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 94.87it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 21.67it/s, v_num=17890, train_loss_step=3.960, train_loss_epoch=3.960]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 96.95it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 21.86it/s, v_num=17892, train_loss_step=3.610, train_loss_epoch=3.610]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.02it/s, v_num=17894, train_loss_step=3.570, train_loss_epoch=3.570]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.78it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 31.82it/s, v_num=17896, train_loss_step=3.510, train_loss_epoch=3.510]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 68.94it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s, v_num=17898, train_loss_step=3.740, train_loss_epoch=3.740]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 148.08it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 20.26it/s, v_num=17900, train_loss_step=3.790, train_loss_epoch=3.790]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 149.41it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.06it/s, v_num=17902, train_loss_step=3.500, train_loss_epoch=3.500]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 120.61it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 20.55it/s, v_num=17904, train_loss_step=3.440, train_loss_epoch=3.440]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 79.97it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 21.76it/s, v_num=17906, train_loss_step=3.500, train_loss_epoch=3.500]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 89.97it/s] \n"
     ]
    }
   ],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "prefix = \"NFLX\"\n",
    "# modes = ['financial', 'news', 'financial_and_news']\n",
    "# model_types = ['NBEATS', 'NHITS', 'TFT']\n",
    "# final_columns = [\n",
    "#     ['norm_rsi_gspc_14', 'norm_rsi_14', 'norm_slowk_14', 'minmax_high_norm', 'log_return_1'],\n",
    "#     ['finbert_Score', 'bart_Score', 'vader_Score', 'mean_influential', 'mean_trustworthy'],\n",
    "#     ['finbert_Score', 'bart_Score', 'vader_Score', 'mean_influential', 'mean_trustworthy', 'norm_rsi_gspc_14', 'norm_rsi_14', 'norm_slowk_14', 'minmax_high_norm', 'log_return_1']\n",
    "# ]\n",
    "modes = ['financial_and_news']\n",
    "model_types = ['NBEATS']\n",
    "final_columns = [\n",
    "    # ['norm_rsi_gspc_14', 'norm_rsi_14', 'norm_slowk_14', 'minmax_high_norm', 'log_return_1'],\n",
    "    # ['finbert_Score', 'bart_Score', 'vader_Score', 'mean_influential', 'mean_trustworthy'],\n",
    "    ['finbert_Score', 'bart_Score', 'vader_Score', 'mean_influential', 'mean_trustworthy', 'norm_rsi_gspc_14', 'norm_rsi_14', 'norm_slowk_14', 'minmax_high_norm']\n",
    "]\n",
    "train_set_all = pd.read_csv('csv/'+prefix+'/train_set_full.csv')\n",
    "val_set_all = pd.read_csv('csv/'+prefix+'/val_set_full.csv')\n",
    "test_set_all = pd.read_csv('csv/'+prefix+'/test_set_full.csv')\n",
    "horizon = 5\n",
    "# max_steps = [250, 250, 50]\n",
    "max_steps = [20]\n",
    "scaler_type = 'standard'\n",
    "loss_func = f1_score\n",
    "loss=MSE()\n",
    "n_trials = 3\n",
    "random_seed = 1\n",
    "\n",
    "for i, mode in enumerate(modes):\n",
    "    for j, model_type in enumerate(model_types):\n",
    "        print(f'Prefix: {prefix} | mode: {mode} | model_type: {model_type}')\n",
    "        ht = HorizonTrainer(prefix, mode, model_type, final_columns[i], train_set_all, val_set_all, test_set_all, horizon, max_steps[j], scaler_type, loss_func, loss, n_trials, random_seed, timestamp)\n",
    "        ht.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 18:50:47,200] A new study created in memory with name: no-name-b0ae5c61-4516-4c43-b4f1-e31808d2577a\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prefix: NFLX | mode: financial | model_type: NBEATS\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 23.85it/s, v_num=17908, train_loss_step=11.50, train_loss_epoch=11.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 216.84it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 21.49it/s, v_num=17910, train_loss_step=11.50, train_loss_epoch=11.50] \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 319.13it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 20.46it/s, v_num=17912, train_loss_step=11.60, train_loss_epoch=11.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 58.82it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 21.70it/s, v_num=17914, train_loss_step=11.70, train_loss_epoch=11.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 124.84it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.54it/s, v_num=17916, train_loss_step=12.20, train_loss_epoch=12.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 343.46it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.91it/s, v_num=17918, train_loss_step=11.90, train_loss_epoch=11.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 127.32it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.53it/s, v_num=17920, train_loss_step=13.90, train_loss_epoch=13.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 76.90it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.60it/s, v_num=17922, train_loss_step=15.10, train_loss_epoch=15.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 231.03it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.53it/s, v_num=17924, train_loss_step=15.10, train_loss_epoch=15.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 314.65it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 20.33it/s, v_num=17926, train_loss_step=15.00, train_loss_epoch=15.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 299.02it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 21.88it/s, v_num=17928, train_loss_step=13.80, train_loss_epoch=13.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 128.38it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.87it/s, v_num=17930, train_loss_step=13.80, train_loss_epoch=13.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 92.74it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 20.19it/s, v_num=17932, train_loss_step=13.90, train_loss_epoch=13.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 425.47it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 22.75it/s, v_num=17934, train_loss_step=13.70, train_loss_epoch=13.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 306.56it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.98it/s, v_num=17936, train_loss_step=14.10, train_loss_epoch=14.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 153.25it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.30it/s, v_num=17938, train_loss_step=14.60, train_loss_epoch=14.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 289.90it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.85it/s, v_num=17940, train_loss_step=14.30, train_loss_epoch=14.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 192.35it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 21.68it/s, v_num=17942, train_loss_step=15.70, train_loss_epoch=15.70] \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 915.79it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  8.71it/s, v_num=17944, train_loss_step=15.60, train_loss_epoch=15.60] \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 465.10it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.27it/s, v_num=17946, train_loss_step=15.40, train_loss_epoch=15.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 323.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 18:52:02,142] Trial 0 finished with value: 194.2419531465276 and parameters: {'n_blocks_season': 2, 'n_blocks_trend': 1, 'n_blocks_ident': 2, 'mlp_units': 128, 'num_hidden': 1, 'n_harmonics': 4, 'n_polynomials': 4, 'learning_rate': 0.008426316121014377}. Best is trial 0 with value: 194.2419531465276.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.49it/s, v_num=17948, train_loss_step=11.40, train_loss_epoch=11.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 555.17it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.72it/s, v_num=17950, train_loss_step=11.50, train_loss_epoch=11.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 151.99it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.91it/s, v_num=17952, train_loss_step=11.60, train_loss_epoch=11.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 377.59it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.51it/s, v_num=17954, train_loss_step=11.70, train_loss_epoch=11.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 139.17it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.92it/s, v_num=17956, train_loss_step=12.20, train_loss_epoch=12.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 126.98it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.83it/s, v_num=17958, train_loss_step=11.80, train_loss_epoch=11.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 210.93it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.54it/s, v_num=17960, train_loss_step=13.80, train_loss_epoch=13.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.23it/s, v_num=17962, train_loss_step=15.00, train_loss_epoch=15.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.95it/s, v_num=17964, train_loss_step=15.00, train_loss_epoch=15.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 1840.41it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.75it/s, v_num=17966, train_loss_step=14.90, train_loss_epoch=14.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.97it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 20.89it/s, v_num=17968, train_loss_step=13.70, train_loss_epoch=13.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 140.81it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.98it/s, v_num=17970, train_loss_step=13.70, train_loss_epoch=13.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 254.20it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.33it/s, v_num=17972, train_loss_step=13.70, train_loss_epoch=13.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 71.38it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.36it/s, v_num=17974, train_loss_step=13.60, train_loss_epoch=13.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 162.04it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.09it/s, v_num=17976, train_loss_step=14.00, train_loss_epoch=14.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 1974.72it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.66it/s, v_num=17978, train_loss_step=14.40, train_loss_epoch=14.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 219.53it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.02it/s, v_num=17980, train_loss_step=14.20, train_loss_epoch=14.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 259.15it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.71it/s, v_num=17982, train_loss_step=15.70, train_loss_epoch=15.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 411.37it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.54it/s, v_num=17984, train_loss_step=15.60, train_loss_epoch=15.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 95.67it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.06it/s, v_num=17986, train_loss_step=15.40, train_loss_epoch=15.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 60.28it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 18:53:20,399] Trial 1 finished with value: 211.8503047348234 and parameters: {'n_blocks_season': 3, 'n_blocks_trend': 1, 'n_blocks_ident': 3, 'mlp_units': 64, 'num_hidden': 3, 'n_harmonics': 4, 'n_polynomials': 3, 'learning_rate': 0.0022601462359613713}. Best is trial 0 with value: 194.2419531465276.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.81it/s, v_num=17988, train_loss_step=11.40, train_loss_epoch=11.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 92.18it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s, v_num=17990, train_loss_step=11.50, train_loss_epoch=11.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 130.33it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s, v_num=17992, train_loss_step=11.60, train_loss_epoch=11.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 119.02it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.92it/s, v_num=17994, train_loss_step=11.70, train_loss_epoch=11.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 406.70it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.55it/s, v_num=17996, train_loss_step=12.20, train_loss_epoch=12.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 124.82it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.96it/s, v_num=17998, train_loss_step=11.80, train_loss_epoch=11.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.79it/s, v_num=18000, train_loss_step=13.90, train_loss_epoch=13.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 104.26it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.01it/s, v_num=18002, train_loss_step=15.00, train_loss_epoch=15.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 53.41it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.89it/s, v_num=18004, train_loss_step=15.10, train_loss_epoch=15.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 201.88it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.53it/s, v_num=18006, train_loss_step=15.00, train_loss_epoch=15.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 51.43it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.78it/s, v_num=18008, train_loss_step=13.80, train_loss_epoch=13.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 333.84it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.32it/s, v_num=18010, train_loss_step=13.80, train_loss_epoch=13.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.99it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.91it/s, v_num=18012, train_loss_step=13.80, train_loss_epoch=13.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 980.89it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.87it/s, v_num=18014, train_loss_step=13.70, train_loss_epoch=13.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.02it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.33it/s, v_num=18016, train_loss_step=14.00, train_loss_epoch=14.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 115.63it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.01it/s, v_num=18018, train_loss_step=14.50, train_loss_epoch=14.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 59.25it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.84it/s, v_num=18020, train_loss_step=14.30, train_loss_epoch=14.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 70.04it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.09it/s, v_num=18022, train_loss_step=15.80, train_loss_epoch=15.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 49.92it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.16it/s, v_num=18024, train_loss_step=15.70, train_loss_epoch=15.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.67it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.25it/s, v_num=18026, train_loss_step=15.50, train_loss_epoch=15.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 52.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 18:54:42,700] Trial 2 finished with value: 201.60825129922023 and parameters: {'n_blocks_season': 2, 'n_blocks_trend': 3, 'n_blocks_ident': 3, 'mlp_units': 64, 'num_hidden': 2, 'n_harmonics': 5, 'n_polynomials': 3, 'learning_rate': 0.013402187742846093}. Best is trial 0 with value: 194.2419531465276.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.16it/s, v_num=18028, train_loss_step=11.50, train_loss_epoch=11.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 57.26it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.40it/s, v_num=18030, train_loss_step=11.50, train_loss_epoch=11.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.73it/s, v_num=18032, train_loss_step=11.60, train_loss_epoch=11.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 65.52it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.94it/s, v_num=18034, train_loss_step=11.70, train_loss_epoch=11.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 418.80it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.95it/s, v_num=18036, train_loss_step=12.20, train_loss_epoch=12.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 161.63it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.25it/s, v_num=18038, train_loss_step=11.90, train_loss_epoch=11.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.35it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.45it/s, v_num=18040, train_loss_step=13.90, train_loss_epoch=13.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 124.25it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.38it/s, v_num=18042, train_loss_step=15.10, train_loss_epoch=15.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 374.83it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.81it/s, v_num=18044, train_loss_step=15.10, train_loss_epoch=15.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 118.36it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.59it/s, v_num=18046, train_loss_step=15.00, train_loss_epoch=15.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.68it/s, v_num=18048, train_loss_step=13.80, train_loss_epoch=13.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 199.58it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.51it/s, v_num=18050, train_loss_step=13.80, train_loss_epoch=13.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 266.36it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.68it/s, v_num=18052, train_loss_step=13.90, train_loss_epoch=13.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 476.57it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s, v_num=18054, train_loss_step=13.70, train_loss_epoch=13.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.27it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.34it/s, v_num=18056, train_loss_step=14.10, train_loss_epoch=14.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 119.73it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.31it/s, v_num=18058, train_loss_step=14.60, train_loss_epoch=14.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 60.54it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.18it/s, v_num=18060, train_loss_step=14.30, train_loss_epoch=14.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 184.27it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.15it/s, v_num=18062, train_loss_step=15.70, train_loss_epoch=15.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 72.33it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  8.24it/s, v_num=18064, train_loss_step=15.60, train_loss_epoch=15.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 222.51it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.24it/s, v_num=18066, train_loss_step=15.40, train_loss_epoch=15.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 211.91it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.18it/s, v_num=18068, train_loss_step=15.30, train_loss_epoch=15.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.96it/s, v_num=18070, train_loss_step=15.30, train_loss_epoch=15.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 59.82it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.77it/s, v_num=18072, train_loss_step=14.70, train_loss_epoch=14.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.26it/s, v_num=18074, train_loss_step=12.50, train_loss_epoch=12.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 635.40it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.13it/s, v_num=18076, train_loss_step=16.00, train_loss_epoch=16.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 113.48it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.81it/s, v_num=18078, train_loss_step=17.30, train_loss_epoch=17.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.34it/s, v_num=18080, train_loss_step=17.20, train_loss_epoch=17.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 129.93it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.82it/s, v_num=18082, train_loss_step=17.70, train_loss_epoch=17.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 273.80it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.11it/s, v_num=18084, train_loss_step=17.80, train_loss_epoch=17.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 143.40it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.26it/s, v_num=18086, train_loss_step=17.80, train_loss_epoch=17.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 354.37it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.71it/s, v_num=18088, train_loss_step=17.60, train_loss_epoch=17.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 189.50it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.70it/s, v_num=18090, train_loss_step=17.40, train_loss_epoch=17.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 58.46it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.26it/s, v_num=18092, train_loss_step=17.40, train_loss_epoch=17.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 147.07it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.21it/s, v_num=18094, train_loss_step=16.60, train_loss_epoch=16.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 369.41it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.43it/s, v_num=18096, train_loss_step=16.50, train_loss_epoch=16.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 128.13it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.40it/s, v_num=18098, train_loss_step=15.80, train_loss_epoch=15.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 147.35it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.07it/s, v_num=18100, train_loss_step=16.00, train_loss_epoch=16.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 221.86it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.12it/s, v_num=18102, train_loss_step=17.50, train_loss_epoch=17.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.05it/s, v_num=18104, train_loss_step=17.50, train_loss_epoch=17.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 220.81it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.96it/s, v_num=18106, train_loss_step=17.50, train_loss_epoch=17.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 59.58it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.40it/s, v_num=18108, train_loss_step=17.20, train_loss_epoch=17.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 403.49it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  5.48it/s, v_num=18110, train_loss_step=16.80, train_loss_epoch=16.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 123.16it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.24it/s, v_num=18112, train_loss_step=14.30, train_loss_epoch=14.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 130.31it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.28it/s, v_num=18114, train_loss_step=13.40, train_loss_epoch=13.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 69.52it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.82it/s, v_num=18116, train_loss_step=12.20, train_loss_epoch=12.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 121.30it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.20it/s, v_num=18118, train_loss_step=12.20, train_loss_epoch=12.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 800.90it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.05it/s, v_num=18120, train_loss_step=12.90, train_loss_epoch=12.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 402.06it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.54it/s, v_num=18122, train_loss_step=12.70, train_loss_epoch=12.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 277.11it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.55it/s, v_num=18124, train_loss_step=12.90, train_loss_epoch=12.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 228.62it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.44it/s, v_num=18126, train_loss_step=12.60, train_loss_epoch=12.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 71.17it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 18:58:13,707] A new study created in memory with name: no-name-aeabba5e-4d45-4ab2-9bb5-9f7997f1ebaa\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prefix: NFLX | mode: financial | model_type: NHITS\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.87it/s, v_num=18128, train_loss_step=1.06e+4, train_loss_epoch=1.06e+4]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 252.36it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.10it/s, v_num=18130, train_loss_step=6.84e+4, train_loss_epoch=6.84e+4]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 220.42it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.15it/s, v_num=18132, train_loss_step=3.97e+3, train_loss_epoch=3.97e+3]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 130.27it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.36it/s, v_num=18134, train_loss_step=5.96e+3, train_loss_epoch=5.96e+3]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 422.30it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.53it/s, v_num=18136, train_loss_step=1.73e+6, train_loss_epoch=1.73e+6] \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.52it/s, v_num=18138, train_loss_step=8.54e+5, train_loss_epoch=8.54e+5] \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 300.32it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.46it/s, v_num=18140, train_loss_step=3.24e+7, train_loss_epoch=3.24e+7]  \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 102.95it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.78it/s, v_num=18142, train_loss_step=2.94e+6, train_loss_epoch=2.94e+6]  \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 312.63it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s, v_num=18144, train_loss_step=9.69e+5, train_loss_epoch=9.69e+5] \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 139.86it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s, v_num=18146, train_loss_step=2.17e+5, train_loss_epoch=2.17e+5] \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 100.64it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.19it/s, v_num=18148, train_loss_step=6.68e+4, train_loss_epoch=6.68e+4] \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 373.29it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.62it/s, v_num=18150, train_loss_step=2.53e+5, train_loss_epoch=2.53e+5]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 55.91it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.67it/s, v_num=18152, train_loss_step=2.1e+5, train_loss_epoch=2.1e+5]  \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 332.27it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.66it/s, v_num=18154, train_loss_step=1.4e+5, train_loss_epoch=1.4e+5]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.09it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.37it/s, v_num=18156, train_loss_step=8.83e+3, train_loss_epoch=8.83e+3] \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 165.75it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.79it/s, v_num=18158, train_loss_step=1.63e+4, train_loss_epoch=1.63e+4]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 211.42it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.88it/s, v_num=18160, train_loss_step=2.29e+6, train_loss_epoch=2.29e+6] \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 184.05it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.71it/s, v_num=18162, train_loss_step=2.25e+3, train_loss_epoch=2.25e+3]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 136.87it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.02it/s, v_num=18164, train_loss_step=1.31e+4, train_loss_epoch=1.31e+4] \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 239.39it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.39it/s, v_num=18166, train_loss_step=9.1e+4, train_loss_epoch=9.1e+4]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 180.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 18:59:45,417] Trial 0 finished with value: 26993902.360090863 and parameters: {'n_blocks1': 1, 'n_blocks2': 3, 'n_blocks3': 3, 'mlp_units': 64, 'n_pool_kernel_size1': 1, 'n_pool_kernel_size2': 1, 'n_pool_kernel_size3': 1, 'learning_rate': 0.0992325396426077}. Best is trial 0 with value: 26993902.360090863.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.73it/s, v_num=18168, train_loss_step=11.40, train_loss_epoch=11.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 57.01it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.85it/s, v_num=18170, train_loss_step=11.50, train_loss_epoch=11.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 1340.89it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.62it/s, v_num=18172, train_loss_step=11.70, train_loss_epoch=11.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 267.44it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.28it/s, v_num=18174, train_loss_step=11.70, train_loss_epoch=11.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 249.63it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.82it/s, v_num=18176, train_loss_step=12.20, train_loss_epoch=12.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 221.27it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.94it/s, v_num=18178, train_loss_step=11.90, train_loss_epoch=11.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 372.33it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.87it/s, v_num=18180, train_loss_step=13.90, train_loss_epoch=13.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.73it/s, v_num=18182, train_loss_step=15.10, train_loss_epoch=15.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 121.23it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.88it/s, v_num=18184, train_loss_step=15.20, train_loss_epoch=15.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 327.22it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.70it/s, v_num=18186, train_loss_step=15.00, train_loss_epoch=15.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 135.21it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s, v_num=18188, train_loss_step=13.80, train_loss_epoch=13.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 96.77it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.23it/s, v_num=18190, train_loss_step=13.80, train_loss_epoch=13.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 199.66it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.16it/s, v_num=18192, train_loss_step=13.80, train_loss_epoch=13.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 55.41it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.68it/s, v_num=18194, train_loss_step=13.70, train_loss_epoch=13.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 440.58it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  7.66it/s, v_num=18196, train_loss_step=14.10, train_loss_epoch=14.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 72.85it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.77it/s, v_num=18198, train_loss_step=14.50, train_loss_epoch=14.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 111.20it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.87it/s, v_num=18200, train_loss_step=14.40, train_loss_epoch=14.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 80.66it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.00it/s, v_num=18202, train_loss_step=15.80, train_loss_epoch=15.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 505.03it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.00it/s, v_num=18204, train_loss_step=15.80, train_loss_epoch=15.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 304.93it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.66it/s, v_num=18206, train_loss_step=15.50, train_loss_epoch=15.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 395.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 19:01:19,308] Trial 1 finished with value: 210.15182122299453 and parameters: {'n_blocks1': 1, 'n_blocks2': 3, 'n_blocks3': 1, 'mlp_units': 128, 'n_pool_kernel_size1': 2, 'n_pool_kernel_size2': 3, 'n_pool_kernel_size3': 1, 'learning_rate': 0.0001141473913068866}. Best is trial 1 with value: 210.15182122299453.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.01it/s, v_num=18208, train_loss_step=11.60, train_loss_epoch=11.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 158.23it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.60it/s, v_num=18210, train_loss_step=11.70, train_loss_epoch=11.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 451.63it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.14it/s, v_num=18212, train_loss_step=11.80, train_loss_epoch=11.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.08it/s, v_num=18214, train_loss_step=11.90, train_loss_epoch=11.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 86.91it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.40it/s, v_num=18216, train_loss_step=12.40, train_loss_epoch=12.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 156.98it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.19it/s, v_num=18218, train_loss_step=12.00, train_loss_epoch=12.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 199.87it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.61it/s, v_num=18220, train_loss_step=14.00, train_loss_epoch=14.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 107.00it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.64it/s, v_num=18222, train_loss_step=15.20, train_loss_epoch=15.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 152.82it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.03it/s, v_num=18224, train_loss_step=15.30, train_loss_epoch=15.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 163.38it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.67it/s, v_num=18226, train_loss_step=15.20, train_loss_epoch=15.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 297.81it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.59it/s, v_num=18228, train_loss_step=14.00, train_loss_epoch=14.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.74it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.32it/s, v_num=18230, train_loss_step=13.90, train_loss_epoch=13.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 94.30it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.43it/s, v_num=18232, train_loss_step=13.90, train_loss_epoch=13.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 133.92it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.86it/s, v_num=18234, train_loss_step=13.80, train_loss_epoch=13.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.88it/s, v_num=18236, train_loss_step=14.20, train_loss_epoch=14.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.34it/s, v_num=18238, train_loss_step=14.60, train_loss_epoch=14.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 143.73it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.01it/s, v_num=18240, train_loss_step=14.50, train_loss_epoch=14.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 117.11it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s, v_num=18242, train_loss_step=16.00, train_loss_epoch=16.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 269.64it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.23it/s, v_num=18244, train_loss_step=15.90, train_loss_epoch=15.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 329.66it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.27it/s, v_num=18246, train_loss_step=15.70, train_loss_epoch=15.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 72.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 19:02:47,972] Trial 2 finished with value: 219.97926820381548 and parameters: {'n_blocks1': 2, 'n_blocks2': 1, 'n_blocks3': 2, 'mlp_units': 64, 'n_pool_kernel_size1': 1, 'n_pool_kernel_size2': 3, 'n_pool_kernel_size3': 2, 'learning_rate': 2.369216133726877e-05}. Best is trial 1 with value: 210.15182122299453.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.12it/s, v_num=18248, train_loss_step=11.40, train_loss_epoch=11.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 149.55it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.03it/s, v_num=18250, train_loss_step=11.50, train_loss_epoch=11.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.73it/s, v_num=18252, train_loss_step=11.70, train_loss_epoch=11.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 82.87it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.58it/s, v_num=18254, train_loss_step=11.70, train_loss_epoch=11.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 104.98it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.86it/s, v_num=18256, train_loss_step=12.20, train_loss_epoch=12.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 99.63it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.51it/s, v_num=18258, train_loss_step=11.90, train_loss_epoch=11.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 188.97it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  8.13it/s, v_num=18260, train_loss_step=13.90, train_loss_epoch=13.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 195.71it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.61it/s, v_num=18262, train_loss_step=15.10, train_loss_epoch=15.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 304.69it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.90it/s, v_num=18264, train_loss_step=15.20, train_loss_epoch=15.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 254.97it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.74it/s, v_num=18266, train_loss_step=15.00, train_loss_epoch=15.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s, v_num=18268, train_loss_step=13.80, train_loss_epoch=13.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 189.02it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.25it/s, v_num=18270, train_loss_step=13.80, train_loss_epoch=13.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 385.75it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.79it/s, v_num=18272, train_loss_step=13.80, train_loss_epoch=13.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 156.94it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.37it/s, v_num=18274, train_loss_step=13.70, train_loss_epoch=13.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 73.36it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.83it/s, v_num=18276, train_loss_step=14.10, train_loss_epoch=14.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 183.86it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.45it/s, v_num=18278, train_loss_step=14.50, train_loss_epoch=14.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 127.10it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.10it/s, v_num=18280, train_loss_step=14.40, train_loss_epoch=14.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 434.60it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.52it/s, v_num=18282, train_loss_step=15.80, train_loss_epoch=15.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 73.19it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.74it/s, v_num=18284, train_loss_step=15.80, train_loss_epoch=15.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 226.55it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.81it/s, v_num=18286, train_loss_step=15.50, train_loss_epoch=15.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 613.83it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.51it/s, v_num=18288, train_loss_step=15.40, train_loss_epoch=15.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 139.29it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.08it/s, v_num=18290, train_loss_step=15.40, train_loss_epoch=15.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 940.22it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.43it/s, v_num=18292, train_loss_step=14.90, train_loss_epoch=14.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 388.25it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.05it/s, v_num=18294, train_loss_step=12.60, train_loss_epoch=12.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 174.30it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.36it/s, v_num=18296, train_loss_step=16.10, train_loss_epoch=16.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 349.61it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.08it/s, v_num=18298, train_loss_step=17.40, train_loss_epoch=17.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 356.99it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.20it/s, v_num=18300, train_loss_step=17.30, train_loss_epoch=17.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 70.96it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.82it/s, v_num=18302, train_loss_step=17.70, train_loss_epoch=17.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 31.93it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.50it/s, v_num=18304, train_loss_step=17.90, train_loss_epoch=17.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 420.27it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.01it/s, v_num=18306, train_loss_step=17.90, train_loss_epoch=17.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.36it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  8.99it/s, v_num=18308, train_loss_step=17.70, train_loss_epoch=17.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 412.91it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.69it/s, v_num=18310, train_loss_step=17.50, train_loss_epoch=17.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 154.77it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.55it/s, v_num=18312, train_loss_step=17.40, train_loss_epoch=17.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 106.02it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s, v_num=18314, train_loss_step=16.60, train_loss_epoch=16.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 164.59it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.33it/s, v_num=18316, train_loss_step=16.40, train_loss_epoch=16.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 373.99it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.23it/s, v_num=18318, train_loss_step=15.80, train_loss_epoch=15.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 232.38it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.41it/s, v_num=18320, train_loss_step=15.90, train_loss_epoch=15.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 297.57it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.81it/s, v_num=18322, train_loss_step=17.30, train_loss_epoch=17.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 220.25it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.88it/s, v_num=18324, train_loss_step=17.30, train_loss_epoch=17.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 181.93it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.77it/s, v_num=18326, train_loss_step=17.30, train_loss_epoch=17.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 111.25it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.94it/s, v_num=18328, train_loss_step=17.00, train_loss_epoch=17.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 260.76it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.13it/s, v_num=18330, train_loss_step=16.70, train_loss_epoch=16.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 283.11it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.31it/s, v_num=18332, train_loss_step=14.20, train_loss_epoch=14.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 171.81it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.38it/s, v_num=18334, train_loss_step=13.30, train_loss_epoch=13.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 333.33it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.70it/s, v_num=18336, train_loss_step=12.20, train_loss_epoch=12.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 65.68it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.09it/s, v_num=18338, train_loss_step=12.20, train_loss_epoch=12.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 70.07it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.39it/s, v_num=18340, train_loss_step=12.80, train_loss_epoch=12.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 168.18it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.73it/s, v_num=18342, train_loss_step=12.60, train_loss_epoch=12.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 332.35it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.65it/s, v_num=18344, train_loss_step=12.80, train_loss_epoch=12.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 186.07it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.59it/s, v_num=18346, train_loss_step=12.50, train_loss_epoch=12.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 634.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 19:06:51,401] A new study created in memory with name: no-name-bc9d404e-4fb7-4d3d-a070-1ba65012025f\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prefix: NFLX | mode: financial | model_type: TFT\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.23it/s, v_num=18348, train_loss_step=18.10, train_loss_epoch=18.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 37.52it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.37it/s, v_num=18350, train_loss_step=15.90, train_loss_epoch=15.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 95.47it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=18352, train_loss_step=16.00, train_loss_epoch=16.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 272.48it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.29it/s, v_num=18354, train_loss_step=15.90, train_loss_epoch=15.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 191.92it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=18356, train_loss_step=16.10, train_loss_epoch=16.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 484.27it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.02it/s, v_num=18358, train_loss_step=13.60, train_loss_epoch=13.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 48.59it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.96it/s, v_num=18360, train_loss_step=13.70, train_loss_epoch=13.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 121.04it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.94it/s, v_num=18362, train_loss_step=14.10, train_loss_epoch=14.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.37it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.83it/s, v_num=18364, train_loss_step=14.00, train_loss_epoch=14.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 82.54it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.52it/s, v_num=18366, train_loss_step=13.70, train_loss_epoch=13.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 369.15it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.93it/s, v_num=18368, train_loss_step=13.30, train_loss_epoch=13.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.36it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.29it/s, v_num=18370, train_loss_step=13.40, train_loss_epoch=13.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 130.23it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.07it/s, v_num=18372, train_loss_step=12.70, train_loss_epoch=12.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 139.59it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=18374, train_loss_step=12.80, train_loss_epoch=12.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 205.59it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.22it/s, v_num=18376, train_loss_step=12.90, train_loss_epoch=12.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 261.33it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=18378, train_loss_step=13.00, train_loss_epoch=13.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 203.73it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.01it/s, v_num=18380, train_loss_step=12.00, train_loss_epoch=12.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.17it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.20it/s, v_num=18382, train_loss_step=14.30, train_loss_epoch=14.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 487.31it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.04it/s, v_num=18384, train_loss_step=14.20, train_loss_epoch=14.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 141.38it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s, v_num=18386, train_loss_step=14.30, train_loss_epoch=14.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 340.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 19:08:37,332] Trial 0 finished with value: 215.57388961412948 and parameters: {'learning_rate': 0.00021878728762492227, 'hidden_size': 32}. Best is trial 0 with value: 215.57388961412948.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=18388, train_loss_step=18.50, train_loss_epoch=18.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 985.50it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.81it/s, v_num=18390, train_loss_step=16.20, train_loss_epoch=16.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 54.10it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=18392, train_loss_step=16.30, train_loss_epoch=16.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 57.94it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=18394, train_loss_step=16.30, train_loss_epoch=16.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 225.21it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.82it/s, v_num=18396, train_loss_step=16.50, train_loss_epoch=16.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 288.15it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.49it/s, v_num=18398, train_loss_step=13.90, train_loss_epoch=13.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 102.09it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=18400, train_loss_step=14.00, train_loss_epoch=14.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 135.78it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.33it/s, v_num=18402, train_loss_step=14.40, train_loss_epoch=14.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 105.67it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.95it/s, v_num=18404, train_loss_step=14.30, train_loss_epoch=14.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.34it/s, v_num=18406, train_loss_step=14.00, train_loss_epoch=14.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 136.85it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.33it/s, v_num=18408, train_loss_step=13.60, train_loss_epoch=13.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 121.29it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.84it/s, v_num=18410, train_loss_step=13.60, train_loss_epoch=13.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 353.20it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.98it/s, v_num=18412, train_loss_step=13.00, train_loss_epoch=13.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 194.32it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=18414, train_loss_step=13.10, train_loss_epoch=13.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 78.05it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.85it/s, v_num=18416, train_loss_step=13.10, train_loss_epoch=13.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 74.28it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.33it/s, v_num=18418, train_loss_step=13.30, train_loss_epoch=13.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 95.13it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=18420, train_loss_step=12.30, train_loss_epoch=12.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 243.05it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.05it/s, v_num=18422, train_loss_step=14.70, train_loss_epoch=14.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 180.41it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.85it/s, v_num=18424, train_loss_step=14.60, train_loss_epoch=14.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 88.37it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.24it/s, v_num=18426, train_loss_step=14.70, train_loss_epoch=14.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 145.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 19:10:23,167] Trial 1 finished with value: 192.02604594586893 and parameters: {'learning_rate': 0.0010841668464641855, 'hidden_size': 28}. Best is trial 1 with value: 192.02604594586893.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.10it/s, v_num=18428, train_loss_step=18.00, train_loss_epoch=18.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 112.86it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.09it/s, v_num=18430, train_loss_step=15.70, train_loss_epoch=15.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 53.75it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.54it/s, v_num=18432, train_loss_step=15.90, train_loss_epoch=15.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 139.48it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.97it/s, v_num=18434, train_loss_step=15.80, train_loss_epoch=15.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 118.34it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s, v_num=18436, train_loss_step=16.00, train_loss_epoch=16.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 984.35it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.92it/s, v_num=18438, train_loss_step=13.50, train_loss_epoch=13.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.35it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s, v_num=18440, train_loss_step=13.60, train_loss_epoch=13.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 165.75it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.29it/s, v_num=18442, train_loss_step=14.10, train_loss_epoch=14.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 151.86it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.70it/s, v_num=18444, train_loss_step=14.00, train_loss_epoch=14.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.51it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.23it/s, v_num=18446, train_loss_step=13.70, train_loss_epoch=13.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 107.95it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.46it/s, v_num=18448, train_loss_step=13.30, train_loss_epoch=13.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 152.99it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.48it/s, v_num=18450, train_loss_step=13.40, train_loss_epoch=13.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.23it/s, v_num=18452, train_loss_step=12.70, train_loss_epoch=12.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 136.90it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.31it/s, v_num=18454, train_loss_step=12.80, train_loss_epoch=12.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 70.08it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.55it/s, v_num=18456, train_loss_step=12.80, train_loss_epoch=12.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 50.64it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.70it/s, v_num=18458, train_loss_step=12.90, train_loss_epoch=12.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 164.07it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.19it/s, v_num=18460, train_loss_step=11.90, train_loss_epoch=11.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 98.62it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.81it/s, v_num=18462, train_loss_step=14.20, train_loss_epoch=14.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 65.97it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.80it/s, v_num=18464, train_loss_step=14.20, train_loss_epoch=14.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 32.76it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.19it/s, v_num=18466, train_loss_step=14.20, train_loss_epoch=14.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 19:12:06,465] Trial 2 finished with value: 244.81195039455787 and parameters: {'learning_rate': 0.021784972978666824, 'hidden_size': 24}. Best is trial 1 with value: 192.02604594586893.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=18468, train_loss_step=18.50, train_loss_epoch=18.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 61.99it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.25it/s, v_num=18470, train_loss_step=16.20, train_loss_epoch=16.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 271.79it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.65it/s, v_num=18472, train_loss_step=16.30, train_loss_epoch=16.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 100.27it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=18474, train_loss_step=16.30, train_loss_epoch=16.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 198.81it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=18476, train_loss_step=16.50, train_loss_epoch=16.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 60.25it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.00it/s, v_num=18478, train_loss_step=13.90, train_loss_epoch=13.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 931.03it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=18480, train_loss_step=14.00, train_loss_epoch=14.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 69.88it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.05it/s, v_num=18482, train_loss_step=14.40, train_loss_epoch=14.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 109.33it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.36it/s, v_num=18484, train_loss_step=14.30, train_loss_epoch=14.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 60.89it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.31it/s, v_num=18486, train_loss_step=14.00, train_loss_epoch=14.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 47.32it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.18it/s, v_num=18488, train_loss_step=13.60, train_loss_epoch=13.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 45.97it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.69it/s, v_num=18490, train_loss_step=13.60, train_loss_epoch=13.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 176.43it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.69it/s, v_num=18492, train_loss_step=13.00, train_loss_epoch=13.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 143.79it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.69it/s, v_num=18494, train_loss_step=13.10, train_loss_epoch=13.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.90it/s, v_num=18496, train_loss_step=13.10, train_loss_epoch=13.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.71it/s, v_num=18498, train_loss_step=13.30, train_loss_epoch=13.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 324.59it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.89it/s, v_num=18500, train_loss_step=12.30, train_loss_epoch=12.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 107.36it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.09it/s, v_num=18502, train_loss_step=14.70, train_loss_epoch=14.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 224.47it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.45it/s, v_num=18504, train_loss_step=14.60, train_loss_epoch=14.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 165.53it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=18506, train_loss_step=14.70, train_loss_epoch=14.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 140.45it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.53it/s, v_num=18508, train_loss_step=14.60, train_loss_epoch=14.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 76.66it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.24it/s, v_num=18510, train_loss_step=14.80, train_loss_epoch=14.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 339.18it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.80it/s, v_num=18512, train_loss_step=14.70, train_loss_epoch=14.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 123.66it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.74it/s, v_num=18514, train_loss_step=14.80, train_loss_epoch=14.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 181.10it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.98it/s, v_num=18516, train_loss_step=13.80, train_loss_epoch=13.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 65.56it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.65it/s, v_num=18518, train_loss_step=14.30, train_loss_epoch=14.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 114.63it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.51it/s, v_num=18520, train_loss_step=13.40, train_loss_epoch=13.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 228.25it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.56it/s, v_num=18522, train_loss_step=13.20, train_loss_epoch=13.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 143.06it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.99it/s, v_num=18524, train_loss_step=13.20, train_loss_epoch=13.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 248.05it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s, v_num=18526, train_loss_step=13.10, train_loss_epoch=13.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.82it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.31it/s, v_num=18528, train_loss_step=13.40, train_loss_epoch=13.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 348.57it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.22it/s, v_num=18530, train_loss_step=13.60, train_loss_epoch=13.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 291.43it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.44it/s, v_num=18532, train_loss_step=13.90, train_loss_epoch=13.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 262.95it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=18534, train_loss_step=14.40, train_loss_epoch=14.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.23it/s, v_num=18536, train_loss_step=14.40, train_loss_epoch=14.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 458.59it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.38it/s, v_num=18538, train_loss_step=14.70, train_loss_epoch=14.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 315.43it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.50it/s, v_num=18540, train_loss_step=14.80, train_loss_epoch=14.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 206.19it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.18it/s, v_num=18542, train_loss_step=15.00, train_loss_epoch=15.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 128.43it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.93it/s, v_num=18544, train_loss_step=16.10, train_loss_epoch=16.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 285.40it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.66it/s, v_num=18546, train_loss_step=16.30, train_loss_epoch=16.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 225.89it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=18548, train_loss_step=16.10, train_loss_epoch=16.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 223.14it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.96it/s, v_num=18550, train_loss_step=15.90, train_loss_epoch=15.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 83.44it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.64it/s, v_num=18552, train_loss_step=15.90, train_loss_epoch=15.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 431.07it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=18554, train_loss_step=15.90, train_loss_epoch=15.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 300.32it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.37it/s, v_num=18556, train_loss_step=15.30, train_loss_epoch=15.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 196.84it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.72it/s, v_num=18558, train_loss_step=15.60, train_loss_epoch=15.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 236.42it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.20it/s, v_num=18560, train_loss_step=15.90, train_loss_epoch=15.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 125.79it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=18562, train_loss_step=15.80, train_loss_epoch=15.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 125.29it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.59it/s, v_num=18564, train_loss_step=15.70, train_loss_epoch=15.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.96it/s, v_num=18566, train_loss_step=15.80, train_loss_epoch=15.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 76.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 19:16:18,605] A new study created in memory with name: no-name-4e0ed8ff-6957-44c2-b8fe-8b67fcd8b890\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prefix: NFLX | mode: news | model_type: NBEATS\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.88it/s, v_num=18568, train_loss_step=11.60, train_loss_epoch=11.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 114.40it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.20it/s, v_num=18570, train_loss_step=11.70, train_loss_epoch=11.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 117.40it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.88it/s, v_num=18572, train_loss_step=11.80, train_loss_epoch=11.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 49.27it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s, v_num=18574, train_loss_step=11.90, train_loss_epoch=11.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 220.64it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.95it/s, v_num=18576, train_loss_step=12.40, train_loss_epoch=12.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.76it/s, v_num=18578, train_loss_step=12.00, train_loss_epoch=12.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 65.34it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.07it/s, v_num=18580, train_loss_step=14.00, train_loss_epoch=14.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 347.41it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.97it/s, v_num=18582, train_loss_step=15.20, train_loss_epoch=15.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 211.08it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.09it/s, v_num=18584, train_loss_step=15.30, train_loss_epoch=15.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 369.77it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.68it/s, v_num=18586, train_loss_step=15.10, train_loss_epoch=15.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.02it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.17it/s, v_num=18588, train_loss_step=13.90, train_loss_epoch=13.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 161.57it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.93it/s, v_num=18590, train_loss_step=14.00, train_loss_epoch=14.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.99it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.17it/s, v_num=18592, train_loss_step=14.00, train_loss_epoch=14.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.62it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.18it/s, v_num=18594, train_loss_step=13.90, train_loss_epoch=13.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 308.84it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.14it/s, v_num=18596, train_loss_step=14.30, train_loss_epoch=14.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 320.44it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.27it/s, v_num=18598, train_loss_step=14.70, train_loss_epoch=14.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 174.67it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.23it/s, v_num=18600, train_loss_step=14.50, train_loss_epoch=14.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 309.00it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.74it/s, v_num=18602, train_loss_step=16.00, train_loss_epoch=16.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 130.12it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.97it/s, v_num=18604, train_loss_step=15.90, train_loss_epoch=15.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 140.46it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.71it/s, v_num=18606, train_loss_step=15.70, train_loss_epoch=15.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 241.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 19:17:41,623] Trial 0 finished with value: 225.04895174077245 and parameters: {'n_blocks_season': 3, 'n_blocks_trend': 1, 'n_blocks_ident': 2, 'mlp_units': 128, 'num_hidden': 1, 'n_harmonics': 2, 'n_polynomials': 5, 'learning_rate': 1.644909866812828e-05}. Best is trial 0 with value: 225.04895174077245.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.50it/s, v_num=18608, train_loss_step=11.30, train_loss_epoch=11.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 359.69it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 24.20it/s, v_num=18610, train_loss_step=11.50, train_loss_epoch=11.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 295.94it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.27it/s, v_num=18612, train_loss_step=11.70, train_loss_epoch=11.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 163.04it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 22.50it/s, v_num=18614, train_loss_step=11.70, train_loss_epoch=11.70] \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.05it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.98it/s, v_num=18616, train_loss_step=12.30, train_loss_epoch=12.30] \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 328.27it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.16it/s, v_num=18618, train_loss_step=11.90, train_loss_epoch=11.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 59.77it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 23.91it/s, v_num=18620, train_loss_step=13.90, train_loss_epoch=13.90] \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 185.47it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 21.72it/s, v_num=18622, train_loss_step=15.10, train_loss_epoch=15.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 66.01it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 23.38it/s, v_num=18624, train_loss_step=15.20, train_loss_epoch=15.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 185.24it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.67it/s, v_num=18626, train_loss_step=15.10, train_loss_epoch=15.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.62it/s, v_num=18628, train_loss_step=13.80, train_loss_epoch=13.80] \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 26.66it/s, v_num=18630, train_loss_step=13.90, train_loss_epoch=13.90] \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 54.86it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.45it/s, v_num=18632, train_loss_step=13.90, train_loss_epoch=13.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 86.56it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.25it/s, v_num=18634, train_loss_step=13.70, train_loss_epoch=13.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 151.46it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.14it/s, v_num=18636, train_loss_step=14.10, train_loss_epoch=14.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 77.07it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.65it/s, v_num=18638, train_loss_step=14.50, train_loss_epoch=14.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 59.99it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 21.45it/s, v_num=18640, train_loss_step=14.30, train_loss_epoch=14.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 132.10it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 21.89it/s, v_num=18642, train_loss_step=15.80, train_loss_epoch=15.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 144.20it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 20.16it/s, v_num=18644, train_loss_step=15.80, train_loss_epoch=15.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 70.80it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 23.30it/s, v_num=18646, train_loss_step=15.50, train_loss_epoch=15.50] \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 274.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 19:18:59,247] Trial 1 finished with value: 201.91415765238935 and parameters: {'n_blocks_season': 1, 'n_blocks_trend': 1, 'n_blocks_ident': 1, 'mlp_units': 32, 'num_hidden': 3, 'n_harmonics': 3, 'n_polynomials': 1, 'learning_rate': 0.06732296052575899}. Best is trial 1 with value: 201.91415765238935.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.45it/s, v_num=18648, train_loss_step=11.50, train_loss_epoch=11.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 99.78it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.64it/s, v_num=18650, train_loss_step=11.60, train_loss_epoch=11.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 253.16it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.05it/s, v_num=18652, train_loss_step=11.80, train_loss_epoch=11.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 68.61it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.16it/s, v_num=18654, train_loss_step=11.80, train_loss_epoch=11.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 570.27it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.58it/s, v_num=18656, train_loss_step=12.30, train_loss_epoch=12.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 284.88it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.60it/s, v_num=18658, train_loss_step=12.00, train_loss_epoch=12.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 194.57it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 20.61it/s, v_num=18660, train_loss_step=14.00, train_loss_epoch=14.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 446.54it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.30it/s, v_num=18662, train_loss_step=15.20, train_loss_epoch=15.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 152.53it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 21.14it/s, v_num=18664, train_loss_step=15.30, train_loss_epoch=15.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 324.41it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.13it/s, v_num=18666, train_loss_step=15.10, train_loss_epoch=15.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 71.93it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.35it/s, v_num=18668, train_loss_step=13.90, train_loss_epoch=13.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 348.65it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.05it/s, v_num=18670, train_loss_step=13.90, train_loss_epoch=13.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 267.53it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.75it/s, v_num=18672, train_loss_step=13.90, train_loss_epoch=13.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 393.43it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.82it/s, v_num=18674, train_loss_step=13.80, train_loss_epoch=13.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 178.73it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.22it/s, v_num=18676, train_loss_step=14.20, train_loss_epoch=14.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 385.68it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.24it/s, v_num=18678, train_loss_step=14.60, train_loss_epoch=14.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 67.44it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.81it/s, v_num=18680, train_loss_step=14.40, train_loss_epoch=14.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 168.29it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s, v_num=18682, train_loss_step=15.90, train_loss_epoch=15.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 178.07it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.41it/s, v_num=18684, train_loss_step=15.90, train_loss_epoch=15.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 150.31it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.90it/s, v_num=18686, train_loss_step=15.60, train_loss_epoch=15.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 135.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 19:20:19,786] Trial 2 finished with value: 214.17119077197285 and parameters: {'n_blocks_season': 1, 'n_blocks_trend': 1, 'n_blocks_ident': 2, 'mlp_units': 64, 'num_hidden': 3, 'n_harmonics': 3, 'n_polynomials': 3, 'learning_rate': 0.00011302520294374461}. Best is trial 1 with value: 201.91415765238935.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.02it/s, v_num=18688, train_loss_step=11.30, train_loss_epoch=11.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 342.67it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 20.63it/s, v_num=18690, train_loss_step=11.50, train_loss_epoch=11.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 354.88it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 24.97it/s, v_num=18692, train_loss_step=11.70, train_loss_epoch=11.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 208.14it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.10it/s, v_num=18694, train_loss_step=11.70, train_loss_epoch=11.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 367.92it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 20.06it/s, v_num=18696, train_loss_step=12.30, train_loss_epoch=12.30] \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 218.43it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.50it/s, v_num=18698, train_loss_step=11.90, train_loss_epoch=11.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 146.07it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 21.27it/s, v_num=18700, train_loss_step=13.90, train_loss_epoch=13.90] \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 147.06it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 22.54it/s, v_num=18702, train_loss_step=15.10, train_loss_epoch=15.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 131.49it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.99it/s, v_num=18704, train_loss_step=15.20, train_loss_epoch=15.20] \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 21.92it/s, v_num=18706, train_loss_step=15.10, train_loss_epoch=15.10] \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 20.24it/s, v_num=18708, train_loss_step=13.80, train_loss_epoch=13.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 22.73it/s, v_num=18710, train_loss_step=13.90, train_loss_epoch=13.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 127.98it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 23.48it/s, v_num=18712, train_loss_step=13.90, train_loss_epoch=13.90] \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 122.83it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.04it/s, v_num=18714, train_loss_step=13.70, train_loss_epoch=13.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 162.99it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 22.10it/s, v_num=18716, train_loss_step=14.10, train_loss_epoch=14.10] \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 148.54it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.56it/s, v_num=18718, train_loss_step=14.50, train_loss_epoch=14.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.98it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 22.31it/s, v_num=18720, train_loss_step=14.30, train_loss_epoch=14.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 292.90it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.31it/s, v_num=18722, train_loss_step=15.80, train_loss_epoch=15.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 74.04it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.71it/s, v_num=18724, train_loss_step=15.80, train_loss_epoch=15.80] \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 239.87it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.25it/s, v_num=18726, train_loss_step=15.50, train_loss_epoch=15.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 236.15it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 22.99it/s, v_num=18728, train_loss_step=15.30, train_loss_epoch=15.30] \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 664.92it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.24it/s, v_num=18730, train_loss_step=15.30, train_loss_epoch=15.30] \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 229.21it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.88it/s, v_num=18732, train_loss_step=14.80, train_loss_epoch=14.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 103.07it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.81it/s, v_num=18734, train_loss_step=12.50, train_loss_epoch=12.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 79.58it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 21.09it/s, v_num=18736, train_loss_step=16.00, train_loss_epoch=16.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 175.15it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 20.29it/s, v_num=18738, train_loss_step=17.30, train_loss_epoch=17.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 229.64it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 20.20it/s, v_num=18740, train_loss_step=17.20, train_loss_epoch=17.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 568.80it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.34it/s, v_num=18742, train_loss_step=17.70, train_loss_epoch=17.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 394.35it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 22.57it/s, v_num=18744, train_loss_step=17.80, train_loss_epoch=17.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 61.81it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.27it/s, v_num=18746, train_loss_step=17.90, train_loss_epoch=17.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 154.30it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.27it/s, v_num=18748, train_loss_step=17.70, train_loss_epoch=17.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 134.80it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.27it/s, v_num=18750, train_loss_step=17.50, train_loss_epoch=17.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 68.95it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.62it/s, v_num=18752, train_loss_step=17.30, train_loss_epoch=17.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 70.51it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.92it/s, v_num=18754, train_loss_step=16.60, train_loss_epoch=16.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 97.16it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.00it/s, v_num=18756, train_loss_step=16.50, train_loss_epoch=16.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 382.34it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.41it/s, v_num=18758, train_loss_step=15.80, train_loss_epoch=15.80] \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 93.10it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 21.64it/s, v_num=18760, train_loss_step=16.00, train_loss_epoch=16.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 164.05it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.95it/s, v_num=18762, train_loss_step=17.40, train_loss_epoch=17.40] \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 699.87it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.00it/s, v_num=18764, train_loss_step=17.40, train_loss_epoch=17.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 158.69it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.70it/s, v_num=18766, train_loss_step=17.30, train_loss_epoch=17.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 196.99it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 22.61it/s, v_num=18768, train_loss_step=17.10, train_loss_epoch=17.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 153.28it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.79it/s, v_num=18770, train_loss_step=16.70, train_loss_epoch=16.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 147.73it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 22.26it/s, v_num=18772, train_loss_step=14.30, train_loss_epoch=14.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.30it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 21.01it/s, v_num=18774, train_loss_step=13.40, train_loss_epoch=13.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 120.93it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 21.80it/s, v_num=18776, train_loss_step=12.10, train_loss_epoch=12.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 166.32it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 21.70it/s, v_num=18778, train_loss_step=12.20, train_loss_epoch=12.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 314.44it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 21.64it/s, v_num=18780, train_loss_step=12.80, train_loss_epoch=12.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 525.21it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.25it/s, v_num=18782, train_loss_step=12.60, train_loss_epoch=12.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 120.35it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 21.75it/s, v_num=18784, train_loss_step=12.90, train_loss_epoch=12.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 258.52it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 20.62it/s, v_num=18786, train_loss_step=12.60, train_loss_epoch=12.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 19:23:33,202] A new study created in memory with name: no-name-437760fe-d164-42a7-be71-3818642b7c2e\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prefix: NFLX | mode: news | model_type: NHITS\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.28it/s, v_num=18788, train_loss_step=10.20, train_loss_epoch=10.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 110.92it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  8.52it/s, v_num=18790, train_loss_step=10.50, train_loss_epoch=10.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.17it/s, v_num=18792, train_loss_step=10.50, train_loss_epoch=10.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 380.75it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.70it/s, v_num=18794, train_loss_step=10.60, train_loss_epoch=10.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 98.31it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.02it/s, v_num=18796, train_loss_step=10.90, train_loss_epoch=10.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.01it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.33it/s, v_num=18798, train_loss_step=10.60, train_loss_epoch=10.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 97.34it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  7.17it/s, v_num=18800, train_loss_step=12.50, train_loss_epoch=12.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 485.40it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.23it/s, v_num=18802, train_loss_step=13.50, train_loss_epoch=13.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 133.14it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  8.76it/s, v_num=18804, train_loss_step=13.50, train_loss_epoch=13.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 139.63it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.18it/s, v_num=18806, train_loss_step=13.40, train_loss_epoch=13.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 242.01it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  8.41it/s, v_num=18808, train_loss_step=12.50, train_loss_epoch=12.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 105.26it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  8.92it/s, v_num=18810, train_loss_step=12.50, train_loss_epoch=12.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 49.53it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  8.96it/s, v_num=18812, train_loss_step=12.60, train_loss_epoch=12.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 330.83it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.08it/s, v_num=18814, train_loss_step=12.50, train_loss_epoch=12.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 416.56it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.57it/s, v_num=18816, train_loss_step=12.80, train_loss_epoch=12.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 107.04it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.66it/s, v_num=18818, train_loss_step=13.30, train_loss_epoch=13.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 210.49it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.59it/s, v_num=18820, train_loss_step=13.20, train_loss_epoch=13.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.18it/s, v_num=18822, train_loss_step=14.40, train_loss_epoch=14.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 91.93it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.41it/s, v_num=18824, train_loss_step=14.40, train_loss_epoch=14.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 225.09it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.14it/s, v_num=18826, train_loss_step=14.20, train_loss_epoch=14.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 130.78it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 19:25:14,899] Trial 0 finished with value: 147.49607371548205 and parameters: {'n_blocks1': 3, 'n_blocks2': 3, 'n_blocks3': 2, 'mlp_units': 128, 'n_pool_kernel_size1': 2, 'n_pool_kernel_size2': 2, 'n_pool_kernel_size3': 1, 'learning_rate': 0.0025149677929521413}. Best is trial 0 with value: 147.49607371548205.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.47it/s, v_num=18828, train_loss_step=10.90, train_loss_epoch=10.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 215.80it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.30it/s, v_num=18830, train_loss_step=11.10, train_loss_epoch=11.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 89.92it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.01it/s, v_num=18832, train_loss_step=11.20, train_loss_epoch=11.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.30it/s, v_num=18834, train_loss_step=11.30, train_loss_epoch=11.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 65.58it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.02it/s, v_num=18836, train_loss_step=11.70, train_loss_epoch=11.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.73it/s, v_num=18838, train_loss_step=11.40, train_loss_epoch=11.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 199.71it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.13it/s, v_num=18840, train_loss_step=13.30, train_loss_epoch=13.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 210.48it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.53it/s, v_num=18842, train_loss_step=14.40, train_loss_epoch=14.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.00it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.58it/s, v_num=18844, train_loss_step=14.50, train_loss_epoch=14.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 116.90it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.68it/s, v_num=18846, train_loss_step=14.30, train_loss_epoch=14.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 329.09it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.72it/s, v_num=18848, train_loss_step=13.20, train_loss_epoch=13.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 144.67it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.28it/s, v_num=18850, train_loss_step=13.30, train_loss_epoch=13.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 109.51it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.45it/s, v_num=18852, train_loss_step=13.30, train_loss_epoch=13.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 382.38it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.48it/s, v_num=18854, train_loss_step=13.20, train_loss_epoch=13.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 325.85it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.79it/s, v_num=18856, train_loss_step=13.50, train_loss_epoch=13.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 389.77it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.60it/s, v_num=18858, train_loss_step=14.00, train_loss_epoch=14.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 69.56it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.47it/s, v_num=18860, train_loss_step=13.90, train_loss_epoch=13.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 116.66it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.11it/s, v_num=18862, train_loss_step=15.30, train_loss_epoch=15.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 66.63it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s, v_num=18864, train_loss_step=15.20, train_loss_epoch=15.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.45it/s, v_num=18866, train_loss_step=15.00, train_loss_epoch=15.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 312.82it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 19:26:46,068] Trial 1 finished with value: 192.4982448522235 and parameters: {'n_blocks1': 3, 'n_blocks2': 2, 'n_blocks3': 3, 'mlp_units': 64, 'n_pool_kernel_size1': 2, 'n_pool_kernel_size2': 3, 'n_pool_kernel_size3': 2, 'learning_rate': 0.00285884060237973}. Best is trial 0 with value: 147.49607371548205.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.47it/s, v_num=18868, train_loss_step=11.60, train_loss_epoch=11.60]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 88.65it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.20it/s, v_num=18870, train_loss_step=13.80, train_loss_epoch=13.80]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.80it/s, v_num=18872, train_loss_step=11.90, train_loss_epoch=11.90]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.40it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.87it/s, v_num=18874, train_loss_step=12.30, train_loss_epoch=12.30]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 57.16it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.68it/s, v_num=18876, train_loss_step=12.10, train_loss_epoch=12.10]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 91.55it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.30it/s, v_num=18878, train_loss_step=12.10, train_loss_epoch=12.10]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 46.05it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.02it/s, v_num=18880, train_loss_step=14.60, train_loss_epoch=14.60]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 134.25it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.96it/s, v_num=18882, train_loss_step=15.40, train_loss_epoch=15.40]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 95.18it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.95it/s, v_num=18884, train_loss_step=15.00, train_loss_epoch=15.00]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 992.97it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.25it/s, v_num=18886, train_loss_step=14.70, train_loss_epoch=14.70]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.30it/s, v_num=18888, train_loss_step=13.80, train_loss_epoch=13.80]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 74.03it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.44it/s, v_num=18890, train_loss_step=14.00, train_loss_epoch=14.00]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 636.18it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.26it/s, v_num=18892, train_loss_step=13.90, train_loss_epoch=13.90]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 578.13it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s, v_num=18894, train_loss_step=16.70, train_loss_epoch=16.70] \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 145.61it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.29it/s, v_num=18896, train_loss_step=15.10, train_loss_epoch=15.10]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 46.44it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.92it/s, v_num=18898, train_loss_step=16.30, train_loss_epoch=16.30]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 218.46it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.32it/s, v_num=18900, train_loss_step=17.10, train_loss_epoch=17.10]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 287.42it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s, v_num=18902, train_loss_step=18.40, train_loss_epoch=18.40]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 130.81it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.02it/s, v_num=18904, train_loss_step=18.10, train_loss_epoch=18.10]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 121.12it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.77it/s, v_num=18906, train_loss_step=17.90, train_loss_epoch=17.90]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 176.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 19:28:16,013] Trial 2 finished with value: 187.4441450516694 and parameters: {'n_blocks1': 1, 'n_blocks2': 1, 'n_blocks3': 3, 'mlp_units': 128, 'n_pool_kernel_size1': 3, 'n_pool_kernel_size2': 1, 'n_pool_kernel_size3': 2, 'learning_rate': 0.03656365417258768}. Best is trial 0 with value: 147.49607371548205.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.54it/s, v_num=18908, train_loss_step=10.20, train_loss_epoch=10.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.00it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.84it/s, v_num=18910, train_loss_step=10.50, train_loss_epoch=10.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 13.97it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  7.74it/s, v_num=18912, train_loss_step=10.50, train_loss_epoch=10.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 68.86it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.80it/s, v_num=18914, train_loss_step=10.60, train_loss_epoch=10.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 102.02it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.29it/s, v_num=18916, train_loss_step=10.90, train_loss_epoch=10.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 341.11it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  8.86it/s, v_num=18918, train_loss_step=10.60, train_loss_epoch=10.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.06it/s, v_num=18920, train_loss_step=12.50, train_loss_epoch=12.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 88.11it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.51it/s, v_num=18922, train_loss_step=13.50, train_loss_epoch=13.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 253.34it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.64it/s, v_num=18924, train_loss_step=13.50, train_loss_epoch=13.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 141.96it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.54it/s, v_num=18926, train_loss_step=13.40, train_loss_epoch=13.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 255.77it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.83it/s, v_num=18928, train_loss_step=12.50, train_loss_epoch=12.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 252.27it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  8.49it/s, v_num=18930, train_loss_step=12.50, train_loss_epoch=12.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 290.28it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.31it/s, v_num=18932, train_loss_step=12.60, train_loss_epoch=12.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 364.69it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.18it/s, v_num=18934, train_loss_step=12.50, train_loss_epoch=12.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 112.35it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.24it/s, v_num=18936, train_loss_step=12.80, train_loss_epoch=12.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 76.56it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  8.85it/s, v_num=18938, train_loss_step=13.30, train_loss_epoch=13.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 44.76it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.88it/s, v_num=18940, train_loss_step=13.20, train_loss_epoch=13.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 144.95it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.50it/s, v_num=18942, train_loss_step=14.40, train_loss_epoch=14.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 131.81it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.97it/s, v_num=18944, train_loss_step=14.40, train_loss_epoch=14.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.57it/s, v_num=18946, train_loss_step=14.20, train_loss_epoch=14.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 649.68it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.86it/s, v_num=18948, train_loss_step=14.10, train_loss_epoch=14.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.72it/s, v_num=18950, train_loss_step=14.10, train_loss_epoch=14.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 70.33it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.07it/s, v_num=18952, train_loss_step=13.50, train_loss_epoch=13.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 76.78it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.85it/s, v_num=18954, train_loss_step=11.50, train_loss_epoch=11.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  8.56it/s, v_num=18956, train_loss_step=14.70, train_loss_epoch=14.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 463.56it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.13it/s, v_num=18958, train_loss_step=15.90, train_loss_epoch=15.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 207.58it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  7.95it/s, v_num=18960, train_loss_step=15.80, train_loss_epoch=15.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.10it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  8.59it/s, v_num=18962, train_loss_step=16.20, train_loss_epoch=16.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 52.49it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  8.61it/s, v_num=18964, train_loss_step=16.30, train_loss_epoch=16.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 31.78it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.45it/s, v_num=18966, train_loss_step=16.40, train_loss_epoch=16.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 65.43it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.13it/s, v_num=18968, train_loss_step=16.20, train_loss_epoch=16.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 153.98it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  7.18it/s, v_num=18970, train_loss_step=16.00, train_loss_epoch=16.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 150.63it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  8.69it/s, v_num=18972, train_loss_step=15.80, train_loss_epoch=15.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 205.64it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.94it/s, v_num=18974, train_loss_step=15.00, train_loss_epoch=15.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 112.53it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.57it/s, v_num=18976, train_loss_step=15.00, train_loss_epoch=15.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 185.15it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.18it/s, v_num=18978, train_loss_step=14.50, train_loss_epoch=14.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 271.13it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.41it/s, v_num=18980, train_loss_step=14.60, train_loss_epoch=14.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 129.16it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.81it/s, v_num=18982, train_loss_step=15.90, train_loss_epoch=15.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 107.28it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  8.00it/s, v_num=18984, train_loss_step=15.90, train_loss_epoch=15.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 167.72it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  7.42it/s, v_num=18986, train_loss_step=15.80, train_loss_epoch=15.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 148.38it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.15it/s, v_num=18988, train_loss_step=15.50, train_loss_epoch=15.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 57.49it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.43it/s, v_num=18990, train_loss_step=15.30, train_loss_epoch=15.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 173.31it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.63it/s, v_num=18992, train_loss_step=12.90, train_loss_epoch=12.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 355.03it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  8.78it/s, v_num=18994, train_loss_step=12.10, train_loss_epoch=12.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 643.10it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.17it/s, v_num=18996, train_loss_step=11.20, train_loss_epoch=11.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 133.74it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  7.25it/s, v_num=18998, train_loss_step=11.20, train_loss_epoch=11.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.67it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.98it/s, v_num=19000, train_loss_step=11.70, train_loss_epoch=11.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 432.94it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.70it/s, v_num=19002, train_loss_step=11.40, train_loss_epoch=11.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 285.85it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.61it/s, v_num=19004, train_loss_step=11.60, train_loss_epoch=11.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 70.16it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.29it/s, v_num=19006, train_loss_step=11.30, train_loss_epoch=11.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 187.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 19:32:35,882] A new study created in memory with name: no-name-9dabf13e-7e4f-4aeb-bad8-34978b23cda2\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prefix: NFLX | mode: news | model_type: TFT\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.41it/s, v_num=19008, train_loss_step=19.80, train_loss_epoch=19.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 241.51it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.87it/s, v_num=19010, train_loss_step=17.40, train_loss_epoch=17.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 68.90it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.92it/s, v_num=19012, train_loss_step=17.60, train_loss_epoch=17.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 175.97it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.88it/s, v_num=19014, train_loss_step=17.50, train_loss_epoch=17.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 84.63it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.85it/s, v_num=19016, train_loss_step=17.80, train_loss_epoch=17.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 221.96it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.70it/s, v_num=19018, train_loss_step=15.10, train_loss_epoch=15.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 100.14it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.11it/s, v_num=19020, train_loss_step=15.20, train_loss_epoch=15.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 111.69it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.27it/s, v_num=19022, train_loss_step=15.60, train_loss_epoch=15.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 186.56it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.64it/s, v_num=19024, train_loss_step=15.50, train_loss_epoch=15.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 166.39it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.56it/s, v_num=19026, train_loss_step=15.20, train_loss_epoch=15.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.00it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.68it/s, v_num=19028, train_loss_step=14.70, train_loss_epoch=14.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 338.74it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.97it/s, v_num=19030, train_loss_step=14.60, train_loss_epoch=14.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 120.93it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.13it/s, v_num=19032, train_loss_step=14.00, train_loss_epoch=14.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 208.28it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.84it/s, v_num=19034, train_loss_step=14.10, train_loss_epoch=14.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.02it/s, v_num=19036, train_loss_step=14.20, train_loss_epoch=14.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 59.42it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.21it/s, v_num=19038, train_loss_step=14.40, train_loss_epoch=14.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 332.59it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.83it/s, v_num=19040, train_loss_step=13.40, train_loss_epoch=13.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 88.41it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.13it/s, v_num=19042, train_loss_step=15.90, train_loss_epoch=15.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 340.86it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.71it/s, v_num=19044, train_loss_step=15.90, train_loss_epoch=15.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 132.07it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.21it/s, v_num=19046, train_loss_step=15.90, train_loss_epoch=15.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 89.46it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 19:34:04,800] Trial 0 finished with value: 197.5424368384296 and parameters: {'learning_rate': 0.0024172598840406607, 'hidden_size': 4}. Best is trial 0 with value: 197.5424368384296.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.73it/s, v_num=19048, train_loss_step=20.70, train_loss_epoch=20.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 111.44it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.76it/s, v_num=19050, train_loss_step=18.20, train_loss_epoch=18.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 75.78it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.60it/s, v_num=19052, train_loss_step=18.40, train_loss_epoch=18.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 347.33it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.40it/s, v_num=19054, train_loss_step=18.40, train_loss_epoch=18.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 91.42it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.38it/s, v_num=19056, train_loss_step=18.70, train_loss_epoch=18.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 208.12it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.57it/s, v_num=19058, train_loss_step=16.00, train_loss_epoch=16.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 19.77it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.67it/s, v_num=19060, train_loss_step=16.00, train_loss_epoch=16.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 268.18it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.10it/s, v_num=19062, train_loss_step=16.50, train_loss_epoch=16.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 120.86it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.34it/s, v_num=19064, train_loss_step=16.30, train_loss_epoch=16.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 1347.35it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.34it/s, v_num=19066, train_loss_step=16.00, train_loss_epoch=16.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 122.99it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.23it/s, v_num=19068, train_loss_step=15.50, train_loss_epoch=15.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 115.67it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.39it/s, v_num=19070, train_loss_step=15.40, train_loss_epoch=15.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 242.18it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.86it/s, v_num=19072, train_loss_step=14.80, train_loss_epoch=14.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 51.13it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.72it/s, v_num=19074, train_loss_step=14.90, train_loss_epoch=14.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 116.09it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.51it/s, v_num=19076, train_loss_step=14.90, train_loss_epoch=14.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 198.27it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.80it/s, v_num=19078, train_loss_step=15.20, train_loss_epoch=15.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 68.38it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.69it/s, v_num=19080, train_loss_step=14.20, train_loss_epoch=14.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 76.16it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.21it/s, v_num=19082, train_loss_step=16.70, train_loss_epoch=16.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 117.94it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.27it/s, v_num=19084, train_loss_step=16.70, train_loss_epoch=16.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 249.01it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.89it/s, v_num=19086, train_loss_step=16.80, train_loss_epoch=16.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 19:35:33,085] Trial 1 finished with value: 218.676454021712 and parameters: {'learning_rate': 6.783070388396254e-05, 'hidden_size': 4}. Best is trial 0 with value: 197.5424368384296.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.82it/s, v_num=19088, train_loss_step=18.00, train_loss_epoch=18.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 118.63it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.96it/s, v_num=19090, train_loss_step=15.80, train_loss_epoch=15.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 330.68it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.90it/s, v_num=19092, train_loss_step=15.80, train_loss_epoch=15.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 310.74it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.88it/s, v_num=19094, train_loss_step=15.90, train_loss_epoch=15.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 132.05it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.77it/s, v_num=19096, train_loss_step=16.00, train_loss_epoch=16.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 115.88it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.79it/s, v_num=19098, train_loss_step=13.50, train_loss_epoch=13.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 634.25it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.90it/s, v_num=19100, train_loss_step=13.60, train_loss_epoch=13.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 57.40it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.40it/s, v_num=19102, train_loss_step=14.10, train_loss_epoch=14.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 288.61it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=19104, train_loss_step=13.90, train_loss_epoch=13.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 65.12it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.47it/s, v_num=19106, train_loss_step=13.60, train_loss_epoch=13.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 61.44it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.65it/s, v_num=19108, train_loss_step=13.30, train_loss_epoch=13.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 121.66it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.78it/s, v_num=19110, train_loss_step=13.40, train_loss_epoch=13.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 77.43it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.01it/s, v_num=19112, train_loss_step=12.70, train_loss_epoch=12.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 308.11it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.74it/s, v_num=19114, train_loss_step=12.70, train_loss_epoch=12.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 103.19it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.01it/s, v_num=19116, train_loss_step=12.80, train_loss_epoch=12.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 179.33it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s, v_num=19118, train_loss_step=12.90, train_loss_epoch=12.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 220.16it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.02it/s, v_num=19120, train_loss_step=11.90, train_loss_epoch=11.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 177.94it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.74it/s, v_num=19122, train_loss_step=14.20, train_loss_epoch=14.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 222.03it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.01it/s, v_num=19124, train_loss_step=14.20, train_loss_epoch=14.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 234.11it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.94it/s, v_num=19126, train_loss_step=14.10, train_loss_epoch=14.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 227.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 19:37:12,978] Trial 2 finished with value: 228.66942899245777 and parameters: {'learning_rate': 0.01811317904451828, 'hidden_size': 24}. Best is trial 0 with value: 197.5424368384296.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.93it/s, v_num=19128, train_loss_step=19.80, train_loss_epoch=19.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 97.88it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.20it/s, v_num=19130, train_loss_step=17.40, train_loss_epoch=17.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 289.66it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.16it/s, v_num=19132, train_loss_step=17.60, train_loss_epoch=17.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 116.50it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.81it/s, v_num=19134, train_loss_step=17.50, train_loss_epoch=17.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.16it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.64it/s, v_num=19136, train_loss_step=17.80, train_loss_epoch=17.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 137.63it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.64it/s, v_num=19138, train_loss_step=15.10, train_loss_epoch=15.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 311.27it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.15it/s, v_num=19140, train_loss_step=15.20, train_loss_epoch=15.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 60.57it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.66it/s, v_num=19142, train_loss_step=15.60, train_loss_epoch=15.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 282.52it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.50it/s, v_num=19144, train_loss_step=15.50, train_loss_epoch=15.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 106.20it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.24it/s, v_num=19146, train_loss_step=15.20, train_loss_epoch=15.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 98.96it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.11it/s, v_num=19148, train_loss_step=14.70, train_loss_epoch=14.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.98it/s, v_num=19150, train_loss_step=14.60, train_loss_epoch=14.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 285.35it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.12it/s, v_num=19152, train_loss_step=14.00, train_loss_epoch=14.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 259.63it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.67it/s, v_num=19154, train_loss_step=14.10, train_loss_epoch=14.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 335.87it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.67it/s, v_num=19156, train_loss_step=14.20, train_loss_epoch=14.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 114.45it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.38it/s, v_num=19158, train_loss_step=14.40, train_loss_epoch=14.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 99.26it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.53it/s, v_num=19160, train_loss_step=13.40, train_loss_epoch=13.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 247.29it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.55it/s, v_num=19162, train_loss_step=15.90, train_loss_epoch=15.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 111.05it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.43it/s, v_num=19164, train_loss_step=15.90, train_loss_epoch=15.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 56.93it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.58it/s, v_num=19166, train_loss_step=15.90, train_loss_epoch=15.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 279.34it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.26it/s, v_num=19168, train_loss_step=15.90, train_loss_epoch=15.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 94.05it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.77it/s, v_num=19170, train_loss_step=16.10, train_loss_epoch=16.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.43it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.48it/s, v_num=19172, train_loss_step=16.00, train_loss_epoch=16.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 77.08it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.99it/s, v_num=19174, train_loss_step=16.10, train_loss_epoch=16.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 711.02it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.73it/s, v_num=19176, train_loss_step=14.90, train_loss_epoch=14.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 403.22it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.38it/s, v_num=19178, train_loss_step=15.50, train_loss_epoch=15.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 133.98it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s, v_num=19180, train_loss_step=14.70, train_loss_epoch=14.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 69.15it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.96it/s, v_num=19182, train_loss_step=14.40, train_loss_epoch=14.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 310.32it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.97it/s, v_num=19184, train_loss_step=14.50, train_loss_epoch=14.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 67.54it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.73it/s, v_num=19186, train_loss_step=14.40, train_loss_epoch=14.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.04it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.64it/s, v_num=19188, train_loss_step=14.60, train_loss_epoch=14.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 487.82it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.02it/s, v_num=19190, train_loss_step=14.80, train_loss_epoch=14.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 232.55it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.20it/s, v_num=19192, train_loss_step=15.10, train_loss_epoch=15.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 123.99it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.90it/s, v_num=19194, train_loss_step=15.60, train_loss_epoch=15.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.51it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.45it/s, v_num=19196, train_loss_step=15.70, train_loss_epoch=15.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 57.71it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.52it/s, v_num=19198, train_loss_step=15.90, train_loss_epoch=15.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 80.83it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.01it/s, v_num=19200, train_loss_step=15.90, train_loss_epoch=15.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 204.76it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.68it/s, v_num=19202, train_loss_step=16.20, train_loss_epoch=16.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 202.95it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.49it/s, v_num=19204, train_loss_step=17.20, train_loss_epoch=17.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 201.30it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.41it/s, v_num=19206, train_loss_step=17.30, train_loss_epoch=17.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 274.87it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.11it/s, v_num=19208, train_loss_step=17.20, train_loss_epoch=17.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 241.19it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.33it/s, v_num=19210, train_loss_step=17.00, train_loss_epoch=17.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 280.37it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.45it/s, v_num=19212, train_loss_step=17.00, train_loss_epoch=17.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 139.05it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.08it/s, v_num=19214, train_loss_step=17.00, train_loss_epoch=17.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 128.71it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.72it/s, v_num=19216, train_loss_step=16.50, train_loss_epoch=16.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 88.18it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.37it/s, v_num=19218, train_loss_step=16.70, train_loss_epoch=16.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 187.82it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.96it/s, v_num=19220, train_loss_step=17.00, train_loss_epoch=17.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 112.51it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.64it/s, v_num=19222, train_loss_step=16.90, train_loss_epoch=16.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 135.71it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.30it/s, v_num=19224, train_loss_step=16.80, train_loss_epoch=16.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 185.67it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.09it/s, v_num=19226, train_loss_step=16.90, train_loss_epoch=16.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 19:40:57,666] A new study created in memory with name: no-name-23aa3455-7771-447b-abb7-1547d12b5173\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prefix: NFLX | mode: financial | model_type: NBEATS\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.43it/s, v_num=19228, train_loss_step=5.060, train_loss_epoch=5.060]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 298.25it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.91it/s, v_num=19230, train_loss_step=4.710, train_loss_epoch=4.710]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 123.68it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.35it/s, v_num=19232, train_loss_step=5.340, train_loss_epoch=5.340]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 66.44it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.42it/s, v_num=19234, train_loss_step=4.910, train_loss_epoch=4.910]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 274.28it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.43it/s, v_num=19236, train_loss_step=5.210, train_loss_epoch=5.210]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.75it/s, v_num=19238, train_loss_step=5.380, train_loss_epoch=5.380]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 334.63it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.62it/s, v_num=19240, train_loss_step=5.590, train_loss_epoch=5.590]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 105.91it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.90it/s, v_num=19242, train_loss_step=5.730, train_loss_epoch=5.730]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 127.73it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 19:41:33,784] Trial 0 finished with value: 152.86387875343235 and parameters: {'n_blocks_season': 3, 'n_blocks_trend': 2, 'n_blocks_ident': 1, 'mlp_units': 128, 'num_hidden': 2, 'n_harmonics': 2, 'n_polynomials': 4, 'learning_rate': 0.0013329498496175666}. Best is trial 0 with value: 152.86387875343235.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.53it/s, v_num=19244, train_loss_step=5.440, train_loss_epoch=5.440]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 141.92it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.43it/s, v_num=19246, train_loss_step=5.130, train_loss_epoch=5.130]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.15it/s, v_num=19248, train_loss_step=5.760, train_loss_epoch=5.760]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 61.21it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.88it/s, v_num=19250, train_loss_step=5.330, train_loss_epoch=5.330]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 211.56it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.76it/s, v_num=19252, train_loss_step=5.650, train_loss_epoch=5.650]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.51it/s, v_num=19254, train_loss_step=5.850, train_loss_epoch=5.850]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.41it/s, v_num=19256, train_loss_step=6.050, train_loss_epoch=6.050]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 54.90it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.06it/s, v_num=19258, train_loss_step=6.180, train_loss_epoch=6.180]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 576.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 19:42:06,029] Trial 1 finished with value: 166.40200614114318 and parameters: {'n_blocks_season': 2, 'n_blocks_trend': 3, 'n_blocks_ident': 1, 'mlp_units': 32, 'num_hidden': 1, 'n_harmonics': 1, 'n_polynomials': 4, 'learning_rate': 0.0022142976543750945}. Best is trial 0 with value: 152.86387875343235.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.34it/s, v_num=19260, train_loss_step=5.940, train_loss_epoch=5.940]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 148.33it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.05it/s, v_num=19262, train_loss_step=5.610, train_loss_epoch=5.610]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 83.88it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.16it/s, v_num=19264, train_loss_step=6.260, train_loss_epoch=6.260]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 302.38it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.64it/s, v_num=19266, train_loss_step=5.770, train_loss_epoch=5.770]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 129.47it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.74it/s, v_num=19268, train_loss_step=6.110, train_loss_epoch=6.110]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 221.85it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.48it/s, v_num=19270, train_loss_step=6.320, train_loss_epoch=6.320]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 263.73it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.38it/s, v_num=19272, train_loss_step=6.520, train_loss_epoch=6.520]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 143.73it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.96it/s, v_num=19274, train_loss_step=6.640, train_loss_epoch=6.640]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 215.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 19:42:40,136] Trial 2 finished with value: 221.86705447000023 and parameters: {'n_blocks_season': 2, 'n_blocks_trend': 3, 'n_blocks_ident': 1, 'mlp_units': 64, 'num_hidden': 3, 'n_harmonics': 5, 'n_polynomials': 2, 'learning_rate': 2.0837987924145733e-05}. Best is trial 0 with value: 152.86387875343235.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.90it/s, v_num=19276, train_loss_step=5.060, train_loss_epoch=5.060]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 150.60it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.23it/s, v_num=19278, train_loss_step=4.710, train_loss_epoch=4.710]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 187.16it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.14it/s, v_num=19280, train_loss_step=5.340, train_loss_epoch=5.340]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 53.11it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.16it/s, v_num=19282, train_loss_step=4.910, train_loss_epoch=4.910]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.49it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.26it/s, v_num=19284, train_loss_step=5.210, train_loss_epoch=5.210]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 98.20it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.69it/s, v_num=19286, train_loss_step=5.380, train_loss_epoch=5.380]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 81.71it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.57it/s, v_num=19288, train_loss_step=5.590, train_loss_epoch=5.590]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 321.28it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.06it/s, v_num=19290, train_loss_step=5.730, train_loss_epoch=5.730]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 65.32it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.91it/s, v_num=19292, train_loss_step=5.300, train_loss_epoch=5.300]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 203.46it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.62it/s, v_num=19294, train_loss_step=5.380, train_loss_epoch=5.380]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.60it/s, v_num=19296, train_loss_step=5.750, train_loss_epoch=5.750]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 179.24it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.55it/s, v_num=19298, train_loss_step=5.740, train_loss_epoch=5.740]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 234.17it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.00it/s, v_num=19300, train_loss_step=5.450, train_loss_epoch=5.450]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.37it/s, v_num=19302, train_loss_step=5.240, train_loss_epoch=5.240]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.83it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.47it/s, v_num=19304, train_loss_step=5.070, train_loss_epoch=5.070]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 93.37it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.56it/s, v_num=19306, train_loss_step=5.190, train_loss_epoch=5.190]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 112.45it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.84it/s, v_num=19308, train_loss_step=5.390, train_loss_epoch=5.390]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 218.84it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.71it/s, v_num=19310, train_loss_step=4.820, train_loss_epoch=4.820]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.15it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.31it/s, v_num=19312, train_loss_step=4.690, train_loss_epoch=4.690]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 141.77it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.04it/s, v_num=19314, train_loss_step=4.650, train_loss_epoch=4.650]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 222.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 19:44:11,995] A new study created in memory with name: no-name-b1406270-a35f-4c1d-9ea0-5a0333aeb3bf\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prefix: NFLX | mode: financial | model_type: NHITS\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.02it/s, v_num=19316, train_loss_step=4.550, train_loss_epoch=4.550]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 249.42it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.45it/s, v_num=19318, train_loss_step=4.190, train_loss_epoch=4.190]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 377.19it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.46it/s, v_num=19320, train_loss_step=4.540, train_loss_epoch=4.540]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 134.90it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.62it/s, v_num=19322, train_loss_step=4.290, train_loss_epoch=4.290]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 156.03it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.14it/s, v_num=19324, train_loss_step=4.540, train_loss_epoch=4.540]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 88.71it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.37it/s, v_num=19326, train_loss_step=4.620, train_loss_epoch=4.620]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 382.17it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.14it/s, v_num=19328, train_loss_step=4.950, train_loss_epoch=4.950]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 105.73it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.02it/s, v_num=19330, train_loss_step=5.020, train_loss_epoch=5.020]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 201.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 19:44:49,922] Trial 0 finished with value: 336.99454306699363 and parameters: {'n_blocks1': 1, 'n_blocks2': 2, 'n_blocks3': 2, 'mlp_units': 128, 'n_pool_kernel_size1': 3, 'n_pool_kernel_size2': 3, 'n_pool_kernel_size3': 1, 'learning_rate': 0.007160111202370424}. Best is trial 0 with value: 336.99454306699363.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.75it/s, v_num=19332, train_loss_step=5.670, train_loss_epoch=5.670]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 58.72it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.80it/s, v_num=19334, train_loss_step=5.340, train_loss_epoch=5.340]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 322.84it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.44it/s, v_num=19336, train_loss_step=5.990, train_loss_epoch=5.990]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 106.58it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.65it/s, v_num=19338, train_loss_step=5.510, train_loss_epoch=5.510]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 149.11it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.28it/s, v_num=19340, train_loss_step=5.840, train_loss_epoch=5.840]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 264.03it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.91it/s, v_num=19342, train_loss_step=6.040, train_loss_epoch=6.040]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 134.40it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.36it/s, v_num=19344, train_loss_step=6.230, train_loss_epoch=6.230]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 484.00it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.76it/s, v_num=19346, train_loss_step=6.350, train_loss_epoch=6.350]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 51.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 19:45:25,303] Trial 1 finished with value: 180.4315270403636 and parameters: {'n_blocks1': 1, 'n_blocks2': 1, 'n_blocks3': 3, 'mlp_units': 64, 'n_pool_kernel_size1': 1, 'n_pool_kernel_size2': 1, 'n_pool_kernel_size3': 2, 'learning_rate': 0.00024487338832168633}. Best is trial 1 with value: 180.4315270403636.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.65it/s, v_num=19348, train_loss_step=5.670, train_loss_epoch=5.670]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 60.61it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.17it/s, v_num=19350, train_loss_step=5.330, train_loss_epoch=5.330]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 65.87it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.88it/s, v_num=19352, train_loss_step=5.980, train_loss_epoch=5.980]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 136.71it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.19it/s, v_num=19354, train_loss_step=5.510, train_loss_epoch=5.510]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 65.71it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.68it/s, v_num=19356, train_loss_step=5.830, train_loss_epoch=5.830]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 100.47it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.36it/s, v_num=19358, train_loss_step=6.030, train_loss_epoch=6.030]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 202.01it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=19360, train_loss_step=6.250, train_loss_epoch=6.250]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 138.19it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.40it/s, v_num=19362, train_loss_step=6.370, train_loss_epoch=6.370]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 133.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 19:46:03,830] Trial 2 finished with value: 156.749692603946 and parameters: {'n_blocks1': 2, 'n_blocks2': 1, 'n_blocks3': 2, 'mlp_units': 128, 'n_pool_kernel_size1': 1, 'n_pool_kernel_size2': 2, 'n_pool_kernel_size3': 2, 'learning_rate': 2.1699408062050564e-05}. Best is trial 2 with value: 156.749692603946.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.34it/s, v_num=19364, train_loss_step=5.670, train_loss_epoch=5.670]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 142.67it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.52it/s, v_num=19366, train_loss_step=5.330, train_loss_epoch=5.330]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 254.02it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.61it/s, v_num=19368, train_loss_step=5.980, train_loss_epoch=5.980]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 157.25it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.81it/s, v_num=19370, train_loss_step=5.510, train_loss_epoch=5.510]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 77.45it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  5.29it/s, v_num=19372, train_loss_step=5.830, train_loss_epoch=5.830]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 243.22it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.69it/s, v_num=19374, train_loss_step=6.030, train_loss_epoch=6.030]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.88it/s, v_num=19376, train_loss_step=6.250, train_loss_epoch=6.250]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.21it/s, v_num=19378, train_loss_step=6.370, train_loss_epoch=6.370]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 123.46it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.49it/s, v_num=19380, train_loss_step=5.860, train_loss_epoch=5.860]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.80it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.90it/s, v_num=19382, train_loss_step=5.950, train_loss_epoch=5.950]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.18it/s, v_num=19384, train_loss_step=6.340, train_loss_epoch=6.340]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 68.22it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.34it/s, v_num=19386, train_loss_step=6.320, train_loss_epoch=6.320]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 55.02it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.19it/s, v_num=19388, train_loss_step=5.970, train_loss_epoch=5.970]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 275.92it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.54it/s, v_num=19390, train_loss_step=5.770, train_loss_epoch=5.770]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 75.49it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.60it/s, v_num=19392, train_loss_step=5.590, train_loss_epoch=5.590]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 152.84it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.50it/s, v_num=19394, train_loss_step=5.700, train_loss_epoch=5.700]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 301.97it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.35it/s, v_num=19396, train_loss_step=5.900, train_loss_epoch=5.900]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 67.81it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.01it/s, v_num=19398, train_loss_step=5.250, train_loss_epoch=5.250]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 65.48it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.89it/s, v_num=19400, train_loss_step=5.120, train_loss_epoch=5.120]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 259.81it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.47it/s, v_num=19402, train_loss_step=5.050, train_loss_epoch=5.050]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 124.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 19:47:39,526] A new study created in memory with name: no-name-cbdc1fe9-3c33-40d5-a78e-c944d9bac856\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prefix: NFLX | mode: financial | model_type: TFT\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.54it/s, v_num=19404, train_loss_step=8.520, train_loss_epoch=8.520]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.15it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.91it/s, v_num=19406, train_loss_step=8.590, train_loss_epoch=8.590]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 81.83it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.63it/s, v_num=19408, train_loss_step=8.960, train_loss_epoch=8.960]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 383.81it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.82it/s, v_num=19410, train_loss_step=8.970, train_loss_epoch=8.970]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 49.02it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.47it/s, v_num=19412, train_loss_step=9.140, train_loss_epoch=9.140]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 220.97it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.49it/s, v_num=19414, train_loss_step=8.720, train_loss_epoch=8.720]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 174.97it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.65it/s, v_num=19416, train_loss_step=8.740, train_loss_epoch=8.740]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 355.93it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.51it/s, v_num=19418, train_loss_step=8.490, train_loss_epoch=8.490]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 19:48:20,256] Trial 0 finished with value: 418.1188584276939 and parameters: {'learning_rate': 0.00028396253924311383, 'hidden_size': 4}. Best is trial 0 with value: 418.1188584276939.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.12it/s, v_num=19420, train_loss_step=6.520, train_loss_epoch=6.520]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 190.11it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.46it/s, v_num=19422, train_loss_step=6.600, train_loss_epoch=6.600]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.15it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.74it/s, v_num=19424, train_loss_step=6.830, train_loss_epoch=6.830]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 54.98it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.55it/s, v_num=19426, train_loss_step=6.880, train_loss_epoch=6.880]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 85.35it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.34it/s, v_num=19428, train_loss_step=7.020, train_loss_epoch=7.020]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 234.00it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.14it/s, v_num=19430, train_loss_step=6.540, train_loss_epoch=6.540]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 170.47it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.55it/s, v_num=19432, train_loss_step=6.580, train_loss_epoch=6.580]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 61.46it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.64it/s, v_num=19434, train_loss_step=6.400, train_loss_epoch=6.400]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 275.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 19:49:04,530] Trial 1 finished with value: 250.05736852479177 and parameters: {'learning_rate': 0.0002740971140777402, 'hidden_size': 12}. Best is trial 1 with value: 250.05736852479177.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.43it/s, v_num=19436, train_loss_step=8.700, train_loss_epoch=8.700]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.94it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.33it/s, v_num=19438, train_loss_step=8.780, train_loss_epoch=8.780]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 73.30it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.29it/s, v_num=19440, train_loss_step=9.130, train_loss_epoch=9.130]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 89.79it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.38it/s, v_num=19442, train_loss_step=9.110, train_loss_epoch=9.110]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 304.42it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.46it/s, v_num=19444, train_loss_step=9.300, train_loss_epoch=9.300]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 390.93it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.50it/s, v_num=19446, train_loss_step=8.890, train_loss_epoch=8.890]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 124.15it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.36it/s, v_num=19448, train_loss_step=8.920, train_loss_epoch=8.920]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 127.43it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.50it/s, v_num=19450, train_loss_step=8.660, train_loss_epoch=8.660]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 183.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 19:49:45,455] Trial 2 finished with value: 490.97343379268403 and parameters: {'learning_rate': 2.1552497338062897e-05, 'hidden_size': 8}. Best is trial 1 with value: 250.05736852479177.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.35it/s, v_num=19452, train_loss_step=6.520, train_loss_epoch=6.520]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 115.86it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.39it/s, v_num=19454, train_loss_step=6.600, train_loss_epoch=6.600]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 71.38it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.46it/s, v_num=19456, train_loss_step=6.830, train_loss_epoch=6.830]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 161.39it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.21it/s, v_num=19458, train_loss_step=6.880, train_loss_epoch=6.880]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 87.85it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.37it/s, v_num=19460, train_loss_step=7.020, train_loss_epoch=7.020]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.96it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.36it/s, v_num=19462, train_loss_step=6.540, train_loss_epoch=6.540]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 218.51it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.31it/s, v_num=19464, train_loss_step=6.580, train_loss_epoch=6.580]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.20it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.02it/s, v_num=19466, train_loss_step=6.400, train_loss_epoch=6.400]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 160.70it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.37it/s, v_num=19468, train_loss_step=6.870, train_loss_epoch=6.870]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 295.67it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.31it/s, v_num=19470, train_loss_step=6.830, train_loss_epoch=6.830]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 92.97it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.08it/s, v_num=19472, train_loss_step=6.940, train_loss_epoch=6.940]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 193.05it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.32it/s, v_num=19474, train_loss_step=6.770, train_loss_epoch=6.770]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 103.79it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.49it/s, v_num=19476, train_loss_step=7.140, train_loss_epoch=7.140]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 99.57it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.25it/s, v_num=19478, train_loss_step=7.010, train_loss_epoch=7.010]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 153.71it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  2.77it/s, v_num=19480, train_loss_step=6.940, train_loss_epoch=6.940]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 56.17it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.50it/s, v_num=19482, train_loss_step=6.740, train_loss_epoch=6.740]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.58it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.08it/s, v_num=19484, train_loss_step=6.660, train_loss_epoch=6.660]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 192.98it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.42it/s, v_num=19486, train_loss_step=6.550, train_loss_epoch=6.550]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 194.35it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.09it/s, v_num=19488, train_loss_step=6.530, train_loss_epoch=6.530]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 410.32it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.16it/s, v_num=19490, train_loss_step=6.380, train_loss_epoch=6.380]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 313.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 19:51:39,322] A new study created in memory with name: no-name-0b439a21-b432-4759-aed0-95c1916c2f2f\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prefix: NFLX | mode: news | model_type: NBEATS\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.29it/s, v_num=19492, train_loss_step=5.390, train_loss_epoch=5.390]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 225.78it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.41it/s, v_num=19494, train_loss_step=5.070, train_loss_epoch=5.070]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 271.00it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.07it/s, v_num=19496, train_loss_step=5.710, train_loss_epoch=5.710]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 149.10it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.24it/s, v_num=19498, train_loss_step=5.280, train_loss_epoch=5.280]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 165.27it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.19it/s, v_num=19500, train_loss_step=5.600, train_loss_epoch=5.600]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 333.86it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.49it/s, v_num=19502, train_loss_step=5.790, train_loss_epoch=5.790]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 38.10it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.67it/s, v_num=19504, train_loss_step=5.990, train_loss_epoch=5.990]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 88.56it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.93it/s, v_num=19506, train_loss_step=6.120, train_loss_epoch=6.120]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 186.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 19:52:20,217] Trial 0 finished with value: 173.8338438872018 and parameters: {'n_blocks_season': 2, 'n_blocks_trend': 1, 'n_blocks_ident': 3, 'mlp_units': 128, 'num_hidden': 3, 'n_harmonics': 3, 'n_polynomials': 3, 'learning_rate': 0.0009170734077169037}. Best is trial 0 with value: 173.8338438872018.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.04it/s, v_num=19508, train_loss_step=5.420, train_loss_epoch=5.420]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 322.66it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.28it/s, v_num=19510, train_loss_step=5.080, train_loss_epoch=5.080]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  5.36it/s, v_num=19512, train_loss_step=5.670, train_loss_epoch=5.670]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 65.66it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s, v_num=19514, train_loss_step=5.290, train_loss_epoch=5.290]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.64it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.46it/s, v_num=19516, train_loss_step=5.550, train_loss_epoch=5.550]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 249.02it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.08it/s, v_num=19518, train_loss_step=5.700, train_loss_epoch=5.700]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 54.03it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.49it/s, v_num=19520, train_loss_step=5.950, train_loss_epoch=5.950]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 202.14it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.90it/s, v_num=19522, train_loss_step=6.060, train_loss_epoch=6.060]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 110.24it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 19:52:57,777] Trial 1 finished with value: 192.38788486947334 and parameters: {'n_blocks_season': 2, 'n_blocks_trend': 2, 'n_blocks_ident': 2, 'mlp_units': 128, 'num_hidden': 2, 'n_harmonics': 5, 'n_polynomials': 3, 'learning_rate': 0.010229290090426758}. Best is trial 0 with value: 173.8338438872018.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.82it/s, v_num=19524, train_loss_step=5.580, train_loss_epoch=5.580]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 162.56it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, v_num=19526, train_loss_step=5.250, train_loss_epoch=5.250]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 249.13it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.07it/s, v_num=19528, train_loss_step=5.900, train_loss_epoch=5.900]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 348.45it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.37it/s, v_num=19530, train_loss_step=5.430, train_loss_epoch=5.430]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 212.03it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.77it/s, v_num=19532, train_loss_step=5.750, train_loss_epoch=5.750]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 170.83it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.98it/s, v_num=19534, train_loss_step=5.950, train_loss_epoch=5.950]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 114.92it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.32it/s, v_num=19536, train_loss_step=6.160, train_loss_epoch=6.160]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 72.88it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.90it/s, v_num=19538, train_loss_step=6.280, train_loss_epoch=6.280]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 19:53:32,928] Trial 2 finished with value: 161.18976554947466 and parameters: {'n_blocks_season': 1, 'n_blocks_trend': 3, 'n_blocks_ident': 1, 'mlp_units': 64, 'num_hidden': 2, 'n_harmonics': 4, 'n_polynomials': 2, 'learning_rate': 0.0004275826165513168}. Best is trial 2 with value: 161.18976554947466.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.69it/s, v_num=19540, train_loss_step=5.580, train_loss_epoch=5.580]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 52.33it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.11it/s, v_num=19542, train_loss_step=5.250, train_loss_epoch=5.250]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 61.31it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.63it/s, v_num=19544, train_loss_step=5.900, train_loss_epoch=5.900]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 384.30it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.81it/s, v_num=19546, train_loss_step=5.430, train_loss_epoch=5.430]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.27it/s, v_num=19548, train_loss_step=5.750, train_loss_epoch=5.750]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.38it/s, v_num=19550, train_loss_step=5.950, train_loss_epoch=5.950]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 237.02it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.42it/s, v_num=19552, train_loss_step=6.160, train_loss_epoch=6.160]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 138.54it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.18it/s, v_num=19554, train_loss_step=6.280, train_loss_epoch=6.280]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 488.39it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.20it/s, v_num=19556, train_loss_step=5.790, train_loss_epoch=5.790]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.69it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.00it/s, v_num=19558, train_loss_step=5.880, train_loss_epoch=5.880]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.35it/s, v_num=19560, train_loss_step=6.250, train_loss_epoch=6.250]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 113.11it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s, v_num=19562, train_loss_step=6.230, train_loss_epoch=6.230]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 123.75it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.36it/s, v_num=19564, train_loss_step=5.890, train_loss_epoch=5.890]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 283.15it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.60it/s, v_num=19566, train_loss_step=5.670, train_loss_epoch=5.670]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 104.87it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.10it/s, v_num=19568, train_loss_step=5.500, train_loss_epoch=5.500]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 314.65it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.25it/s, v_num=19570, train_loss_step=5.620, train_loss_epoch=5.620]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 65.94it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.23it/s, v_num=19572, train_loss_step=5.830, train_loss_epoch=5.830]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 165.55it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.18it/s, v_num=19574, train_loss_step=5.190, train_loss_epoch=5.190]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 389.48it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.40it/s, v_num=19576, train_loss_step=5.050, train_loss_epoch=5.050]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 182.27it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.72it/s, v_num=19578, train_loss_step=4.980, train_loss_epoch=4.980]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 508.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 19:55:01,752] A new study created in memory with name: no-name-a6893bc5-1bf3-4920-ae55-a602bd9e0abf\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prefix: NFLX | mode: news | model_type: NHITS\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.39it/s, v_num=19580, train_loss_step=5.690, train_loss_epoch=5.690]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 296.04it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.24it/s, v_num=19582, train_loss_step=5.360, train_loss_epoch=5.360]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 266.34it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.55it/s, v_num=19584, train_loss_step=6.000, train_loss_epoch=6.000]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 125.80it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.66it/s, v_num=19586, train_loss_step=5.520, train_loss_epoch=5.520]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 92.79it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.72it/s, v_num=19588, train_loss_step=5.850, train_loss_epoch=5.850]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 736.36it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.01it/s, v_num=19590, train_loss_step=6.050, train_loss_epoch=6.050]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 131.04it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.63it/s, v_num=19592, train_loss_step=6.260, train_loss_epoch=6.260]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 199.21it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s, v_num=19594, train_loss_step=6.380, train_loss_epoch=6.380]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 116.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 19:55:38,559] Trial 0 finished with value: 164.90504936152163 and parameters: {'n_blocks1': 3, 'n_blocks2': 2, 'n_blocks3': 1, 'mlp_units': 32, 'n_pool_kernel_size1': 2, 'n_pool_kernel_size2': 3, 'n_pool_kernel_size3': 3, 'learning_rate': 0.00011841915765966078}. Best is trial 0 with value: 164.90504936152163.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.63it/s, v_num=19596, train_loss_step=4.210, train_loss_epoch=4.210]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 261.60it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.45it/s, v_num=19598, train_loss_step=3.890, train_loss_epoch=3.890]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 167.94it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.01it/s, v_num=19600, train_loss_step=4.410, train_loss_epoch=4.410]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 258.46it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.14it/s, v_num=19602, train_loss_step=3.990, train_loss_epoch=3.990]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 209.48it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.82it/s, v_num=19604, train_loss_step=4.120, train_loss_epoch=4.120]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 59.33it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.07it/s, v_num=19606, train_loss_step=4.160, train_loss_epoch=4.160]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 133.65it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.30it/s, v_num=19608, train_loss_step=4.270, train_loss_epoch=4.270]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 208.24it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.34it/s, v_num=19610, train_loss_step=4.390, train_loss_epoch=4.390]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 497.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 19:56:16,484] Trial 1 finished with value: 207.20945659792073 and parameters: {'n_blocks1': 1, 'n_blocks2': 3, 'n_blocks3': 2, 'mlp_units': 32, 'n_pool_kernel_size1': 2, 'n_pool_kernel_size2': 1, 'n_pool_kernel_size3': 3, 'learning_rate': 0.009787392075522906}. Best is trial 0 with value: 164.90504936152163.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.49it/s, v_num=19612, train_loss_step=5.310, train_loss_epoch=5.310]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.43it/s, v_num=19614, train_loss_step=4.990, train_loss_epoch=4.990]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 105.00it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.89it/s, v_num=19616, train_loss_step=5.620, train_loss_epoch=5.620]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 115.80it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.23it/s, v_num=19618, train_loss_step=5.190, train_loss_epoch=5.190]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 127.42it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.45it/s, v_num=19620, train_loss_step=5.510, train_loss_epoch=5.510]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 97.41it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.40it/s, v_num=19622, train_loss_step=5.700, train_loss_epoch=5.700]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 298.38it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.16it/s, v_num=19624, train_loss_step=5.900, train_loss_epoch=5.900]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 222.62it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.12it/s, v_num=19626, train_loss_step=6.030, train_loss_epoch=6.030]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 134.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 19:56:57,647] Trial 2 finished with value: 160.1582268575209 and parameters: {'n_blocks1': 2, 'n_blocks2': 1, 'n_blocks3': 2, 'mlp_units': 128, 'n_pool_kernel_size1': 1, 'n_pool_kernel_size2': 3, 'n_pool_kernel_size3': 2, 'learning_rate': 0.000637773963970088}. Best is trial 2 with value: 160.1582268575209.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.63it/s, v_num=19628, train_loss_step=5.310, train_loss_epoch=5.310]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 102.79it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.39it/s, v_num=19630, train_loss_step=4.990, train_loss_epoch=4.990]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 147.67it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.48it/s, v_num=19632, train_loss_step=5.620, train_loss_epoch=5.620]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 54.11it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.83it/s, v_num=19634, train_loss_step=5.190, train_loss_epoch=5.190]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.98it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.04it/s, v_num=19636, train_loss_step=5.510, train_loss_epoch=5.510]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 184.28it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.87it/s, v_num=19638, train_loss_step=5.700, train_loss_epoch=5.700]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 223.03it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.17it/s, v_num=19640, train_loss_step=5.900, train_loss_epoch=5.900]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 122.93it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.86it/s, v_num=19642, train_loss_step=6.030, train_loss_epoch=6.030]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 58.71it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.63it/s, v_num=19644, train_loss_step=5.560, train_loss_epoch=5.560]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.67it/s, v_num=19646, train_loss_step=5.670, train_loss_epoch=5.670]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 375.23it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.73it/s, v_num=19648, train_loss_step=6.030, train_loss_epoch=6.030]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.51it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.86it/s, v_num=19650, train_loss_step=6.010, train_loss_epoch=6.010]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 150.72it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.50it/s, v_num=19652, train_loss_step=5.660, train_loss_epoch=5.660]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 103.90it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  7.30it/s, v_num=19654, train_loss_step=5.470, train_loss_epoch=5.470]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 59.22it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.19it/s, v_num=19656, train_loss_step=5.280, train_loss_epoch=5.280]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 167.71it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.55it/s, v_num=19658, train_loss_step=5.380, train_loss_epoch=5.380]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 141.31it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.77it/s, v_num=19660, train_loss_step=5.550, train_loss_epoch=5.550]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 339.34it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.11it/s, v_num=19662, train_loss_step=4.950, train_loss_epoch=4.950]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 183.94it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.30it/s, v_num=19664, train_loss_step=4.830, train_loss_epoch=4.830]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 168.39it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.96it/s, v_num=19666, train_loss_step=4.760, train_loss_epoch=4.760]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 19:58:38,973] A new study created in memory with name: no-name-a9f5bedc-a7d2-4bca-868e-af09c2e24876\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prefix: NFLX | mode: news | model_type: TFT\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.12it/s, v_num=19668, train_loss_step=5.770, train_loss_epoch=5.770]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 193.21it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.83it/s, v_num=19670, train_loss_step=5.890, train_loss_epoch=5.890]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 59.87it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.85it/s, v_num=19672, train_loss_step=6.100, train_loss_epoch=6.100]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 282.27it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  2.43it/s, v_num=19674, train_loss_step=6.250, train_loss_epoch=6.250]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 116.63it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.06it/s, v_num=19676, train_loss_step=6.360, train_loss_epoch=6.360]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 53.80it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.69it/s, v_num=19678, train_loss_step=5.910, train_loss_epoch=5.910]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 197.43it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.52it/s, v_num=19680, train_loss_step=5.940, train_loss_epoch=5.940]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 180.24it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.15it/s, v_num=19682, train_loss_step=5.800, train_loss_epoch=5.800]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 118.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 19:59:27,508] Trial 0 finished with value: 235.74333581163108 and parameters: {'learning_rate': 0.005690881149213277, 'hidden_size': 16}. Best is trial 0 with value: 235.74333581163108.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.77it/s, v_num=19684, train_loss_step=5.740, train_loss_epoch=5.740]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 174.15it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=19686, train_loss_step=5.840, train_loss_epoch=5.840]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 475.54it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  2.95it/s, v_num=19688, train_loss_step=6.020, train_loss_epoch=6.020]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 163.84it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.25it/s, v_num=19690, train_loss_step=6.160, train_loss_epoch=6.160]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 55.53it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.13it/s, v_num=19692, train_loss_step=6.280, train_loss_epoch=6.280]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 114.48it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.54it/s, v_num=19694, train_loss_step=5.800, train_loss_epoch=5.800]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 98.44it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.92it/s, v_num=19696, train_loss_step=5.800, train_loss_epoch=5.800]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 59.80it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.09it/s, v_num=19698, train_loss_step=5.640, train_loss_epoch=5.640]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 142.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 20:00:13,092] Trial 1 finished with value: 192.26186898348413 and parameters: {'learning_rate': 0.02577272686074656, 'hidden_size': 8}. Best is trial 1 with value: 192.26186898348413.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.29it/s, v_num=19700, train_loss_step=7.750, train_loss_epoch=7.750]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 83.92it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.16it/s, v_num=19702, train_loss_step=7.790, train_loss_epoch=7.790]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.93it/s, v_num=19704, train_loss_step=8.100, train_loss_epoch=8.100]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 51.69it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.83it/s, v_num=19706, train_loss_step=8.110, train_loss_epoch=8.110]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 143.49it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.10it/s, v_num=19708, train_loss_step=8.250, train_loss_epoch=8.250]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 293.14it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.38it/s, v_num=19710, train_loss_step=7.760, train_loss_epoch=7.760]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 58.26it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.21it/s, v_num=19712, train_loss_step=7.790, train_loss_epoch=7.790]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 544.50it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  2.43it/s, v_num=19714, train_loss_step=7.610, train_loss_epoch=7.610]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 20:01:02,130] Trial 2 finished with value: 304.06050650728866 and parameters: {'learning_rate': 1.839962864351748e-05, 'hidden_size': 12}. Best is trial 1 with value: 192.26186898348413.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=19716, train_loss_step=5.740, train_loss_epoch=5.740]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 30.97it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.84it/s, v_num=19718, train_loss_step=5.840, train_loss_epoch=5.840]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 96.88it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.90it/s, v_num=19720, train_loss_step=6.020, train_loss_epoch=6.020]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.41it/s, v_num=19722, train_loss_step=6.160, train_loss_epoch=6.160]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 243.29it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  2.33it/s, v_num=19724, train_loss_step=6.280, train_loss_epoch=6.280]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 98.45it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.93it/s, v_num=19726, train_loss_step=5.800, train_loss_epoch=5.800]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.00it/s, v_num=19728, train_loss_step=5.800, train_loss_epoch=5.800]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=19730, train_loss_step=5.640, train_loss_epoch=5.640]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 102.92it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=19732, train_loss_step=6.140, train_loss_epoch=6.140]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 58.30it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.95it/s, v_num=19734, train_loss_step=6.100, train_loss_epoch=6.100]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 145.07it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.99it/s, v_num=19736, train_loss_step=6.170, train_loss_epoch=6.170]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 332.72it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.92it/s, v_num=19738, train_loss_step=6.060, train_loss_epoch=6.060]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 174.29it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.01it/s, v_num=19740, train_loss_step=6.500, train_loss_epoch=6.500]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 58.22it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.54it/s, v_num=19742, train_loss_step=6.340, train_loss_epoch=6.340]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.41it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.48it/s, v_num=19744, train_loss_step=6.340, train_loss_epoch=6.340]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 40.20it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.93it/s, v_num=19746, train_loss_step=6.210, train_loss_epoch=6.210]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 265.50it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  2.50it/s, v_num=19748, train_loss_step=6.080, train_loss_epoch=6.080]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.19it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=19750, train_loss_step=6.000, train_loss_epoch=6.000]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 111.37it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  2.62it/s, v_num=19752, train_loss_step=5.840, train_loss_epoch=5.840]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 126.90it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.21it/s, v_num=19754, train_loss_step=5.750, train_loss_epoch=5.750]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 99.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 20:02:59,957] A new study created in memory with name: no-name-0c6c3e89-ff60-4e51-ad06-ff9196b2f52b\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prefix: NFLX | mode: financial | model_type: NBEATS\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.89it/s, v_num=19756, train_loss_step=5.460, train_loss_epoch=5.460]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.01it/s, v_num=19758, train_loss_step=5.440, train_loss_epoch=5.440] \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 360.34it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 23.46it/s, v_num=19760, train_loss_step=5.560, train_loss_epoch=5.560] \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 194.71it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 21.51it/s, v_num=19762, train_loss_step=5.450, train_loss_epoch=5.450]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 347.82it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 23.74it/s, v_num=19764, train_loss_step=5.470, train_loss_epoch=5.470]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 147.32it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.91it/s, v_num=19766, train_loss_step=5.520, train_loss_epoch=5.520]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 191.63it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.72it/s, v_num=19768, train_loss_step=5.860, train_loss_epoch=5.860]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 218.33it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 20.96it/s, v_num=19770, train_loss_step=6.320, train_loss_epoch=6.320]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 70.54it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.29it/s, v_num=19772, train_loss_step=6.430, train_loss_epoch=6.430]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 298.68it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.35it/s, v_num=19774, train_loss_step=6.390, train_loss_epoch=6.390]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 59.32it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.98it/s, v_num=19776, train_loss_step=6.040, train_loss_epoch=6.040]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 86.29it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.66it/s, v_num=19778, train_loss_step=5.920, train_loss_epoch=5.920]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 57.68it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 20.94it/s, v_num=19780, train_loss_step=6.060, train_loss_epoch=6.060]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 81.40it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.88it/s, v_num=19782, train_loss_step=6.070, train_loss_epoch=6.070]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 252.58it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.62it/s, v_num=19784, train_loss_step=6.300, train_loss_epoch=6.300]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 115.23it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.65it/s, v_num=19786, train_loss_step=6.740, train_loss_epoch=6.740]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 85.16it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.23it/s, v_num=19788, train_loss_step=6.990, train_loss_epoch=6.990]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 132.34it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.53it/s, v_num=19790, train_loss_step=7.350, train_loss_epoch=7.350]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 257.65it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.09it/s, v_num=19792, train_loss_step=7.370, train_loss_epoch=7.370]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 413.39it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 20.44it/s, v_num=19794, train_loss_step=7.070, train_loss_epoch=7.070] \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 150.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 20:04:27,112] Trial 0 finished with value: 0.46764705882352936 and parameters: {'n_blocks_season': 1, 'n_blocks_trend': 1, 'n_blocks_ident': 1, 'mlp_units': 64, 'num_hidden': 2, 'n_harmonics': 4, 'n_polynomials': 1, 'learning_rate': 0.019553772580571033}. Best is trial 0 with value: 0.46764705882352936.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 21.54it/s, v_num=19796, train_loss_step=5.480, train_loss_epoch=5.480] \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 169.84it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 20.42it/s, v_num=19798, train_loss_step=5.470, train_loss_epoch=5.470] \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 683.67it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 33.91it/s, v_num=19800, train_loss_step=5.590, train_loss_epoch=5.590] \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 354.28it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.85it/s, v_num=19802, train_loss_step=5.470, train_loss_epoch=5.470]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 104.75it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 23.49it/s, v_num=19804, train_loss_step=5.490, train_loss_epoch=5.490]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 191.91it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 23.07it/s, v_num=19806, train_loss_step=5.540, train_loss_epoch=5.540] \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 65.58it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 21.15it/s, v_num=19808, train_loss_step=5.870, train_loss_epoch=5.870] \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 164.46it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 20.71it/s, v_num=19810, train_loss_step=6.330, train_loss_epoch=6.330]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 48.83it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.29it/s, v_num=19812, train_loss_step=6.450, train_loss_epoch=6.450] \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 133.48it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.62it/s, v_num=19814, train_loss_step=6.420, train_loss_epoch=6.420]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 56.35it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 21.66it/s, v_num=19816, train_loss_step=6.060, train_loss_epoch=6.060]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 166.76it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 21.65it/s, v_num=19818, train_loss_step=5.940, train_loss_epoch=5.940]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 60.50it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.20it/s, v_num=19820, train_loss_step=6.090, train_loss_epoch=6.090]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 191.46it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.49it/s, v_num=19822, train_loss_step=6.100, train_loss_epoch=6.100]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 570.50it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 20.70it/s, v_num=19824, train_loss_step=6.330, train_loss_epoch=6.330]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 271.69it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.89it/s, v_num=19826, train_loss_step=6.750, train_loss_epoch=6.750]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 295.48it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 25.12it/s, v_num=19828, train_loss_step=7.000, train_loss_epoch=7.000] \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 139.67it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 22.56it/s, v_num=19830, train_loss_step=7.380, train_loss_epoch=7.380]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 153.74it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 21.23it/s, v_num=19832, train_loss_step=7.390, train_loss_epoch=7.390]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 20.44it/s, v_num=19834, train_loss_step=7.080, train_loss_epoch=7.080]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 204.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 20:05:46,424] Trial 1 finished with value: 0.5129411764705882 and parameters: {'n_blocks_season': 1, 'n_blocks_trend': 1, 'n_blocks_ident': 1, 'mlp_units': 64, 'num_hidden': 1, 'n_harmonics': 3, 'n_polynomials': 4, 'learning_rate': 0.002023816238192758}. Best is trial 1 with value: 0.5129411764705882.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.29it/s, v_num=19836, train_loss_step=5.520, train_loss_epoch=5.520]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.51it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 20.48it/s, v_num=19838, train_loss_step=5.520, train_loss_epoch=5.520]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 124.35it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.52it/s, v_num=19840, train_loss_step=5.640, train_loss_epoch=5.640]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 176.98it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 20.92it/s, v_num=19842, train_loss_step=5.520, train_loss_epoch=5.520]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 80.61it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.47it/s, v_num=19844, train_loss_step=5.540, train_loss_epoch=5.540] \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 199.57it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.11it/s, v_num=19846, train_loss_step=5.590, train_loss_epoch=5.590]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 189.78it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.54it/s, v_num=19848, train_loss_step=5.930, train_loss_epoch=5.930]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 167.69it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 20.42it/s, v_num=19850, train_loss_step=6.390, train_loss_epoch=6.390]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 849.22it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  7.04it/s, v_num=19852, train_loss_step=6.500, train_loss_epoch=6.500]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 131.82it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 23.84it/s, v_num=19854, train_loss_step=6.470, train_loss_epoch=6.470]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 973.38it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.34it/s, v_num=19856, train_loss_step=6.100, train_loss_epoch=6.100] \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 256.72it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 22.21it/s, v_num=19858, train_loss_step=5.980, train_loss_epoch=5.980] \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 792.42it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.34it/s, v_num=19860, train_loss_step=6.130, train_loss_epoch=6.130]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 537.94it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.86it/s, v_num=19862, train_loss_step=6.140, train_loss_epoch=6.140]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 481.55it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 20.22it/s, v_num=19864, train_loss_step=6.370, train_loss_epoch=6.370]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 70.89it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.08it/s, v_num=19866, train_loss_step=6.800, train_loss_epoch=6.800]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 276.21it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, v_num=19868, train_loss_step=7.040, train_loss_epoch=7.040]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 494.84it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.63it/s, v_num=19870, train_loss_step=7.430, train_loss_epoch=7.430]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 224.34it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.20it/s, v_num=19872, train_loss_step=7.450, train_loss_epoch=7.450]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 133.94it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.35it/s, v_num=19874, train_loss_step=7.130, train_loss_epoch=7.130]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 126.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 20:07:08,892] Trial 2 finished with value: 0.55119825708061 and parameters: {'n_blocks_season': 1, 'n_blocks_trend': 2, 'n_blocks_ident': 1, 'mlp_units': 32, 'num_hidden': 2, 'n_harmonics': 1, 'n_polynomials': 4, 'learning_rate': 0.0019516501963741976}. Best is trial 2 with value: 0.55119825708061.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.48it/s, v_num=19876, train_loss_step=5.520, train_loss_epoch=5.520]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.28it/s, v_num=19878, train_loss_step=5.520, train_loss_epoch=5.520]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 66.34it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.68it/s, v_num=19880, train_loss_step=5.640, train_loss_epoch=5.640]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.00it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 25.00it/s, v_num=19882, train_loss_step=5.520, train_loss_epoch=5.520]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 188.23it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.16it/s, v_num=19884, train_loss_step=5.540, train_loss_epoch=5.540]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 80.27it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  8.56it/s, v_num=19886, train_loss_step=5.590, train_loss_epoch=5.590]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 69.62it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.82it/s, v_num=19888, train_loss_step=5.930, train_loss_epoch=5.930]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 91.43it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.33it/s, v_num=19890, train_loss_step=6.390, train_loss_epoch=6.390]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 176.53it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.38it/s, v_num=19892, train_loss_step=6.500, train_loss_epoch=6.500]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.21it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.81it/s, v_num=19894, train_loss_step=6.470, train_loss_epoch=6.470]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.75it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.90it/s, v_num=19896, train_loss_step=6.100, train_loss_epoch=6.100]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 105.53it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.88it/s, v_num=19898, train_loss_step=5.980, train_loss_epoch=5.980]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 65.74it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.80it/s, v_num=19900, train_loss_step=6.130, train_loss_epoch=6.130]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 128.46it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.46it/s, v_num=19902, train_loss_step=6.140, train_loss_epoch=6.140]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 293.16it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 20.25it/s, v_num=19904, train_loss_step=6.370, train_loss_epoch=6.370]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.69it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.51it/s, v_num=19906, train_loss_step=6.800, train_loss_epoch=6.800]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 179.57it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.52it/s, v_num=19908, train_loss_step=7.040, train_loss_epoch=7.040]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 106.14it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.04it/s, v_num=19910, train_loss_step=7.430, train_loss_epoch=7.430]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 165.59it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.22it/s, v_num=19912, train_loss_step=7.450, train_loss_epoch=7.450]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 69.91it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.23it/s, v_num=19914, train_loss_step=7.130, train_loss_epoch=7.130]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 89.68it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.88it/s, v_num=19916, train_loss_step=7.150, train_loss_epoch=7.150]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 266.63it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.37it/s, v_num=19918, train_loss_step=7.130, train_loss_epoch=7.130]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 437.77it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s, v_num=19920, train_loss_step=6.830, train_loss_epoch=6.830]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 235.07it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.86it/s, v_num=19922, train_loss_step=6.430, train_loss_epoch=6.430]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 208.83it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.25it/s, v_num=19924, train_loss_step=6.720, train_loss_epoch=6.720]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 92.51it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.42it/s, v_num=19926, train_loss_step=6.910, train_loss_epoch=6.910]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 68.93it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.18it/s, v_num=19928, train_loss_step=6.890, train_loss_epoch=6.890]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.97it/s, v_num=19930, train_loss_step=6.870, train_loss_epoch=6.870]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 955.86it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.27it/s, v_num=19932, train_loss_step=6.940, train_loss_epoch=6.940]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 74.28it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 21.07it/s, v_num=19934, train_loss_step=7.050, train_loss_epoch=7.050]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 163.52it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.02it/s, v_num=19936, train_loss_step=6.900, train_loss_epoch=6.900]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 219.05it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.49it/s, v_num=19938, train_loss_step=7.030, train_loss_epoch=7.030]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 148.20it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 21.92it/s, v_num=19940, train_loss_step=6.680, train_loss_epoch=6.680]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 57.00it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.84it/s, v_num=19942, train_loss_step=6.320, train_loss_epoch=6.320]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.60it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.50it/s, v_num=19944, train_loss_step=5.980, train_loss_epoch=5.980]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 142.90it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 20.12it/s, v_num=19946, train_loss_step=5.890, train_loss_epoch=5.890]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 228.44it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.80it/s, v_num=19948, train_loss_step=5.920, train_loss_epoch=5.920] \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 262.65it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.62it/s, v_num=2e+4, train_loss_step=6.230, train_loss_epoch=6.230]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 221.94it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.31it/s, v_num=2e+4, train_loss_step=5.950, train_loss_epoch=5.950]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 374.99it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.83it/s, v_num=2e+4, train_loss_step=5.960, train_loss_epoch=5.960]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 206.27it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.75it/s, v_num=2e+4, train_loss_step=5.920, train_loss_epoch=5.920]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 84.13it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.18it/s, v_num=2e+4, train_loss_step=5.850, train_loss_epoch=5.850]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 300.11it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 20.30it/s, v_num=2e+4, train_loss_step=5.570, train_loss_epoch=5.570]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 167.60it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.90it/s, v_num=2e+4, train_loss_step=5.520, train_loss_epoch=5.520]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 173.28it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 20.53it/s, v_num=2e+4, train_loss_step=5.170, train_loss_epoch=5.170]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 134.02it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.62it/s, v_num=2e+4, train_loss_step=5.340, train_loss_epoch=5.340]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 371.05it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 20.48it/s, v_num=2e+4, train_loss_step=5.590, train_loss_epoch=5.590]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 44.56it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.22it/s, v_num=2e+4, train_loss_step=5.650, train_loss_epoch=5.650] \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 303.80it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.03it/s, v_num=2e+4, train_loss_step=5.450, train_loss_epoch=5.450]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 275.40it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 20.83it/s, v_num=2e+4, train_loss_step=5.380, train_loss_epoch=5.380]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 20:10:42,661] A new study created in memory with name: no-name-2677145a-acd9-4375-8ce7-6a1840c3786d\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prefix: NFLX | mode: financial | model_type: NHITS\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s, v_num=2e+4, train_loss_step=5.040, train_loss_epoch=5.040]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 54.18it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.97it/s, v_num=2e+4, train_loss_step=5.060, train_loss_epoch=5.060]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 99.90it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.25it/s, v_num=2e+4, train_loss_step=5.170, train_loss_epoch=5.170]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.65it/s, v_num=2e+4, train_loss_step=5.140, train_loss_epoch=5.140]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.61it/s, v_num=2e+4, train_loss_step=5.160, train_loss_epoch=5.160]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 57.94it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.80it/s, v_num=2e+4, train_loss_step=5.240, train_loss_epoch=5.240]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 122.41it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.25it/s, v_num=2e+4, train_loss_step=5.580, train_loss_epoch=5.580]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 106.47it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.66it/s, v_num=2e+4, train_loss_step=6.060, train_loss_epoch=6.060]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 136.32it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.32it/s, v_num=2e+4, train_loss_step=6.210, train_loss_epoch=6.210]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 75.06it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.87it/s, v_num=2e+4, train_loss_step=6.170, train_loss_epoch=6.170]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 208.12it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.41it/s, v_num=2e+4, train_loss_step=5.890, train_loss_epoch=5.890]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 80.75it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.05it/s, v_num=2e+4, train_loss_step=5.740, train_loss_epoch=5.740]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 77.29it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.33it/s, v_num=2e+4, train_loss_step=5.880, train_loss_epoch=5.880]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.15it/s, v_num=2e+4, train_loss_step=5.860, train_loss_epoch=5.860]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 87.07it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  8.43it/s, v_num=2e+4, train_loss_step=6.080, train_loss_epoch=6.080]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 219.77it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.42it/s, v_num=2e+4, train_loss_step=6.570, train_loss_epoch=6.570]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 77.89it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.88it/s, v_num=2e+4, train_loss_step=6.880, train_loss_epoch=6.880]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 200.67it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.92it/s, v_num=2e+4, train_loss_step=7.240, train_loss_epoch=7.240]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 155.89it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.75it/s, v_num=2e+4, train_loss_step=7.340, train_loss_epoch=7.340]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 66.46it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.66it/s, v_num=2e+4, train_loss_step=7.010, train_loss_epoch=7.010]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 105.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 20:12:26,983] Trial 0 finished with value: 0.4507739938080496 and parameters: {'n_blocks1': 3, 'n_blocks2': 3, 'n_blocks3': 3, 'mlp_units': 64, 'n_pool_kernel_size1': 1, 'n_pool_kernel_size2': 2, 'n_pool_kernel_size3': 1, 'learning_rate': 0.01533401671119421}. Best is trial 0 with value: 0.4507739938080496.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.11it/s, v_num=2e+4, train_loss_step=5.870, train_loss_epoch=5.870]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 371.54it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.56it/s, v_num=2e+4, train_loss_step=5.880, train_loss_epoch=5.880]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 196.67it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.45it/s, v_num=2e+4, train_loss_step=6.030, train_loss_epoch=6.030]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 288.19it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.43it/s, v_num=2e+4, train_loss_step=5.980, train_loss_epoch=5.980]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 70.31it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.76it/s, v_num=2e+4, train_loss_step=6.060, train_loss_epoch=6.060]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 285.02it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.48it/s, v_num=2e+4, train_loss_step=6.070, train_loss_epoch=6.070]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 234.23it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.52it/s, v_num=2e+4, train_loss_step=6.410, train_loss_epoch=6.410]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 35.81it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  8.82it/s, v_num=2e+4, train_loss_step=6.910, train_loss_epoch=6.910]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 298.72it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.58it/s, v_num=2e+4, train_loss_step=7.040, train_loss_epoch=7.040]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 113.26it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.98it/s, v_num=2e+4, train_loss_step=7.000, train_loss_epoch=7.000]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 76.07it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.38it/s, v_num=2e+4, train_loss_step=6.570, train_loss_epoch=6.570]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 300.04it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.44it/s, v_num=2e+4, train_loss_step=6.470, train_loss_epoch=6.470]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 95.83it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.32it/s, v_num=2e+4, train_loss_step=6.650, train_loss_epoch=6.650]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 325.14it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.24it/s, v_num=2e+4, train_loss_step=6.730, train_loss_epoch=6.730]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 46.13it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.33it/s, v_num=2e+4, train_loss_step=7.020, train_loss_epoch=7.020]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 128.97it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  6.40it/s, v_num=2e+4, train_loss_step=7.400, train_loss_epoch=7.400]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 172.22it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.13it/s, v_num=2e+4, train_loss_step=7.680, train_loss_epoch=7.680]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 102.90it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.38it/s, v_num=2e+4, train_loss_step=8.060, train_loss_epoch=8.060]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 497.19it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.83it/s, v_num=20052, train_loss_step=8.150, train_loss_epoch=8.150]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 70.93it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.17it/s, v_num=20054, train_loss_step=7.790, train_loss_epoch=7.790]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 320.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 20:14:12,598] Trial 1 finished with value: 0.3098039215686274 and parameters: {'n_blocks1': 3, 'n_blocks2': 2, 'n_blocks3': 1, 'mlp_units': 128, 'n_pool_kernel_size1': 2, 'n_pool_kernel_size2': 3, 'n_pool_kernel_size3': 1, 'learning_rate': 0.0001997010333737244}. Best is trial 0 with value: 0.4507739938080496.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.41it/s, v_num=20056, train_loss_step=5.650, train_loss_epoch=5.650]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 439.38it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.63it/s, v_num=20058, train_loss_step=5.650, train_loss_epoch=5.650]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 112.10it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.05it/s, v_num=20060, train_loss_step=5.810, train_loss_epoch=5.810]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.57it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.58it/s, v_num=20062, train_loss_step=5.760, train_loss_epoch=5.760]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 101.38it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.15it/s, v_num=20064, train_loss_step=5.830, train_loss_epoch=5.830]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 118.22it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.03it/s, v_num=20066, train_loss_step=5.840, train_loss_epoch=5.840]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 90.83it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.95it/s, v_num=20068, train_loss_step=6.190, train_loss_epoch=6.190]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 86.31it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.19it/s, v_num=20070, train_loss_step=6.700, train_loss_epoch=6.700]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 167.87it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.57it/s, v_num=20072, train_loss_step=6.810, train_loss_epoch=6.810]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 212.81it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.50it/s, v_num=20074, train_loss_step=6.770, train_loss_epoch=6.770]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 385.36it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.91it/s, v_num=20076, train_loss_step=6.370, train_loss_epoch=6.370]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 122.35it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.49it/s, v_num=20078, train_loss_step=6.250, train_loss_epoch=6.250]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 418.89it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.33it/s, v_num=20080, train_loss_step=6.430, train_loss_epoch=6.430]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 144.23it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.61it/s, v_num=20082, train_loss_step=6.500, train_loss_epoch=6.500]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 114.83it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.50it/s, v_num=20084, train_loss_step=6.790, train_loss_epoch=6.790]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 69.89it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.84it/s, v_num=20086, train_loss_step=7.200, train_loss_epoch=7.200]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 67.51it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.76it/s, v_num=20088, train_loss_step=7.490, train_loss_epoch=7.490]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.93it/s, v_num=20090, train_loss_step=7.860, train_loss_epoch=7.860]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 66.19it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.90it/s, v_num=20092, train_loss_step=7.950, train_loss_epoch=7.950]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 19.10it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.35it/s, v_num=20094, train_loss_step=7.580, train_loss_epoch=7.580]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 238.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 20:15:36,757] Trial 2 finished with value: 0.40261437908496733 and parameters: {'n_blocks1': 1, 'n_blocks2': 1, 'n_blocks3': 1, 'mlp_units': 32, 'n_pool_kernel_size1': 2, 'n_pool_kernel_size2': 1, 'n_pool_kernel_size3': 3, 'learning_rate': 0.002332310037746937}. Best is trial 0 with value: 0.4507739938080496.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.17it/s, v_num=20096, train_loss_step=5.040, train_loss_epoch=5.040]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 403.92it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  8.65it/s, v_num=20098, train_loss_step=5.060, train_loss_epoch=5.060]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 147.76it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.95it/s, v_num=20100, train_loss_step=5.170, train_loss_epoch=5.170]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 56.86it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.96it/s, v_num=20102, train_loss_step=5.140, train_loss_epoch=5.140]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 243.11it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.74it/s, v_num=20104, train_loss_step=5.160, train_loss_epoch=5.160]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 131.55it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.65it/s, v_num=20106, train_loss_step=5.240, train_loss_epoch=5.240]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 72.66it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.15it/s, v_num=20108, train_loss_step=5.580, train_loss_epoch=5.580]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.23it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.17it/s, v_num=20110, train_loss_step=6.060, train_loss_epoch=6.060]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.08it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.52it/s, v_num=20112, train_loss_step=6.210, train_loss_epoch=6.210]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.87it/s, v_num=20114, train_loss_step=6.170, train_loss_epoch=6.170]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 117.26it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.65it/s, v_num=20116, train_loss_step=5.890, train_loss_epoch=5.890]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 185.15it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.97it/s, v_num=20118, train_loss_step=5.740, train_loss_epoch=5.740]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 385.68it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.43it/s, v_num=20120, train_loss_step=5.880, train_loss_epoch=5.880]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.00it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.31it/s, v_num=20122, train_loss_step=5.860, train_loss_epoch=5.860]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 153.56it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.11it/s, v_num=20124, train_loss_step=6.080, train_loss_epoch=6.080]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 159.84it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.24it/s, v_num=20126, train_loss_step=6.570, train_loss_epoch=6.570]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 220.81it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.39it/s, v_num=20128, train_loss_step=6.880, train_loss_epoch=6.880]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 353.35it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s, v_num=20130, train_loss_step=7.240, train_loss_epoch=7.240]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 61.06it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  7.57it/s, v_num=20132, train_loss_step=7.340, train_loss_epoch=7.340]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.72it/s, v_num=20134, train_loss_step=7.010, train_loss_epoch=7.010]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 68.04it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.78it/s, v_num=20136, train_loss_step=6.870, train_loss_epoch=6.870]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.37it/s, v_num=20138, train_loss_step=6.860, train_loss_epoch=6.860]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 14.14it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.53it/s, v_num=20140, train_loss_step=6.550, train_loss_epoch=6.550]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.41it/s, v_num=20142, train_loss_step=6.140, train_loss_epoch=6.140]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.00it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.85it/s, v_num=20144, train_loss_step=6.470, train_loss_epoch=6.470]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 115.73it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.11it/s, v_num=20146, train_loss_step=6.630, train_loss_epoch=6.630]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.81it/s, v_num=20148, train_loss_step=6.590, train_loss_epoch=6.590]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.00it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  8.92it/s, v_num=20150, train_loss_step=6.580, train_loss_epoch=6.580]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 73.27it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.39it/s, v_num=20152, train_loss_step=6.650, train_loss_epoch=6.650]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 153.85it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.86it/s, v_num=20154, train_loss_step=6.670, train_loss_epoch=6.670]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 79.04it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.48it/s, v_num=20156, train_loss_step=6.520, train_loss_epoch=6.520]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 262.09it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.17it/s, v_num=20158, train_loss_step=6.660, train_loss_epoch=6.660]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 219.09it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.21it/s, v_num=20160, train_loss_step=6.390, train_loss_epoch=6.390]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 261.03it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.88it/s, v_num=20162, train_loss_step=6.010, train_loss_epoch=6.010]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.70it/s, v_num=20164, train_loss_step=5.640, train_loss_epoch=5.640]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 82.44it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.47it/s, v_num=20166, train_loss_step=5.500, train_loss_epoch=5.500]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 92.82it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.96it/s, v_num=20168, train_loss_step=5.580, train_loss_epoch=5.580]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 184.26it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.77it/s, v_num=20170, train_loss_step=5.780, train_loss_epoch=5.780]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 349.38it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.89it/s, v_num=20172, train_loss_step=5.460, train_loss_epoch=5.460]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 80.98it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.44it/s, v_num=20174, train_loss_step=5.470, train_loss_epoch=5.470]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 220.99it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.51it/s, v_num=20176, train_loss_step=5.420, train_loss_epoch=5.420]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 360.49it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.34it/s, v_num=20178, train_loss_step=5.390, train_loss_epoch=5.390]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 130.68it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.91it/s, v_num=20180, train_loss_step=5.070, train_loss_epoch=5.070]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.90it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.35it/s, v_num=20182, train_loss_step=5.070, train_loss_epoch=5.070]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.01it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.20it/s, v_num=20184, train_loss_step=4.740, train_loss_epoch=4.740]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 190.17it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.17it/s, v_num=20186, train_loss_step=4.870, train_loss_epoch=4.870]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.21it/s, v_num=20188, train_loss_step=5.100, train_loss_epoch=5.100]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 198.32it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.12it/s, v_num=20190, train_loss_step=5.190, train_loss_epoch=5.190]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 89.56it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.40it/s, v_num=20192, train_loss_step=4.930, train_loss_epoch=4.930]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 320.76it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.15it/s, v_num=20194, train_loss_step=5.030, train_loss_epoch=5.030]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 20:19:43,019] A new study created in memory with name: no-name-f051ce30-845d-4ef8-b36f-603a77bde3ac\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prefix: NFLX | mode: financial | model_type: TFT\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=20196, train_loss_step=5.630, train_loss_epoch=5.630]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 106.19it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.58it/s, v_num=20198, train_loss_step=5.440, train_loss_epoch=5.440]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 101.02it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.41it/s, v_num=20200, train_loss_step=5.450, train_loss_epoch=5.450]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 98.66it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.25it/s, v_num=20202, train_loss_step=5.540, train_loss_epoch=5.540]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 98.78it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.70it/s, v_num=20204, train_loss_step=5.660, train_loss_epoch=5.660]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 116.33it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.38it/s, v_num=20206, train_loss_step=5.340, train_loss_epoch=5.340]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 79.90it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=20208, train_loss_step=5.330, train_loss_epoch=5.330]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.62it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.32it/s, v_num=20210, train_loss_step=5.340, train_loss_epoch=5.340]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=20212, train_loss_step=5.270, train_loss_epoch=5.270]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 123.12it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.15it/s, v_num=20214, train_loss_step=5.130, train_loss_epoch=5.130]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 289.28it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.78it/s, v_num=20216, train_loss_step=4.760, train_loss_epoch=4.760]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 100.29it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=20218, train_loss_step=4.800, train_loss_epoch=4.800]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 200.07it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=20220, train_loss_step=4.910, train_loss_epoch=4.910]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 85.97it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.70it/s, v_num=20222, train_loss_step=4.870, train_loss_epoch=4.870]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 209.89it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s, v_num=20224, train_loss_step=4.910, train_loss_epoch=4.910]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 95.02it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.19it/s, v_num=20226, train_loss_step=5.040, train_loss_epoch=5.040]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 228.81it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.40it/s, v_num=20228, train_loss_step=4.890, train_loss_epoch=4.890]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 359.35it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.77it/s, v_num=20230, train_loss_step=5.160, train_loss_epoch=5.160]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 202.83it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.53it/s, v_num=20232, train_loss_step=5.210, train_loss_epoch=5.210]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 383.60it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s, v_num=20234, train_loss_step=5.250, train_loss_epoch=5.250]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 112.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 20:21:30,583] Trial 0 finished with value: 0.6235294117647059 and parameters: {'learning_rate': 0.020872845519212948, 'hidden_size': 32}. Best is trial 0 with value: 0.6235294117647059.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.94it/s, v_num=20236, train_loss_step=6.020, train_loss_epoch=6.020]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 129.98it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.42it/s, v_num=20238, train_loss_step=5.820, train_loss_epoch=5.820]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 203.70it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=20240, train_loss_step=5.810, train_loss_epoch=5.810]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 40.08it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.55it/s, v_num=20242, train_loss_step=5.930, train_loss_epoch=5.930]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 142.17it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.98it/s, v_num=20244, train_loss_step=6.010, train_loss_epoch=6.010]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 30.59it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.96it/s, v_num=20246, train_loss_step=5.670, train_loss_epoch=5.670]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 55.66it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.63it/s, v_num=20248, train_loss_step=5.660, train_loss_epoch=5.660]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 165.63it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.42it/s, v_num=20250, train_loss_step=5.650, train_loss_epoch=5.650]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 186.07it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.85it/s, v_num=20252, train_loss_step=5.600, train_loss_epoch=5.600]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 110.22it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.74it/s, v_num=20254, train_loss_step=5.440, train_loss_epoch=5.440]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 124.88it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.42it/s, v_num=20256, train_loss_step=5.070, train_loss_epoch=5.070]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 96.37it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s, v_num=20258, train_loss_step=5.090, train_loss_epoch=5.090]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 157.60it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.50it/s, v_num=20260, train_loss_step=5.220, train_loss_epoch=5.220]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 354.01it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.65it/s, v_num=20262, train_loss_step=5.150, train_loss_epoch=5.150]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 129.45it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.54it/s, v_num=20264, train_loss_step=5.180, train_loss_epoch=5.180]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.05it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s, v_num=20266, train_loss_step=5.330, train_loss_epoch=5.330]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.49it/s, v_num=20268, train_loss_step=5.210, train_loss_epoch=5.210]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 72.36it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.38it/s, v_num=20270, train_loss_step=5.490, train_loss_epoch=5.490]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 50.23it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.77it/s, v_num=20272, train_loss_step=5.550, train_loss_epoch=5.550]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 78.23it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.27it/s, v_num=20274, train_loss_step=5.590, train_loss_epoch=5.590]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 74.79it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 20:23:16,632] Trial 1 finished with value: 0.5574660633484163 and parameters: {'learning_rate': 1.513524514303846e-05, 'hidden_size': 28}. Best is trial 0 with value: 0.6235294117647059.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.12it/s, v_num=20276, train_loss_step=5.650, train_loss_epoch=5.650]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 115.06it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.98it/s, v_num=20278, train_loss_step=5.460, train_loss_epoch=5.460]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 398.96it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.14it/s, v_num=20280, train_loss_step=5.440, train_loss_epoch=5.440]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.75it/s, v_num=20282, train_loss_step=5.580, train_loss_epoch=5.580]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 96.77it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.98it/s, v_num=20284, train_loss_step=5.690, train_loss_epoch=5.690]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 96.05it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  9.51it/s, v_num=20286, train_loss_step=5.360, train_loss_epoch=5.360]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.61it/s, v_num=20288, train_loss_step=5.370, train_loss_epoch=5.370]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 112.73it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  9.27it/s, v_num=20290, train_loss_step=5.390, train_loss_epoch=5.390]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.18it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.90it/s, v_num=20292, train_loss_step=5.330, train_loss_epoch=5.330]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 68.86it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.80it/s, v_num=20294, train_loss_step=5.190, train_loss_epoch=5.190]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 199.34it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  9.37it/s, v_num=20296, train_loss_step=4.820, train_loss_epoch=4.820]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 78.15it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.37it/s, v_num=20298, train_loss_step=4.880, train_loss_epoch=4.880]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 102.38it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.85it/s, v_num=20300, train_loss_step=4.990, train_loss_epoch=4.990]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 574.80it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.46it/s, v_num=20302, train_loss_step=4.930, train_loss_epoch=4.930]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 112.81it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.41it/s, v_num=20304, train_loss_step=4.980, train_loss_epoch=4.980]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 68.42it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.48it/s, v_num=20306, train_loss_step=5.090, train_loss_epoch=5.090]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 77.79it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.59it/s, v_num=20308, train_loss_step=4.940, train_loss_epoch=4.940]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 69.63it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.40it/s, v_num=20310, train_loss_step=5.170, train_loss_epoch=5.170]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 121.81it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.61it/s, v_num=20312, train_loss_step=5.230, train_loss_epoch=5.230]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 54.69it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.38it/s, v_num=20314, train_loss_step=5.280, train_loss_epoch=5.280]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 58.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 20:24:49,080] Trial 2 finished with value: 0.48907563025210077 and parameters: {'learning_rate': 0.038136856349816256, 'hidden_size': 4}. Best is trial 0 with value: 0.6235294117647059.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=20316, train_loss_step=5.630, train_loss_epoch=5.630]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 70.51it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.52it/s, v_num=20318, train_loss_step=5.440, train_loss_epoch=5.440]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 51.76it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.23it/s, v_num=20320, train_loss_step=5.450, train_loss_epoch=5.450]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.60it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s, v_num=20322, train_loss_step=5.540, train_loss_epoch=5.540]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 260.11it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.49it/s, v_num=20324, train_loss_step=5.660, train_loss_epoch=5.660]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 327.81it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.44it/s, v_num=20326, train_loss_step=5.340, train_loss_epoch=5.340]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 242.10it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.37it/s, v_num=20328, train_loss_step=5.330, train_loss_epoch=5.330]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 74.98it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=20330, train_loss_step=5.340, train_loss_epoch=5.340]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 317.87it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.59it/s, v_num=20332, train_loss_step=5.270, train_loss_epoch=5.270]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 129.78it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.68it/s, v_num=20334, train_loss_step=5.130, train_loss_epoch=5.130]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 125.67it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.32it/s, v_num=20336, train_loss_step=4.760, train_loss_epoch=4.760]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 298.97it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.49it/s, v_num=20338, train_loss_step=4.800, train_loss_epoch=4.800]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 72.84it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.50it/s, v_num=20340, train_loss_step=4.910, train_loss_epoch=4.910]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.00it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.62it/s, v_num=20342, train_loss_step=4.870, train_loss_epoch=4.870]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 196.14it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=20344, train_loss_step=4.910, train_loss_epoch=4.910]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 51.48it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.51it/s, v_num=20346, train_loss_step=5.040, train_loss_epoch=5.040]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 597.91it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=20348, train_loss_step=4.890, train_loss_epoch=4.890]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 99.64it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.52it/s, v_num=20350, train_loss_step=5.160, train_loss_epoch=5.160]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 132.41it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.40it/s, v_num=20352, train_loss_step=5.210, train_loss_epoch=5.210]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 36.12it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.40it/s, v_num=20354, train_loss_step=5.250, train_loss_epoch=5.250]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 30.16it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.84it/s, v_num=20356, train_loss_step=5.220, train_loss_epoch=5.220]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 126.57it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.00it/s, v_num=20358, train_loss_step=5.250, train_loss_epoch=5.250]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 194.88it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.21it/s, v_num=20360, train_loss_step=5.220, train_loss_epoch=5.220]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 81.36it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.32it/s, v_num=20362, train_loss_step=5.290, train_loss_epoch=5.290]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 69.19it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.79it/s, v_num=20364, train_loss_step=5.390, train_loss_epoch=5.390]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 204.52it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.52it/s, v_num=20366, train_loss_step=5.500, train_loss_epoch=5.500]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 97.58it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.41it/s, v_num=20368, train_loss_step=5.320, train_loss_epoch=5.320]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 143.38it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.31it/s, v_num=20370, train_loss_step=5.000, train_loss_epoch=5.000]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 222.67it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.91it/s, v_num=20372, train_loss_step=5.070, train_loss_epoch=5.070]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 181.53it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.02it/s, v_num=20374, train_loss_step=5.070, train_loss_epoch=5.070]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 214.87it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.83it/s, v_num=20376, train_loss_step=5.160, train_loss_epoch=5.160]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 148.25it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.48it/s, v_num=20378, train_loss_step=5.280, train_loss_epoch=5.280]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 84.67it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.70it/s, v_num=20380, train_loss_step=5.350, train_loss_epoch=5.350]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.70it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.18it/s, v_num=20382, train_loss_step=5.380, train_loss_epoch=5.380]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 204.66it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=20384, train_loss_step=5.350, train_loss_epoch=5.350]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 234.76it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.57it/s, v_num=20386, train_loss_step=5.450, train_loss_epoch=5.450]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 27.58it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.05it/s, v_num=20388, train_loss_step=5.520, train_loss_epoch=5.520]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 272.23it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=20390, train_loss_step=5.790, train_loss_epoch=5.790]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 589.34it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.40it/s, v_num=20392, train_loss_step=6.180, train_loss_epoch=6.180]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 151.39it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.30it/s, v_num=20394, train_loss_step=6.290, train_loss_epoch=6.290]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 67.71it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s, v_num=20396, train_loss_step=6.130, train_loss_epoch=6.130]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 188.41it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.77it/s, v_num=20398, train_loss_step=6.080, train_loss_epoch=6.080]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 59.89it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.18it/s, v_num=20400, train_loss_step=6.160, train_loss_epoch=6.160]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 46.04it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s, v_num=20402, train_loss_step=6.230, train_loss_epoch=6.230]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 60.12it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.40it/s, v_num=20404, train_loss_step=6.130, train_loss_epoch=6.130]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.00it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.58it/s, v_num=20406, train_loss_step=6.140, train_loss_epoch=6.140]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 219.49it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.52it/s, v_num=20408, train_loss_step=6.470, train_loss_epoch=6.470]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 129.64it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.86it/s, v_num=20410, train_loss_step=6.470, train_loss_epoch=6.470]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 299.55it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.48it/s, v_num=20412, train_loss_step=6.440, train_loss_epoch=6.440]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 42.96it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.28it/s, v_num=20414, train_loss_step=6.510, train_loss_epoch=6.510]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 104.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 20:29:25,955] A new study created in memory with name: no-name-82308b7e-2410-4fc0-b606-923690b7afcc\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prefix: NFLX | mode: news | model_type: NBEATS\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.04it/s, v_num=20416, train_loss_step=6.500, train_loss_epoch=6.500]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 672.06it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.25it/s, v_num=20418, train_loss_step=6.500, train_loss_epoch=6.500]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.91it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.62it/s, v_num=20420, train_loss_step=6.630, train_loss_epoch=6.630]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 291.39it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.51it/s, v_num=20422, train_loss_step=6.580, train_loss_epoch=6.580]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 200.47it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.66it/s, v_num=20424, train_loss_step=6.640, train_loss_epoch=6.640]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 219.22it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.41it/s, v_num=20426, train_loss_step=6.650, train_loss_epoch=6.650]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 979.75it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.88it/s, v_num=20428, train_loss_step=6.990, train_loss_epoch=6.990]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 117.91it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.85it/s, v_num=20430, train_loss_step=7.500, train_loss_epoch=7.500]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.14it/s, v_num=20432, train_loss_step=7.640, train_loss_epoch=7.640]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 60.25it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.86it/s, v_num=20434, train_loss_step=7.590, train_loss_epoch=7.590]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 272.84it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.03it/s, v_num=20436, train_loss_step=7.110, train_loss_epoch=7.110]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 199.17it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.11it/s, v_num=20438, train_loss_step=7.020, train_loss_epoch=7.020]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 325.62it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.30it/s, v_num=20440, train_loss_step=7.210, train_loss_epoch=7.210]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 83.48it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.27it/s, v_num=20442, train_loss_step=7.300, train_loss_epoch=7.300]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 198.03it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.54it/s, v_num=20444, train_loss_step=7.570, train_loss_epoch=7.570]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 264.51it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s, v_num=20446, train_loss_step=7.970, train_loss_epoch=7.970]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 229.35it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.46it/s, v_num=20448, train_loss_step=8.230, train_loss_epoch=8.230]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 157.77it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.04it/s, v_num=20450, train_loss_step=8.650, train_loss_epoch=8.650]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 759.56it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.12it/s, v_num=20452, train_loss_step=8.740, train_loss_epoch=8.740]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 135.76it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.91it/s, v_num=20454, train_loss_step=8.370, train_loss_epoch=8.370]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 122.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 20:30:59,007] Trial 0 finished with value: 0.24117647058823533 and parameters: {'n_blocks_season': 1, 'n_blocks_trend': 1, 'n_blocks_ident': 2, 'mlp_units': 128, 'num_hidden': 2, 'n_harmonics': 2, 'n_polynomials': 2, 'learning_rate': 2.6049666586688852e-05}. Best is trial 0 with value: 0.24117647058823533.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.69it/s, v_num=20456, train_loss_step=5.510, train_loss_epoch=5.510]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 84.84it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.97it/s, v_num=20458, train_loss_step=5.490, train_loss_epoch=5.490]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 123.95it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.73it/s, v_num=20460, train_loss_step=5.620, train_loss_epoch=5.620]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 362.64it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.82it/s, v_num=20462, train_loss_step=5.520, train_loss_epoch=5.520]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 325.29it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.94it/s, v_num=20464, train_loss_step=5.540, train_loss_epoch=5.540]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 475.60it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.91it/s, v_num=20466, train_loss_step=5.580, train_loss_epoch=5.580]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 207.48it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, v_num=20468, train_loss_step=5.910, train_loss_epoch=5.910]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 74.52it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.97it/s, v_num=20470, train_loss_step=6.380, train_loss_epoch=6.380]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 200.21it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.24it/s, v_num=20472, train_loss_step=6.500, train_loss_epoch=6.500]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 206.97it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.09it/s, v_num=20474, train_loss_step=6.470, train_loss_epoch=6.470]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 308.06it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.85it/s, v_num=20476, train_loss_step=6.090, train_loss_epoch=6.090]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 188.89it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.27it/s, v_num=20478, train_loss_step=5.980, train_loss_epoch=5.980]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.73it/s, v_num=20480, train_loss_step=6.130, train_loss_epoch=6.130]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 104.37it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.67it/s, v_num=20482, train_loss_step=6.150, train_loss_epoch=6.150]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 247.51it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.57it/s, v_num=20484, train_loss_step=6.390, train_loss_epoch=6.390]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 90.94it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.98it/s, v_num=20486, train_loss_step=6.820, train_loss_epoch=6.820]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 70.81it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.46it/s, v_num=20488, train_loss_step=7.080, train_loss_epoch=7.080]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 72.95it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.47it/s, v_num=20490, train_loss_step=7.470, train_loss_epoch=7.470]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.02it/s, v_num=20492, train_loss_step=7.500, train_loss_epoch=7.500]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 76.02it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.90it/s, v_num=20494, train_loss_step=7.170, train_loss_epoch=7.170]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 20:32:33,715] Trial 1 finished with value: 0.4741687979539642 and parameters: {'n_blocks_season': 3, 'n_blocks_trend': 3, 'n_blocks_ident': 1, 'mlp_units': 32, 'num_hidden': 3, 'n_harmonics': 3, 'n_polynomials': 1, 'learning_rate': 0.005352548860445602}. Best is trial 1 with value: 0.4741687979539642.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.67it/s, v_num=20496, train_loss_step=5.490, train_loss_epoch=5.490]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.45it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.96it/s, v_num=20498, train_loss_step=5.470, train_loss_epoch=5.470]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 435.23it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.02it/s, v_num=20500, train_loss_step=5.580, train_loss_epoch=5.580]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 201.39it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.38it/s, v_num=20502, train_loss_step=5.480, train_loss_epoch=5.480]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 497.43it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.15it/s, v_num=20504, train_loss_step=5.500, train_loss_epoch=5.500]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.05it/s, v_num=20506, train_loss_step=5.550, train_loss_epoch=5.550]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.97it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 20.00it/s, v_num=20508, train_loss_step=5.880, train_loss_epoch=5.880]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 77.86it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.08it/s, v_num=20510, train_loss_step=6.340, train_loss_epoch=6.340]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.67it/s, v_num=20512, train_loss_step=6.450, train_loss_epoch=6.450]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 300.45it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.68it/s, v_num=20514, train_loss_step=6.420, train_loss_epoch=6.420]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 212.23it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.32it/s, v_num=20516, train_loss_step=6.080, train_loss_epoch=6.080]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 269.92it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.36it/s, v_num=20518, train_loss_step=5.980, train_loss_epoch=5.980]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 279.40it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.13it/s, v_num=20520, train_loss_step=6.120, train_loss_epoch=6.120]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 150.65it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.53it/s, v_num=20522, train_loss_step=6.140, train_loss_epoch=6.140]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 471.01it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.81it/s, v_num=20524, train_loss_step=6.330, train_loss_epoch=6.330]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 154.30it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.17it/s, v_num=20526, train_loss_step=6.770, train_loss_epoch=6.770]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 59.74it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.18it/s, v_num=20528, train_loss_step=7.040, train_loss_epoch=7.040]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 150.49it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.27it/s, v_num=20530, train_loss_step=7.410, train_loss_epoch=7.410]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.73it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.53it/s, v_num=20532, train_loss_step=7.440, train_loss_epoch=7.440]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.61it/s, v_num=20534, train_loss_step=7.120, train_loss_epoch=7.120]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 100.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 20:34:00,885] Trial 2 finished with value: 0.4741687979539642 and parameters: {'n_blocks_season': 3, 'n_blocks_trend': 1, 'n_blocks_ident': 1, 'mlp_units': 32, 'num_hidden': 2, 'n_harmonics': 2, 'n_polynomials': 4, 'learning_rate': 0.03018544348561157}. Best is trial 1 with value: 0.4741687979539642.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.84it/s, v_num=20536, train_loss_step=5.510, train_loss_epoch=5.510]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 169.44it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.07it/s, v_num=20538, train_loss_step=5.490, train_loss_epoch=5.490]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 203.03it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.68it/s, v_num=20540, train_loss_step=5.620, train_loss_epoch=5.620]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 246.75it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.59it/s, v_num=20542, train_loss_step=5.520, train_loss_epoch=5.520]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 190.37it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.00it/s, v_num=20544, train_loss_step=5.540, train_loss_epoch=5.540]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 143.21it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.63it/s, v_num=20546, train_loss_step=5.580, train_loss_epoch=5.580]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 255.14it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.04it/s, v_num=20548, train_loss_step=5.910, train_loss_epoch=5.910]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 494.26it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.60it/s, v_num=20550, train_loss_step=6.380, train_loss_epoch=6.380]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 126.81it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.05it/s, v_num=20552, train_loss_step=6.500, train_loss_epoch=6.500]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 154.32it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.99it/s, v_num=20554, train_loss_step=6.470, train_loss_epoch=6.470]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 144.42it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.17it/s, v_num=20556, train_loss_step=6.090, train_loss_epoch=6.090]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.82it/s, v_num=20558, train_loss_step=5.980, train_loss_epoch=5.980]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 153.69it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.46it/s, v_num=20560, train_loss_step=6.130, train_loss_epoch=6.130]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 80.18it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.34it/s, v_num=20562, train_loss_step=6.150, train_loss_epoch=6.150]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 117.82it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.82it/s, v_num=20564, train_loss_step=6.390, train_loss_epoch=6.390]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 213.21it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.52it/s, v_num=20566, train_loss_step=6.820, train_loss_epoch=6.820]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 512.19it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.86it/s, v_num=20568, train_loss_step=7.080, train_loss_epoch=7.080]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 90.65it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.30it/s, v_num=20570, train_loss_step=7.470, train_loss_epoch=7.470]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 234.27it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.01it/s, v_num=20572, train_loss_step=7.500, train_loss_epoch=7.500]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 82.32it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.11it/s, v_num=20574, train_loss_step=7.170, train_loss_epoch=7.170]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 81.84it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.75it/s, v_num=20576, train_loss_step=7.190, train_loss_epoch=7.190]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 38.71it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.49it/s, v_num=20578, train_loss_step=7.160, train_loss_epoch=7.160]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 335.81it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.82it/s, v_num=20580, train_loss_step=6.860, train_loss_epoch=6.860]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 257.05it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.65it/s, v_num=20582, train_loss_step=6.460, train_loss_epoch=6.460]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 452.22it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.97it/s, v_num=20584, train_loss_step=6.770, train_loss_epoch=6.770]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.26it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.26it/s, v_num=20586, train_loss_step=6.970, train_loss_epoch=6.970]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 69.19it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.69it/s, v_num=20588, train_loss_step=6.940, train_loss_epoch=6.940]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.14it/s, v_num=20590, train_loss_step=6.920, train_loss_epoch=6.920]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.05it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.24it/s, v_num=20592, train_loss_step=6.990, train_loss_epoch=6.990]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 128.45it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.67it/s, v_num=20594, train_loss_step=7.090, train_loss_epoch=7.090]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 124.24it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.23it/s, v_num=20596, train_loss_step=6.940, train_loss_epoch=6.940]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 995.09it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.46it/s, v_num=20598, train_loss_step=7.070, train_loss_epoch=7.070]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 211.09it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.99it/s, v_num=20600, train_loss_step=6.710, train_loss_epoch=6.710]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 177.01it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.38it/s, v_num=20602, train_loss_step=6.340, train_loss_epoch=6.340]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 159.89it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.26it/s, v_num=20604, train_loss_step=5.990, train_loss_epoch=5.990]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 58.26it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.83it/s, v_num=20606, train_loss_step=5.890, train_loss_epoch=5.890]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 114.03it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.78it/s, v_num=20608, train_loss_step=5.930, train_loss_epoch=5.930]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 119.65it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.18it/s, v_num=20610, train_loss_step=6.230, train_loss_epoch=6.230]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 264.66it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.41it/s, v_num=20612, train_loss_step=5.940, train_loss_epoch=5.940]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 325.77it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.84it/s, v_num=20614, train_loss_step=5.960, train_loss_epoch=5.960]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 68.88it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.33it/s, v_num=20616, train_loss_step=5.910, train_loss_epoch=5.910]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 328.99it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.26it/s, v_num=20618, train_loss_step=5.840, train_loss_epoch=5.840]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 53.79it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.93it/s, v_num=20620, train_loss_step=5.530, train_loss_epoch=5.530]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 116.02it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.26it/s, v_num=20622, train_loss_step=5.490, train_loss_epoch=5.490]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 336.38it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.26it/s, v_num=20624, train_loss_step=5.130, train_loss_epoch=5.130]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.91it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.84it/s, v_num=20626, train_loss_step=5.290, train_loss_epoch=5.290]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 65.64it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.44it/s, v_num=20628, train_loss_step=5.540, train_loss_epoch=5.540]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 117.72it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.47it/s, v_num=20630, train_loss_step=5.590, train_loss_epoch=5.590]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 101.80it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.53it/s, v_num=20632, train_loss_step=5.400, train_loss_epoch=5.400]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 122.39it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.55it/s, v_num=20634, train_loss_step=5.340, train_loss_epoch=5.340]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 105.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 20:37:50,351] A new study created in memory with name: no-name-1a612480-43b9-4dad-a5d4-0314ca356876\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prefix: NFLX | mode: news | model_type: NHITS\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.77it/s, v_num=20636, train_loss_step=5.850, train_loss_epoch=5.850]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 327.14it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.26it/s, v_num=20638, train_loss_step=5.850, train_loss_epoch=5.850]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.84it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.74it/s, v_num=20640, train_loss_step=6.120, train_loss_epoch=6.120]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 146.54it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.77it/s, v_num=20642, train_loss_step=6.210, train_loss_epoch=6.210]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 161.74it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.65it/s, v_num=20644, train_loss_step=6.070, train_loss_epoch=6.070]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 318.91it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.14it/s, v_num=20646, train_loss_step=6.270, train_loss_epoch=6.270]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 249.39it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.79it/s, v_num=20648, train_loss_step=6.750, train_loss_epoch=6.750]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 104.14it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.55it/s, v_num=20650, train_loss_step=7.310, train_loss_epoch=7.310]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 167.47it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.44it/s, v_num=20652, train_loss_step=7.480, train_loss_epoch=7.480]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 148.54it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.66it/s, v_num=20654, train_loss_step=7.210, train_loss_epoch=7.210]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.30it/s, v_num=20656, train_loss_step=6.910, train_loss_epoch=6.910]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.03it/s, v_num=20658, train_loss_step=6.530, train_loss_epoch=6.530]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.28it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.73it/s, v_num=20660, train_loss_step=7.100, train_loss_epoch=7.100]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 81.37it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.89it/s, v_num=20662, train_loss_step=6.840, train_loss_epoch=6.840]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 102.49it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.13it/s, v_num=20664, train_loss_step=7.030, train_loss_epoch=7.030]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 450.56it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.20it/s, v_num=20666, train_loss_step=6.900, train_loss_epoch=6.900]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 195.86it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.94it/s, v_num=20668, train_loss_step=7.580, train_loss_epoch=7.580]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 198.92it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.22it/s, v_num=20670, train_loss_step=8.390, train_loss_epoch=8.390]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 193.96it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.94it/s, v_num=20672, train_loss_step=8.600, train_loss_epoch=8.600]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 112.31it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.36it/s, v_num=20674, train_loss_step=7.170, train_loss_epoch=7.170]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 115.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 20:39:19,834] Trial 0 finished with value: 0.46764705882352936 and parameters: {'n_blocks1': 2, 'n_blocks2': 1, 'n_blocks3': 1, 'mlp_units': 64, 'n_pool_kernel_size1': 3, 'n_pool_kernel_size2': 3, 'n_pool_kernel_size3': 3, 'learning_rate': 0.029946250989078306}. Best is trial 0 with value: 0.46764705882352936.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.44it/s, v_num=20676, train_loss_step=6.560, train_loss_epoch=6.560]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 104.56it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.74it/s, v_num=20678, train_loss_step=6.560, train_loss_epoch=6.560]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 328.73it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.58it/s, v_num=20680, train_loss_step=6.680, train_loss_epoch=6.680]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.62it/s, v_num=20682, train_loss_step=6.630, train_loss_epoch=6.630]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 85.42it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.37it/s, v_num=20684, train_loss_step=6.700, train_loss_epoch=6.700]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 149.69it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.65it/s, v_num=20686, train_loss_step=6.710, train_loss_epoch=6.710]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.93it/s, v_num=20688, train_loss_step=7.040, train_loss_epoch=7.040]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 50.37it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.25it/s, v_num=20690, train_loss_step=7.540, train_loss_epoch=7.540]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.47it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.57it/s, v_num=20692, train_loss_step=7.700, train_loss_epoch=7.700]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 993.20it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.47it/s, v_num=20694, train_loss_step=7.650, train_loss_epoch=7.650]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.42it/s, v_num=20696, train_loss_step=7.170, train_loss_epoch=7.170]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 68.19it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.96it/s, v_num=20698, train_loss_step=7.090, train_loss_epoch=7.090]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 101.06it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s, v_num=20700, train_loss_step=7.280, train_loss_epoch=7.280]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.00it/s, v_num=20702, train_loss_step=7.370, train_loss_epoch=7.370]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 86.88it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.73it/s, v_num=20704, train_loss_step=7.650, train_loss_epoch=7.650]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.54it/s, v_num=20706, train_loss_step=8.030, train_loss_epoch=8.030]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 129.22it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.51it/s, v_num=20708, train_loss_step=8.290, train_loss_epoch=8.290]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.91it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.84it/s, v_num=20710, train_loss_step=8.710, train_loss_epoch=8.710]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.64it/s, v_num=20712, train_loss_step=8.790, train_loss_epoch=8.790]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 135.10it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.15it/s, v_num=20714, train_loss_step=8.420, train_loss_epoch=8.420]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 96.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 20:40:51,997] Trial 1 finished with value: 0.24117647058823533 and parameters: {'n_blocks1': 3, 'n_blocks2': 3, 'n_blocks3': 1, 'mlp_units': 32, 'n_pool_kernel_size1': 2, 'n_pool_kernel_size2': 2, 'n_pool_kernel_size3': 3, 'learning_rate': 2.1756607712788766e-05}. Best is trial 0 with value: 0.46764705882352936.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.53it/s, v_num=20716, train_loss_step=5.470, train_loss_epoch=5.470]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 198.94it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.61it/s, v_num=20718, train_loss_step=5.490, train_loss_epoch=5.490]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 264.98it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.46it/s, v_num=20720, train_loss_step=5.670, train_loss_epoch=5.670]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 180.31it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.97it/s, v_num=20722, train_loss_step=5.500, train_loss_epoch=5.500]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 115.49it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.12it/s, v_num=20724, train_loss_step=5.450, train_loss_epoch=5.450]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 112.68it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.23it/s, v_num=20726, train_loss_step=5.500, train_loss_epoch=5.500]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 385.47it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.98it/s, v_num=20728, train_loss_step=5.770, train_loss_epoch=5.770]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 296.02it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.39it/s, v_num=20730, train_loss_step=6.320, train_loss_epoch=6.320]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 264.11it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.66it/s, v_num=20732, train_loss_step=6.420, train_loss_epoch=6.420]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 148.63it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.05it/s, v_num=20734, train_loss_step=6.380, train_loss_epoch=6.380]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 66.40it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.55it/s, v_num=20736, train_loss_step=5.990, train_loss_epoch=5.990]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 57.48it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.90it/s, v_num=20738, train_loss_step=5.930, train_loss_epoch=5.930]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 258.78it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 20.59it/s, v_num=20740, train_loss_step=6.040, train_loss_epoch=6.040]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 220.67it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.19it/s, v_num=20742, train_loss_step=6.080, train_loss_epoch=6.080]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 70.34it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.14it/s, v_num=20744, train_loss_step=6.280, train_loss_epoch=6.280]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 101.07it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.31it/s, v_num=20746, train_loss_step=6.630, train_loss_epoch=6.630]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 89.68it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.85it/s, v_num=20748, train_loss_step=6.940, train_loss_epoch=6.940]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 260.61it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.27it/s, v_num=20750, train_loss_step=7.250, train_loss_epoch=7.250]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 80.60it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.40it/s, v_num=20752, train_loss_step=7.410, train_loss_epoch=7.410]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 578.37it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.60it/s, v_num=20754, train_loss_step=7.100, train_loss_epoch=7.100]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 172.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 20:42:20,667] Trial 2 finished with value: 0.5067873303167421 and parameters: {'n_blocks1': 2, 'n_blocks2': 1, 'n_blocks3': 2, 'mlp_units': 32, 'n_pool_kernel_size1': 2, 'n_pool_kernel_size2': 2, 'n_pool_kernel_size3': 3, 'learning_rate': 0.021233726084412603}. Best is trial 2 with value: 0.5067873303167421.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.45it/s, v_num=20756, train_loss_step=5.470, train_loss_epoch=5.470]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 383.43it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.30it/s, v_num=20758, train_loss_step=5.490, train_loss_epoch=5.490]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.47it/s, v_num=20760, train_loss_step=5.670, train_loss_epoch=5.670]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 549.42it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.05it/s, v_num=20762, train_loss_step=5.500, train_loss_epoch=5.500]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 126.17it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.82it/s, v_num=20764, train_loss_step=5.450, train_loss_epoch=5.450]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 138.86it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.48it/s, v_num=20766, train_loss_step=5.500, train_loss_epoch=5.500]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 123.65it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.72it/s, v_num=20768, train_loss_step=5.770, train_loss_epoch=5.770]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 56.01it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.64it/s, v_num=20770, train_loss_step=6.320, train_loss_epoch=6.320]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 70.65it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.17it/s, v_num=20772, train_loss_step=6.420, train_loss_epoch=6.420]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 194.83it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.41it/s, v_num=20774, train_loss_step=6.380, train_loss_epoch=6.380]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 249.39it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.67it/s, v_num=20776, train_loss_step=5.990, train_loss_epoch=5.990]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 157.18it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.33it/s, v_num=20778, train_loss_step=5.930, train_loss_epoch=5.930]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 73.82it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.51it/s, v_num=20780, train_loss_step=6.040, train_loss_epoch=6.040]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 307.64it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.59it/s, v_num=20782, train_loss_step=6.080, train_loss_epoch=6.080]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 139.02it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.77it/s, v_num=20784, train_loss_step=6.280, train_loss_epoch=6.280]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 72.45it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.68it/s, v_num=20786, train_loss_step=6.630, train_loss_epoch=6.630]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 114.12it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.94it/s, v_num=20788, train_loss_step=6.940, train_loss_epoch=6.940]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 221.41it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.55it/s, v_num=20790, train_loss_step=7.250, train_loss_epoch=7.250]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 327.63it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.95it/s, v_num=20792, train_loss_step=7.410, train_loss_epoch=7.410]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 269.75it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.51it/s, v_num=20794, train_loss_step=7.100, train_loss_epoch=7.100]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 233.21it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.28it/s, v_num=20796, train_loss_step=7.210, train_loss_epoch=7.210]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 110.63it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.37it/s, v_num=20798, train_loss_step=7.130, train_loss_epoch=7.130]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 114.72it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.50it/s, v_num=20800, train_loss_step=6.830, train_loss_epoch=6.830]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 717.47it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.46it/s, v_num=20802, train_loss_step=6.480, train_loss_epoch=6.480]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 148.89it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.42it/s, v_num=20804, train_loss_step=6.690, train_loss_epoch=6.690]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 114.61it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.38it/s, v_num=20806, train_loss_step=6.910, train_loss_epoch=6.910]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 123.49it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.99it/s, v_num=20808, train_loss_step=6.890, train_loss_epoch=6.890]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 149.55it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.19it/s, v_num=20810, train_loss_step=6.820, train_loss_epoch=6.820]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 272.45it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.35it/s, v_num=20812, train_loss_step=6.880, train_loss_epoch=6.880]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 128.25it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.55it/s, v_num=20814, train_loss_step=7.000, train_loss_epoch=7.000]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 141.16it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.17it/s, v_num=20816, train_loss_step=6.880, train_loss_epoch=6.880]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 150.45it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.13it/s, v_num=20818, train_loss_step=6.980, train_loss_epoch=6.980]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.57it/s, v_num=20820, train_loss_step=6.670, train_loss_epoch=6.670]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 173.97it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.73it/s, v_num=20822, train_loss_step=6.270, train_loss_epoch=6.270]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 176.29it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.38it/s, v_num=20824, train_loss_step=5.960, train_loss_epoch=5.960]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.49it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.94it/s, v_num=20826, train_loss_step=5.930, train_loss_epoch=5.930]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.16it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.94it/s, v_num=20828, train_loss_step=5.910, train_loss_epoch=5.910]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 69.41it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.25it/s, v_num=20830, train_loss_step=6.220, train_loss_epoch=6.220]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 181.51it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.37it/s, v_num=20832, train_loss_step=5.920, train_loss_epoch=5.920]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 205.74it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.86it/s, v_num=20834, train_loss_step=6.010, train_loss_epoch=6.010]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 203.96it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.53it/s, v_num=20836, train_loss_step=5.850, train_loss_epoch=5.850]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 109.37it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.67it/s, v_num=20838, train_loss_step=5.840, train_loss_epoch=5.840]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 235.08it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.95it/s, v_num=20840, train_loss_step=5.560, train_loss_epoch=5.560]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 139.20it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.82it/s, v_num=20842, train_loss_step=5.500, train_loss_epoch=5.500]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 263.15it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.80it/s, v_num=20844, train_loss_step=5.120, train_loss_epoch=5.120]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 386.68it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.09it/s, v_num=20846, train_loss_step=5.250, train_loss_epoch=5.250]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 60.92it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.51it/s, v_num=20848, train_loss_step=5.470, train_loss_epoch=5.470]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 58.58it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.96it/s, v_num=20850, train_loss_step=5.540, train_loss_epoch=5.540]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 95.28it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.29it/s, v_num=20852, train_loss_step=5.330, train_loss_epoch=5.330]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 80.22it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.11it/s, v_num=20854, train_loss_step=5.280, train_loss_epoch=5.280]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 80.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 20:46:02,081] A new study created in memory with name: no-name-20ad9bf6-6bc8-484e-aac6-0e677c8b0b33\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prefix: NFLX | mode: news | model_type: TFT\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.67it/s, v_num=20856, train_loss_step=5.920, train_loss_epoch=5.920]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 61.18it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.45it/s, v_num=20858, train_loss_step=5.740, train_loss_epoch=5.740]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 66.66it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.16it/s, v_num=20860, train_loss_step=5.740, train_loss_epoch=5.740]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 60.99it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.84it/s, v_num=20862, train_loss_step=5.870, train_loss_epoch=5.870]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 95.17it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.98it/s, v_num=20864, train_loss_step=6.000, train_loss_epoch=6.000]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 73.82it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.62it/s, v_num=20866, train_loss_step=5.680, train_loss_epoch=5.680]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.48it/s, v_num=20868, train_loss_step=5.660, train_loss_epoch=5.660]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 107.40it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.03it/s, v_num=20870, train_loss_step=5.680, train_loss_epoch=5.680]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 254.99it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  9.06it/s, v_num=20872, train_loss_step=5.610, train_loss_epoch=5.610]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.28it/s, v_num=20874, train_loss_step=5.460, train_loss_epoch=5.460]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 86.86it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.81it/s, v_num=20876, train_loss_step=5.090, train_loss_epoch=5.090]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 229.08it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.44it/s, v_num=20878, train_loss_step=5.110, train_loss_epoch=5.110]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.01it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.32it/s, v_num=20880, train_loss_step=5.210, train_loss_epoch=5.210]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 100.96it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.19it/s, v_num=20882, train_loss_step=5.150, train_loss_epoch=5.150]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.04it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.58it/s, v_num=20884, train_loss_step=5.180, train_loss_epoch=5.180]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.64it/s, v_num=20886, train_loss_step=5.320, train_loss_epoch=5.320]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 137.07it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.86it/s, v_num=20888, train_loss_step=5.240, train_loss_epoch=5.240]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.26it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.83it/s, v_num=20890, train_loss_step=5.510, train_loss_epoch=5.510]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.42it/s, v_num=20892, train_loss_step=5.570, train_loss_epoch=5.570]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 504.79it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.58it/s, v_num=20894, train_loss_step=5.640, train_loss_epoch=5.640]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 89.59it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 20:47:37,223] Trial 0 finished with value: 0.6807843137254903 and parameters: {'learning_rate': 0.00019494718650438748, 'hidden_size': 4}. Best is trial 0 with value: 0.6807843137254903.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.23it/s, v_num=20896, train_loss_step=5.800, train_loss_epoch=5.800]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 149.89it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.18it/s, v_num=20898, train_loss_step=5.620, train_loss_epoch=5.620]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 55.52it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.89it/s, v_num=20900, train_loss_step=5.620, train_loss_epoch=5.620]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 133.10it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=20902, train_loss_step=5.750, train_loss_epoch=5.750]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 87.08it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.19it/s, v_num=20904, train_loss_step=5.870, train_loss_epoch=5.870]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 29.36it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.84it/s, v_num=20906, train_loss_step=5.550, train_loss_epoch=5.550]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 186.96it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.25it/s, v_num=20908, train_loss_step=5.550, train_loss_epoch=5.550]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 366.28it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.24it/s, v_num=20910, train_loss_step=5.580, train_loss_epoch=5.580]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 237.80it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.94it/s, v_num=20912, train_loss_step=5.510, train_loss_epoch=5.510]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 906.88it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.04it/s, v_num=20914, train_loss_step=5.360, train_loss_epoch=5.360]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 512.63it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.36it/s, v_num=20916, train_loss_step=4.990, train_loss_epoch=4.990]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.91it/s, v_num=20918, train_loss_step=5.020, train_loss_epoch=5.020]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 461.12it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.96it/s, v_num=20920, train_loss_step=5.120, train_loss_epoch=5.120]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 117.56it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.33it/s, v_num=20922, train_loss_step=5.060, train_loss_epoch=5.060]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 122.51it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.84it/s, v_num=20924, train_loss_step=5.100, train_loss_epoch=5.100]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 72.01it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.93it/s, v_num=20926, train_loss_step=5.230, train_loss_epoch=5.230]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.51it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.24it/s, v_num=20928, train_loss_step=5.120, train_loss_epoch=5.120]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 96.14it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.18it/s, v_num=20930, train_loss_step=5.370, train_loss_epoch=5.370]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=20932, train_loss_step=5.430, train_loss_epoch=5.430]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 101.18it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.23it/s, v_num=20934, train_loss_step=5.490, train_loss_epoch=5.490]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 20:49:26,700] Trial 1 finished with value: 0.6013071895424836 and parameters: {'learning_rate': 4.5807369285682176e-05, 'hidden_size': 28}. Best is trial 0 with value: 0.6807843137254903.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s, v_num=20936, train_loss_step=5.660, train_loss_epoch=5.660]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 83.75it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.12it/s, v_num=20938, train_loss_step=5.470, train_loss_epoch=5.470]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 159.61it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.70it/s, v_num=20940, train_loss_step=5.460, train_loss_epoch=5.460]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 79.90it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.88it/s, v_num=20942, train_loss_step=5.580, train_loss_epoch=5.580]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 151.05it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.84it/s, v_num=20944, train_loss_step=5.680, train_loss_epoch=5.680]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 319.15it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.63it/s, v_num=20946, train_loss_step=5.360, train_loss_epoch=5.360]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 197.05it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.65it/s, v_num=20948, train_loss_step=5.400, train_loss_epoch=5.400]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 148.41it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.07it/s, v_num=20950, train_loss_step=5.400, train_loss_epoch=5.400]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 55.38it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s, v_num=20952, train_loss_step=5.340, train_loss_epoch=5.340]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 70.41it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.00it/s, v_num=20954, train_loss_step=5.200, train_loss_epoch=5.200]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 455.75it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.29it/s, v_num=20956, train_loss_step=4.830, train_loss_epoch=4.830]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 105.22it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.92it/s, v_num=20958, train_loss_step=4.870, train_loss_epoch=4.870]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 131.04it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.55it/s, v_num=20960, train_loss_step=4.970, train_loss_epoch=4.970]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 452.75it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.86it/s, v_num=20962, train_loss_step=4.930, train_loss_epoch=4.930]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.98it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.91it/s, v_num=20964, train_loss_step=4.990, train_loss_epoch=4.990]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 321.16it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.64it/s, v_num=20966, train_loss_step=5.100, train_loss_epoch=5.100]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 97.88it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.73it/s, v_num=20968, train_loss_step=4.950, train_loss_epoch=4.950]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.53it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.64it/s, v_num=20970, train_loss_step=5.170, train_loss_epoch=5.170]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 105.94it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.68it/s, v_num=20972, train_loss_step=5.250, train_loss_epoch=5.250]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 280.39it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.86it/s, v_num=20974, train_loss_step=5.280, train_loss_epoch=5.280]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 196.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 20:51:12,634] Trial 2 finished with value: 0.40261437908496733 and parameters: {'learning_rate': 0.0002605164691006754, 'hidden_size': 20}. Best is trial 0 with value: 0.6807843137254903.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.86it/s, v_num=20976, train_loss_step=5.920, train_loss_epoch=5.920]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 150.07it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.01it/s, v_num=20978, train_loss_step=5.740, train_loss_epoch=5.740]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 369.12it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.97it/s, v_num=20980, train_loss_step=5.740, train_loss_epoch=5.740]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 285.40it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.61it/s, v_num=20982, train_loss_step=5.870, train_loss_epoch=5.870]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 199.76it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s, v_num=20984, train_loss_step=6.000, train_loss_epoch=6.000]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 146.28it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.42it/s, v_num=20986, train_loss_step=5.680, train_loss_epoch=5.680]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 71.38it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.56it/s, v_num=20988, train_loss_step=5.660, train_loss_epoch=5.660]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.00it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.23it/s, v_num=20990, train_loss_step=5.680, train_loss_epoch=5.680]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 114.75it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.98it/s, v_num=20992, train_loss_step=5.610, train_loss_epoch=5.610]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 58.30it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.18it/s, v_num=20994, train_loss_step=5.460, train_loss_epoch=5.460]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 95.99it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.95it/s, v_num=20996, train_loss_step=5.090, train_loss_epoch=5.090]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 173.02it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.33it/s, v_num=20998, train_loss_step=5.110, train_loss_epoch=5.110]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 263.06it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.27it/s, v_num=21000, train_loss_step=5.210, train_loss_epoch=5.210]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 103.37it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.20it/s, v_num=21002, train_loss_step=5.150, train_loss_epoch=5.150]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 215.95it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.57it/s, v_num=21004, train_loss_step=5.180, train_loss_epoch=5.180]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 56.81it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.06it/s, v_num=21006, train_loss_step=5.320, train_loss_epoch=5.320]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.25it/s, v_num=21008, train_loss_step=5.240, train_loss_epoch=5.240]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 292.96it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.41it/s, v_num=21010, train_loss_step=5.510, train_loss_epoch=5.510]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 122.36it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.10it/s, v_num=21012, train_loss_step=5.570, train_loss_epoch=5.570]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 98.01it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.20it/s, v_num=21014, train_loss_step=5.640, train_loss_epoch=5.640]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 104.70it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.92it/s, v_num=21016, train_loss_step=5.570, train_loss_epoch=5.570]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 55.92it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.43it/s, v_num=21018, train_loss_step=5.590, train_loss_epoch=5.590]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 169.80it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.06it/s, v_num=21020, train_loss_step=5.550, train_loss_epoch=5.550]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 118.22it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.46it/s, v_num=21022, train_loss_step=5.620, train_loss_epoch=5.620]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 140.17it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.43it/s, v_num=21024, train_loss_step=5.740, train_loss_epoch=5.740]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.55it/s, v_num=21026, train_loss_step=5.850, train_loss_epoch=5.850]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 280.91it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.20it/s, v_num=21028, train_loss_step=5.690, train_loss_epoch=5.690]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 321.75it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.14it/s, v_num=21030, train_loss_step=5.410, train_loss_epoch=5.410]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 14.30it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.39it/s, v_num=21032, train_loss_step=5.470, train_loss_epoch=5.470]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 226.61it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.35it/s, v_num=21034, train_loss_step=5.450, train_loss_epoch=5.450]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 45.07it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.16it/s, v_num=21036, train_loss_step=5.560, train_loss_epoch=5.560]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.24it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.02it/s, v_num=21038, train_loss_step=5.690, train_loss_epoch=5.690]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.21it/s, v_num=21040, train_loss_step=5.730, train_loss_epoch=5.730]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 248.71it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.84it/s, v_num=21042, train_loss_step=5.770, train_loss_epoch=5.770]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 127.61it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  9.18it/s, v_num=21044, train_loss_step=5.730, train_loss_epoch=5.730]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 699.98it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.92it/s, v_num=21046, train_loss_step=5.860, train_loss_epoch=5.860]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 240.02it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.71it/s, v_num=21048, train_loss_step=5.930, train_loss_epoch=5.930]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 128.77it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.20it/s, v_num=21050, train_loss_step=6.190, train_loss_epoch=6.190]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 76.26it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.83it/s, v_num=21052, train_loss_step=6.560, train_loss_epoch=6.560]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 179.52it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.85it/s, v_num=21054, train_loss_step=6.610, train_loss_epoch=6.610]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 238.16it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.24it/s, v_num=21056, train_loss_step=6.460, train_loss_epoch=6.460]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 152.00it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.76it/s, v_num=21058, train_loss_step=6.430, train_loss_epoch=6.430]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.45it/s, v_num=21060, train_loss_step=6.480, train_loss_epoch=6.480]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 260.08it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.32it/s, v_num=21062, train_loss_step=6.560, train_loss_epoch=6.560]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 376.64it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.52it/s, v_num=21064, train_loss_step=6.490, train_loss_epoch=6.490]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 964.87it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.12it/s, v_num=21066, train_loss_step=6.450, train_loss_epoch=6.450]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 115.88it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.95it/s, v_num=21068, train_loss_step=6.760, train_loss_epoch=6.760]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.26it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.98it/s, v_num=21070, train_loss_step=6.780, train_loss_epoch=6.780]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.48it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.20it/s, v_num=21072, train_loss_step=6.760, train_loss_epoch=6.760]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.14it/s, v_num=21074, train_loss_step=6.830, train_loss_epoch=6.830]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 66.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 20:55:08,574] A new study created in memory with name: no-name-f847906a-dfe9-4b15-90d4-184241ca336f\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prefix: NFLX | mode: financial | model_type: NBEATS\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.82it/s, v_num=21076, train_loss_step=5.740, train_loss_epoch=5.740]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 120.83it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.39it/s, v_num=21078, train_loss_step=7.260, train_loss_epoch=7.260]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 497.66it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.39it/s, v_num=21080, train_loss_step=5.670, train_loss_epoch=5.670]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 58.29it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.27it/s, v_num=21082, train_loss_step=5.430, train_loss_epoch=5.430]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 187.14it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.88it/s, v_num=21084, train_loss_step=4.190, train_loss_epoch=4.190]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 80.10it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.48it/s, v_num=21086, train_loss_step=4.840, train_loss_epoch=4.840]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.04it/s, v_num=21088, train_loss_step=5.470, train_loss_epoch=5.470]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 437.91it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.19it/s, v_num=21090, train_loss_step=5.350, train_loss_epoch=5.350]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 66.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 20:55:45,015] Trial 0 finished with value: 0.579539641943734 and parameters: {'n_blocks_season': 3, 'n_blocks_trend': 2, 'n_blocks_ident': 1, 'mlp_units': 64, 'num_hidden': 3, 'n_harmonics': 3, 'n_polynomials': 3, 'learning_rate': 0.048794683863959284}. Best is trial 0 with value: 0.579539641943734.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.70it/s, v_num=21092, train_loss_step=2.680, train_loss_epoch=2.680]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 66.59it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.70it/s, v_num=21094, train_loss_step=2.730, train_loss_epoch=2.730]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 185.55it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.18it/s, v_num=21096, train_loss_step=2.990, train_loss_epoch=2.990]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 74.68it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.77it/s, v_num=21098, train_loss_step=2.770, train_loss_epoch=2.770]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 128.75it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 20.25it/s, v_num=21100, train_loss_step=2.910, train_loss_epoch=2.910]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.17it/s, v_num=21102, train_loss_step=2.810, train_loss_epoch=2.810]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 151.95it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s, v_num=21104, train_loss_step=3.030, train_loss_epoch=3.030]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.68it/s, v_num=21106, train_loss_step=3.020, train_loss_epoch=3.020]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 168.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 20:56:19,327] Trial 1 finished with value: 0.2253869969040248 and parameters: {'n_blocks_season': 3, 'n_blocks_trend': 1, 'n_blocks_ident': 2, 'mlp_units': 64, 'num_hidden': 1, 'n_harmonics': 2, 'n_polynomials': 2, 'learning_rate': 0.0014408380305010943}. Best is trial 0 with value: 0.579539641943734.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.88it/s, v_num=21108, train_loss_step=3.900, train_loss_epoch=3.900]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 127.53it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.22it/s, v_num=21110, train_loss_step=3.890, train_loss_epoch=3.890]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 82.47it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.15it/s, v_num=21112, train_loss_step=4.170, train_loss_epoch=4.170]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 151.12it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.00it/s, v_num=21114, train_loss_step=3.870, train_loss_epoch=3.870]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 284.92it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.67it/s, v_num=21116, train_loss_step=4.040, train_loss_epoch=4.040]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 361.20it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.67it/s, v_num=21118, train_loss_step=3.950, train_loss_epoch=3.950]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 155.93it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.14it/s, v_num=21120, train_loss_step=4.260, train_loss_epoch=4.260]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.63it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.67it/s, v_num=21122, train_loss_step=4.300, train_loss_epoch=4.300]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 115.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 20:56:56,743] Trial 2 finished with value: 0.5071207430340557 and parameters: {'n_blocks_season': 2, 'n_blocks_trend': 3, 'n_blocks_ident': 3, 'mlp_units': 64, 'num_hidden': 2, 'n_harmonics': 4, 'n_polynomials': 2, 'learning_rate': 8.457851568881981e-05}. Best is trial 0 with value: 0.579539641943734.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.77it/s, v_num=21124, train_loss_step=5.740, train_loss_epoch=5.740]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 78.62it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.46it/s, v_num=21126, train_loss_step=7.260, train_loss_epoch=7.260]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 143.19it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.80it/s, v_num=21128, train_loss_step=5.670, train_loss_epoch=5.670]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.00it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.58it/s, v_num=21130, train_loss_step=5.430, train_loss_epoch=5.430]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.12it/s, v_num=21132, train_loss_step=4.190, train_loss_epoch=4.190]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 222.63it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.23it/s, v_num=21134, train_loss_step=4.840, train_loss_epoch=4.840]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.82it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.23it/s, v_num=21136, train_loss_step=5.470, train_loss_epoch=5.470]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 199.73it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.69it/s, v_num=21138, train_loss_step=5.350, train_loss_epoch=5.350]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.32it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s, v_num=21140, train_loss_step=5.400, train_loss_epoch=5.400]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 277.69it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.48it/s, v_num=21142, train_loss_step=3.900, train_loss_epoch=3.900]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 61.85it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.69it/s, v_num=21144, train_loss_step=4.660, train_loss_epoch=4.660]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 95.56it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.81it/s, v_num=21146, train_loss_step=6.870, train_loss_epoch=6.870]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 117.87it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.60it/s, v_num=21148, train_loss_step=5.030, train_loss_epoch=5.030]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 290.99it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.05it/s, v_num=21150, train_loss_step=7.720, train_loss_epoch=7.720]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 145.02it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.41it/s, v_num=21152, train_loss_step=3.710, train_loss_epoch=3.710]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 66.28it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 20.51it/s, v_num=21154, train_loss_step=9.140, train_loss_epoch=9.140]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 420.23it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.87it/s, v_num=21156, train_loss_step=8.730, train_loss_epoch=8.730]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 241.72it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.37it/s, v_num=21158, train_loss_step=6.120, train_loss_epoch=6.120]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.31it/s, v_num=21160, train_loss_step=5.580, train_loss_epoch=5.580]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 255.33it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.59it/s, v_num=21162, train_loss_step=4.780, train_loss_epoch=4.780]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 443.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 20:58:28,063] A new study created in memory with name: no-name-3b524ff2-a7cd-442c-b5da-57f9ca5dc2c8\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prefix: NFLX | mode: financial | model_type: NHITS\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.89it/s, v_num=21164, train_loss_step=1.71e+5, train_loss_epoch=1.71e+5]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 80.52it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.47it/s, v_num=21166, train_loss_step=1.53e+3, train_loss_epoch=1.53e+3]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 60.21it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.05it/s, v_num=21168, train_loss_step=9.08e+3, train_loss_epoch=9.08e+3] \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 215.53it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.93it/s, v_num=21170, train_loss_step=2.74e+4, train_loss_epoch=2.74e+4]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 96.96it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.18it/s, v_num=21172, train_loss_step=7.82e+3, train_loss_epoch=7.82e+3]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.54it/s, v_num=21174, train_loss_step=8.62e+5, train_loss_epoch=8.62e+5] \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 51.22it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.14it/s, v_num=21176, train_loss_step=3.3e+4, train_loss_epoch=3.3e+4]  \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 292.82it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.31it/s, v_num=21178, train_loss_step=2.46e+5, train_loss_epoch=2.46e+5]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 61.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 20:59:10,684] Trial 0 finished with value: 0.5010893246187363 and parameters: {'n_blocks1': 3, 'n_blocks2': 3, 'n_blocks3': 1, 'mlp_units': 128, 'n_pool_kernel_size1': 3, 'n_pool_kernel_size2': 1, 'n_pool_kernel_size3': 3, 'learning_rate': 0.04267787072943645}. Best is trial 0 with value: 0.5010893246187363.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s, v_num=21180, train_loss_step=3.650, train_loss_epoch=3.650]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 111.02it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.09it/s, v_num=21182, train_loss_step=3.650, train_loss_epoch=3.650]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.94it/s, v_num=21184, train_loss_step=3.940, train_loss_epoch=3.940]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 77.05it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.24it/s, v_num=21186, train_loss_step=3.660, train_loss_epoch=3.660]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 152.51it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.62it/s, v_num=21188, train_loss_step=3.820, train_loss_epoch=3.820]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.39it/s, v_num=21190, train_loss_step=3.710, train_loss_epoch=3.710]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 132.52it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.37it/s, v_num=21192, train_loss_step=3.990, train_loss_epoch=3.990]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.06it/s, v_num=21194, train_loss_step=4.020, train_loss_epoch=4.020]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 3054.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 20:59:47,775] Trial 1 finished with value: 0.49568627450980396 and parameters: {'n_blocks1': 1, 'n_blocks2': 2, 'n_blocks3': 1, 'mlp_units': 64, 'n_pool_kernel_size1': 3, 'n_pool_kernel_size2': 2, 'n_pool_kernel_size3': 2, 'learning_rate': 0.0007910019503925216}. Best is trial 0 with value: 0.5010893246187363.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.83it/s, v_num=21196, train_loss_step=3.840, train_loss_epoch=3.840]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 245.35it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.39it/s, v_num=21198, train_loss_step=3.830, train_loss_epoch=3.830]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 75.04it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.31it/s, v_num=21200, train_loss_step=4.120, train_loss_epoch=4.120]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 99.10it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.79it/s, v_num=21202, train_loss_step=3.840, train_loss_epoch=3.840]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.16it/s, v_num=21204, train_loss_step=4.000, train_loss_epoch=4.000]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 81.90it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.52it/s, v_num=21206, train_loss_step=3.900, train_loss_epoch=3.900]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 138.98it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.29it/s, v_num=21208, train_loss_step=4.190, train_loss_epoch=4.190]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 217.10it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.40it/s, v_num=21210, train_loss_step=4.230, train_loss_epoch=4.230]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 86.73it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 21:00:26,576] Trial 2 finished with value: 0.579539641943734 and parameters: {'n_blocks1': 1, 'n_blocks2': 2, 'n_blocks3': 2, 'mlp_units': 64, 'n_pool_kernel_size1': 1, 'n_pool_kernel_size2': 1, 'n_pool_kernel_size3': 3, 'learning_rate': 0.000333646951638192}. Best is trial 2 with value: 0.579539641943734.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.04it/s, v_num=21212, train_loss_step=3.840, train_loss_epoch=3.840]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 118.34it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.68it/s, v_num=21214, train_loss_step=3.830, train_loss_epoch=3.830]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 183.24it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.66it/s, v_num=21216, train_loss_step=4.120, train_loss_epoch=4.120]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 66.47it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.26it/s, v_num=21218, train_loss_step=3.840, train_loss_epoch=3.840]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 135.36it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.88it/s, v_num=21220, train_loss_step=4.000, train_loss_epoch=4.000]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 81.69it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s, v_num=21222, train_loss_step=3.900, train_loss_epoch=3.900]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 205.03it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.37it/s, v_num=21224, train_loss_step=4.190, train_loss_epoch=4.190]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.20it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.34it/s, v_num=21226, train_loss_step=4.230, train_loss_epoch=4.230]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.84it/s, v_num=21228, train_loss_step=3.780, train_loss_epoch=3.780]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 59.21it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  5.93it/s, v_num=21230, train_loss_step=3.650, train_loss_epoch=3.650]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.37it/s, v_num=21232, train_loss_step=3.730, train_loss_epoch=3.730]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 177.56it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.17it/s, v_num=21234, train_loss_step=3.570, train_loss_epoch=3.570]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 285.00it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.81it/s, v_num=21236, train_loss_step=3.560, train_loss_epoch=3.560]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 106.49it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.96it/s, v_num=21238, train_loss_step=3.340, train_loss_epoch=3.340]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 127.49it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s, v_num=21240, train_loss_step=3.390, train_loss_epoch=3.390]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 209.20it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.86it/s, v_num=21242, train_loss_step=3.540, train_loss_epoch=3.540]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 244.07it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.96it/s, v_num=21244, train_loss_step=3.640, train_loss_epoch=3.640]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 315.17it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.89it/s, v_num=21246, train_loss_step=3.470, train_loss_epoch=3.470]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 81.33it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.92it/s, v_num=21248, train_loss_step=3.400, train_loss_epoch=3.400]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 222.43it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.14it/s, v_num=21250, train_loss_step=3.330, train_loss_epoch=3.330]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 21:02:05,919] A new study created in memory with name: no-name-79154fe4-945a-479c-8782-cffd937601b3\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prefix: NFLX | mode: financial | model_type: TFT\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.25it/s, v_num=21252, train_loss_step=2.620, train_loss_epoch=2.620]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 316.84it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.24it/s, v_num=21254, train_loss_step=2.750, train_loss_epoch=2.750]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 145.95it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.18it/s, v_num=21256, train_loss_step=2.920, train_loss_epoch=2.920]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 65.37it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.77it/s, v_num=21258, train_loss_step=2.790, train_loss_epoch=2.790]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.22it/s, v_num=21260, train_loss_step=2.840, train_loss_epoch=2.840]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 149.80it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.32it/s, v_num=21262, train_loss_step=2.940, train_loss_epoch=2.940]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.08it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.45it/s, v_num=21264, train_loss_step=3.060, train_loss_epoch=3.060]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 74.44it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.34it/s, v_num=21266, train_loss_step=2.840, train_loss_epoch=2.840]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 397.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 21:02:54,622] Trial 0 finished with value: 0.583529411764706 and parameters: {'learning_rate': 0.002577491694464552, 'hidden_size': 16}. Best is trial 0 with value: 0.583529411764706.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.00it/s, v_num=21268, train_loss_step=2.770, train_loss_epoch=2.770]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 442.62it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.92it/s, v_num=21270, train_loss_step=2.910, train_loss_epoch=2.910]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 124.84it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.46it/s, v_num=21272, train_loss_step=3.090, train_loss_epoch=3.090]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 662.40it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  2.73it/s, v_num=21274, train_loss_step=2.950, train_loss_epoch=2.950]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 57.17it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.95it/s, v_num=21276, train_loss_step=2.990, train_loss_epoch=2.990]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 239.47it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.60it/s, v_num=21278, train_loss_step=3.100, train_loss_epoch=3.100]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 43.02it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.08it/s, v_num=21280, train_loss_step=3.220, train_loss_epoch=3.220]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 410.48it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  2.51it/s, v_num=21282, train_loss_step=3.000, train_loss_epoch=3.000]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 75.39it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 21:03:43,598] Trial 1 finished with value: 0.6807843137254903 and parameters: {'learning_rate': 0.00019886352165969544, 'hidden_size': 12}. Best is trial 1 with value: 0.6807843137254903.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s, v_num=21284, train_loss_step=2.630, train_loss_epoch=2.630]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.45it/s, v_num=21286, train_loss_step=2.760, train_loss_epoch=2.760]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 236.99it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.65it/s, v_num=21288, train_loss_step=2.940, train_loss_epoch=2.940]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 79.15it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.71it/s, v_num=21290, train_loss_step=2.810, train_loss_epoch=2.810]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 373.36it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.55it/s, v_num=21292, train_loss_step=2.850, train_loss_epoch=2.850]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 95.46it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.51it/s, v_num=21294, train_loss_step=2.950, train_loss_epoch=2.950]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 233.43it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.78it/s, v_num=21296, train_loss_step=3.080, train_loss_epoch=3.080]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 360.40it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.12it/s, v_num=21298, train_loss_step=2.860, train_loss_epoch=2.860]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 75.66it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 21:04:28,502] Trial 2 finished with value: 0.583529411764706 and parameters: {'learning_rate': 0.05371861430986545, 'hidden_size': 4}. Best is trial 1 with value: 0.6807843137254903.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.23it/s, v_num=21300, train_loss_step=2.770, train_loss_epoch=2.770]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 86.44it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.42it/s, v_num=21302, train_loss_step=2.910, train_loss_epoch=2.910]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 125.35it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.47it/s, v_num=21304, train_loss_step=3.090, train_loss_epoch=3.090]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 103.93it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.27it/s, v_num=21306, train_loss_step=2.950, train_loss_epoch=2.950]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 301.38it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.15it/s, v_num=21308, train_loss_step=2.990, train_loss_epoch=2.990]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 146.85it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.14it/s, v_num=21310, train_loss_step=3.100, train_loss_epoch=3.100]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 170.67it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.16it/s, v_num=21312, train_loss_step=3.220, train_loss_epoch=3.220]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 242.89it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.64it/s, v_num=21314, train_loss_step=3.000, train_loss_epoch=3.000]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 79.97it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.49it/s, v_num=21316, train_loss_step=3.600, train_loss_epoch=3.600]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 121.42it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.42it/s, v_num=21318, train_loss_step=3.650, train_loss_epoch=3.650]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 99.78it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.36it/s, v_num=21320, train_loss_step=3.510, train_loss_epoch=3.510]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 99.48it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.59it/s, v_num=21322, train_loss_step=3.430, train_loss_epoch=3.430]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 141.36it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.19it/s, v_num=21324, train_loss_step=3.650, train_loss_epoch=3.650]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 111.04it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.26it/s, v_num=21326, train_loss_step=3.700, train_loss_epoch=3.700]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 98.56it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.56it/s, v_num=21328, train_loss_step=3.670, train_loss_epoch=3.670]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.78it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.08it/s, v_num=21330, train_loss_step=3.570, train_loss_epoch=3.570]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 61.04it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.21it/s, v_num=21332, train_loss_step=3.730, train_loss_epoch=3.730]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 166.41it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.45it/s, v_num=21334, train_loss_step=3.660, train_loss_epoch=3.660]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 85.21it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.46it/s, v_num=21336, train_loss_step=3.860, train_loss_epoch=3.860]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 164.47it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.26it/s, v_num=21338, train_loss_step=3.780, train_loss_epoch=3.780]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 21:06:31,451] A new study created in memory with name: no-name-8fac7da0-4e39-499a-8986-c1b123771cb3\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prefix: NFLX | mode: news | model_type: NBEATS\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.46it/s, v_num=21340, train_loss_step=3.990, train_loss_epoch=3.990]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 396.32it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.17it/s, v_num=21342, train_loss_step=3.970, train_loss_epoch=3.970]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 120.71it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.22it/s, v_num=21344, train_loss_step=4.270, train_loss_epoch=4.270]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 324.29it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.48it/s, v_num=21346, train_loss_step=3.980, train_loss_epoch=3.980]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 299.10it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.99it/s, v_num=21348, train_loss_step=4.140, train_loss_epoch=4.140]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 147.80it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  6.47it/s, v_num=21350, train_loss_step=4.050, train_loss_epoch=4.050]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 127.01it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.30it/s, v_num=21352, train_loss_step=4.340, train_loss_epoch=4.340]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 126.57it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.33it/s, v_num=21354, train_loss_step=4.380, train_loss_epoch=4.380]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 21:07:14,015] Trial 0 finished with value: 0.6322250639386189 and parameters: {'n_blocks_season': 3, 'n_blocks_trend': 2, 'n_blocks_ident': 1, 'mlp_units': 128, 'num_hidden': 3, 'n_harmonics': 2, 'n_polynomials': 5, 'learning_rate': 1.6328225956308555e-05}. Best is trial 0 with value: 0.6322250639386189.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  3.76it/s, v_num=21356, train_loss_step=3.980, train_loss_epoch=3.980]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.60it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.13it/s, v_num=21358, train_loss_step=3.960, train_loss_epoch=3.960]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.49it/s, v_num=21360, train_loss_step=4.260, train_loss_epoch=4.260]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 131.22it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.68it/s, v_num=21362, train_loss_step=3.940, train_loss_epoch=3.940]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 95.36it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.31it/s, v_num=21364, train_loss_step=4.120, train_loss_epoch=4.120]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 132.43it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.45it/s, v_num=21366, train_loss_step=4.020, train_loss_epoch=4.020]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 884.13it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.41it/s, v_num=21368, train_loss_step=4.320, train_loss_epoch=4.320]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 256.14it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.14it/s, v_num=21370, train_loss_step=4.360, train_loss_epoch=4.360]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 297.47it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 21:07:55,033] Trial 1 finished with value: 0.5294117647058824 and parameters: {'n_blocks_season': 1, 'n_blocks_trend': 2, 'n_blocks_ident': 2, 'mlp_units': 128, 'num_hidden': 3, 'n_harmonics': 3, 'n_polynomials': 2, 'learning_rate': 3.147788542231296e-05}. Best is trial 0 with value: 0.6322250639386189.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.72it/s, v_num=21372, train_loss_step=2.690, train_loss_epoch=2.690]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 330.29it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.57it/s, v_num=21374, train_loss_step=2.740, train_loss_epoch=2.740]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 974.29it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.43it/s, v_num=21376, train_loss_step=2.990, train_loss_epoch=2.990]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 368.47it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.54it/s, v_num=21378, train_loss_step=2.780, train_loss_epoch=2.780]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.01it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.38it/s, v_num=21380, train_loss_step=2.910, train_loss_epoch=2.910]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.51it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.66it/s, v_num=21382, train_loss_step=2.810, train_loss_epoch=2.810]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 65.33it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.79it/s, v_num=21384, train_loss_step=3.040, train_loss_epoch=3.040]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 248.71it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.23it/s, v_num=21386, train_loss_step=3.030, train_loss_epoch=3.030]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 21:08:41,327] Trial 2 finished with value: 0.5010893246187363 and parameters: {'n_blocks_season': 3, 'n_blocks_trend': 3, 'n_blocks_ident': 2, 'mlp_units': 128, 'num_hidden': 3, 'n_harmonics': 3, 'n_polynomials': 4, 'learning_rate': 0.0008649718537752358}. Best is trial 0 with value: 0.6322250639386189.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  8.69it/s, v_num=21388, train_loss_step=3.990, train_loss_epoch=3.990]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 103.67it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.73it/s, v_num=21390, train_loss_step=3.970, train_loss_epoch=3.970]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 146.96it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.01it/s, v_num=21392, train_loss_step=4.270, train_loss_epoch=4.270]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 120.48it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.86it/s, v_num=21394, train_loss_step=3.980, train_loss_epoch=3.980]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 235.12it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.56it/s, v_num=21396, train_loss_step=4.140, train_loss_epoch=4.140]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 133.18it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.04it/s, v_num=21398, train_loss_step=4.050, train_loss_epoch=4.050]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 145.75it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.19it/s, v_num=21400, train_loss_step=4.340, train_loss_epoch=4.340]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 186.48it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.35it/s, v_num=21402, train_loss_step=4.380, train_loss_epoch=4.380]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.15it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.83it/s, v_num=21404, train_loss_step=3.930, train_loss_epoch=3.930]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 242.61it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.14it/s, v_num=21406, train_loss_step=3.790, train_loss_epoch=3.790]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 241.97it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.17it/s, v_num=21408, train_loss_step=3.880, train_loss_epoch=3.880]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 70.72it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  8.49it/s, v_num=21410, train_loss_step=3.710, train_loss_epoch=3.710]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 111.24it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.95it/s, v_num=21412, train_loss_step=3.700, train_loss_epoch=3.700]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 148.53it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.02it/s, v_num=21414, train_loss_step=3.480, train_loss_epoch=3.480]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 71.24it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.46it/s, v_num=21416, train_loss_step=3.520, train_loss_epoch=3.520]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 139.33it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.70it/s, v_num=21418, train_loss_step=3.670, train_loss_epoch=3.670]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 141.34it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.57it/s, v_num=21420, train_loss_step=3.780, train_loss_epoch=3.780]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 132.40it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  8.78it/s, v_num=21422, train_loss_step=3.600, train_loss_epoch=3.600]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 267.03it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.76it/s, v_num=21424, train_loss_step=3.520, train_loss_epoch=3.520]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 52.17it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.87it/s, v_num=21426, train_loss_step=3.450, train_loss_epoch=3.450]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 498.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 21:10:29,224] A new study created in memory with name: no-name-0214e69f-010c-4f2a-b3e1-81825b1dc392\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prefix: NFLX | mode: news | model_type: NHITS\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.23it/s, v_num=21428, train_loss_step=3.780, train_loss_epoch=3.780]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 223.72it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.58it/s, v_num=21430, train_loss_step=3.760, train_loss_epoch=3.760]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 111.04it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.94it/s, v_num=21432, train_loss_step=4.060, train_loss_epoch=4.060]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 72.76it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.72it/s, v_num=21434, train_loss_step=3.770, train_loss_epoch=3.770]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 126.27it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.49it/s, v_num=21436, train_loss_step=3.930, train_loss_epoch=3.930]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 97.67it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.55it/s, v_num=21438, train_loss_step=3.830, train_loss_epoch=3.830]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 360.99it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.71it/s, v_num=21440, train_loss_step=4.120, train_loss_epoch=4.120]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 287.38it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.36it/s, v_num=21442, train_loss_step=4.150, train_loss_epoch=4.150]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 118.78it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 21:11:09,483] Trial 0 finished with value: 0.6322250639386189 and parameters: {'n_blocks1': 1, 'n_blocks2': 2, 'n_blocks3': 3, 'mlp_units': 64, 'n_pool_kernel_size1': 1, 'n_pool_kernel_size2': 1, 'n_pool_kernel_size3': 2, 'learning_rate': 0.000737755373895744}. Best is trial 0 with value: 0.6322250639386189.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.04it/s, v_num=21444, train_loss_step=3.940, train_loss_epoch=3.940]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 105.62it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.69it/s, v_num=21446, train_loss_step=3.920, train_loss_epoch=3.920]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 57.46it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.84it/s, v_num=21448, train_loss_step=4.210, train_loss_epoch=4.210]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 280.05it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.99it/s, v_num=21450, train_loss_step=3.920, train_loss_epoch=3.920]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 249.44it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.01it/s, v_num=21452, train_loss_step=4.090, train_loss_epoch=4.090]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 173.86it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.37it/s, v_num=21454, train_loss_step=3.990, train_loss_epoch=3.990]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 407.81it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.84it/s, v_num=21456, train_loss_step=4.280, train_loss_epoch=4.280]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 117.29it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.01it/s, v_num=21458, train_loss_step=4.330, train_loss_epoch=4.330]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 456.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 21:11:47,306] Trial 1 finished with value: 0.6417112299465241 and parameters: {'n_blocks1': 1, 'n_blocks2': 1, 'n_blocks3': 1, 'mlp_units': 64, 'n_pool_kernel_size1': 3, 'n_pool_kernel_size2': 1, 'n_pool_kernel_size3': 3, 'learning_rate': 0.00041869739107755786}. Best is trial 1 with value: 0.6417112299465241.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.21it/s, v_num=21460, train_loss_step=3.990, train_loss_epoch=3.990]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 109.23it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.92it/s, v_num=21462, train_loss_step=3.970, train_loss_epoch=3.970]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 137.14it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.23it/s, v_num=21464, train_loss_step=4.270, train_loss_epoch=4.270]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 118.26it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.65it/s, v_num=21466, train_loss_step=3.960, train_loss_epoch=3.960]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 197.48it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.77it/s, v_num=21468, train_loss_step=4.130, train_loss_epoch=4.130]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 50.38it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.37it/s, v_num=21470, train_loss_step=4.030, train_loss_epoch=4.030]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 368.50it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.41it/s, v_num=21472, train_loss_step=4.330, train_loss_epoch=4.330]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 238.45it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.11it/s, v_num=21474, train_loss_step=4.380, train_loss_epoch=4.380]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 134.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 21:12:28,654] Trial 2 finished with value: 0.5529411764705883 and parameters: {'n_blocks1': 3, 'n_blocks2': 2, 'n_blocks3': 2, 'mlp_units': 64, 'n_pool_kernel_size1': 2, 'n_pool_kernel_size2': 1, 'n_pool_kernel_size3': 1, 'learning_rate': 6.590452464020706e-05}. Best is trial 1 with value: 0.6417112299465241.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.57it/s, v_num=21476, train_loss_step=3.940, train_loss_epoch=3.940]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 399.15it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.83it/s, v_num=21478, train_loss_step=3.920, train_loss_epoch=3.920]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 314.49it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.92it/s, v_num=21480, train_loss_step=4.210, train_loss_epoch=4.210]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 255.00it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.06it/s, v_num=21482, train_loss_step=3.920, train_loss_epoch=3.920]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 659.48it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  6.71it/s, v_num=21484, train_loss_step=4.090, train_loss_epoch=4.090]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 198.76it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.73it/s, v_num=21486, train_loss_step=3.990, train_loss_epoch=3.990]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 158.11it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.97it/s, v_num=21488, train_loss_step=4.280, train_loss_epoch=4.280]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 372.03it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.47it/s, v_num=21490, train_loss_step=4.330, train_loss_epoch=4.330]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 148.85it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.39it/s, v_num=21492, train_loss_step=3.880, train_loss_epoch=3.880]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 337.16it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.26it/s, v_num=21494, train_loss_step=3.740, train_loss_epoch=3.740]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 269.87it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.85it/s, v_num=21496, train_loss_step=3.840, train_loss_epoch=3.840]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 417.14it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.30it/s, v_num=21498, train_loss_step=3.670, train_loss_epoch=3.670]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 212.33it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.68it/s, v_num=21500, train_loss_step=3.660, train_loss_epoch=3.660]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.98it/s, v_num=21502, train_loss_step=3.440, train_loss_epoch=3.440]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.37it/s, v_num=21504, train_loss_step=3.490, train_loss_epoch=3.490]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 192.73it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.96it/s, v_num=21506, train_loss_step=3.630, train_loss_epoch=3.630]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 583.60it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.70it/s, v_num=21508, train_loss_step=3.740, train_loss_epoch=3.740]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 213.14it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.83it/s, v_num=21510, train_loss_step=3.560, train_loss_epoch=3.560]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 219.31it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.61it/s, v_num=21512, train_loss_step=3.490, train_loss_epoch=3.490]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 199.31it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.37it/s, v_num=21514, train_loss_step=3.420, train_loss_epoch=3.420]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 180.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 21:14:02,399] A new study created in memory with name: no-name-a1893048-375d-4d8a-922e-db9886f24937\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prefix: NFLX | mode: news | model_type: TFT\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.09it/s, v_num=21516, train_loss_step=2.730, train_loss_epoch=2.730]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 210.55it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  2.96it/s, v_num=21518, train_loss_step=2.860, train_loss_epoch=2.860]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 241.27it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  2.95it/s, v_num=21520, train_loss_step=3.030, train_loss_epoch=3.030]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 280.89it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.09it/s, v_num=21522, train_loss_step=2.890, train_loss_epoch=2.890]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 123.56it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=21524, train_loss_step=2.940, train_loss_epoch=2.940]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 55.88it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=21526, train_loss_step=3.040, train_loss_epoch=3.040]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 46.60it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.10it/s, v_num=21528, train_loss_step=3.180, train_loss_epoch=3.180]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 184.83it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.09it/s, v_num=21530, train_loss_step=2.940, train_loss_epoch=2.940]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 21:14:59,583] Trial 0 finished with value: 0.5347593582887701 and parameters: {'learning_rate': 0.0007556490703645633, 'hidden_size': 24}. Best is trial 0 with value: 0.5347593582887701.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.96it/s, v_num=21532, train_loss_step=2.630, train_loss_epoch=2.630]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 105.79it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.05it/s, v_num=21534, train_loss_step=2.760, train_loss_epoch=2.760]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.26it/s, v_num=21536, train_loss_step=2.940, train_loss_epoch=2.940]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.00it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.57it/s, v_num=21538, train_loss_step=2.800, train_loss_epoch=2.800]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 413.23it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.57it/s, v_num=21540, train_loss_step=2.850, train_loss_epoch=2.850]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=21542, train_loss_step=2.950, train_loss_epoch=2.950]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 61.58it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=21544, train_loss_step=3.080, train_loss_epoch=3.080]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 82.02it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s, v_num=21546, train_loss_step=2.850, train_loss_epoch=2.850]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 277.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 21:15:45,841] Trial 1 finished with value: 0.6213235294117647 and parameters: {'learning_rate': 0.011551165659666487, 'hidden_size': 8}. Best is trial 1 with value: 0.6213235294117647.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.06it/s, v_num=21548, train_loss_step=2.640, train_loss_epoch=2.640]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 166.26it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.33it/s, v_num=21550, train_loss_step=2.770, train_loss_epoch=2.770]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 171.64it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.95it/s, v_num=21552, train_loss_step=2.940, train_loss_epoch=2.940]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.43it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.97it/s, v_num=21554, train_loss_step=2.810, train_loss_epoch=2.810]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 129.21it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.11it/s, v_num=21556, train_loss_step=2.860, train_loss_epoch=2.860]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 351.19it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.49it/s, v_num=21558, train_loss_step=2.950, train_loss_epoch=2.950]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.24it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  1.94it/s, v_num=21560, train_loss_step=3.080, train_loss_epoch=3.080]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 107.02it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.62it/s, v_num=21562, train_loss_step=2.860, train_loss_epoch=2.860]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 98.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 21:16:36,683] Trial 2 finished with value: 0.632156862745098 and parameters: {'learning_rate': 8.844391998405512e-05, 'hidden_size': 12}. Best is trial 2 with value: 0.632156862745098.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.26it/s, v_num=21564, train_loss_step=2.640, train_loss_epoch=2.640]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 191.69it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s, v_num=21566, train_loss_step=2.770, train_loss_epoch=2.770]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 254.23it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.63it/s, v_num=21568, train_loss_step=2.940, train_loss_epoch=2.940]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 133.12it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.02it/s, v_num=21570, train_loss_step=2.810, train_loss_epoch=2.810]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 58.61it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.98it/s, v_num=21572, train_loss_step=2.860, train_loss_epoch=2.860]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 498.08it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.89it/s, v_num=21574, train_loss_step=2.950, train_loss_epoch=2.950]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 392.98it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.15it/s, v_num=21576, train_loss_step=3.080, train_loss_epoch=3.080]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 281.69it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.36it/s, v_num=21578, train_loss_step=2.860, train_loss_epoch=2.860]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 66.48it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.20it/s, v_num=21580, train_loss_step=3.450, train_loss_epoch=3.450]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 153.77it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.40it/s, v_num=21582, train_loss_step=3.490, train_loss_epoch=3.490]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 257.84it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.07it/s, v_num=21584, train_loss_step=3.370, train_loss_epoch=3.370]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 44.93it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.03it/s, v_num=21586, train_loss_step=3.290, train_loss_epoch=3.290]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 61.76it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.43it/s, v_num=21588, train_loss_step=3.500, train_loss_epoch=3.500]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 110.83it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.26it/s, v_num=21590, train_loss_step=3.560, train_loss_epoch=3.560]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 274.33it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.10it/s, v_num=21592, train_loss_step=3.510, train_loss_epoch=3.510]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 269.64it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.11it/s, v_num=21594, train_loss_step=3.420, train_loss_epoch=3.420]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 205.34it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.47it/s, v_num=21596, train_loss_step=3.570, train_loss_epoch=3.570]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 379.20it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.48it/s, v_num=21598, train_loss_step=3.520, train_loss_epoch=3.520]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 168.01it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.30it/s, v_num=21600, train_loss_step=3.700, train_loss_epoch=3.700]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 352.55it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.25it/s, v_num=21602, train_loss_step=3.640, train_loss_epoch=3.640]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 66.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 21:18:41,106] A new study created in memory with name: no-name-4a53dbe8-dfe2-4f98-9549-37ad6c4577bb\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prefix: NFLX | mode: financial | model_type: NBEATS\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.36it/s, v_num=21604, train_loss_step=15.00, train_loss_epoch=15.00]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 262.92it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.15it/s, v_num=21606, train_loss_step=15.70, train_loss_epoch=15.70]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.26it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.43it/s, v_num=21608, train_loss_step=54.90, train_loss_epoch=54.90]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 196.30it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.52it/s, v_num=21610, train_loss_step=16.40, train_loss_epoch=16.40]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 204.78it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.74it/s, v_num=21612, train_loss_step=21.40, train_loss_epoch=21.40]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 94.12it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.63it/s, v_num=21614, train_loss_step=48.70, train_loss_epoch=48.70]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 398.66it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.38it/s, v_num=21616, train_loss_step=21.70, train_loss_epoch=21.70]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 226.36it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.28it/s, v_num=21618, train_loss_step=22.10, train_loss_epoch=22.10]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 588.59it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s, v_num=21620, train_loss_step=112.0, train_loss_epoch=112.0]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 331.02it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.39it/s, v_num=21622, train_loss_step=23.60, train_loss_epoch=23.60]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 275.94it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.77it/s, v_num=21624, train_loss_step=29.30, train_loss_epoch=29.30]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 338.41it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.74it/s, v_num=21626, train_loss_step=23.60, train_loss_epoch=23.60]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 199.49it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.01it/s, v_num=21628, train_loss_step=18.70, train_loss_epoch=18.70]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 338.99it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.40it/s, v_num=21630, train_loss_step=18.90, train_loss_epoch=18.90]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 51.51it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.19it/s, v_num=21632, train_loss_step=18.20, train_loss_epoch=18.20]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.02it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.33it/s, v_num=21634, train_loss_step=20.80, train_loss_epoch=20.80]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 135.68it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.87it/s, v_num=21636, train_loss_step=21.90, train_loss_epoch=21.90]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.79it/s, v_num=21638, train_loss_step=20.50, train_loss_epoch=20.50]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 240.07it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.26it/s, v_num=21640, train_loss_step=18.80, train_loss_epoch=18.80]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.54it/s, v_num=21642, train_loss_step=21.70, train_loss_epoch=21.70]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 21:20:12,257] Trial 0 finished with value: 0.6263636363636363 and parameters: {'n_blocks_season': 2, 'n_blocks_trend': 3, 'n_blocks_ident': 2, 'mlp_units': 64, 'num_hidden': 2, 'n_harmonics': 2, 'n_polynomials': 3, 'learning_rate': 0.04451346988818291}. Best is trial 0 with value: 0.6263636363636363.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.20it/s, v_num=21644, train_loss_step=12.90, train_loss_epoch=12.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 281.06it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.10it/s, v_num=21646, train_loss_step=13.40, train_loss_epoch=13.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 247.73it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.59it/s, v_num=21648, train_loss_step=14.50, train_loss_epoch=14.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.26it/s, v_num=21650, train_loss_step=13.40, train_loss_epoch=13.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 130.91it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.24it/s, v_num=21652, train_loss_step=14.00, train_loss_epoch=14.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 156.73it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.81it/s, v_num=21654, train_loss_step=14.00, train_loss_epoch=14.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 172.02it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.81it/s, v_num=21656, train_loss_step=14.60, train_loss_epoch=14.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 182.22it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.85it/s, v_num=21658, train_loss_step=15.60, train_loss_epoch=15.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 442.44it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s, v_num=21660, train_loss_step=15.50, train_loss_epoch=15.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 379.37it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.73it/s, v_num=21662, train_loss_step=15.30, train_loss_epoch=15.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.56it/s, v_num=21664, train_loss_step=15.30, train_loss_epoch=15.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 400.14it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.80it/s, v_num=21666, train_loss_step=15.30, train_loss_epoch=15.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.00it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.68it/s, v_num=21668, train_loss_step=15.60, train_loss_epoch=15.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 229.25it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.43it/s, v_num=21670, train_loss_step=15.70, train_loss_epoch=15.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 140.87it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.68it/s, v_num=21672, train_loss_step=16.10, train_loss_epoch=16.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 246.23it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.32it/s, v_num=21674, train_loss_step=16.60, train_loss_epoch=16.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.76it/s, v_num=21676, train_loss_step=17.70, train_loss_epoch=17.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.21it/s, v_num=21678, train_loss_step=18.50, train_loss_epoch=18.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.14it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.48it/s, v_num=21680, train_loss_step=17.60, train_loss_epoch=17.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 223.61it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.58it/s, v_num=21682, train_loss_step=17.30, train_loss_epoch=17.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 21:21:41,223] Trial 1 finished with value: 0.7847619047619048 and parameters: {'n_blocks_season': 1, 'n_blocks_trend': 1, 'n_blocks_ident': 3, 'mlp_units': 32, 'num_hidden': 3, 'n_harmonics': 3, 'n_polynomials': 3, 'learning_rate': 0.08829092905484154}. Best is trial 1 with value: 0.7847619047619048.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.91it/s, v_num=21684, train_loss_step=12.80, train_loss_epoch=12.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 332.78it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.86it/s, v_num=21686, train_loss_step=13.40, train_loss_epoch=13.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.16it/s, v_num=21688, train_loss_step=14.30, train_loss_epoch=14.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 183.45it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.86it/s, v_num=21690, train_loss_step=13.70, train_loss_epoch=13.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 128.75it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.15it/s, v_num=21692, train_loss_step=14.20, train_loss_epoch=14.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 213.45it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.34it/s, v_num=21694, train_loss_step=14.10, train_loss_epoch=14.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.84it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.73it/s, v_num=21696, train_loss_step=14.70, train_loss_epoch=14.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 210.22it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.48it/s, v_num=21698, train_loss_step=15.80, train_loss_epoch=15.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 83.09it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.90it/s, v_num=21700, train_loss_step=15.90, train_loss_epoch=15.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 58.49it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.38it/s, v_num=21702, train_loss_step=15.80, train_loss_epoch=15.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 59.49it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.29it/s, v_num=21704, train_loss_step=15.90, train_loss_epoch=15.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.20it/s, v_num=21706, train_loss_step=15.60, train_loss_epoch=15.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 138.15it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.56it/s, v_num=21708, train_loss_step=15.90, train_loss_epoch=15.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 73.81it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.48it/s, v_num=21710, train_loss_step=16.10, train_loss_epoch=16.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 169.63it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.41it/s, v_num=21712, train_loss_step=16.40, train_loss_epoch=16.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 103.22it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 20.56it/s, v_num=21714, train_loss_step=16.80, train_loss_epoch=16.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 305.55it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.64it/s, v_num=21716, train_loss_step=17.60, train_loss_epoch=17.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 104.25it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.34it/s, v_num=21718, train_loss_step=18.60, train_loss_epoch=18.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 942.12it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.39it/s, v_num=21720, train_loss_step=17.70, train_loss_epoch=17.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 236.70it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.28it/s, v_num=21722, train_loss_step=17.80, train_loss_epoch=17.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 21:23:07,490] Trial 2 finished with value: 0.7657894736842106 and parameters: {'n_blocks_season': 3, 'n_blocks_trend': 1, 'n_blocks_ident': 2, 'mlp_units': 32, 'num_hidden': 1, 'n_harmonics': 3, 'n_polynomials': 5, 'learning_rate': 0.0002468645569756153}. Best is trial 1 with value: 0.7847619047619048.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.53it/s, v_num=21724, train_loss_step=12.90, train_loss_epoch=12.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 45.87it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.25it/s, v_num=21726, train_loss_step=13.40, train_loss_epoch=13.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 184.67it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.97it/s, v_num=21728, train_loss_step=14.50, train_loss_epoch=14.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 146.70it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.91it/s, v_num=21730, train_loss_step=13.40, train_loss_epoch=13.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 221.99it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.22it/s, v_num=21732, train_loss_step=14.00, train_loss_epoch=14.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 93.70it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.25it/s, v_num=21734, train_loss_step=14.00, train_loss_epoch=14.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 394.20it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.06it/s, v_num=21736, train_loss_step=14.60, train_loss_epoch=14.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 60.18it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.43it/s, v_num=21738, train_loss_step=15.60, train_loss_epoch=15.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 76.51it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.57it/s, v_num=21740, train_loss_step=15.50, train_loss_epoch=15.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 82.74it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.31it/s, v_num=21742, train_loss_step=15.30, train_loss_epoch=15.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 265.58it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.85it/s, v_num=21744, train_loss_step=15.30, train_loss_epoch=15.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.67it/s, v_num=21746, train_loss_step=15.30, train_loss_epoch=15.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.54it/s, v_num=21748, train_loss_step=15.60, train_loss_epoch=15.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 47.59it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.43it/s, v_num=21750, train_loss_step=15.70, train_loss_epoch=15.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.45it/s, v_num=21752, train_loss_step=16.10, train_loss_epoch=16.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.97it/s, v_num=21754, train_loss_step=16.60, train_loss_epoch=16.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 140.10it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.32it/s, v_num=21756, train_loss_step=17.70, train_loss_epoch=17.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.59it/s, v_num=21758, train_loss_step=18.50, train_loss_epoch=18.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.45it/s, v_num=21760, train_loss_step=17.60, train_loss_epoch=17.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 189.65it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.48it/s, v_num=21762, train_loss_step=17.30, train_loss_epoch=17.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 92.32it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.19it/s, v_num=21764, train_loss_step=16.90, train_loss_epoch=16.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 1323.54it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.08it/s, v_num=21766, train_loss_step=16.60, train_loss_epoch=16.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.33it/s, v_num=21768, train_loss_step=16.80, train_loss_epoch=16.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.15it/s, v_num=21770, train_loss_step=16.00, train_loss_epoch=16.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.91it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.45it/s, v_num=21772, train_loss_step=16.10, train_loss_epoch=16.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 123.90it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.37it/s, v_num=21774, train_loss_step=16.40, train_loss_epoch=16.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 90.58it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.78it/s, v_num=21776, train_loss_step=16.70, train_loss_epoch=16.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 151.42it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.69it/s, v_num=21778, train_loss_step=16.20, train_loss_epoch=16.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 150.38it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.21it/s, v_num=21780, train_loss_step=16.10, train_loss_epoch=16.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 239.06it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.54it/s, v_num=21782, train_loss_step=16.90, train_loss_epoch=16.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.00it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.01it/s, v_num=21784, train_loss_step=16.70, train_loss_epoch=16.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 425.43it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.63it/s, v_num=21786, train_loss_step=16.40, train_loss_epoch=16.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 529.52it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.97it/s, v_num=21788, train_loss_step=16.20, train_loss_epoch=16.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 144.62it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.72it/s, v_num=21790, train_loss_step=15.10, train_loss_epoch=15.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 326.30it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.50it/s, v_num=21792, train_loss_step=14.60, train_loss_epoch=14.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.65it/s, v_num=21794, train_loss_step=14.10, train_loss_epoch=14.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 619.45it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.84it/s, v_num=21796, train_loss_step=14.00, train_loss_epoch=14.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 192.99it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  7.00it/s, v_num=21798, train_loss_step=14.10, train_loss_epoch=14.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 67.85it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.16it/s, v_num=21800, train_loss_step=13.40, train_loss_epoch=13.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 120.76it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.33it/s, v_num=21802, train_loss_step=13.70, train_loss_epoch=13.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.96it/s, v_num=21804, train_loss_step=13.70, train_loss_epoch=13.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 338.69it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.49it/s, v_num=21806, train_loss_step=13.10, train_loss_epoch=13.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 137.00it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.88it/s, v_num=21808, train_loss_step=13.50, train_loss_epoch=13.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 375.26it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.12it/s, v_num=21810, train_loss_step=13.10, train_loss_epoch=13.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 406.15it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.44it/s, v_num=21812, train_loss_step=13.40, train_loss_epoch=13.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.88it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.83it/s, v_num=21814, train_loss_step=13.00, train_loss_epoch=13.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 91.22it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.60it/s, v_num=21816, train_loss_step=13.40, train_loss_epoch=13.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 178.12it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.49it/s, v_num=21818, train_loss_step=13.60, train_loss_epoch=13.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 699.98it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.36it/s, v_num=21820, train_loss_step=12.00, train_loss_epoch=12.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 215.82it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.01it/s, v_num=21822, train_loss_step=12.20, train_loss_epoch=12.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 264.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 21:26:49,683] A new study created in memory with name: no-name-07544fcb-f2e0-4542-86c3-f5522a600678\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prefix: NFLX | mode: financial | model_type: NHITS\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.44it/s, v_num=21824, train_loss_step=12.70, train_loss_epoch=12.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 66.62it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.56it/s, v_num=21826, train_loss_step=13.40, train_loss_epoch=13.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 58.69it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.88it/s, v_num=21828, train_loss_step=14.20, train_loss_epoch=14.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 78.32it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.23it/s, v_num=21830, train_loss_step=13.70, train_loss_epoch=13.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 165.06it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.60it/s, v_num=21832, train_loss_step=14.20, train_loss_epoch=14.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 185.04it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.57it/s, v_num=21834, train_loss_step=14.10, train_loss_epoch=14.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 254.08it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.33it/s, v_num=21836, train_loss_step=14.70, train_loss_epoch=14.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 108.19it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.88it/s, v_num=21838, train_loss_step=15.80, train_loss_epoch=15.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 168.54it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.80it/s, v_num=21840, train_loss_step=15.90, train_loss_epoch=15.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 79.67it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.03it/s, v_num=21842, train_loss_step=15.80, train_loss_epoch=15.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 290.14it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.76it/s, v_num=21844, train_loss_step=15.90, train_loss_epoch=15.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 211.03it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.07it/s, v_num=21846, train_loss_step=15.60, train_loss_epoch=15.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 227.86it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.77it/s, v_num=21848, train_loss_step=15.90, train_loss_epoch=15.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 65.88it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.63it/s, v_num=21850, train_loss_step=16.10, train_loss_epoch=16.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 65.83it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.16it/s, v_num=21852, train_loss_step=16.40, train_loss_epoch=16.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 199.76it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.52it/s, v_num=21854, train_loss_step=16.80, train_loss_epoch=16.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 230.95it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.41it/s, v_num=21856, train_loss_step=17.70, train_loss_epoch=17.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 122.32it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.57it/s, v_num=21858, train_loss_step=18.60, train_loss_epoch=18.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 344.33it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.19it/s, v_num=21860, train_loss_step=17.70, train_loss_epoch=17.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 230.67it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.66it/s, v_num=21862, train_loss_step=17.80, train_loss_epoch=17.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 105.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 21:28:38,135] Trial 0 finished with value: 0.7847619047619048 and parameters: {'n_blocks1': 1, 'n_blocks2': 3, 'n_blocks3': 2, 'mlp_units': 128, 'n_pool_kernel_size1': 2, 'n_pool_kernel_size2': 3, 'n_pool_kernel_size3': 3, 'learning_rate': 1.121253680013063e-05}. Best is trial 0 with value: 0.7847619047619048.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.30it/s, v_num=21864, train_loss_step=12.50, train_loss_epoch=12.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 66.64it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.56it/s, v_num=21866, train_loss_step=13.20, train_loss_epoch=13.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.20it/s, v_num=21868, train_loss_step=14.00, train_loss_epoch=14.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.29it/s, v_num=21870, train_loss_step=13.50, train_loss_epoch=13.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 398.05it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.09it/s, v_num=21872, train_loss_step=14.00, train_loss_epoch=14.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 88.96it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.48it/s, v_num=21874, train_loss_step=13.90, train_loss_epoch=13.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 169.70it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.47it/s, v_num=21876, train_loss_step=14.40, train_loss_epoch=14.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 120.63it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s, v_num=21878, train_loss_step=15.60, train_loss_epoch=15.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 75.75it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.75it/s, v_num=21880, train_loss_step=15.60, train_loss_epoch=15.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 182.31it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.75it/s, v_num=21882, train_loss_step=15.50, train_loss_epoch=15.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 92.67it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.18it/s, v_num=21884, train_loss_step=15.70, train_loss_epoch=15.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 56.70it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.67it/s, v_num=21886, train_loss_step=15.40, train_loss_epoch=15.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 164.43it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.12it/s, v_num=21888, train_loss_step=15.70, train_loss_epoch=15.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.99it/s, v_num=21890, train_loss_step=15.90, train_loss_epoch=15.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 463.25it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.87it/s, v_num=21892, train_loss_step=16.20, train_loss_epoch=16.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 297.81it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.21it/s, v_num=21894, train_loss_step=16.60, train_loss_epoch=16.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 250.74it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.12it/s, v_num=21896, train_loss_step=17.40, train_loss_epoch=17.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 329.40it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.12it/s, v_num=21898, train_loss_step=18.40, train_loss_epoch=18.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 206.54it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.69it/s, v_num=21900, train_loss_step=17.50, train_loss_epoch=17.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 139.70it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.85it/s, v_num=21902, train_loss_step=17.70, train_loss_epoch=17.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 113.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 21:30:15,918] Trial 1 finished with value: 0.7847619047619048 and parameters: {'n_blocks1': 1, 'n_blocks2': 2, 'n_blocks3': 2, 'mlp_units': 32, 'n_pool_kernel_size1': 3, 'n_pool_kernel_size2': 3, 'n_pool_kernel_size3': 2, 'learning_rate': 0.0010150568129948553}. Best is trial 0 with value: 0.7847619047619048.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.64it/s, v_num=21904, train_loss_step=12.20, train_loss_epoch=12.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 336.46it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.64it/s, v_num=21906, train_loss_step=12.70, train_loss_epoch=12.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 187.29it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 21.20it/s, v_num=21908, train_loss_step=13.50, train_loss_epoch=13.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 95.70it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.43it/s, v_num=21910, train_loss_step=12.80, train_loss_epoch=12.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 156.40it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.36it/s, v_num=21912, train_loss_step=13.10, train_loss_epoch=13.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 191.14it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.49it/s, v_num=21914, train_loss_step=12.90, train_loss_epoch=12.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 101.44it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.39it/s, v_num=21916, train_loss_step=13.60, train_loss_epoch=13.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 147.08it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.90it/s, v_num=21918, train_loss_step=14.70, train_loss_epoch=14.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 375.26it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.06it/s, v_num=21920, train_loss_step=15.00, train_loss_epoch=15.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.91it/s, v_num=21922, train_loss_step=14.70, train_loss_epoch=14.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 281.99it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.88it/s, v_num=21924, train_loss_step=14.70, train_loss_epoch=14.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 302.82it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 20.29it/s, v_num=21926, train_loss_step=14.50, train_loss_epoch=14.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 144.92it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.98it/s, v_num=21928, train_loss_step=14.80, train_loss_epoch=14.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 229.89it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.65it/s, v_num=21930, train_loss_step=15.20, train_loss_epoch=15.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 313.64it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.28it/s, v_num=21932, train_loss_step=15.50, train_loss_epoch=15.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 161.06it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.32it/s, v_num=21934, train_loss_step=15.90, train_loss_epoch=15.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 474.74it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.54it/s, v_num=21936, train_loss_step=16.50, train_loss_epoch=16.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 251.73it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.10it/s, v_num=21938, train_loss_step=17.20, train_loss_epoch=17.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 177.78it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 20.55it/s, v_num=21940, train_loss_step=16.50, train_loss_epoch=16.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 348.48it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.06it/s, v_num=21942, train_loss_step=16.80, train_loss_epoch=16.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 162.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 21:31:48,563] Trial 2 finished with value: 0.6266666666666667 and parameters: {'n_blocks1': 1, 'n_blocks2': 1, 'n_blocks3': 1, 'mlp_units': 32, 'n_pool_kernel_size1': 1, 'n_pool_kernel_size2': 3, 'n_pool_kernel_size3': 3, 'learning_rate': 0.03645514084208752}. Best is trial 0 with value: 0.7847619047619048.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.31it/s, v_num=21944, train_loss_step=12.70, train_loss_epoch=12.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 330.91it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.11it/s, v_num=21946, train_loss_step=13.40, train_loss_epoch=13.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 337.62it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.77it/s, v_num=21948, train_loss_step=14.20, train_loss_epoch=14.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 197.36it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.86it/s, v_num=21950, train_loss_step=13.70, train_loss_epoch=13.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 54.70it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.79it/s, v_num=21952, train_loss_step=14.20, train_loss_epoch=14.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 52.31it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.04it/s, v_num=21954, train_loss_step=14.10, train_loss_epoch=14.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 271.02it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.95it/s, v_num=21956, train_loss_step=14.70, train_loss_epoch=14.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 331.70it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.29it/s, v_num=21958, train_loss_step=15.80, train_loss_epoch=15.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 111.21it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.28it/s, v_num=21960, train_loss_step=15.90, train_loss_epoch=15.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 97.18it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.53it/s, v_num=21962, train_loss_step=15.80, train_loss_epoch=15.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 77.00it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.71it/s, v_num=21964, train_loss_step=15.90, train_loss_epoch=15.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 102.22it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.02it/s, v_num=21966, train_loss_step=15.60, train_loss_epoch=15.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 102.67it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.20it/s, v_num=21968, train_loss_step=15.90, train_loss_epoch=15.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 54.19it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.58it/s, v_num=21970, train_loss_step=16.10, train_loss_epoch=16.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.73it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.84it/s, v_num=21972, train_loss_step=16.40, train_loss_epoch=16.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 245.48it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.57it/s, v_num=21974, train_loss_step=16.80, train_loss_epoch=16.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 49.66it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.61it/s, v_num=21976, train_loss_step=17.70, train_loss_epoch=17.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 210.53it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.93it/s, v_num=21978, train_loss_step=18.60, train_loss_epoch=18.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.49it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.58it/s, v_num=21980, train_loss_step=17.70, train_loss_epoch=17.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 150.23it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.25it/s, v_num=21982, train_loss_step=17.80, train_loss_epoch=17.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 112.08it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.85it/s, v_num=21984, train_loss_step=17.30, train_loss_epoch=17.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 60.14it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.39it/s, v_num=21986, train_loss_step=16.70, train_loss_epoch=16.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 204.71it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.86it/s, v_num=21988, train_loss_step=17.00, train_loss_epoch=17.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 152.81it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.91it/s, v_num=21990, train_loss_step=16.30, train_loss_epoch=16.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.67it/s, v_num=21992, train_loss_step=16.10, train_loss_epoch=16.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.01it/s, v_num=21994, train_loss_step=16.30, train_loss_epoch=16.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 341.28it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.26it/s, v_num=21996, train_loss_step=16.80, train_loss_epoch=16.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 235.38it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.15it/s, v_num=21998, train_loss_step=16.30, train_loss_epoch=16.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 211.07it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.65it/s, v_num=22000, train_loss_step=16.20, train_loss_epoch=16.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 111.15it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.37it/s, v_num=22002, train_loss_step=16.80, train_loss_epoch=16.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 176.93it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.00it/s, v_num=22004, train_loss_step=16.80, train_loss_epoch=16.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 231.08it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.74it/s, v_num=22006, train_loss_step=16.50, train_loss_epoch=16.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 209.55it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.34it/s, v_num=22008, train_loss_step=16.30, train_loss_epoch=16.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 282.64it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  8.63it/s, v_num=22010, train_loss_step=15.40, train_loss_epoch=15.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 118.23it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.73it/s, v_num=22012, train_loss_step=14.90, train_loss_epoch=14.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 306.71it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.37it/s, v_num=22014, train_loss_step=14.30, train_loss_epoch=14.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 352.79it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.81it/s, v_num=22016, train_loss_step=14.30, train_loss_epoch=14.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 106.33it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.19it/s, v_num=22018, train_loss_step=14.20, train_loss_epoch=14.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 401.41it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.74it/s, v_num=22020, train_loss_step=13.80, train_loss_epoch=13.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 234.70it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.74it/s, v_num=22022, train_loss_step=14.10, train_loss_epoch=14.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 146.59it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.06it/s, v_num=22024, train_loss_step=14.00, train_loss_epoch=14.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 121.92it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.18it/s, v_num=22026, train_loss_step=13.30, train_loss_epoch=13.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 159.57it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.11it/s, v_num=22028, train_loss_step=13.50, train_loss_epoch=13.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 79.98it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.19it/s, v_num=22030, train_loss_step=13.40, train_loss_epoch=13.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 392.21it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.18it/s, v_num=22032, train_loss_step=13.60, train_loss_epoch=13.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 80.66it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  8.79it/s, v_num=22034, train_loss_step=13.20, train_loss_epoch=13.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 184.37it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.78it/s, v_num=22036, train_loss_step=13.50, train_loss_epoch=13.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 197.74it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.02it/s, v_num=22038, train_loss_step=13.80, train_loss_epoch=13.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.72it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.29it/s, v_num=22040, train_loss_step=12.10, train_loss_epoch=12.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 373.79it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.70it/s, v_num=22042, train_loss_step=12.20, train_loss_epoch=12.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 343.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 21:36:20,361] A new study created in memory with name: no-name-8c2c8a8d-b328-48e1-abe8-53a1c185a644\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prefix: NFLX | mode: financial | model_type: TFT\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.12it/s, v_num=22044, train_loss_step=16.20, train_loss_epoch=16.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.00it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.26it/s, v_num=22046, train_loss_step=16.00, train_loss_epoch=16.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 95.06it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.97it/s, v_num=22048, train_loss_step=15.90, train_loss_epoch=15.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 271.13it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.45it/s, v_num=22050, train_loss_step=15.40, train_loss_epoch=15.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 125.41it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.99it/s, v_num=22052, train_loss_step=15.10, train_loss_epoch=15.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.06it/s, v_num=22054, train_loss_step=14.70, train_loss_epoch=14.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.20it/s, v_num=22056, train_loss_step=14.70, train_loss_epoch=14.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 69.61it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.31it/s, v_num=22058, train_loss_step=14.40, train_loss_epoch=14.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 84.18it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.81it/s, v_num=22060, train_loss_step=14.30, train_loss_epoch=14.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 66.51it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.05it/s, v_num=22062, train_loss_step=13.80, train_loss_epoch=13.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 185.60it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.43it/s, v_num=22064, train_loss_step=13.20, train_loss_epoch=13.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 69.65it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.88it/s, v_num=22066, train_loss_step=13.40, train_loss_epoch=13.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 290.79it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.08it/s, v_num=22068, train_loss_step=13.80, train_loss_epoch=13.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 607.61it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.19it/s, v_num=22070, train_loss_step=13.90, train_loss_epoch=13.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 90.44it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.15it/s, v_num=22072, train_loss_step=13.80, train_loss_epoch=13.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 89.88it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.10it/s, v_num=22074, train_loss_step=13.80, train_loss_epoch=13.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 116.91it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.93it/s, v_num=22076, train_loss_step=13.40, train_loss_epoch=13.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.09it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.90it/s, v_num=22078, train_loss_step=13.70, train_loss_epoch=13.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 39.97it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=22080, train_loss_step=12.80, train_loss_epoch=12.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 71.33it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.06it/s, v_num=22082, train_loss_step=12.40, train_loss_epoch=12.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 66.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 21:38:12,686] Trial 0 finished with value: 0.8 and parameters: {'learning_rate': 0.018234835620977576, 'hidden_size': 20}. Best is trial 0 with value: 0.8.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.55it/s, v_num=22084, train_loss_step=18.10, train_loss_epoch=18.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 68.94it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.49it/s, v_num=22086, train_loss_step=17.90, train_loss_epoch=17.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 101.12it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.64it/s, v_num=22088, train_loss_step=17.80, train_loss_epoch=17.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 355.00it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.57it/s, v_num=22090, train_loss_step=17.20, train_loss_epoch=17.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.25it/s, v_num=22092, train_loss_step=16.80, train_loss_epoch=16.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 89.41it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.10it/s, v_num=22094, train_loss_step=16.40, train_loss_epoch=16.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 849.74it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.99it/s, v_num=22096, train_loss_step=16.40, train_loss_epoch=16.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 104.58it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.30it/s, v_num=22098, train_loss_step=16.10, train_loss_epoch=16.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 143.88it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.19it/s, v_num=22100, train_loss_step=16.00, train_loss_epoch=16.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 160.66it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.56it/s, v_num=22102, train_loss_step=15.70, train_loss_epoch=15.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 142.65it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.71it/s, v_num=22104, train_loss_step=15.20, train_loss_epoch=15.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 47.01it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  8.54it/s, v_num=22106, train_loss_step=15.40, train_loss_epoch=15.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 71.58it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.44it/s, v_num=22108, train_loss_step=15.80, train_loss_epoch=15.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 59.47it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.04it/s, v_num=22110, train_loss_step=16.10, train_loss_epoch=16.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 330.47it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.45it/s, v_num=22112, train_loss_step=16.00, train_loss_epoch=16.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 209.32it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.34it/s, v_num=22114, train_loss_step=16.00, train_loss_epoch=16.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 152.83it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.77it/s, v_num=22116, train_loss_step=15.70, train_loss_epoch=15.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 49.91it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.99it/s, v_num=22118, train_loss_step=16.00, train_loss_epoch=16.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 119.29it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.41it/s, v_num=22120, train_loss_step=15.00, train_loss_epoch=15.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 88.94it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.13it/s, v_num=22122, train_loss_step=14.50, train_loss_epoch=14.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 58.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 21:39:55,150] Trial 1 finished with value: 0.495 and parameters: {'learning_rate': 0.00015853367566334624, 'hidden_size': 8}. Best is trial 0 with value: 0.8.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.91it/s, v_num=22124, train_loss_step=16.10, train_loss_epoch=16.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 209.95it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.41it/s, v_num=22126, train_loss_step=15.90, train_loss_epoch=15.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 494.67it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.29it/s, v_num=22128, train_loss_step=15.90, train_loss_epoch=15.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 92.91it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.19it/s, v_num=22130, train_loss_step=15.50, train_loss_epoch=15.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 85.18it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.20it/s, v_num=22132, train_loss_step=15.10, train_loss_epoch=15.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.24it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.96it/s, v_num=22134, train_loss_step=14.80, train_loss_epoch=14.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 65.36it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=22136, train_loss_step=14.70, train_loss_epoch=14.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 58.40it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.43it/s, v_num=22138, train_loss_step=14.40, train_loss_epoch=14.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 87.99it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.94it/s, v_num=22140, train_loss_step=14.40, train_loss_epoch=14.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 621.84it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.32it/s, v_num=22142, train_loss_step=13.90, train_loss_epoch=13.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 912.40it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.00it/s, v_num=22144, train_loss_step=13.20, train_loss_epoch=13.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 82.24it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.76it/s, v_num=22146, train_loss_step=13.40, train_loss_epoch=13.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 78.97it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.56it/s, v_num=22148, train_loss_step=13.80, train_loss_epoch=13.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 189.56it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.67it/s, v_num=22150, train_loss_step=13.90, train_loss_epoch=13.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 92.58it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.47it/s, v_num=22152, train_loss_step=13.80, train_loss_epoch=13.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 84.54it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.59it/s, v_num=22154, train_loss_step=13.80, train_loss_epoch=13.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 249.78it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.55it/s, v_num=22156, train_loss_step=13.40, train_loss_epoch=13.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 293.66it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.71it/s, v_num=22158, train_loss_step=13.60, train_loss_epoch=13.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 259.05it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.44it/s, v_num=22160, train_loss_step=12.80, train_loss_epoch=12.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 162.43it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.88it/s, v_num=22162, train_loss_step=12.50, train_loss_epoch=12.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 222.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 21:41:51,227] Trial 2 finished with value: 0.7847619047619048 and parameters: {'learning_rate': 0.0058331016358380465, 'hidden_size': 28}. Best is trial 0 with value: 0.8.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.36it/s, v_num=22164, train_loss_step=16.20, train_loss_epoch=16.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 90.96it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.77it/s, v_num=22166, train_loss_step=16.00, train_loss_epoch=16.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 168.03it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.05it/s, v_num=22168, train_loss_step=15.90, train_loss_epoch=15.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 144.93it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.63it/s, v_num=22170, train_loss_step=15.40, train_loss_epoch=15.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 177.01it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.40it/s, v_num=22172, train_loss_step=15.10, train_loss_epoch=15.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 51.91it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.28it/s, v_num=22174, train_loss_step=14.70, train_loss_epoch=14.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 57.39it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.05it/s, v_num=22176, train_loss_step=14.70, train_loss_epoch=14.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 93.75it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.71it/s, v_num=22178, train_loss_step=14.40, train_loss_epoch=14.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 49.68it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.33it/s, v_num=22180, train_loss_step=14.30, train_loss_epoch=14.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.03it/s, v_num=22182, train_loss_step=13.80, train_loss_epoch=13.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 97.05it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.30it/s, v_num=22184, train_loss_step=13.20, train_loss_epoch=13.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 110.33it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.22it/s, v_num=22186, train_loss_step=13.40, train_loss_epoch=13.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.10it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.33it/s, v_num=22188, train_loss_step=13.80, train_loss_epoch=13.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 77.88it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.22it/s, v_num=22190, train_loss_step=13.90, train_loss_epoch=13.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 80.06it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.84it/s, v_num=22192, train_loss_step=13.80, train_loss_epoch=13.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 51.99it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.78it/s, v_num=22194, train_loss_step=13.80, train_loss_epoch=13.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 196.50it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.30it/s, v_num=22196, train_loss_step=13.40, train_loss_epoch=13.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 205.80it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.30it/s, v_num=22198, train_loss_step=13.70, train_loss_epoch=13.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 236.13it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.92it/s, v_num=22200, train_loss_step=12.80, train_loss_epoch=12.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 313.19it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.62it/s, v_num=22202, train_loss_step=12.40, train_loss_epoch=12.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 120.79it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.09it/s, v_num=22204, train_loss_step=12.60, train_loss_epoch=12.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 278.69it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.65it/s, v_num=22206, train_loss_step=12.90, train_loss_epoch=12.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 126.57it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.92it/s, v_num=22208, train_loss_step=12.80, train_loss_epoch=12.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 88.26it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.92it/s, v_num=22210, train_loss_step=12.90, train_loss_epoch=12.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 110.14it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.91it/s, v_num=22212, train_loss_step=13.00, train_loss_epoch=13.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.68it/s, v_num=22214, train_loss_step=13.30, train_loss_epoch=13.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 103.48it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.15it/s, v_num=22216, train_loss_step=13.00, train_loss_epoch=13.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 169.03it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.24it/s, v_num=22218, train_loss_step=12.70, train_loss_epoch=12.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 69.99it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.43it/s, v_num=22220, train_loss_step=12.60, train_loss_epoch=12.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 75.74it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.73it/s, v_num=22222, train_loss_step=13.10, train_loss_epoch=13.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 67.35it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.86it/s, v_num=22224, train_loss_step=13.20, train_loss_epoch=13.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.88it/s, v_num=22226, train_loss_step=12.40, train_loss_epoch=12.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 83.97it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.23it/s, v_num=22228, train_loss_step=11.70, train_loss_epoch=11.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 68.94it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.01it/s, v_num=22230, train_loss_step=11.10, train_loss_epoch=11.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 44.71it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.46it/s, v_num=22232, train_loss_step=11.20, train_loss_epoch=11.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 79.67it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.25it/s, v_num=22234, train_loss_step=11.60, train_loss_epoch=11.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 266.00it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.05it/s, v_num=22236, train_loss_step=11.60, train_loss_epoch=11.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 69.50it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.00it/s, v_num=22238, train_loss_step=12.00, train_loss_epoch=12.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 78.62it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.44it/s, v_num=22240, train_loss_step=12.70, train_loss_epoch=12.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 70.17it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.12it/s, v_num=22242, train_loss_step=12.80, train_loss_epoch=12.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 85.90it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.99it/s, v_num=22244, train_loss_step=13.20, train_loss_epoch=13.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 1983.12it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.87it/s, v_num=22246, train_loss_step=13.30, train_loss_epoch=13.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 102.39it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.61it/s, v_num=22248, train_loss_step=13.50, train_loss_epoch=13.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 112.70it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.89it/s, v_num=22250, train_loss_step=13.50, train_loss_epoch=13.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 56.28it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.14it/s, v_num=22252, train_loss_step=13.60, train_loss_epoch=13.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 41.39it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.40it/s, v_num=22254, train_loss_step=13.70, train_loss_epoch=13.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 77.32it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.10it/s, v_num=22256, train_loss_step=14.00, train_loss_epoch=14.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 262.01it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.16it/s, v_num=22258, train_loss_step=14.00, train_loss_epoch=14.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 392.95it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.67it/s, v_num=22260, train_loss_step=13.90, train_loss_epoch=13.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 57.73it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.94it/s, v_num=22262, train_loss_step=13.90, train_loss_epoch=13.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 128.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 21:46:27,923] A new study created in memory with name: no-name-d6cdedae-cd6c-4118-8432-ef73248c4393\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prefix: NFLX | mode: news | model_type: NBEATS\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.98it/s, v_num=22264, train_loss_step=12.70, train_loss_epoch=12.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 193.64it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.26it/s, v_num=22266, train_loss_step=13.40, train_loss_epoch=13.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 140.01it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.49it/s, v_num=22268, train_loss_step=14.20, train_loss_epoch=14.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 123.16it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.91it/s, v_num=22270, train_loss_step=13.60, train_loss_epoch=13.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 187.35it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.31it/s, v_num=22272, train_loss_step=14.20, train_loss_epoch=14.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.59it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.24it/s, v_num=22274, train_loss_step=14.00, train_loss_epoch=14.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 281.69it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.98it/s, v_num=22276, train_loss_step=14.60, train_loss_epoch=14.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 264.91it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  6.58it/s, v_num=22278, train_loss_step=15.70, train_loss_epoch=15.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 173.76it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.65it/s, v_num=22280, train_loss_step=15.80, train_loss_epoch=15.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 86.91it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.30it/s, v_num=22282, train_loss_step=15.60, train_loss_epoch=15.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 327.48it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.01it/s, v_num=22284, train_loss_step=15.80, train_loss_epoch=15.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 263.83it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.66it/s, v_num=22286, train_loss_step=15.60, train_loss_epoch=15.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 72.50it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.13it/s, v_num=22288, train_loss_step=15.80, train_loss_epoch=15.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 431.47it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.16it/s, v_num=22290, train_loss_step=16.00, train_loss_epoch=16.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 137.07it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.53it/s, v_num=22292, train_loss_step=16.40, train_loss_epoch=16.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 166.61it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.98it/s, v_num=22294, train_loss_step=16.70, train_loss_epoch=16.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 166.55it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.66it/s, v_num=22296, train_loss_step=17.60, train_loss_epoch=17.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 73.90it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.70it/s, v_num=22298, train_loss_step=18.50, train_loss_epoch=18.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 319.66it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.65it/s, v_num=22300, train_loss_step=17.60, train_loss_epoch=17.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 187.88it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.12it/s, v_num=22302, train_loss_step=17.80, train_loss_epoch=17.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 163.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 21:48:04,763] Trial 0 finished with value: 0.7227272727272727 and parameters: {'n_blocks_season': 2, 'n_blocks_trend': 1, 'n_blocks_ident': 3, 'mlp_units': 128, 'num_hidden': 1, 'n_harmonics': 3, 'n_polynomials': 2, 'learning_rate': 1.1975579961748119e-05}. Best is trial 0 with value: 0.7227272727272727.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 20.15it/s, v_num=22304, train_loss_step=13.00, train_loss_epoch=13.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 109.41it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.53it/s, v_num=22306, train_loss_step=13.70, train_loss_epoch=13.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 486.58it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.48it/s, v_num=22308, train_loss_step=14.60, train_loss_epoch=14.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 313.41it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.15it/s, v_num=22310, train_loss_step=14.00, train_loss_epoch=14.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 81.92it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.27it/s, v_num=22312, train_loss_step=14.50, train_loss_epoch=14.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 218.08it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.68it/s, v_num=22314, train_loss_step=14.40, train_loss_epoch=14.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 200.44it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.27it/s, v_num=22316, train_loss_step=15.00, train_loss_epoch=15.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 302.71it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.32it/s, v_num=22318, train_loss_step=16.20, train_loss_epoch=16.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 400.11it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.16it/s, v_num=22320, train_loss_step=16.20, train_loss_epoch=16.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 330.16it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.28it/s, v_num=22322, train_loss_step=16.10, train_loss_epoch=16.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 194.30it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 20.11it/s, v_num=22324, train_loss_step=16.20, train_loss_epoch=16.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 179.22it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.55it/s, v_num=22326, train_loss_step=15.90, train_loss_epoch=15.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 147.13it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.85it/s, v_num=22328, train_loss_step=16.20, train_loss_epoch=16.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 379.51it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 20.35it/s, v_num=22330, train_loss_step=16.40, train_loss_epoch=16.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 323.34it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.12it/s, v_num=22332, train_loss_step=16.70, train_loss_epoch=16.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 123.19it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.90it/s, v_num=22334, train_loss_step=17.10, train_loss_epoch=17.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.85it/s, v_num=22336, train_loss_step=18.00, train_loss_epoch=18.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 86.23it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.65it/s, v_num=22338, train_loss_step=18.90, train_loss_epoch=18.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 188.67it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.08it/s, v_num=22340, train_loss_step=18.10, train_loss_epoch=18.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 104.24it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.73it/s, v_num=22342, train_loss_step=18.20, train_loss_epoch=18.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 289.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 21:49:37,481] Trial 1 finished with value: 0.7311111111111112 and parameters: {'n_blocks_season': 2, 'n_blocks_trend': 2, 'n_blocks_ident': 3, 'mlp_units': 32, 'num_hidden': 1, 'n_harmonics': 4, 'n_polynomials': 3, 'learning_rate': 0.0001873765573816776}. Best is trial 1 with value: 0.7311111111111112.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.92it/s, v_num=22344, train_loss_step=12.50, train_loss_epoch=12.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.29it/s, v_num=22346, train_loss_step=13.10, train_loss_epoch=13.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 60.31it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.90it/s, v_num=22348, train_loss_step=14.00, train_loss_epoch=14.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 278.40it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.65it/s, v_num=22350, train_loss_step=13.40, train_loss_epoch=13.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 117.11it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.75it/s, v_num=22352, train_loss_step=13.90, train_loss_epoch=13.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 116.62it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.79it/s, v_num=22354, train_loss_step=13.80, train_loss_epoch=13.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 214.13it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.61it/s, v_num=22356, train_loss_step=14.30, train_loss_epoch=14.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 249.14it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.00it/s, v_num=22358, train_loss_step=15.40, train_loss_epoch=15.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 83.71it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.15it/s, v_num=22360, train_loss_step=15.50, train_loss_epoch=15.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 154.30it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.50it/s, v_num=22362, train_loss_step=15.40, train_loss_epoch=15.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 158.48it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.98it/s, v_num=22364, train_loss_step=15.50, train_loss_epoch=15.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 221.06it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.67it/s, v_num=22366, train_loss_step=15.20, train_loss_epoch=15.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 123.29it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.16it/s, v_num=22368, train_loss_step=15.50, train_loss_epoch=15.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 249.29it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.22it/s, v_num=22370, train_loss_step=15.70, train_loss_epoch=15.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 98.18it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.42it/s, v_num=22372, train_loss_step=16.10, train_loss_epoch=16.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 186.30it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.37it/s, v_num=22374, train_loss_step=16.40, train_loss_epoch=16.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 303.28it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.93it/s, v_num=22376, train_loss_step=17.30, train_loss_epoch=17.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  8.01it/s, v_num=22378, train_loss_step=18.10, train_loss_epoch=18.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 110.90it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  8.09it/s, v_num=22380, train_loss_step=17.20, train_loss_epoch=17.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 332.62it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.25it/s, v_num=22382, train_loss_step=17.40, train_loss_epoch=17.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 176.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 21:51:13,769] Trial 2 finished with value: 0.7 and parameters: {'n_blocks_season': 2, 'n_blocks_trend': 3, 'n_blocks_ident': 3, 'mlp_units': 32, 'num_hidden': 2, 'n_harmonics': 2, 'n_polynomials': 1, 'learning_rate': 0.020782288532358344}. Best is trial 1 with value: 0.7311111111111112.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.07it/s, v_num=22384, train_loss_step=13.00, train_loss_epoch=13.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 66.12it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.91it/s, v_num=22386, train_loss_step=13.70, train_loss_epoch=13.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 152.89it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.46it/s, v_num=22388, train_loss_step=14.60, train_loss_epoch=14.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 267.14it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.91it/s, v_num=22390, train_loss_step=14.00, train_loss_epoch=14.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 1979.38it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.78it/s, v_num=22392, train_loss_step=14.50, train_loss_epoch=14.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 21.68it/s, v_num=22394, train_loss_step=14.40, train_loss_epoch=14.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 264.03it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.66it/s, v_num=22396, train_loss_step=15.00, train_loss_epoch=15.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 194.84it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.34it/s, v_num=22398, train_loss_step=16.20, train_loss_epoch=16.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 148.79it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.23it/s, v_num=22400, train_loss_step=16.20, train_loss_epoch=16.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 218.27it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.59it/s, v_num=22402, train_loss_step=16.10, train_loss_epoch=16.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 227.85it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.15it/s, v_num=22404, train_loss_step=16.20, train_loss_epoch=16.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 71.01it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.62it/s, v_num=22406, train_loss_step=15.90, train_loss_epoch=15.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 117.40it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.44it/s, v_num=22408, train_loss_step=16.20, train_loss_epoch=16.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 211.87it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.74it/s, v_num=22410, train_loss_step=16.40, train_loss_epoch=16.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 186.16it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.70it/s, v_num=22412, train_loss_step=16.70, train_loss_epoch=16.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.52it/s, v_num=22414, train_loss_step=17.10, train_loss_epoch=17.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 168.57it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.67it/s, v_num=22416, train_loss_step=18.00, train_loss_epoch=18.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 397.41it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.46it/s, v_num=22418, train_loss_step=18.90, train_loss_epoch=18.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 56.31it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.89it/s, v_num=22420, train_loss_step=18.10, train_loss_epoch=18.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 866.59it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.91it/s, v_num=22422, train_loss_step=18.20, train_loss_epoch=18.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 99.45it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.23it/s, v_num=22424, train_loss_step=17.60, train_loss_epoch=17.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 322.99it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.58it/s, v_num=22426, train_loss_step=17.00, train_loss_epoch=17.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 200.45it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  7.26it/s, v_num=22428, train_loss_step=17.20, train_loss_epoch=17.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 370.16it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.79it/s, v_num=22430, train_loss_step=16.60, train_loss_epoch=16.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 119.67it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.45it/s, v_num=22432, train_loss_step=16.40, train_loss_epoch=16.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 58.66it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.19it/s, v_num=22434, train_loss_step=16.60, train_loss_epoch=16.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 307.61it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.41it/s, v_num=22436, train_loss_step=17.10, train_loss_epoch=17.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 154.65it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.76it/s, v_num=22438, train_loss_step=16.60, train_loss_epoch=16.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 347.93it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.99it/s, v_num=22440, train_loss_step=16.50, train_loss_epoch=16.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 141.05it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.37it/s, v_num=22442, train_loss_step=17.10, train_loss_epoch=17.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 136.46it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.07it/s, v_num=22444, train_loss_step=17.10, train_loss_epoch=17.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.50it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.68it/s, v_num=22446, train_loss_step=16.80, train_loss_epoch=16.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 326.86it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.88it/s, v_num=22448, train_loss_step=16.50, train_loss_epoch=16.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 267.55it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.89it/s, v_num=22450, train_loss_step=15.60, train_loss_epoch=15.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 154.16it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.56it/s, v_num=22452, train_loss_step=15.10, train_loss_epoch=15.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 265.48it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.06it/s, v_num=22454, train_loss_step=14.50, train_loss_epoch=14.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 323.61it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.86it/s, v_num=22456, train_loss_step=14.50, train_loss_epoch=14.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 125.89it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.31it/s, v_num=22458, train_loss_step=14.40, train_loss_epoch=14.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 154.59it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.65it/s, v_num=22460, train_loss_step=13.90, train_loss_epoch=13.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 268.90it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, v_num=22462, train_loss_step=14.30, train_loss_epoch=14.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.15it/s, v_num=22464, train_loss_step=14.30, train_loss_epoch=14.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 97.97it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.72it/s, v_num=22466, train_loss_step=13.50, train_loss_epoch=13.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 229.41it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.71it/s, v_num=22468, train_loss_step=13.70, train_loss_epoch=13.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 152.91it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.56it/s, v_num=22470, train_loss_step=13.60, train_loss_epoch=13.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 61.65it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.96it/s, v_num=22472, train_loss_step=13.80, train_loss_epoch=13.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 459.80it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.11it/s, v_num=22474, train_loss_step=13.40, train_loss_epoch=13.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 172.72it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 20.20it/s, v_num=22476, train_loss_step=13.70, train_loss_epoch=13.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.64it/s, v_num=22478, train_loss_step=14.00, train_loss_epoch=14.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 379.33it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.91it/s, v_num=22480, train_loss_step=12.30, train_loss_epoch=12.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 84.23it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.25it/s, v_num=22482, train_loss_step=12.50, train_loss_epoch=12.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 165.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 21:55:07,057] A new study created in memory with name: no-name-18c366ae-760c-459e-b2e4-bf36e3ec3b79\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prefix: NFLX | mode: news | model_type: NHITS\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.50it/s, v_num=22484, train_loss_step=12.70, train_loss_epoch=12.70]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.37it/s, v_num=22486, train_loss_step=15.80, train_loss_epoch=15.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 193.58it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.37it/s, v_num=22488, train_loss_step=14.70, train_loss_epoch=14.70]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.98it/s, v_num=22490, train_loss_step=13.50, train_loss_epoch=13.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 167.19it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.57it/s, v_num=22492, train_loss_step=14.10, train_loss_epoch=14.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 72.93it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.84it/s, v_num=22494, train_loss_step=13.80, train_loss_epoch=13.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 218.73it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.65it/s, v_num=22496, train_loss_step=14.60, train_loss_epoch=14.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 144.47it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.00it/s, v_num=22498, train_loss_step=18.10, train_loss_epoch=18.10]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 197.50it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.87it/s, v_num=22500, train_loss_step=15.50, train_loss_epoch=15.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 152.14it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.83it/s, v_num=22502, train_loss_step=15.70, train_loss_epoch=15.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.90it/s, v_num=22504, train_loss_step=16.60, train_loss_epoch=16.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 212.29it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.65it/s, v_num=22506, train_loss_step=16.50, train_loss_epoch=16.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 497.37it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.96it/s, v_num=22508, train_loss_step=15.70, train_loss_epoch=15.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 148.85it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.06it/s, v_num=22510, train_loss_step=16.90, train_loss_epoch=16.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.61it/s, v_num=22512, train_loss_step=17.80, train_loss_epoch=17.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 447.97it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s, v_num=22514, train_loss_step=16.90, train_loss_epoch=16.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 180.76it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.56it/s, v_num=22516, train_loss_step=17.50, train_loss_epoch=17.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 109.91it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.69it/s, v_num=22518, train_loss_step=18.60, train_loss_epoch=18.60]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  8.67it/s, v_num=22520, train_loss_step=17.50, train_loss_epoch=17.50]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 114.65it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.77it/s, v_num=22522, train_loss_step=19.10, train_loss_epoch=19.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 459.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 21:56:45,543] Trial 0 finished with value: 0.7709090909090909 and parameters: {'n_blocks1': 1, 'n_blocks2': 2, 'n_blocks3': 2, 'mlp_units': 64, 'n_pool_kernel_size1': 2, 'n_pool_kernel_size2': 2, 'n_pool_kernel_size3': 2, 'learning_rate': 0.05217969694635568}. Best is trial 0 with value: 0.7709090909090909.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.77it/s, v_num=22524, train_loss_step=22.00, train_loss_epoch=22.00]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 111.33it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.63it/s, v_num=22526, train_loss_step=17.80, train_loss_epoch=17.80]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 325.92it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.84it/s, v_num=22528, train_loss_step=34.60, train_loss_epoch=34.60]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.83it/s, v_num=22530, train_loss_step=17.00, train_loss_epoch=17.00]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 389.48it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.20it/s, v_num=22532, train_loss_step=16.30, train_loss_epoch=16.30]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 166.08it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.96it/s, v_num=22534, train_loss_step=98.30, train_loss_epoch=98.30]    \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 126.94it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.25it/s, v_num=22536, train_loss_step=22.80, train_loss_epoch=22.80]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 88.22it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.68it/s, v_num=22538, train_loss_step=1.73e+3, train_loss_epoch=1.73e+3]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 133.96it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.00it/s, v_num=22540, train_loss_step=16.80, train_loss_epoch=16.80]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 114.72it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.51it/s, v_num=22542, train_loss_step=15.90, train_loss_epoch=15.90]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 396.74it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.83it/s, v_num=22544, train_loss_step=19.30, train_loss_epoch=19.30]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 223.14it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.52it/s, v_num=22546, train_loss_step=17.30, train_loss_epoch=17.30] \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 343.43it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.06it/s, v_num=22548, train_loss_step=63.80, train_loss_epoch=63.80]    \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 104.13it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.69it/s, v_num=22550, train_loss_step=902.0, train_loss_epoch=902.0]    \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 105.82it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.95it/s, v_num=22552, train_loss_step=19.70, train_loss_epoch=19.70]    \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 58.38it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.28it/s, v_num=22554, train_loss_step=24.20, train_loss_epoch=24.20]    \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 198.32it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.57it/s, v_num=22556, train_loss_step=78.00, train_loss_epoch=78.00]    \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 137.01it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.72it/s, v_num=22558, train_loss_step=25.00, train_loss_epoch=25.00]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.43it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  7.42it/s, v_num=22560, train_loss_step=34.30, train_loss_epoch=34.30]    \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 114.03it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.35it/s, v_num=22562, train_loss_step=32.40, train_loss_epoch=32.40]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 58.78it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 21:58:33,881] Trial 1 finished with value: 0.6636842105263158 and parameters: {'n_blocks1': 3, 'n_blocks2': 2, 'n_blocks3': 1, 'mlp_units': 128, 'n_pool_kernel_size1': 3, 'n_pool_kernel_size2': 1, 'n_pool_kernel_size3': 2, 'learning_rate': 0.0319572012764943}. Best is trial 0 with value: 0.7709090909090909.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.13it/s, v_num=22564, train_loss_step=420.0, train_loss_epoch=420.0]    \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.58it/s, v_num=22566, train_loss_step=298.0, train_loss_epoch=298.0]    \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.30it/s, v_num=22568, train_loss_step=49.30, train_loss_epoch=49.30]    \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 331.28it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.50it/s, v_num=22570, train_loss_step=481.0, train_loss_epoch=481.0]    \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.04it/s, v_num=22572, train_loss_step=122.0, train_loss_epoch=122.0]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 68.83it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.55it/s, v_num=22574, train_loss_step=475.0, train_loss_epoch=475.0]    \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 249.10it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.70it/s, v_num=22576, train_loss_step=270.0, train_loss_epoch=270.0]    \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 190.19it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  7.53it/s, v_num=22578, train_loss_step=27.80, train_loss_epoch=27.80]    \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.62it/s, v_num=22580, train_loss_step=107.0, train_loss_epoch=107.0]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 91.04it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.45it/s, v_num=22582, train_loss_step=578.0, train_loss_epoch=578.0]    \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 363.52it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.99it/s, v_num=22584, train_loss_step=42.70, train_loss_epoch=42.70]    \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.74it/s, v_num=22586, train_loss_step=34.30, train_loss_epoch=34.30]    \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 71.26it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.20it/s, v_num=22588, train_loss_step=65.30, train_loss_epoch=65.30]    \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 168.97it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.47it/s, v_num=22590, train_loss_step=61.70, train_loss_epoch=61.70]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 240.78it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.41it/s, v_num=22592, train_loss_step=158.0, train_loss_epoch=158.0]    \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 395.32it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.84it/s, v_num=22594, train_loss_step=266.0, train_loss_epoch=266.0]    \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 59.58it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.26it/s, v_num=22596, train_loss_step=28.40, train_loss_epoch=28.40]    \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 188.83it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.11it/s, v_num=22598, train_loss_step=77.40, train_loss_epoch=77.40]    \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 185.60it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.92it/s, v_num=22600, train_loss_step=141.0, train_loss_epoch=141.0]    \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.91it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.59it/s, v_num=22602, train_loss_step=37.20, train_loss_epoch=37.20]    \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 59.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 22:00:24,417] Trial 2 finished with value: 0.7618518518518519 and parameters: {'n_blocks1': 1, 'n_blocks2': 3, 'n_blocks3': 2, 'mlp_units': 128, 'n_pool_kernel_size1': 3, 'n_pool_kernel_size2': 1, 'n_pool_kernel_size3': 1, 'learning_rate': 0.039012997940145844}. Best is trial 0 with value: 0.7709090909090909.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.99it/s, v_num=22604, train_loss_step=12.70, train_loss_epoch=12.70]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.51it/s, v_num=22606, train_loss_step=15.80, train_loss_epoch=15.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 66.59it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.02it/s, v_num=22608, train_loss_step=14.70, train_loss_epoch=14.70]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 79.97it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.10it/s, v_num=22610, train_loss_step=13.50, train_loss_epoch=13.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 47.88it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.22it/s, v_num=22612, train_loss_step=14.10, train_loss_epoch=14.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.64it/s, v_num=22614, train_loss_step=13.80, train_loss_epoch=13.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 54.29it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.80it/s, v_num=22616, train_loss_step=14.60, train_loss_epoch=14.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 351.11it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.50it/s, v_num=22618, train_loss_step=18.10, train_loss_epoch=18.10]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 120.23it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.57it/s, v_num=22620, train_loss_step=15.50, train_loss_epoch=15.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 181.49it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.43it/s, v_num=22622, train_loss_step=15.70, train_loss_epoch=15.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 655.77it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.80it/s, v_num=22624, train_loss_step=16.60, train_loss_epoch=16.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 105.84it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.49it/s, v_num=22626, train_loss_step=16.50, train_loss_epoch=16.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 56.47it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.93it/s, v_num=22628, train_loss_step=15.70, train_loss_epoch=15.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 65.80it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.00it/s, v_num=22630, train_loss_step=16.90, train_loss_epoch=16.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 41.91it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 21.02it/s, v_num=22632, train_loss_step=17.80, train_loss_epoch=17.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.13it/s, v_num=22634, train_loss_step=16.90, train_loss_epoch=16.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 111.05it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.04it/s, v_num=22636, train_loss_step=17.50, train_loss_epoch=17.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 59.99it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.51it/s, v_num=22638, train_loss_step=18.60, train_loss_epoch=18.60]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 232.42it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.77it/s, v_num=22640, train_loss_step=17.50, train_loss_epoch=17.50]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 334.66it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.51it/s, v_num=22642, train_loss_step=19.10, train_loss_epoch=19.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 65.35it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.17it/s, v_num=22644, train_loss_step=19.50, train_loss_epoch=19.50]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 263.79it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.01it/s, v_num=22646, train_loss_step=16.10, train_loss_epoch=16.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 385.01it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.00it/s, v_num=22648, train_loss_step=18.20, train_loss_epoch=18.20]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 261.77it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.57it/s, v_num=22650, train_loss_step=17.00, train_loss_epoch=17.00]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 59.98it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.63it/s, v_num=22652, train_loss_step=16.30, train_loss_epoch=16.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 304.46it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.83it/s, v_num=22654, train_loss_step=17.10, train_loss_epoch=17.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 164.80it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.50it/s, v_num=22656, train_loss_step=16.70, train_loss_epoch=16.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 204.51it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.17it/s, v_num=22658, train_loss_step=16.40, train_loss_epoch=16.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 128.70it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.25it/s, v_num=22660, train_loss_step=16.00, train_loss_epoch=16.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 258.54it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.68it/s, v_num=22662, train_loss_step=18.40, train_loss_epoch=18.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 142.95it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.16it/s, v_num=22664, train_loss_step=16.80, train_loss_epoch=16.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 56.71it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.45it/s, v_num=22666, train_loss_step=16.60, train_loss_epoch=16.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 275.13it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.68it/s, v_num=22668, train_loss_step=16.70, train_loss_epoch=16.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 243.47it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.35it/s, v_num=22670, train_loss_step=15.30, train_loss_epoch=15.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 102.68it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.15it/s, v_num=22672, train_loss_step=14.50, train_loss_epoch=14.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 126.53it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.39it/s, v_num=22674, train_loss_step=14.30, train_loss_epoch=14.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 47.26it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.03it/s, v_num=22676, train_loss_step=14.30, train_loss_epoch=14.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 391.70it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.89it/s, v_num=22678, train_loss_step=14.00, train_loss_epoch=14.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.00it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.09it/s, v_num=22680, train_loss_step=13.60, train_loss_epoch=13.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 130.67it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.15it/s, v_num=22682, train_loss_step=14.00, train_loss_epoch=14.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 146.16it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.95it/s, v_num=22684, train_loss_step=13.80, train_loss_epoch=13.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 61.71it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.92it/s, v_num=22686, train_loss_step=13.90, train_loss_epoch=13.90]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 138.06it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.06it/s, v_num=22688, train_loss_step=13.00, train_loss_epoch=13.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 188.80it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.86it/s, v_num=22690, train_loss_step=13.40, train_loss_epoch=13.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 182.71it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.61it/s, v_num=22692, train_loss_step=13.40, train_loss_epoch=13.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.29it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.51it/s, v_num=22694, train_loss_step=13.10, train_loss_epoch=13.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.02it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.83it/s, v_num=22696, train_loss_step=13.00, train_loss_epoch=13.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 268.87it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.69it/s, v_num=22698, train_loss_step=13.30, train_loss_epoch=13.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.65it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.23it/s, v_num=22700, train_loss_step=12.00, train_loss_epoch=12.00]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 66.80it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.44it/s, v_num=22702, train_loss_step=12.30, train_loss_epoch=12.30]   \n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 69.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 22:04:32,853] A new study created in memory with name: no-name-6f149f55-e223-43ed-90c9-8c3a0c2f5415\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prefix: NFLX | mode: news | model_type: TFT\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.67it/s, v_num=22704, train_loss_step=18.00, train_loss_epoch=18.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 106.13it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.39it/s, v_num=22706, train_loss_step=17.90, train_loss_epoch=17.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 27.78it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.68it/s, v_num=22708, train_loss_step=17.90, train_loss_epoch=17.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 91.80it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.20it/s, v_num=22710, train_loss_step=17.30, train_loss_epoch=17.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 326.48it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.15it/s, v_num=22712, train_loss_step=16.90, train_loss_epoch=16.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 88.25it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.36it/s, v_num=22714, train_loss_step=16.50, train_loss_epoch=16.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 156.18it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.43it/s, v_num=22716, train_loss_step=16.50, train_loss_epoch=16.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 44.79it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.30it/s, v_num=22718, train_loss_step=16.20, train_loss_epoch=16.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 270.15it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.67it/s, v_num=22720, train_loss_step=16.20, train_loss_epoch=16.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 947.01it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.07it/s, v_num=22722, train_loss_step=15.80, train_loss_epoch=15.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.52it/s, v_num=22724, train_loss_step=15.40, train_loss_epoch=15.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 72.18it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.46it/s, v_num=22726, train_loss_step=15.60, train_loss_epoch=15.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 234.57it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.75it/s, v_num=22728, train_loss_step=16.00, train_loss_epoch=16.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 68.32it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.24it/s, v_num=22730, train_loss_step=16.10, train_loss_epoch=16.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 86.16it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.34it/s, v_num=22732, train_loss_step=16.00, train_loss_epoch=16.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 187.40it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.35it/s, v_num=22734, train_loss_step=16.10, train_loss_epoch=16.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 121.63it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.61it/s, v_num=22736, train_loss_step=15.80, train_loss_epoch=15.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 182.25it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.00it/s, v_num=22738, train_loss_step=16.10, train_loss_epoch=16.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.59it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.31it/s, v_num=22740, train_loss_step=15.20, train_loss_epoch=15.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 84.12it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.17it/s, v_num=22742, train_loss_step=14.70, train_loss_epoch=14.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 90.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 22:06:22,679] Trial 0 finished with value: 0.47000000000000003 and parameters: {'learning_rate': 6.608353246346496e-05, 'hidden_size': 16}. Best is trial 0 with value: 0.47000000000000003.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.92it/s, v_num=22744, train_loss_step=17.90, train_loss_epoch=17.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 56.71it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.24it/s, v_num=22746, train_loss_step=17.80, train_loss_epoch=17.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 54.58it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.90it/s, v_num=22748, train_loss_step=17.80, train_loss_epoch=17.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 44.53it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.36it/s, v_num=22750, train_loss_step=17.20, train_loss_epoch=17.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 57.61it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.62it/s, v_num=22752, train_loss_step=16.80, train_loss_epoch=16.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 226.07it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.99it/s, v_num=22754, train_loss_step=16.40, train_loss_epoch=16.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 66.48it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.47it/s, v_num=22756, train_loss_step=16.40, train_loss_epoch=16.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 199.76it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.67it/s, v_num=22758, train_loss_step=16.10, train_loss_epoch=16.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 58.89it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.73it/s, v_num=22760, train_loss_step=16.10, train_loss_epoch=16.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.10it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.68it/s, v_num=22762, train_loss_step=15.70, train_loss_epoch=15.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 89.13it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.33it/s, v_num=22764, train_loss_step=15.20, train_loss_epoch=15.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 247.93it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.50it/s, v_num=22766, train_loss_step=15.50, train_loss_epoch=15.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 95.32it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.37it/s, v_num=22768, train_loss_step=15.80, train_loss_epoch=15.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 259.74it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.79it/s, v_num=22770, train_loss_step=16.00, train_loss_epoch=16.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 99.36it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.28it/s, v_num=22772, train_loss_step=15.90, train_loss_epoch=15.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 131.95it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.83it/s, v_num=22774, train_loss_step=15.90, train_loss_epoch=15.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.99it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.92it/s, v_num=22776, train_loss_step=15.70, train_loss_epoch=15.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 76.96it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.36it/s, v_num=22778, train_loss_step=15.90, train_loss_epoch=15.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 121.72it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.97it/s, v_num=22780, train_loss_step=15.10, train_loss_epoch=15.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 77.97it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.18it/s, v_num=22782, train_loss_step=14.60, train_loss_epoch=14.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 272.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 22:08:11,621] Trial 1 finished with value: 0.47000000000000003 and parameters: {'learning_rate': 0.00013368671990616796, 'hidden_size': 16}. Best is trial 0 with value: 0.47000000000000003.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.31it/s, v_num=22784, train_loss_step=17.80, train_loss_epoch=17.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 60.91it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.37it/s, v_num=22786, train_loss_step=17.70, train_loss_epoch=17.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 61.93it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.29it/s, v_num=22788, train_loss_step=17.60, train_loss_epoch=17.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 57.14it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.35it/s, v_num=22790, train_loss_step=17.10, train_loss_epoch=17.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 42.38it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.17it/s, v_num=22792, train_loss_step=16.70, train_loss_epoch=16.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 79.96it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.55it/s, v_num=22794, train_loss_step=16.30, train_loss_epoch=16.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 39.43it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  7.28it/s, v_num=22796, train_loss_step=16.30, train_loss_epoch=16.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 81.11it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.36it/s, v_num=22798, train_loss_step=16.00, train_loss_epoch=16.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 105.73it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.03it/s, v_num=22800, train_loss_step=15.90, train_loss_epoch=15.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 66.27it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.05it/s, v_num=22802, train_loss_step=15.60, train_loss_epoch=15.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 48.52it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.11it/s, v_num=22804, train_loss_step=15.10, train_loss_epoch=15.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.35it/s, v_num=22806, train_loss_step=15.30, train_loss_epoch=15.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 93.22it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.17it/s, v_num=22808, train_loss_step=15.70, train_loss_epoch=15.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 98.20it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.76it/s, v_num=22810, train_loss_step=15.90, train_loss_epoch=15.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 93.31it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.13it/s, v_num=22812, train_loss_step=15.80, train_loss_epoch=15.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 96.15it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.57it/s, v_num=22814, train_loss_step=15.80, train_loss_epoch=15.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 73.97it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.25it/s, v_num=22816, train_loss_step=15.50, train_loss_epoch=15.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 60.71it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.77it/s, v_num=22818, train_loss_step=15.80, train_loss_epoch=15.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 54.11it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.35it/s, v_num=22820, train_loss_step=14.90, train_loss_epoch=14.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 99.93it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  2.80it/s, v_num=22822, train_loss_step=14.50, train_loss_epoch=14.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 114.46it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 22:10:03,601] Trial 2 finished with value: 0.47000000000000003 and parameters: {'learning_rate': 0.0002189613985830208, 'hidden_size': 16}. Best is trial 0 with value: 0.47000000000000003.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.12it/s, v_num=22824, train_loss_step=18.00, train_loss_epoch=18.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 143.17it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.22it/s, v_num=22826, train_loss_step=17.90, train_loss_epoch=17.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 58.97it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.84it/s, v_num=22828, train_loss_step=17.90, train_loss_epoch=17.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 209.99it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.31it/s, v_num=22830, train_loss_step=17.30, train_loss_epoch=17.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 184.91it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.35it/s, v_num=22832, train_loss_step=16.90, train_loss_epoch=16.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 195.90it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.55it/s, v_num=22834, train_loss_step=16.50, train_loss_epoch=16.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 93.01it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.74it/s, v_num=22836, train_loss_step=16.50, train_loss_epoch=16.50]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 413.76it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.68it/s, v_num=22838, train_loss_step=16.20, train_loss_epoch=16.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 299.06it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.41it/s, v_num=22840, train_loss_step=16.20, train_loss_epoch=16.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 87.95it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.66it/s, v_num=22842, train_loss_step=15.80, train_loss_epoch=15.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 43.84it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.92it/s, v_num=22844, train_loss_step=15.40, train_loss_epoch=15.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 351.28it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.41it/s, v_num=22846, train_loss_step=15.60, train_loss_epoch=15.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 54.12it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s, v_num=22848, train_loss_step=16.00, train_loss_epoch=16.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 145.38it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.55it/s, v_num=22850, train_loss_step=16.10, train_loss_epoch=16.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 305.06it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.32it/s, v_num=22852, train_loss_step=16.00, train_loss_epoch=16.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.24it/s, v_num=22854, train_loss_step=16.10, train_loss_epoch=16.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 280.95it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.63it/s, v_num=22856, train_loss_step=15.80, train_loss_epoch=15.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 89.69it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s, v_num=22858, train_loss_step=16.10, train_loss_epoch=16.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 56.40it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.71it/s, v_num=22860, train_loss_step=15.20, train_loss_epoch=15.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 69.02it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.94it/s, v_num=22862, train_loss_step=14.70, train_loss_epoch=14.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 199.49it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.17it/s, v_num=22864, train_loss_step=14.90, train_loss_epoch=14.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 243.67it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.09it/s, v_num=22866, train_loss_step=15.20, train_loss_epoch=15.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 84.72it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.95it/s, v_num=22868, train_loss_step=15.10, train_loss_epoch=15.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 70.66it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.80it/s, v_num=22870, train_loss_step=15.20, train_loss_epoch=15.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 87.38it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.32it/s, v_num=22872, train_loss_step=15.30, train_loss_epoch=15.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 58.99it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.88it/s, v_num=22874, train_loss_step=15.60, train_loss_epoch=15.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 74.15it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.82it/s, v_num=22876, train_loss_step=15.30, train_loss_epoch=15.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 210.39it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.21it/s, v_num=22878, train_loss_step=15.10, train_loss_epoch=15.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 49.88it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.33it/s, v_num=22880, train_loss_step=14.90, train_loss_epoch=14.90]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 94.04it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.49it/s, v_num=22882, train_loss_step=15.40, train_loss_epoch=15.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 98.88it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.62it/s, v_num=22884, train_loss_step=15.40, train_loss_epoch=15.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 97.02it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.65it/s, v_num=22886, train_loss_step=14.70, train_loss_epoch=14.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 123.61it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.43it/s, v_num=22888, train_loss_step=14.10, train_loss_epoch=14.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 176.23it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.36it/s, v_num=22890, train_loss_step=13.60, train_loss_epoch=13.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 32.32it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.06it/s, v_num=22892, train_loss_step=13.60, train_loss_epoch=13.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 335.49it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.06it/s, v_num=22894, train_loss_step=14.00, train_loss_epoch=14.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.06it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.67it/s, v_num=22896, train_loss_step=14.00, train_loss_epoch=14.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 66.11it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.65it/s, v_num=22898, train_loss_step=14.60, train_loss_epoch=14.60]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.85it/s, v_num=22900, train_loss_step=15.20, train_loss_epoch=15.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 235.15it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.05it/s, v_num=22902, train_loss_step=15.20, train_loss_epoch=15.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.81it/s, v_num=22904, train_loss_step=15.70, train_loss_epoch=15.70]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.67it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.36it/s, v_num=22906, train_loss_step=15.80, train_loss_epoch=15.80]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 180.01it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.61it/s, v_num=22908, train_loss_step=16.00, train_loss_epoch=16.00]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.41it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.07it/s, v_num=22910, train_loss_step=16.10, train_loss_epoch=16.10]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 391.30it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.18it/s, v_num=22912, train_loss_step=16.20, train_loss_epoch=16.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 66.92it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.60it/s, v_num=22914, train_loss_step=16.30, train_loss_epoch=16.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 108.69it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s, v_num=22916, train_loss_step=16.30, train_loss_epoch=16.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 80.09it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.58it/s, v_num=22918, train_loss_step=16.40, train_loss_epoch=16.40]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 228.52it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  6.48it/s, v_num=22920, train_loss_step=16.30, train_loss_epoch=16.30]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 85.91it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.90it/s, v_num=22922, train_loss_step=16.20, train_loss_epoch=16.20]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 311.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 22:14:33,342] A new study created in memory with name: no-name-daccadc5-974e-4daa-8097-4566262dba81\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prefix: NFLX | mode: financial | model_type: NBEATS\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.69it/s, v_num=22924, train_loss_step=4.750, train_loss_epoch=4.750]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 148.08it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.39it/s, v_num=22926, train_loss_step=4.470, train_loss_epoch=4.470]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 191.53it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.74it/s, v_num=22928, train_loss_step=4.810, train_loss_epoch=4.810]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 124.85it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.96it/s, v_num=22930, train_loss_step=4.490, train_loss_epoch=4.490]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 273.26it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.11it/s, v_num=22932, train_loss_step=4.670, train_loss_epoch=4.670]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 57.60it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.06it/s, v_num=22934, train_loss_step=4.650, train_loss_epoch=4.650]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 280.89it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.73it/s, v_num=22936, train_loss_step=4.880, train_loss_epoch=4.880]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 66.27it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.93it/s, v_num=22938, train_loss_step=5.020, train_loss_epoch=5.020]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 415.20it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 22:15:14,134] Trial 0 finished with value: 0.7 and parameters: {'n_blocks_season': 2, 'n_blocks_trend': 3, 'n_blocks_ident': 1, 'mlp_units': 128, 'num_hidden': 2, 'n_harmonics': 5, 'n_polynomials': 2, 'learning_rate': 1.3352869776281826e-05}. Best is trial 0 with value: 0.7.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.85it/s, v_num=22940, train_loss_step=4.470, train_loss_epoch=4.470]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 139.73it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.18it/s, v_num=22942, train_loss_step=4.200, train_loss_epoch=4.200]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 217.59it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.40it/s, v_num=22944, train_loss_step=4.530, train_loss_epoch=4.530]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 294.61it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.01it/s, v_num=22946, train_loss_step=4.190, train_loss_epoch=4.190]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 179.36it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.56it/s, v_num=22948, train_loss_step=4.360, train_loss_epoch=4.360]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 169.74it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.75it/s, v_num=22950, train_loss_step=4.330, train_loss_epoch=4.330]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 322.02it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.98it/s, v_num=22952, train_loss_step=4.550, train_loss_epoch=4.550]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 292.82it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.42it/s, v_num=22954, train_loss_step=4.680, train_loss_epoch=4.680]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 200.78it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 22:15:52,220] Trial 1 finished with value: 0.8066666666666666 and parameters: {'n_blocks_season': 2, 'n_blocks_trend': 1, 'n_blocks_ident': 2, 'mlp_units': 64, 'num_hidden': 2, 'n_harmonics': 3, 'n_polynomials': 5, 'learning_rate': 0.00036151210180567433}. Best is trial 1 with value: 0.8066666666666666.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.26it/s, v_num=22956, train_loss_step=4.110, train_loss_epoch=4.110]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 206.72it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.46it/s, v_num=22958, train_loss_step=3.880, train_loss_epoch=3.880]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 136.50it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.48it/s, v_num=22960, train_loss_step=4.200, train_loss_epoch=4.200]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 943.39it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.08it/s, v_num=22962, train_loss_step=3.870, train_loss_epoch=3.870]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 419.22it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.41it/s, v_num=22964, train_loss_step=4.030, train_loss_epoch=4.030]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 491.60it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 20.59it/s, v_num=22966, train_loss_step=4.010, train_loss_epoch=4.010]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 162.85it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.05it/s, v_num=22968, train_loss_step=4.200, train_loss_epoch=4.200]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 167.27it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s, v_num=22970, train_loss_step=4.270, train_loss_epoch=4.270]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 179.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 22:16:29,562] Trial 2 finished with value: 0.78 and parameters: {'n_blocks_season': 1, 'n_blocks_trend': 3, 'n_blocks_ident': 2, 'mlp_units': 64, 'num_hidden': 1, 'n_harmonics': 3, 'n_polynomials': 4, 'learning_rate': 0.0008796997653205443}. Best is trial 1 with value: 0.8066666666666666.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.35it/s, v_num=22972, train_loss_step=4.470, train_loss_epoch=4.470]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 177.22it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.80it/s, v_num=22974, train_loss_step=4.200, train_loss_epoch=4.200]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 661.98it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.33it/s, v_num=22976, train_loss_step=4.530, train_loss_epoch=4.530]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 94.29it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.59it/s, v_num=22978, train_loss_step=4.190, train_loss_epoch=4.190]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 397.56it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.49it/s, v_num=22980, train_loss_step=4.360, train_loss_epoch=4.360]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 371.31it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.40it/s, v_num=22982, train_loss_step=4.330, train_loss_epoch=4.330]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 177.88it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.94it/s, v_num=22984, train_loss_step=4.550, train_loss_epoch=4.550]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 285.07it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.23it/s, v_num=22986, train_loss_step=4.680, train_loss_epoch=4.680]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 107.30it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.28it/s, v_num=22988, train_loss_step=4.110, train_loss_epoch=4.110]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 199.65it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s, v_num=22990, train_loss_step=3.940, train_loss_epoch=3.940]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 265.68it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.97it/s, v_num=22992, train_loss_step=4.310, train_loss_epoch=4.310]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 160.01it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.00it/s, v_num=22994, train_loss_step=4.220, train_loss_epoch=4.220]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 179.84it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.51it/s, v_num=22996, train_loss_step=3.850, train_loss_epoch=3.850]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 72.02it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.71it/s, v_num=22998, train_loss_step=3.720, train_loss_epoch=3.720]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 199.54it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.15it/s, v_num=23000, train_loss_step=3.680, train_loss_epoch=3.680]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 61.45it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.84it/s, v_num=23002, train_loss_step=3.850, train_loss_epoch=3.850]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 184.54it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.63it/s, v_num=23004, train_loss_step=3.930, train_loss_epoch=3.930]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 65.28it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.22it/s, v_num=23006, train_loss_step=3.650, train_loss_epoch=3.650]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 146.69it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.42it/s, v_num=23008, train_loss_step=3.640, train_loss_epoch=3.640]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 328.71it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.24it/s, v_num=23010, train_loss_step=3.700, train_loss_epoch=3.700]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 212.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 22:18:07,772] A new study created in memory with name: no-name-67b224bc-0551-4eb0-94ff-08b3174dd3f2\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prefix: NFLX | mode: financial | model_type: NHITS\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.56it/s, v_num=23012, train_loss_step=3.390, train_loss_epoch=3.390]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.00it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.27it/s, v_num=23014, train_loss_step=3.150, train_loss_epoch=3.150]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 111.71it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.34it/s, v_num=23016, train_loss_step=3.370, train_loss_epoch=3.370]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.66it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.60it/s, v_num=23018, train_loss_step=3.090, train_loss_epoch=3.090]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.80it/s, v_num=23020, train_loss_step=3.230, train_loss_epoch=3.230]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 190.96it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.10it/s, v_num=23022, train_loss_step=3.240, train_loss_epoch=3.240]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.98it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.18it/s, v_num=23024, train_loss_step=3.430, train_loss_epoch=3.430]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 68.95it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.79it/s, v_num=23026, train_loss_step=3.620, train_loss_epoch=3.620]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 22:18:48,834] Trial 0 finished with value: 0.521304347826087 and parameters: {'n_blocks1': 1, 'n_blocks2': 3, 'n_blocks3': 2, 'mlp_units': 32, 'n_pool_kernel_size1': 1, 'n_pool_kernel_size2': 2, 'n_pool_kernel_size3': 3, 'learning_rate': 0.008839792614050018}. Best is trial 0 with value: 0.521304347826087.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.32it/s, v_num=23028, train_loss_step=3.340, train_loss_epoch=3.340]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 131.15it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.61it/s, v_num=23030, train_loss_step=3.130, train_loss_epoch=3.130]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 129.15it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.19it/s, v_num=23032, train_loss_step=3.350, train_loss_epoch=3.350]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 297.13it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.93it/s, v_num=23034, train_loss_step=3.050, train_loss_epoch=3.050]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 210.45it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.62it/s, v_num=23036, train_loss_step=3.190, train_loss_epoch=3.190]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 666.40it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.83it/s, v_num=23038, train_loss_step=3.220, train_loss_epoch=3.220]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 106.05it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  5.38it/s, v_num=23040, train_loss_step=3.390, train_loss_epoch=3.390]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 130.68it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.76it/s, v_num=23042, train_loss_step=3.560, train_loss_epoch=3.560]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 317.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 22:19:31,264] Trial 1 finished with value: 0.4818181818181818 and parameters: {'n_blocks1': 1, 'n_blocks2': 3, 'n_blocks3': 2, 'mlp_units': 64, 'n_pool_kernel_size1': 3, 'n_pool_kernel_size2': 2, 'n_pool_kernel_size3': 3, 'learning_rate': 0.0055352229281079215}. Best is trial 0 with value: 0.521304347826087.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.61it/s, v_num=23044, train_loss_step=3.390, train_loss_epoch=3.390]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 186.61it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.36it/s, v_num=23046, train_loss_step=3.150, train_loss_epoch=3.150]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 86.83it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.73it/s, v_num=23048, train_loss_step=3.390, train_loss_epoch=3.390]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 74.92it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.01it/s, v_num=23050, train_loss_step=3.080, train_loss_epoch=3.080]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 76.88it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.96it/s, v_num=23052, train_loss_step=3.220, train_loss_epoch=3.220]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 110.77it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.00it/s, v_num=23054, train_loss_step=3.230, train_loss_epoch=3.230]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 199.27it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.08it/s, v_num=23056, train_loss_step=3.430, train_loss_epoch=3.430]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 407.02it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.28it/s, v_num=23058, train_loss_step=3.600, train_loss_epoch=3.600]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 451.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 22:20:10,251] Trial 2 finished with value: 0.5599999999999999 and parameters: {'n_blocks1': 1, 'n_blocks2': 1, 'n_blocks3': 2, 'mlp_units': 64, 'n_pool_kernel_size1': 2, 'n_pool_kernel_size2': 3, 'n_pool_kernel_size3': 1, 'learning_rate': 0.004477618809000947}. Best is trial 2 with value: 0.5599999999999999.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.64it/s, v_num=23060, train_loss_step=3.390, train_loss_epoch=3.390]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 282.01it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.24it/s, v_num=23062, train_loss_step=3.150, train_loss_epoch=3.150]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 53.18it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s, v_num=23064, train_loss_step=3.390, train_loss_epoch=3.390]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 47.61it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.62it/s, v_num=23066, train_loss_step=3.080, train_loss_epoch=3.080]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 555.39it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.79it/s, v_num=23068, train_loss_step=3.220, train_loss_epoch=3.220]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 72.73it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.67it/s, v_num=23070, train_loss_step=3.230, train_loss_epoch=3.230]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 242.43it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.03it/s, v_num=23072, train_loss_step=3.430, train_loss_epoch=3.430]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 70.82it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.84it/s, v_num=23074, train_loss_step=3.600, train_loss_epoch=3.600]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 124.72it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.07it/s, v_num=23076, train_loss_step=3.150, train_loss_epoch=3.150]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 137.83it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.20it/s, v_num=23078, train_loss_step=3.020, train_loss_epoch=3.020]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.58it/s, v_num=23080, train_loss_step=3.220, train_loss_epoch=3.220]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 104.87it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.97it/s, v_num=23082, train_loss_step=3.160, train_loss_epoch=3.160]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 314.93it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.34it/s, v_num=23084, train_loss_step=2.920, train_loss_epoch=2.920]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 346.69it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s, v_num=23086, train_loss_step=2.830, train_loss_epoch=2.830]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 315.10it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.84it/s, v_num=23088, train_loss_step=2.800, train_loss_epoch=2.800]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 137.12it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.68it/s, v_num=23090, train_loss_step=2.960, train_loss_epoch=2.960]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 317.49it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.14it/s, v_num=23092, train_loss_step=3.070, train_loss_epoch=3.070]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 161.23it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.03it/s, v_num=23094, train_loss_step=2.850, train_loss_epoch=2.850]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 112.73it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.63it/s, v_num=23096, train_loss_step=2.860, train_loss_epoch=2.860]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 138.58it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.92it/s, v_num=23098, train_loss_step=2.840, train_loss_epoch=2.840]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 57.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 22:21:49,281] A new study created in memory with name: no-name-1f630b23-35b4-4823-9d41-b314e64fc21b\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prefix: NFLX | mode: financial | model_type: TFT\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=23100, train_loss_step=3.880, train_loss_epoch=3.880]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 91.68it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.29it/s, v_num=23102, train_loss_step=3.950, train_loss_epoch=3.950]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 344.11it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.29it/s, v_num=23104, train_loss_step=4.130, train_loss_epoch=4.130]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 132.02it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.41it/s, v_num=23106, train_loss_step=4.040, train_loss_epoch=4.040]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 77.75it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.51it/s, v_num=23108, train_loss_step=4.110, train_loss_epoch=4.110]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 85.90it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.43it/s, v_num=23110, train_loss_step=4.020, train_loss_epoch=4.020]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 130.28it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  2.90it/s, v_num=23112, train_loss_step=4.130, train_loss_epoch=4.130]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 80.18it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  2.14it/s, v_num=23114, train_loss_step=3.910, train_loss_epoch=3.910]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 19.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 22:22:49,762] Trial 0 finished with value: 0.6958823529411765 and parameters: {'learning_rate': 0.013027762765352063, 'hidden_size': 24}. Best is trial 0 with value: 0.6958823529411765.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  2.55it/s, v_num=23116, train_loss_step=3.860, train_loss_epoch=3.860]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 60.63it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s, v_num=23118, train_loss_step=3.940, train_loss_epoch=3.940]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 136.31it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.10it/s, v_num=23120, train_loss_step=4.130, train_loss_epoch=4.130]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 131.52it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.23it/s, v_num=23122, train_loss_step=4.050, train_loss_epoch=4.050]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 47.44it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  2.82it/s, v_num=23124, train_loss_step=4.110, train_loss_epoch=4.110]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 130.70it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  1.84it/s, v_num=23126, train_loss_step=4.020, train_loss_epoch=4.020]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 52.11it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  2.26it/s, v_num=23128, train_loss_step=4.130, train_loss_epoch=4.130]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.32it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  2.48it/s, v_num=23130, train_loss_step=3.910, train_loss_epoch=3.910]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 75.28it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 22:23:58,823] Trial 1 finished with value: 0.6958823529411765 and parameters: {'learning_rate': 0.013562672715622646, 'hidden_size': 24}. Best is trial 0 with value: 0.6958823529411765.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.12it/s, v_num=23132, train_loss_step=4.120, train_loss_epoch=4.120]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.82it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.64it/s, v_num=23134, train_loss_step=4.160, train_loss_epoch=4.160]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 71.56it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.73it/s, v_num=23136, train_loss_step=4.300, train_loss_epoch=4.300]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 45.98it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.87it/s, v_num=23138, train_loss_step=4.230, train_loss_epoch=4.230]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 144.42it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.31it/s, v_num=23140, train_loss_step=4.310, train_loss_epoch=4.310]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 174.92it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.05it/s, v_num=23142, train_loss_step=4.250, train_loss_epoch=4.250]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 207.21it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.06it/s, v_num=23144, train_loss_step=4.340, train_loss_epoch=4.340]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 237.45it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.39it/s, v_num=23146, train_loss_step=4.130, train_loss_epoch=4.130]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 55.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 22:24:50,424] Trial 2 finished with value: 0.506 and parameters: {'learning_rate': 0.004304764658803508, 'hidden_size': 8}. Best is trial 0 with value: 0.6958823529411765.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.32it/s, v_num=23148, train_loss_step=3.880, train_loss_epoch=3.880]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 260.13it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.53it/s, v_num=23150, train_loss_step=3.950, train_loss_epoch=3.950]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 59.69it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  2.88it/s, v_num=23152, train_loss_step=4.130, train_loss_epoch=4.130]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 383.50it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.01it/s, v_num=23154, train_loss_step=4.040, train_loss_epoch=4.040]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 75.98it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  1.88it/s, v_num=23156, train_loss_step=4.110, train_loss_epoch=4.110]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 110.55it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  2.37it/s, v_num=23158, train_loss_step=4.020, train_loss_epoch=4.020]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 91.47it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.08it/s, v_num=23160, train_loss_step=4.130, train_loss_epoch=4.130]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 57.75it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, v_num=23162, train_loss_step=3.910, train_loss_epoch=3.910]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 75.30it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s, v_num=23164, train_loss_step=4.630, train_loss_epoch=4.630]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 110.42it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  2.50it/s, v_num=23166, train_loss_step=4.540, train_loss_epoch=4.540]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 128.69it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  2.73it/s, v_num=23168, train_loss_step=4.530, train_loss_epoch=4.530]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 215.43it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  2.54it/s, v_num=23170, train_loss_step=4.530, train_loss_epoch=4.530]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 70.05it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  1.83it/s, v_num=23172, train_loss_step=4.930, train_loss_epoch=4.930]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 109.53it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  2.86it/s, v_num=23174, train_loss_step=5.000, train_loss_epoch=5.000]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 232.08it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  2.95it/s, v_num=23176, train_loss_step=5.030, train_loss_epoch=5.030]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 85.61it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  2.14it/s, v_num=23178, train_loss_step=4.860, train_loss_epoch=4.860]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.42it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.11it/s, v_num=23180, train_loss_step=5.050, train_loss_epoch=5.050]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, v_num=23182, train_loss_step=5.030, train_loss_epoch=5.030]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  2.22it/s, v_num=23184, train_loss_step=5.060, train_loss_epoch=5.060]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 323.83it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s, v_num=23186, train_loss_step=4.940, train_loss_epoch=4.940]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 276.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 22:27:33,158] A new study created in memory with name: no-name-a7160f4f-dc24-41b9-bebc-fb681ebe084f\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prefix: NFLX | mode: news | model_type: NBEATS\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.42it/s, v_num=23188, train_loss_step=4.230, train_loss_epoch=4.230]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.46it/s, v_num=23190, train_loss_step=3.970, train_loss_epoch=3.970]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s, v_num=23192, train_loss_step=4.270, train_loss_epoch=4.270]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 332.49it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.25it/s, v_num=23194, train_loss_step=3.940, train_loss_epoch=3.940]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 100.44it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.47it/s, v_num=23196, train_loss_step=4.100, train_loss_epoch=4.100]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 60.53it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.70it/s, v_num=23198, train_loss_step=4.070, train_loss_epoch=4.070]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 184.77it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.77it/s, v_num=23200, train_loss_step=4.260, train_loss_epoch=4.260]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.95it/s, v_num=23202, train_loss_step=4.340, train_loss_epoch=4.340]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 22:28:13,756] Trial 0 finished with value: 0.717037037037037 and parameters: {'n_blocks_season': 1, 'n_blocks_trend': 1, 'n_blocks_ident': 3, 'mlp_units': 128, 'num_hidden': 1, 'n_harmonics': 1, 'n_polynomials': 4, 'learning_rate': 0.00021288942050785194}. Best is trial 0 with value: 0.717037037037037.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.91it/s, v_num=23204, train_loss_step=4.250, train_loss_epoch=4.250]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 54.50it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.66it/s, v_num=23206, train_loss_step=4.010, train_loss_epoch=4.010]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 60.67it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.97it/s, v_num=23208, train_loss_step=4.770, train_loss_epoch=4.770]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 207.94it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.78it/s, v_num=23210, train_loss_step=3.940, train_loss_epoch=3.940]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 147.81it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.63it/s, v_num=23212, train_loss_step=4.180, train_loss_epoch=4.180]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 319.27it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.18it/s, v_num=23214, train_loss_step=4.190, train_loss_epoch=4.190]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 171.76it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.20it/s, v_num=23216, train_loss_step=4.300, train_loss_epoch=4.300]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 179.87it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.62it/s, v_num=23218, train_loss_step=4.420, train_loss_epoch=4.420]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 132.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 22:28:55,689] Trial 1 finished with value: 0.6353846153846154 and parameters: {'n_blocks_season': 3, 'n_blocks_trend': 2, 'n_blocks_ident': 3, 'mlp_units': 64, 'num_hidden': 2, 'n_harmonics': 2, 'n_polynomials': 4, 'learning_rate': 0.030437999652751593}. Best is trial 0 with value: 0.717037037037037.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.10it/s, v_num=23220, train_loss_step=5.780, train_loss_epoch=5.780]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 104.00it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.44it/s, v_num=23222, train_loss_step=5.420, train_loss_epoch=5.420]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 92.83it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.04it/s, v_num=23224, train_loss_step=5.810, train_loss_epoch=5.810]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.81it/s, v_num=23226, train_loss_step=5.500, train_loss_epoch=5.500]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 148.76it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.97it/s, v_num=23228, train_loss_step=5.720, train_loss_epoch=5.720]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.24it/s, v_num=23230, train_loss_step=5.710, train_loss_epoch=5.710]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 133.35it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.32it/s, v_num=23232, train_loss_step=5.920, train_loss_epoch=5.920]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 128.43it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.30it/s, v_num=23234, train_loss_step=6.100, train_loss_epoch=6.100]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 126.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 22:29:37,547] Trial 2 finished with value: 0.7006896551724138 and parameters: {'n_blocks_season': 3, 'n_blocks_trend': 1, 'n_blocks_ident': 3, 'mlp_units': 64, 'num_hidden': 1, 'n_harmonics': 5, 'n_polynomials': 2, 'learning_rate': 1.7297784025631263e-05}. Best is trial 0 with value: 0.717037037037037.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.67it/s, v_num=23236, train_loss_step=4.230, train_loss_epoch=4.230]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.84it/s, v_num=23238, train_loss_step=3.970, train_loss_epoch=3.970]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 327.83it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.28it/s, v_num=23240, train_loss_step=4.270, train_loss_epoch=4.270]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.42it/s, v_num=23242, train_loss_step=3.940, train_loss_epoch=3.940]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 413.07it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.01it/s, v_num=23244, train_loss_step=4.100, train_loss_epoch=4.100]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 107.56it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.93it/s, v_num=23246, train_loss_step=4.070, train_loss_epoch=4.070]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 380.92it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.85it/s, v_num=23248, train_loss_step=4.260, train_loss_epoch=4.260]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 256.61it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.95it/s, v_num=23250, train_loss_step=4.340, train_loss_epoch=4.340]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 412.18it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.64it/s, v_num=23252, train_loss_step=3.840, train_loss_epoch=3.840]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 179.74it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.41it/s, v_num=23254, train_loss_step=3.720, train_loss_epoch=3.720]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 129.45it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.46it/s, v_num=23256, train_loss_step=4.110, train_loss_epoch=4.110]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 219.95it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.12it/s, v_num=23258, train_loss_step=4.040, train_loss_epoch=4.040]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 299.08it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.44it/s, v_num=23260, train_loss_step=3.680, train_loss_epoch=3.680]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 276.30it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.54it/s, v_num=23262, train_loss_step=3.580, train_loss_epoch=3.580]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 215.56it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.47it/s, v_num=23264, train_loss_step=3.560, train_loss_epoch=3.560]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 184.75it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 16.00it/s, v_num=23266, train_loss_step=3.720, train_loss_epoch=3.720]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 21.24it/s, v_num=23268, train_loss_step=3.780, train_loss_epoch=3.780]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.85it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.81it/s, v_num=23270, train_loss_step=3.490, train_loss_epoch=3.490]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.34it/s, v_num=23272, train_loss_step=3.480, train_loss_epoch=3.480]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.42it/s, v_num=23274, train_loss_step=3.540, train_loss_epoch=3.540]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 121.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 22:31:16,556] A new study created in memory with name: no-name-5fcb97e6-7130-45f5-8731-c9099f558dcc\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prefix: NFLX | mode: news | model_type: NHITS\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.50it/s, v_num=23276, train_loss_step=4.830, train_loss_epoch=4.830]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 206.84it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.60it/s, v_num=23278, train_loss_step=4.540, train_loss_epoch=4.540]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 79.87it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.93it/s, v_num=23280, train_loss_step=4.890, train_loss_epoch=4.890]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 81.78it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 20.77it/s, v_num=23282, train_loss_step=4.560, train_loss_epoch=4.560]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.90it/s, v_num=23284, train_loss_step=4.740, train_loss_epoch=4.740]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 462.54it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.66it/s, v_num=23286, train_loss_step=4.730, train_loss_epoch=4.730]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.00it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.23it/s, v_num=23288, train_loss_step=4.960, train_loss_epoch=4.960]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.01it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.21it/s, v_num=23290, train_loss_step=5.130, train_loss_epoch=5.130]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 45.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 22:32:04,441] Trial 0 finished with value: 0.7 and parameters: {'n_blocks1': 1, 'n_blocks2': 1, 'n_blocks3': 3, 'mlp_units': 32, 'n_pool_kernel_size1': 1, 'n_pool_kernel_size2': 3, 'n_pool_kernel_size3': 1, 'learning_rate': 0.00016210929379393302}. Best is trial 0 with value: 0.7.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.58it/s, v_num=23292, train_loss_step=4.840, train_loss_epoch=4.840]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 285.04it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.86it/s, v_num=23294, train_loss_step=4.540, train_loss_epoch=4.540]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 121.99it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.23it/s, v_num=23296, train_loss_step=4.890, train_loss_epoch=4.890]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 96.61it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.61it/s, v_num=23298, train_loss_step=4.570, train_loss_epoch=4.570]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 49.80it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s, v_num=23300, train_loss_step=4.760, train_loss_epoch=4.760]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 69.42it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.82it/s, v_num=23302, train_loss_step=4.740, train_loss_epoch=4.740]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 111.29it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.32it/s, v_num=23304, train_loss_step=4.960, train_loss_epoch=4.960]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 15.78it/s, v_num=23306, train_loss_step=5.110, train_loss_epoch=5.110]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 22:32:50,781] Trial 1 finished with value: 0.6642857142857143 and parameters: {'n_blocks1': 2, 'n_blocks2': 1, 'n_blocks3': 1, 'mlp_units': 32, 'n_pool_kernel_size1': 1, 'n_pool_kernel_size2': 1, 'n_pool_kernel_size3': 1, 'learning_rate': 1.2424157416984262e-05}. Best is trial 0 with value: 0.7.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.96it/s, v_num=23308, train_loss_step=2.270, train_loss_epoch=2.270]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 469.16it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.63it/s, v_num=23310, train_loss_step=2.190, train_loss_epoch=2.190]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 112.54it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.58it/s, v_num=23312, train_loss_step=2.390, train_loss_epoch=2.390]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.01it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.80it/s, v_num=23314, train_loss_step=2.270, train_loss_epoch=2.270]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.50it/s, v_num=23316, train_loss_step=2.360, train_loss_epoch=2.360]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.53it/s, v_num=23318, train_loss_step=2.210, train_loss_epoch=2.210]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 166.41it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.65it/s, v_num=23320, train_loss_step=2.270, train_loss_epoch=2.270]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.99it/s, v_num=23322, train_loss_step=2.490, train_loss_epoch=2.490]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 133.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 22:33:38,871] Trial 2 finished with value: 0.7582608695652173 and parameters: {'n_blocks1': 2, 'n_blocks2': 2, 'n_blocks3': 2, 'mlp_units': 128, 'n_pool_kernel_size1': 1, 'n_pool_kernel_size2': 1, 'n_pool_kernel_size3': 3, 'learning_rate': 0.005091931572740299}. Best is trial 2 with value: 0.7582608695652173.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.71it/s, v_num=23324, train_loss_step=2.270, train_loss_epoch=2.270]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.98it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.76it/s, v_num=23326, train_loss_step=2.190, train_loss_epoch=2.190]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.68it/s, v_num=23328, train_loss_step=2.390, train_loss_epoch=2.390]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 182.48it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.06it/s, v_num=23330, train_loss_step=2.270, train_loss_epoch=2.270]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.17it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 13.40it/s, v_num=23332, train_loss_step=2.360, train_loss_epoch=2.360]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.44it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.56it/s, v_num=23334, train_loss_step=2.210, train_loss_epoch=2.210]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 398.70it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.80it/s, v_num=23336, train_loss_step=2.270, train_loss_epoch=2.270]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 88.60it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.62it/s, v_num=23338, train_loss_step=2.490, train_loss_epoch=2.490]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.01it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 14.18it/s, v_num=23340, train_loss_step=2.170, train_loss_epoch=2.170]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 98.66it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.94it/s, v_num=23342, train_loss_step=2.070, train_loss_epoch=2.070]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.62it/s] \n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.25it/s, v_num=23344, train_loss_step=2.250, train_loss_epoch=2.250]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.86it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  8.27it/s, v_num=23346, train_loss_step=2.270, train_loss_epoch=2.270]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 58.01it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 11.15it/s, v_num=23348, train_loss_step=2.140, train_loss_epoch=2.140]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 91.75it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.84it/s, v_num=23350, train_loss_step=2.090, train_loss_epoch=2.090]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 64.00it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.94it/s, v_num=23352, train_loss_step=2.130, train_loss_epoch=2.130]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 104.61it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.96it/s, v_num=23354, train_loss_step=2.220, train_loss_epoch=2.220]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 55.51it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.02it/s, v_num=23356, train_loss_step=2.270, train_loss_epoch=2.270]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 157.83it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  7.08it/s, v_num=23358, train_loss_step=2.180, train_loss_epoch=2.180]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 148.55it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 10.80it/s, v_num=23360, train_loss_step=2.190, train_loss_epoch=2.190]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 198.54it/s]\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  9.78it/s, v_num=23362, train_loss_step=2.270, train_loss_epoch=2.270]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 22:35:38,749] A new study created in memory with name: no-name-90618844-ebf2-47cf-9a93-e3423759e4bb\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prefix: NFLX | mode: news | model_type: TFT\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  2.96it/s, v_num=23364, train_loss_step=4.020, train_loss_epoch=4.020]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 48.51it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.07it/s, v_num=23366, train_loss_step=4.080, train_loss_epoch=4.080]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 61.48it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.00it/s, v_num=23368, train_loss_step=4.210, train_loss_epoch=4.210]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 45.84it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, v_num=23370, train_loss_step=4.130, train_loss_epoch=4.130]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 158.24it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.07it/s, v_num=23372, train_loss_step=4.210, train_loss_epoch=4.210]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 84.62it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  2.95it/s, v_num=23374, train_loss_step=4.140, train_loss_epoch=4.140]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 68.01it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.07it/s, v_num=23376, train_loss_step=4.240, train_loss_epoch=4.240]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 65.97it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  2.62it/s, v_num=23378, train_loss_step=4.010, train_loss_epoch=4.010]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 201.47it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 22:36:34,680] Trial 0 finished with value: 0.7 and parameters: {'learning_rate': 0.00021374652891850934, 'hidden_size': 24}. Best is trial 0 with value: 0.7.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.85it/s, v_num=23380, train_loss_step=4.200, train_loss_epoch=4.200]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.90it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s, v_num=23382, train_loss_step=4.230, train_loss_epoch=4.230]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 106.31it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.39it/s, v_num=23384, train_loss_step=4.370, train_loss_epoch=4.370]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 347.87it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.31it/s, v_num=23386, train_loss_step=4.310, train_loss_epoch=4.310]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 161.32it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.36it/s, v_num=23388, train_loss_step=4.400, train_loss_epoch=4.400]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.90it/s, v_num=23390, train_loss_step=4.330, train_loss_epoch=4.330]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 220.00it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  5.49it/s, v_num=23392, train_loss_step=4.430, train_loss_epoch=4.430]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 99.66it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  4.70it/s, v_num=23394, train_loss_step=4.200, train_loss_epoch=4.200]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 241.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 22:37:20,343] Trial 1 finished with value: 0.3 and parameters: {'learning_rate': 1.3581703403704284e-05, 'hidden_size': 8}. Best is trial 0 with value: 0.7.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.21it/s, v_num=23396, train_loss_step=4.020, train_loss_epoch=4.020]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 91.33it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  2.92it/s, v_num=23398, train_loss_step=4.080, train_loss_epoch=4.080]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 222.52it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.00it/s, v_num=23400, train_loss_step=4.210, train_loss_epoch=4.210]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 23.31it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.20it/s, v_num=23402, train_loss_step=4.130, train_loss_epoch=4.130]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 821.93it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s, v_num=23404, train_loss_step=4.210, train_loss_epoch=4.210]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 96.20it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, v_num=23406, train_loss_step=4.140, train_loss_epoch=4.140]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 82.68it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.27it/s, v_num=23408, train_loss_step=4.240, train_loss_epoch=4.240]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 402.37it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  2.42it/s, v_num=23410, train_loss_step=4.000, train_loss_epoch=4.000]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 105.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-27 22:38:16,202] Trial 2 finished with value: 0.7 and parameters: {'learning_rate': 0.00021971137038628256, 'hidden_size': 24}. Best is trial 0 with value: 0.7.\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  2.64it/s, v_num=23412, train_loss_step=4.020, train_loss_epoch=4.020]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 74.12it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  2.83it/s, v_num=23414, train_loss_step=4.080, train_loss_epoch=4.080]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 79.38it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  2.67it/s, v_num=23416, train_loss_step=4.210, train_loss_epoch=4.210]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 191.20it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.01it/s, v_num=23418, train_loss_step=4.130, train_loss_epoch=4.130]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 84.79it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  2.69it/s, v_num=23420, train_loss_step=4.210, train_loss_epoch=4.210]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 100.45it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  2.98it/s, v_num=23422, train_loss_step=4.140, train_loss_epoch=4.140]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 47.77it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s, v_num=23424, train_loss_step=4.240, train_loss_epoch=4.240]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 206.11it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  2.34it/s, v_num=23426, train_loss_step=4.010, train_loss_epoch=4.010]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 89.27it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.22it/s, v_num=23428, train_loss_step=4.700, train_loss_epoch=4.700]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 351.75it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.09it/s, v_num=23430, train_loss_step=4.660, train_loss_epoch=4.660]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 529.18it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, v_num=23432, train_loss_step=4.600, train_loss_epoch=4.600]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 60.96it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.23it/s, v_num=23434, train_loss_step=4.590, train_loss_epoch=4.590]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 226.61it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.41it/s, v_num=23436, train_loss_step=4.960, train_loss_epoch=4.960]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 15.35it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.20it/s, v_num=23438, train_loss_step=5.040, train_loss_epoch=5.040]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 55.10it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.31it/s, v_num=23440, train_loss_step=5.070, train_loss_epoch=5.070]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 76.09it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.33it/s, v_num=23442, train_loss_step=4.970, train_loss_epoch=4.970]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 62.58it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.27it/s, v_num=23444, train_loss_step=5.150, train_loss_epoch=5.150]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 71.42it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.01it/s, v_num=23446, train_loss_step=5.130, train_loss_epoch=5.130]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 96.00it/s] \n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  3.25it/s, v_num=23448, train_loss_step=5.180, train_loss_epoch=5.180]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 122.41it/s]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  2.50it/s, v_num=23450, train_loss_step=5.060, train_loss_epoch=5.060]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 198.66it/s]\n"
     ]
    }
   ],
   "source": [
    "# timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "prefix = \"NFLX\"\n",
    "modes = ['financial', 'news']\n",
    "model_types = ['NBEATS', 'NHITS', 'TFT']\n",
    "final_columns = [\n",
    "    ['norm_rsi_gspc_14', 'norm_rsi_14', 'norm_slowk_14', 'minmax_high_norm'],\n",
    "    ['finbert_Score', 'bart_Score', 'vader_Score', 'mean_influential', 'mean_trustworthy'],\n",
    "    #['finbert_Score', 'bart_Score', 'vader_Score', 'mean_influential', 'mean_trustworthy', 'norm_rsi_gspc_14', 'norm_rsi_14', 'norm_slowk_14', 'minmax_high_norm', 'log_return_1']\n",
    "]\n",
    "train_set_all = pd.read_csv('csv/'+prefix+'/train_set_full.csv')\n",
    "val_set_all = pd.read_csv('csv/'+prefix+'/val_set_full.csv')\n",
    "test_set_all = pd.read_csv('csv/'+prefix+'/test_set_full.csv')\n",
    "horizons = [2, 5]\n",
    "targets = [f'{prefix}_Close', 'log_return_1', 'log_return_5']\n",
    "max_steps = [20, 20, 10]\n",
    "scaler_type = 'standard'\n",
    "loss=MSE()\n",
    "n_trials = 3\n",
    "random_seed = 1\n",
    "\n",
    "for target in targets:\n",
    "    for horizon in horizons:\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        if target == f'{prefix}_Close':\n",
    "            loss_func = mean_squared_error\n",
    "        else:\n",
    "            loss_func = f1_score\n",
    "        for i, mode in enumerate(modes):\n",
    "            for j, model_type in enumerate(model_types):\n",
    "                print(f'Prefix: {prefix} | mode: {mode} | model_type: {model_type}')\n",
    "                ht = HorizonTrainer(prefix, mode, model_type, final_columns[i], train_set_all, val_set_all, test_set_all, horizon, max_steps[j], scaler_type, loss_func, loss, n_trials, random_seed, timestamp, target)\n",
    "                ht.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RMSE()'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(RMSE())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C:\\Users\\szymo\\LBN-INZ\\CODE\\model_training\\results\\NFLX\\financial_and_news\\NBEATS\\val_pred_20231225_134506.csv\n",
    "# C:\\Users\\szymo\\LBN-INZ\\CODE\\model_training\\results\\NFLX\\financial_and_news\\NBEATS\\val_pred_20231226_002730.csv\n",
    "val = pd.read_csv('results/NFLX/financial_and_news/NBEATS/val_pred_20231226_002730.csv')\n",
    "test = pd.read_csv('results/NFLX/financial_and_news/NBEATS/test_pred_20231226_002730.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>NBEATS</th>\n",
       "      <th>index</th>\n",
       "      <th>y</th>\n",
       "      <th>modelID</th>\n",
       "      <th>sequenceID</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2022-11-28</td>\n",
       "      <td>0.001725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-09-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2022-11-29</td>\n",
       "      <td>0.006401</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.031677</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-09-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2022-11-30</td>\n",
       "      <td>-0.039050</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.078175</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-09-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>-0.032065</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.101197</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-09-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2022-12-02</td>\n",
       "      <td>-0.117686</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.109333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-09-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2022-12-03</td>\n",
       "      <td>-0.102125</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.121517</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-09-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2022-12-04</td>\n",
       "      <td>-0.127835</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-0.092714</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-09-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2022-12-05</td>\n",
       "      <td>-0.122013</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.064991</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-09-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2022-12-06</td>\n",
       "      <td>-0.074278</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-0.041656</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-09-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2022-12-07</td>\n",
       "      <td>-0.066630</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.044114</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-09-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2022-12-08</td>\n",
       "      <td>-0.051873</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-0.024642</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-09-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2022-12-09</td>\n",
       "      <td>-0.045122</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-0.043724</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-09-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2022-12-10</td>\n",
       "      <td>-0.046977</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-0.022805</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-09-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2022-12-11</td>\n",
       "      <td>-0.044218</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-0.020487</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2022-12-12</td>\n",
       "      <td>-0.024557</td>\n",
       "      <td>14.0</td>\n",
       "      <td>-0.005836</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2022-12-13</td>\n",
       "      <td>-0.021166</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-0.011684</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-09-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2022-12-14</td>\n",
       "      <td>-0.014349</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-0.006614</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-09-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2022-12-15</td>\n",
       "      <td>-0.011982</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-0.001829</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-09-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2022-12-16</td>\n",
       "      <td>-0.003453</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-0.010067</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-09-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2022-12-17</td>\n",
       "      <td>-0.002157</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.010302</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-09-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2022-12-18</td>\n",
       "      <td>0.007472</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.014669</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-10-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2022-12-19</td>\n",
       "      <td>0.009882</td>\n",
       "      <td>21.0</td>\n",
       "      <td>-0.009146</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-10-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2022-12-20</td>\n",
       "      <td>-0.013188</td>\n",
       "      <td>22.0</td>\n",
       "      <td>-0.029538</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-10-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2022-12-21</td>\n",
       "      <td>-0.009516</td>\n",
       "      <td>23.0</td>\n",
       "      <td>-0.031047</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-10-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2022-12-22</td>\n",
       "      <td>-0.038203</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-0.070106</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-10-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2022-12-23</td>\n",
       "      <td>-0.031434</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-0.067329</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-10-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2022-12-24</td>\n",
       "      <td>-0.074148</td>\n",
       "      <td>26.0</td>\n",
       "      <td>-0.048292</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-10-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2022-12-25</td>\n",
       "      <td>-0.067812</td>\n",
       "      <td>27.0</td>\n",
       "      <td>-0.055454</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-10-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2022-12-26</td>\n",
       "      <td>-0.058908</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.106448</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-10-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2022-12-27</td>\n",
       "      <td>-0.055840</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.119830</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-10-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2022-12-28</td>\n",
       "      <td>0.086937</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.120041</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-10-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>0.116510</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.151070</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-10-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>0.144657</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.172214</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-10-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>0.150032</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.004396</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-10-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>-0.018483</td>\n",
       "      <td>34.0</td>\n",
       "      <td>-0.007736</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-10-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>0.002899</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.007932</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-10-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>-0.022972</td>\n",
       "      <td>36.0</td>\n",
       "      <td>-0.004943</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-10-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>0.006334</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.021506</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-10-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>0.017477</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.051131</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-10-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>0.020977</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.083133</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-10-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2023-01-07</td>\n",
       "      <td>0.070553</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.058396</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-10-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2023-01-08</td>\n",
       "      <td>0.081862</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.054178</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-10-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2023-01-09</td>\n",
       "      <td>0.049543</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.038425</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>0.053282</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.024284</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-11-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2023-01-11</td>\n",
       "      <td>0.019621</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.033837</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-11-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2023-01-12</td>\n",
       "      <td>0.024234</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.022472</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-11-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>0.019949</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.031794</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-11-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2023-01-14</td>\n",
       "      <td>0.022375</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.056303</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-11-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2023-01-15</td>\n",
       "      <td>0.050826</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.070531</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-11-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2023-01-16</td>\n",
       "      <td>0.055426</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.040897</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-11-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2023-01-17</td>\n",
       "      <td>0.035544</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.064978</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-11-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2023-01-18</td>\n",
       "      <td>0.040513</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.056967</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-11-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2023-01-19</td>\n",
       "      <td>0.052396</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.034176</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-11-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2023-01-20</td>\n",
       "      <td>0.056536</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.023389</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-11-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>2023-01-21</td>\n",
       "      <td>0.017555</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.028877</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-11-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-11-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-11-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-11-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-11-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-11-24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_id          ds    NBEATS  index         y  modelID  sequenceID  \\\n",
       "0       NFLX  2022-11-28  0.001725    0.0  0.012381      0.0         0.0   \n",
       "1       NFLX  2022-11-29  0.006401    1.0 -0.031677      0.0         1.0   \n",
       "2       NFLX  2022-11-30 -0.039050    2.0 -0.078175      1.0         0.0   \n",
       "3       NFLX  2022-12-01 -0.032065    3.0 -0.101197      1.0         1.0   \n",
       "4       NFLX  2022-12-02 -0.117686    4.0 -0.109333      2.0         0.0   \n",
       "5       NFLX  2022-12-03 -0.102125    5.0 -0.121517      2.0         1.0   \n",
       "6       NFLX  2022-12-04 -0.127835    6.0 -0.092714      3.0         0.0   \n",
       "7       NFLX  2022-12-05 -0.122013    7.0 -0.064991      3.0         1.0   \n",
       "8       NFLX  2022-12-06 -0.074278    8.0 -0.041656      4.0         0.0   \n",
       "9       NFLX  2022-12-07 -0.066630    9.0 -0.044114      4.0         1.0   \n",
       "10      NFLX  2022-12-08 -0.051873   10.0 -0.024642      5.0         0.0   \n",
       "11      NFLX  2022-12-09 -0.045122   11.0 -0.043724      5.0         1.0   \n",
       "12      NFLX  2022-12-10 -0.046977   12.0 -0.022805      6.0         0.0   \n",
       "13      NFLX  2022-12-11 -0.044218   13.0 -0.020487      6.0         1.0   \n",
       "14      NFLX  2022-12-12 -0.024557   14.0 -0.005836      7.0         0.0   \n",
       "15      NFLX  2022-12-13 -0.021166   15.0 -0.011684      7.0         1.0   \n",
       "16      NFLX  2022-12-14 -0.014349   16.0 -0.006614      8.0         0.0   \n",
       "17      NFLX  2022-12-15 -0.011982   17.0 -0.001829      8.0         1.0   \n",
       "18      NFLX  2022-12-16 -0.003453   18.0 -0.010067      9.0         0.0   \n",
       "19      NFLX  2022-12-17 -0.002157   19.0  0.010302      9.0         1.0   \n",
       "20      NFLX  2022-12-18  0.007472   20.0  0.014669     10.0         0.0   \n",
       "21      NFLX  2022-12-19  0.009882   21.0 -0.009146     10.0         1.0   \n",
       "22      NFLX  2022-12-20 -0.013188   22.0 -0.029538     11.0         0.0   \n",
       "23      NFLX  2022-12-21 -0.009516   23.0 -0.031047     11.0         1.0   \n",
       "24      NFLX  2022-12-22 -0.038203   24.0 -0.070106     12.0         0.0   \n",
       "25      NFLX  2022-12-23 -0.031434   25.0 -0.067329     12.0         1.0   \n",
       "26      NFLX  2022-12-24 -0.074148   26.0 -0.048292     13.0         0.0   \n",
       "27      NFLX  2022-12-25 -0.067812   27.0 -0.055454     13.0         1.0   \n",
       "28      NFLX  2022-12-26 -0.058908   28.0  0.106448     14.0         0.0   \n",
       "29      NFLX  2022-12-27 -0.055840   29.0  0.119830     14.0         1.0   \n",
       "30      NFLX  2022-12-28  0.086937   30.0  0.120041     15.0         0.0   \n",
       "31      NFLX  2022-12-29  0.116510   31.0  0.151070     15.0         1.0   \n",
       "32      NFLX  2022-12-30  0.144657   32.0  0.172214     16.0         0.0   \n",
       "33      NFLX  2022-12-31  0.150032   33.0  0.004396     16.0         1.0   \n",
       "34      NFLX  2023-01-01 -0.018483   34.0 -0.007736     17.0         0.0   \n",
       "35      NFLX  2023-01-02  0.002899   35.0  0.007932     17.0         1.0   \n",
       "36      NFLX  2023-01-03 -0.022972   36.0 -0.004943     18.0         0.0   \n",
       "37      NFLX  2023-01-04  0.006334   37.0  0.021506     18.0         1.0   \n",
       "38      NFLX  2023-01-05  0.017477   38.0  0.051131     19.0         0.0   \n",
       "39      NFLX  2023-01-06  0.020977   39.0  0.083133     19.0         1.0   \n",
       "40      NFLX  2023-01-07  0.070553   40.0  0.058396     20.0         0.0   \n",
       "41      NFLX  2023-01-08  0.081862   41.0  0.054178     20.0         1.0   \n",
       "42      NFLX  2023-01-09  0.049543   42.0  0.038425     21.0         0.0   \n",
       "43      NFLX  2023-01-10  0.053282   43.0  0.024284     21.0         1.0   \n",
       "44      NFLX  2023-01-11  0.019621   44.0  0.033837     22.0         0.0   \n",
       "45      NFLX  2023-01-12  0.024234   45.0  0.022472     22.0         1.0   \n",
       "46      NFLX  2023-01-13  0.019949   46.0  0.031794     23.0         0.0   \n",
       "47      NFLX  2023-01-14  0.022375   47.0  0.056303     23.0         1.0   \n",
       "48      NFLX  2023-01-15  0.050826   48.0  0.070531     24.0         0.0   \n",
       "49      NFLX  2023-01-16  0.055426   49.0  0.040897     24.0         1.0   \n",
       "50      NFLX  2023-01-17  0.035544   50.0  0.064978     25.0         0.0   \n",
       "51      NFLX  2023-01-18  0.040513   51.0  0.056967     25.0         1.0   \n",
       "52      NFLX  2023-01-19  0.052396   52.0  0.034176     26.0         0.0   \n",
       "53      NFLX  2023-01-20  0.056536   53.0  0.023389     26.0         1.0   \n",
       "54      NFLX  2023-01-21  0.017555   54.0  0.028877     27.0         0.0   \n",
       "55       NaN         NaN       NaN    NaN       NaN      NaN         NaN   \n",
       "56       NaN         NaN       NaN    NaN       NaN      NaN         NaN   \n",
       "57       NaN         NaN       NaN    NaN       NaN      NaN         NaN   \n",
       "58       NaN         NaN       NaN    NaN       NaN      NaN         NaN   \n",
       "59       NaN         NaN       NaN    NaN       NaN      NaN         NaN   \n",
       "\n",
       "          Date  \n",
       "0   2023-09-04  \n",
       "1   2023-09-05  \n",
       "2   2023-09-06  \n",
       "3   2023-09-07  \n",
       "4   2023-09-08  \n",
       "5   2023-09-11  \n",
       "6   2023-09-12  \n",
       "7   2023-09-13  \n",
       "8   2023-09-14  \n",
       "9   2023-09-15  \n",
       "10  2023-09-18  \n",
       "11  2023-09-19  \n",
       "12  2023-09-20  \n",
       "13  2023-09-21  \n",
       "14  2023-09-22  \n",
       "15  2023-09-25  \n",
       "16  2023-09-26  \n",
       "17  2023-09-27  \n",
       "18  2023-09-28  \n",
       "19  2023-09-29  \n",
       "20  2023-10-02  \n",
       "21  2023-10-03  \n",
       "22  2023-10-04  \n",
       "23  2023-10-05  \n",
       "24  2023-10-06  \n",
       "25  2023-10-09  \n",
       "26  2023-10-10  \n",
       "27  2023-10-11  \n",
       "28  2023-10-12  \n",
       "29  2023-10-13  \n",
       "30  2023-10-16  \n",
       "31  2023-10-17  \n",
       "32  2023-10-18  \n",
       "33  2023-10-19  \n",
       "34  2023-10-20  \n",
       "35  2023-10-23  \n",
       "36  2023-10-24  \n",
       "37  2023-10-25  \n",
       "38  2023-10-26  \n",
       "39  2023-10-27  \n",
       "40  2023-10-30  \n",
       "41  2023-10-31  \n",
       "42  2023-11-01  \n",
       "43  2023-11-02  \n",
       "44  2023-11-03  \n",
       "45  2023-11-06  \n",
       "46  2023-11-07  \n",
       "47  2023-11-08  \n",
       "48  2023-11-09  \n",
       "49  2023-11-10  \n",
       "50  2023-11-13  \n",
       "51  2023-11-14  \n",
       "52  2023-11-15  \n",
       "53  2023-11-16  \n",
       "54  2023-11-17  \n",
       "55  2023-11-20  \n",
       "56  2023-11-21  \n",
       "57  2023-11-22  \n",
       "58  2023-11-23  \n",
       "59  2023-11-24  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2IAAAIjCAYAAABh3KjvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdd3hU1dbA4d+ZSe+9EQgQagjSQRAQJEiQImIBK0UsXDuK6L1XkU9RsGJHVAQvKiogAioIKIJSAsRQDDWEQCC99zJzvj9OMjCkTTIhQFivT56QM2f27IkwM+vstddSVFVVEUIIIYQQQgjRZHSXegJCCCGEEEIIcbWRQEwIIYQQQgghmpgEYkIIIYQQQgjRxCQQE0IIIYQQQogmJoGYEEIIIYQQQjQxCcSEEEIIIYQQoolJICaEEEIIIYQQTUwCMSGEEEIIIYRoYhKICSGEEEIIIUQTk0BMCCFEs6MoCi+99NKlnsYlN2TIEIYMGWL6+eTJkyiKwpIlSy7ZnC504RyFEOJqIYGYEEKIWn300UcoikK/fv0aPMbZs2d56aWXiImJabyJXea2bNmCoiimL1tbW9q2bct9993HiRMnLvX06mX79u289NJLZGdnX+qpCCFEs2FzqScghBDi8vbVV1/RunVroqKiOH78OO3atav3GGfPnmXOnDm0bt2a7t27N/4kL2OPP/44ffr0oaysjOjoaBYtWsRPP/3EgQMHCAoKatK5hISEUFRUhK2tbb3ut337dubMmcPkyZPx8PC4OJMTQoirjKyICSGEqFF8fDzbt2/n7bffxtfXl6+++upST+mKM2jQIO655x6mTJnC+++/z5tvvklmZiZLly6t8T4FBQUXZS6KouDg4IBer78o4wshhLCcBGJCCCFq9NVXX+Hp6cmoUaO47bbbagzEsrOzeeqpp2jdujX29vYEBwdz3333kZ6ezpYtW+jTpw8AU6ZMMaXqVe5Tat26NZMnT64y5oV7h0pLS3nxxRfp1asX7u7uODs7M2jQIH7//fd6P6+UlBRsbGyYM2dOlduOHDmCoih88MEHAJSVlTFnzhzat2+Pg4MD3t7eDBw4kI0bN9b7cQFuuOEGQAtyAV566SUURSE2Npa77roLT09PBg4caDp/2bJl9OrVC0dHR7y8vJg4cSKnT5+uMu6iRYsIDQ3F0dGRvn37sm3btirn1LRH7PDhw9xxxx34+vri6OhIx44d+c9//mOa38yZMwFo06aN6f/fyZMnL8ochRDiaiGpiUIIIWr01VdfMX78eOzs7Ljzzjv5+OOP2b17tymwAsjPz2fQoEEcOnSIqVOn0rNnT9LT01mzZg2JiYl07tyZ//u//+PFF1/kwQcfZNCgQQAMGDCgXnPJzc3ls88+48477+SBBx4gLy+Pzz//nBEjRhAVFVWvlEd/f3+uv/56vvvuO2bPnm1227fffoter+f2228HtEDktddeY9q0afTt25fc3Fz27NlDdHQ0w4cPr9dzAIiLiwPA29vb7Pjtt99O+/btefXVV1FVFYC5c+fywgsvcMcddzBt2jTS0tJ4//33GTx4MH///bcpTfDzzz/noYceYsCAATz55JOcOHGCsWPH4uXlRcuWLWudz/79+xk0aBC2trY8+OCDtG7dmri4ONauXcvcuXMZP348R48e5ZtvvuGdd97Bx8cHAF9f3yaboxBCNEuqEEIIUY09e/aogLpx40ZVVVXVaDSqwcHB6hNPPGF23osvvqgC6qpVq6qMYTQaVVVV1d27d6uA+sUXX1Q5JyQkRJ00aVKV49dff716/fXXm34uLy9XS0pKzM7JyspS/f391alTp5odB9TZs2fX+vw++eQTFVAPHDhgdjwsLEy94YYbTD9369ZNHTVqVK1jVef3339XAXXx4sVqWlqaevbsWfWnn35SW7durSqKou7evVtVVVWdPXu2Cqh33nmn2f1Pnjyp6vV6de7cuWbHDxw4oNrY2JiOl5aWqn5+fmr37t3Nfj+LFi1SAbPfYXx8fJX/D4MHD1ZdXV3VhIQEs8ep/H+nqqr6xhtvqIAaHx9/0ecohBBXC0lNFEIIUa2vvvoKf39/hg4dCmj7iyZMmMDy5csxGAym81auXEm3bt245ZZbqoyhKEqjzUev12NnZweA0WgkMzOT8vJyevfuTXR0dL3HGz9+PDY2Nnz77bemYwcPHiQ2NpYJEyaYjnl4ePDPP/9w7NixBs176tSp+Pr6EhQUxKhRoygoKGDp0qX07t3b7LyHH37Y7OdVq1ZhNBq54447SE9PN30FBATQvn17U0rmnj17SE1N5eGHHzb9fgAmT56Mu7t7rXNLS0tj69atTJ06lVatWpndZsn/u6aYoxBCNFeSmiiEEKIKg8HA8uXLGTp0qGkvE0C/fv1466232Lx5MzfeeCOgpdrdeuutTTKvpUuX8tZbb3H48GHKyspMx9u0aVPvsXx8fBg2bBjfffcdL7/8MqClJdrY2DB+/HjTef/3f//HzTffTIcOHQgPDycyMpJ7772Xa665xqLHefHFFxk0aBB6vR4fHx86d+6MjU3Vt98Ln8OxY8dQVZX27dtXO25l5cOEhASAKudVlsuvTWUZ/fDwcIuey4WaYo5CCNFcSSAmhBCiit9++42kpCSWL1/O8uXLq9z+1VdfmQIxa9W08mIwGMyq+y1btozJkyczbtw4Zs6ciZ+fH3q9ntdee82076q+Jk6cyJQpU4iJiaF79+589913DBs2zLQPCmDw4MHExcXx448/8uuvv/LZZ5/xzjvvsHDhQqZNm1bnY3Tt2pWIiIg6z3N0dDT72Wg0oigKv/zyS7VVDl1cXCx4hhfXlTBHIYS4XEkgJoQQooqvvvoKPz8/Pvzwwyq3rVq1ih9++IGFCxfi6OhIaGgoBw8erHW82tLcPD09q20UnJCQYLZasmLFCtq2bcuqVavMxruw2EZ9jBs3joceesiUnnj06FGef/75Kud5eXkxZcoUpkyZQn5+PoMHD+all16yKBBrqNDQUFRVpU2bNnTo0KHG80JCQgBtdaqyIiNo1R7j4+Pp1q1bjfet/P029P9fU8xRCCGaK9kjJoQQwkxRURGrVq1i9OjR3HbbbVW+Hn30UfLy8lizZg0At956K/v27eOHH36oMpZaUf3P2dkZoNqAKzQ0lJ07d1JaWmo6tm7duirlzytXXCrHBNi1axc7duxo8HP18PBgxIgRfPfddyxfvhw7OzvGjRtndk5GRobZzy4uLrRr146SkpIGP64lxo8fj16vZ86cOWbPGbTfQeW8evfuja+vLwsXLjT7HS5ZsqTa3/f5fH19GTx4MIsXL+bUqVNVHqNSTf//mmKOQgjRXMmKmBBCCDNr1qwhLy+PsWPHVnv7tddea2ruPGHCBGbOnMmKFSu4/fbbmTp1Kr169SIzM5M1a9awcOFCunXrRmhoKB4eHixcuBBXV1ecnZ3p168fbdq0Ydq0aaxYsYLIyEjuuOMO4uLiWLZsGaGhoWaPO3r0aFatWsUtt9zCqFGjiI+PZ+HChYSFhZGfn9/g5zthwgTuuecePvroI0aMGGEqt14pLCyMIUOG0KtXL7y8vNizZw8rVqzg0UcfbfBjWiI0NJRXXnmF559/npMnTzJu3DhcXV2Jj4/nhx9+4MEHH+SZZ57B1taWV155hYceeogbbriBCRMmEB8fzxdffGHR/qv33nuPgQMH0rNnTx588EHatGnDyZMn+emnn4iJiQGgV69eAPznP/9h4sSJ2NraMmbMmCaboxBCNEuXqFqjEEKIy9SYMWNUBwcHtaCgoMZzJk+erNra2qrp6emqqqpqRkaG+uijj6otWrRQ7ezs1ODgYHXSpEmm21VVVX/88Uc1LCxMtbGxqVJC/a233lJbtGih2tvbq9ddd526Z8+eKuXrjUaj+uqrr6ohISGqvb292qNHD3XdunXqpEmT1JCQELP5YUH5+kq5ubmqo6OjCqjLli2rcvsrr7yi9u3bV/Xw8FAdHR3VTp06qXPnzlVLS0trHbeyfP33339f63mV5evT0tKqvX3lypXqwIEDVWdnZ9XZ2Vnt1KmT+sgjj6hHjhwxO++jjz5S27Rpo9rb26u9e/dWt27dWuV3WF35elVV1YMHD6q33HKL6uHhoTo4OKgdO3ZUX3jhBbNzXn75ZbVFixaqTqerUsq+MecohBBXC0VVL8glEEIIIYQQQghxUckeMSGEEEIIIYRoYhKICSGEEEIIIUQTk0BMCCGEEEIIIZqYBGJCCCGEEEII0cQkEBNCCCGEEEKIJiaBmBBCCCGEEEI0MWno3AiMRiNnz57F1dUVRVEu9XSEEEIIIYQQl4iqquTl5REUFIROV/O6lwRijeDs2bO0bNnyUk9DCCGEEEIIcZk4ffo0wcHBNd4ugVgjcHV1BbRftpub2yWejRBCCCGEEOJSyc3NpWXLlqYYoSYSiDWCynRENzc3CcSEEEIIIYQQdW5ZkmIdQgghhBBCCNHEJBATQgghhBBCiCYmgZgQQgghhBBCNDEJxIQQQgghhBCiiUkgJoQQQgghhBBNTAIxIYQQQgghhGhiEogJIYQQQgghRBOTQEwIIYQQQgghmpgEYkIIIYQQQgjRxCQQE0IIIYQQQogmJoGYEEIIIYQQQjQxCcSEEEIIIYQQoolJICaa1NatWxkzZgxBQUEoisLq1asv9ZSEEEIIIYRochKINSMGo8qOuAx+jDnDjrgMDEa1geMY2J28m59P/Mzu5N0YjIZGm2NBQQHdunXjww8/bLQxhRBCCCGEuNLYXOoJiMax/mASc9bGkpRTbDoW6O7A7DFhRIYHWjzOpoRNzIuaR0phiumYv5M/z/V9joiQCKvnOXLkSEaOHGn1OEIIIYQQQlzJZEWsGVh/MInpy6LNgjCA5Jxipi+LZv3BJIvG2ZSwiRlbZpgFYQCphanM2DKDTQmbGm3OQgghhBBCXM0kELvCGYwqc9bGUl0SYuWxOWtj60xTNBgNzIuah1rNSJXH5kfNb9Q0RSGEEEIIIa5WEohd4aLiM6ushJ1PBZJyiomKz6x1nOjU6CorYebjqCQXJhOdGl2/CRoNEL8NDqzQvksgJ4QQQgghhOwRu9Kl5tUchJ1v/vrDTB7QmiEdffFwsqtye1phmkXjpBWmkVyQTGphKuE+4eiUWmL52DUY1s8iujSDNL0eX4OBnnbe6CPnQ9hYix5PCCGEEEKI5kgCsSucn6uDRefFnM7myW9j0OsU+rT2JKKzPxGd/Wnt4wyAr5OvReP4Ovny4/Ef+SDmA7wdvBnScgjXB1/PtUHX4mjjeO7E2DVsWvcQ87w9SLHxNx32Ly/nuXUPYX3ZDyGEEEIIIa5cEohd4fq28SLQ3YHknOJq94kpgLeLHXf0bslvh1M5nJzHzhOZ7DyRySs/HaKdnwsRnf0Z1rk17rY+ZJemoyhVx1FV8LTzpadfT3Yl7cLF1oWM4gxWHlvJymMrsdfb0z+wP0NaDmFU60j+/O05Zvh5V5lTUhlML3bi6S+fBCA+Pp6YmBi8vLxo1apVI/92hBBCCCGEuDwpqqo2rNmUMMnNzcXd3Z2cnBzc3Nya/PErqyYCZoFPZTz18T09TSXsT2cWsulQCpsOpbDrRCbl5xXxsHU9iH2LZdp9zwvGKv+GOGZNYecTT6HXKZQZytiTsoctp7ew5fQWzhacBcDZ1pktfecy+o9HSdHruTCqyz+Uz8n5J6s8h0mTJrFkyZIG/gaEEEIIIYS4PFgaG0gg1ggudSAGDesjllNUxh9H09gUm8Km2GQKy4zYuB7E3v9HdLZ5pvOMZe6UpIyhPC+cbx64lv6h3mbjqKrK0ayjbDm9hTJjGf2Kipl6bGmdc17cfhJ9BjzTsCcshBBCCCHEZcjS2EBSE5uJyPBAhocFEBWfSWpeMX6uDvRt44VeV02eYQV3R1vGdgtibLcgVkUnMuO7fZTnhVOeF4beKR7FJg+13BVDYRsqC2xWVxxEURQ6enWko1dHAH7e9bZFc07TS9FOIYQQQghxdZJArBnR65Qqq1WWCnQ/r9AGOgyFodWeZ0lxEF+lalXGas9rOcCi84QQQgghhGhuZElCAOeKfiiAreef6F1iQSkz3a6gpTr2beNV+0DHNtJzwxz8y8tRash6VVSVADt3egb0abwnIIQQQgghxBVEAjEBaKtps8eEga4Qh4B1OLX8EhQjcK7ox+wxYbWmOlJaCD8+gt5QynOO7UBRqgRjiqqCojBrwEvodfqL9GyEEEIIIYS4vEkgJkwiwwN5dqwnAMYyDzDaAxDg7mBWebFGdk5w13fQ4x4iJqzi7SHv4OccYHaKv3MAbw95h4gQ6SQmhBBCCCGuXhKICTO+XtkAdPDU9og52er4c9YNtQdhpYXn/hzUHW7+EPS2RIREsOHWDVxnqzWLvtUxhPW3bpAgTAghhBBCXPUkEBNm4rLjAOgV1AmAwjIj5UZjLXf4Hd69Bk5HVXuzXqdnXuAN7Dh5mtl2rSQdUQghhBBCCCQQExc4kXMCgE7e7bDVa/vB0vNLqz857nf4ZiIUpEHUpzWO6eHaAhdVRSnKavT5CiGEEEIIcSWSQEyYqQzE2nm0w8dF2yO2YdNvjBkzhqCgIBRFYfXq1XBiixaElRdDh5FaOmJNnCpK6hdmXNzJCyGEEEIIcYWQQEyY5Jfmk1yQDEAb9zamQCwlI4du3brx4YcVwVbyQfi6IghrPwLuWAo2NfcOO2Nrx5zgdrziWOMpQgghhBBCXFWkobMwcbBxYMWYFSTkJuBu746PixZcte05kAkP3XXuxK1vQgdVC8Im/A9s7Gsdt9i3PStsS3FTCvjvxXwCQgghhBBCXCFkRUyY2Ohs6OjVkRtb3whgWhFLyysxP9FYCu1vtCgIA/B20FITc0tzKTXUsN9MCCGEEELUaOvWrVW3ipxHUZRqv954441LM2FRJwnERFVGA8RvY3DJFq7VxZKRV2R+e/jtcIdlQRiAm70bNjpt8TWzOLOxZyuEEEII0ewVFBSYbxW5QFJSktnX4sWLURSFW2+9tYlnKiwlqYnC5KtDX2FM2k/E/jUEZp9lDDDGDnL2fwTtF0DYzdqJ4beArYPF4+oUHV4GI6kKZJzdS0D7URdl/kIIIYQQzdXIkSMZOXJkjbcHBASY/fzjjz8ydOhQ2rZte7GnJhpIAjFh8r99n3CmJItOxRmc377ZzZAJ390Hd3zZ4LG9jSqpesjIPW39RIUQQgghGpHBqBIVn0lqXjF+rg70beOFXqc0cCwD0anRpBWm4evkS0+/nk3eRzUlJYWffvqJpUuXNunjivqRQEwAUFSaz9niTFAU2paWmd1mehla/3yDx/dR7IAS0vPPNngMIYQQQojGtv5gEnPWxpKUU2w6FujuwOwxYUSGB9Zyz6o2JWxiXtQ8UgpTTMf8nfx5ru9zRIRE1G9iRgMkbIf8FHDxh5ABYGFAt3TpUlxdXRk/fnz9HlM0KdkjJgA4eWQNqqLgYTDgZTSa3ZZfqhKTbCDm6CkA4uPjiYmJ4dSpUxaP722j1a7PLExrvEkLIYQQQlhh/cEkpi+LNgvCAJJzipm+LJr1B5MsHmtTwiZmbJlhFoQBpBamMmPLDDYlbLJ8YrFrYEE4LB0NK+/Xvi8I145bYPHixdx99904OFi+lUQ0PQnEBABxmYcBaFtWxoUL8XvOGujxSQE9PikAYMaMGfTo0YMXX3zR4vGfcenMzpOnud9J8pSFEEIIcekZjCpz1saiVnNb5bE5a2MxGKs748KxDMyLmodazWiVx+ZHzcdgNNQ9sdg12paQ3AuyiHKTtON1BGPbtm3jyJEjTJs2re7HEpeUpCYKAE4YCgEIvSAtEWBIaxvU2W7aD5PWQZtB9R7f3SUQVBWKsqyapxBCCCFEY4iKz6yyEnY+FUjKKSYqPpP+od61jhWdGl1lJcx8LJXkwmSiU6PpE9Cn5oGMBlg/C2oMDxVY/1ytc/n888/p1asX3bp1q/U8cenJipgAIA6tv1fbsvJqb1dRwK2Flp/cEE4VL2CFGQ27vxBCCCFEI0rNqzkIq+95aRZuvajzvITtVVfCKmhbRcpr3SqSm5vL999/L6thVwhZERMAnMiJB6go1KFw/pUYowqKAkTOs3iT6IUSHV35rGUoNsZk/mv9dIUQQgghrOLnatn+KUvO83XytWisOs/Lr3lVbc9ZA0OXFpp+njFjBgCTJk1iyZIlACxfvhxVVbnzzjstmo+4tGRFTADwzahv+Pqmr+k26gNwM68QlIw3f/V8G8LGNnj8kraDWWlTxi9l6dZOVQghhBDCan3beBHo7lBlb/z5FAVUte49Yj39euLv5I9Sy2hONk709OtZ+0B6+xpvqtwqos52Qz2xFVVVUVXVFIQBPPjggxQWFuLu7l7nnMWlJ4GYAMDFzoWuvl1x7no7PHlQ2wt26+csbP0uA0veJcal/vvCzufj6ANAbmkupYbSxpiyEEIIIUSD6XUKs8eE1XqOqsKkL6JYuTexjrH0PNdX27t1fjBWcKSAhHcSOPzkYaLuiWLtmrVm91MUxfyry1iUObm88VdJDY9k5VYRcVmRQExUZSzXCnJ0vY3cgGsxoiMtr6YXBMu42blho9MyYTOLMxtjlkIIIYQQVokMD+Tje3pWad4c6O7AexO7M6prIGUGlae/38dbvx7BWEsFxYiQCGb1nYW7/bnVKGOJEe9Qb2a9Osvs3NzSXACSkpJIOnOGpDcHkfS0C4vHOqAocGuYLdS0umbFVhFxeZE9YoK1cWvZn7af4SHD6RvYFz4dphXVuONLfF21laz0fOtWsZSyQrzKy0nVQUbeWQKcAxpj6kIIIYQQVhnY3tdUov6VceGE+rrQt40Xep3C6GuCCPF24qMtcbz/23Hi0wt48/ZuONhWHwhll2STXZLNgKAB3Bx6M74jfOnp1xO9Ts/cf80FYGviVp7b9hyvD36dgS0GanfsNQp2nuTH3V4MHepF24ee1KonXli4I2ysVVtFxOVFVsQEfyT+wfIjyzmUeUgrm5p+FPLOgrMPPi5arnJavnUrYtg64V2mBXPpOSetnLEQQgghROOIPautTgW6O3DPtSH0D/U2rZDpdArPRnbi9duuwVavsG5/End9upP0Gj4XHco4BMDg4MHc1PYm+gT0QX/B6tX3h78lrzSPRzb9i28Of6MdvO4JUu5Yz0/b/+H++6dpwdZ5W0UY+m/tvOO/QaFkFjUXEogJ4rLjAGjj3gayToKhBGwcwSPEFIilW5maiKLgg/ZClJFXe561EEIIIURTOXgmB4DwFjUXuLijd0u+nNoPd0dbok9lM+7DvziWklflvMpALKykDA6sgPht2kXuSqmHePtoNDfn5WNE5dVdr2qNnvW2LF2xDldXV8aPH6+dq9Obtoow+FkI6AqlebDjw8Z78uKSkkDsKlduLOdk7kkAQj1CIe2wdoNvB9Dp8HVtpBUxwFunjZVZkGz1WEIIIYQQjcEUiAXVXmmwf6g3q/41gBBvJxKzihj/0Xa2HTvXFyy9KJ3UolQUVaXjj0/Cyvth6WhYEA7RX2on/fYytqmxvFwAT/hraYnLDi3jid+f4LPPP+Puu+/GwaGacvmKAtdXNHLetVBWxZoJCcSucol5iZQby3G0cSTQOfC8QKyT9q1iRSyvuJziMkNNw1jkGZsAdp08zTSvOkq3CiGEEEI0kYNntUCsa7BbneeG+rrww7+uo29rL/JKypn8xW6+3qU1VI79+wsA2pSV43R+yfvcs7DmsYofFOg9FeWxvUyL/Jg3r38Te709P2/+mWNHj3H3pLtrfvBOoyDgGijNh+3vN+i5isuLBGJXubgcLS2xtVtrdIoOUisDsY4AuDnaYKfX/prUlA9tKXcnX+2FSa7iCCGEEOIyUFhazvHUfKDuFbFKXs52/G9aX27p0QKDUeXfPxzg1XUHiN2nBWKdS2spcBYxB0a/A05eAIxoPYLFIxZT+FchQZ2C6Nern+lUg9HA7uTd/HziZ3Yn78agGmHI89qN8Vu12vriiiZVE69yJ7JPABVpiVBlRUxRFHxc7DibU0x6finBnk4NfzAnb+17YUbDxxBCCCGEaCSHkvIwquDrao+fWzUpgTWwt9Hz9h3daOPjzNsbj7J/+3r8g0sAJ8JKzgVi+aUqxzONpp/jTyYQExODl5cXrVq1AqC1fWty9+TyxhtvoChakZBfT/7K67tfJ6UwxXRffyd/nuszi4i7voN2w7V0RXFFkxWxq1xSQRJwXiDWeiC0GgB+nU3n+Lg2TsGOM66+vNSyHS/n7rdqHCGEEEKIxlC5P6xrLYU6aqIoCo8Pa8+7E7sTqM/hyaxs5qZlMLiwyHTOnrMGenxSQI9PCgCYMfcDevTowYsvvmg6Z/ny5aDCPXffA8CGkxt4+o+nzYIwgNTCVGb88TSb7PWgk4/wzYGiqrKuaa3c3Fzc3d3JycnBza3u/OLLTXZxNoqimDUgPN/UJbv57XAqr43vyp19WzX4cU5kn+DmH2/G1c6V7Xdub/A4QgghhBCNYeb3+/h+byKP39COGTd2bPA4h3b8ROcNd9V5nuG+tejbDq75dqOB67+9npzSnGpvV1Dwd/Jn/a3r0RtK4ezfEDKgwfMWF4elsYGE0wIPB48agzA4V7DD2hUxb0ctNTGvNI8Sg/VVGIUQQgghrHHAgtL1lsj26cNZ1avGbVtGFc6q3kQZOtU6TnRqdI1BGICKSnJhMtEnfoF3u8GyWyE/rcbzxeVNAjFxTn4alBZWOezjagdYX6zDzc4NW50tAJlFUrBDCCGEEJdOcZmBY5WFOqwMxLYm/cmTzr05YVu1/IKxIjibU3YvqQVltY6TVmhZUJWmU8AtCMoKYfu79Z6vuDxIIHYV2528m4c3PczSf5ZqBza+AK8Gwc6FZueZmjrn11IFyAJK+jG8yrUXoIxiKdghhBBCiEvncHIeBqOKt7Mdge6WF+qoTmzubxzyP8xWZ0dKVb3Zbcl4M73sSTYY++LnWvvj+Dr5WvR4vk5+5yooRn0mq2JXKKmaeBX7J/0f/jrzF662rtqBtMOACu4tzM4zNXW2MjURWwd8ykpIsbcn3cIrPkIIIYQQF0NloY4uLdxN1QobKqVIqzodVlLK5LJnMaLHj2xS8SDK2AljxdrHh78fw8lOT7eWHtWO09OvJ/5O/qQWpqJSfZ5jgFMAPf16ku2ei21Qd5zPxsBfC2DEXKueg2h6siJ2FavsIdbWoy0YjZB2VLvB1zx/+dyKmJWBmJM33gathGtG/lnrxhJCCCGEsMI/lY2cW1hXaC2nJIczFRUOc4pC2WHsyk5jGGuMA9hpDDMFYXod/Hk8g5s//IuH/reHoyl5VcbS6/Q81/c5QCvMcT6l4r9ZfWeh1+lZ8Pe7jHQu4Us3V0p2fw55KVXGu9i2bt3KmDFjCAoKQlEUVq9ebXZ7fn4+jz76KMHBwTg6OhIWFsbChQurH+wqJIHYVczUQ8w9FHJOQ1kB6GzBs43ZeZWBWJq1gZitE94VrTSyJBATQgghxCVkKtRhYSPnmhxK/weA4LIyXG94kYAL0hwD3R1YeE9PtjwzlFt7BqNTYMM/KYxYsJUZ38ZwKsN8f35ESARvD3kbPyc/s+P+Tv68PeRtIkIiKDWU8nfq32SVF/CGtyejAj1Zselpyoy170FrbAUFBXTr1o0PP/yw2ttnzJjB+vXrWbZsGYcOHeLJJ5/k0UcfZc2aNU06z8uVpCZepVRVPbci5t4W0o5oN/i0B735X4vK1MS84nKKyww42JrnPltMUXi61J7nTp7GKeKGBs9dCCGEEMIapeVGjiRrK1LWFuo4lKV9huocPJD+14/kz0EqUfGZpOYV4+fqQN82Xuh12urWW3d04+Hr2/L2xqP8cjCZVX+fYc2+s0zs25LHbmiPf0VT6YiQCAa3GMLX+7ZwKjeZVm4B3NVtCHY22mc0O70dK8auYM3xNXy8dwEpZDMndx9LVt/CIz0eYUTrEeiUc+stBqOB6NRo0grT8HXypadfT/S6Bn6eO8/IkSMZOXJkjbdv376dSZMmMWTIEAAefPBBPvnkE6Kiohg7dqzVj3+lk0DsKpVSmEJBWQF6RU+IWwjE/qzd4Fu1h4abgw12eh2lBiPp+SUEezo1+HHdHb0gJxEKpWqiEEIIIS6Noyl5lBlU3B1tCfZ0tGqs2IxYAMJaXAuAXqfQP9S7xvPb+7vy8T292J+YzZu/HmXr0TSW7TzF93sSmTygNQ9fH8qu+AzmrI0lKacE8ARK+OTXP5g9JozI8EAAbHW23NrhVka3HcV30R/y6YkfSchL4Nmtz5JamMqkLpMA2JSwiXlR88waRPs7+fNc3+eICImw6rnXZcCAAaxZs4apU6cSFBTEli1bOHr0KO+8885FfdwrhaQmXqVO5Ghpia3cWmGrtz23Iubbucq5iqLg41JZwt66yok4VbwwFUrVRCGEEEJcGgdN/cPcrCvUsWcxhytSE8O8wup112uCPfhyal+WP3gtvUI8KSk38snWE/R/bTMPL4smKafY7PzknGKmL4tm/cEks+P2Ng7c2/dpfrn1Fx7p/giBzoGMazcO0IKwp7Y8ZRaEAaQWpjJjyww2JWyq5xOun/fff5+wsDCCg4Oxs7MjMjKSDz/8kMGDa25qfTW54gKxDz/8kNatW+Pg4EC/fv2Iioqq9fzvv/+eTp064eDgQNeuXfn555/Nbp88eTKKoph9RUZGXsyncFnILcnF1c5V2x8G0HYIdL8HWl1b7fk+jVQ5MdGrJbNbtuP/zvxq1ThCCCGEEA3VKI2cT++GdU/x7dH9/O+Gj+jm161Bw1zb1psVD/fni8l96BTgSnG5sdrzKmsozlkbi8FYtaKis60zD4eM4udOD+Ju747BaGBe1LwaxtLuPz9qPgajwfLJGg0Qvw0OrNC+13Hf999/n507d7JmzRr27t3LW2+9xSOPPMKmTRc3ALxSXFGpid9++y0zZsxg4cKF9OvXjwULFjBixAiOHDmCn59flfO3b9/OnXfeyWuvvcbo0aP5+uuvGTduHNHR0YSHh5vOi4yM5IsvvjD9bG9v3yTP51KKbBPJiNYjKDZUXG255nbtqwa+jVQ5sXTgU6z6cQuuOYd50aqRhBBCCCEa5uDZXMDKQh2/vQyAU+eb6d5ykFXzURSFoZ38sLfRcddnu2o8TwWScoqJis+smv6Yfgw+6o+NTg8hA4kuOF1lJcx8LJXkwmSiU6PpE9Cn7knGroH1syD3vIJrbkEQOR/Cqu73Kioq4t///jc//PADo0aNAuCaa64hJiaGN998k4iIi5sWeSW4olbE3n77bR544AGmTJliKn/p5OTE4sWLqz3/3XffJTIykpkzZ9K5c2defvllevbsyQcffGB2nr29PQEBAaYvT0/Ppng6l5yiKDjaWJYXbSphb+WKmLej9qKRV5pHicHKKoxCCCGEEPVUZjByKEkLxLo2dEXsxB8Q/4dWbXrIrEabm6UVqlPziqse9G4HLXpBeTH8+Q5pFvZstei82DXw3X3mQRhAbpJ2PLZqFcSysjLKysrQ6czDDb1ej9FY/arf1eaKCcRKS0vZu3evWfSs0+mIiIhgx44d1d5nx44dVaLtESNGVDl/y5Yt+Pn50bFjR6ZPn05GRu37l0pKSsjNzTX7uqLlpUDqISivef+Xj6u2R8zaEvZudm7Y6mwByCySgh1CCCGEaFrHU/MpLTfiam9DK68GFCBTVdNq2MLOg3j1yDKOZB5plLn5uTrUfVJN5ykKDH1e+/OeL/BVLdv75uvkW/sJRoO2ElZNg+n8UiMxyQZiPn8SgPj4eGJiYjh16hRubm5cf/31zJw5ky1bthAfH8+SJUv48ssvueWWWyyaW3N3xQRi6enpGAwG/P39zY77+/uTnJxc7X2Sk5PrPD8yMpIvv/ySzZs3M3/+fP744w9GjhyJwVBzzutrr72Gu7u76atly5ZWPLOml16UzqhVo3jitycwqkY4uAI+uhZWTavxPo2VmqjE/4FXudbjIqNYCnYIIYQQomlVFuro0sINna4BhTqOboDE3WDjyC/6Ur45/A2phamNMre+bbwIdHegtlm5OtjQp3UN2VttrodW/cFQQs/Dm/F38q/SGPp8AU4B9PTrWfukErZXXQmrsOesgR6f5NPj7XhA6xvWo0cPXnxR24CyfPly+vTpw913301YWBjz5s1j7ty5PPzww7U/5lXiignELpaJEycyduxYunbtyrhx41i3bh27d+9my5YtNd7n+eefJycnx/R1+vTppptwIziRfYJTeac4mnVU6zGReki7wbdTjfepLNaRnmdl1UQUfMq0YC69KN3KsYQQQggh6uegNY2cjUb47RUACvtMJT5P+wzY2btq1emG0OsUZo/Rqi/WFD7lFZfzyk+Hqi3YgaLAEG1VTB+9lOfCH6wYq/rRZvWdVXc/sfya95kNaW2DOttN+9r/PaqqoqoqS5YsASAgIIAvvviCM2fOUFRUxOHDh5kxY4Z1lSqbkSsmEPPx8UGv15OSYv6XISUlhYCAgGrvExAQUK/zAdq2bYuPjw/Hjx+v8Rx7e3vc3NzMvq4klaXrQz0qKiaaStdX7SFWqXKPmLWpiTj74G3Q8oIzimRFTAghhBBNy1SooyH7wwwl0GYwOPtypPMIVFT8nPzwcfRptPlFhgfy8T09CXA3Tz8MdHfgtl7BACzZfpLHvommuKyaDK42gyHkOjCUEnEiireHvI2f07midgVHCkh+L5mzz55leOvhrF692uwzWX5+Po8++ijBwcE4OjoSNv4ZFu6x4EK8i3/d5wgzV0zVRDs7O3r16sXmzZsZN24cAEajkc2bN/Poo49We5/+/fuzefNmnnzySdOxjRs30r9//xofJzExkYyMDAIDAxtz+peVuOw4ANp6tNXynE2BWM0rYr6ujVOsAydvvCvSPrOKZY+YEEIIIZqOwagSa00gZusIka/CsBeIPb4KqH//MEtEhgcyPCyAqPhMUvOK8XN1oG8bL/Q6hes7+PL0d/v4+UAyGflRLLqvN+6OtufurCgw5Dn4eiI4eRMREsHQlkOJTo0mrTCNYzbHSFFS6NO7D+PHj+dw5mFeXfUq/+n3H25udzMzZszgt80bWfbR67S+ZgC/rl/Pvx6ZTpCrwtiOttXMVtGqJ4YMaPTfQ3N3xQRioOWdTpo0id69e9O3b18WLFhAQUEBU6ZMAeC+++6jRYsWvPbaawA88cQTXH/99bz11luMGjWK5cuXs2fPHhYtWgRoEf+cOXO49dZbCQgIIC4ujmeffZZ27doxYsSIS/Y8LzbTiph7KOQlQ0kOKHqt2k4NKlfE8krKKS4z4GBbxzJ2TRy9eCYzi+cysnC6/daGjSGEEEII0QAn0vIpKjPgZKenjY9zwweydSQ2IxZovLTEC+l1StUS9cCYbkF4O9vx4P/2sis+kzsW7mDp1L7mK2htBsOMWHD0qBhLf65EfVvz8fan7qcosIj//vVf0gqS2b5pLZNCCxmS8RWE3MmDDz/MJ++/SdSZRMZ2VDAv2lGRYhg5D+pKcRRVXDGpiQATJkzgzTff5MUXX6R79+7ExMSwfv16U0GOU6dOkZR0rtv4gAED+Prrr1m0aBHdunVjxYoVrF692tRDTK/Xs3//fsaOHUuHDh24//776dWrF9u2bWvWvcTMUhPTDmsHvdqCTc3P2c3BBju99tfFqqbONna42bripKpQKCtiQgghhGg6lY2cuwS5oa9PoY7yElj1ECTuNR06lKntsQ/zbvwVsboMaOfDdw/1x8/VniMpeYz/6C+Op+aZn1QRhNXlto63MaXLZADejfkAx4B81sTmcyYlHbUwk99//52jp1K4cdpscLsgY8wtCO74sto+YqJuV9SKGMCjjz5aYypidQU2br/9dm6/vfpGxY6OjmzYsKExp3fZyynJMRXJaOPeBo5v026oZX8YaD3HfF3tOZNdRHp+CS0bUu61kpMXlORCYTpQ8yqcEEIIIURjOnhGS0vsUt9CHdFfwv7lWu+wJ/ZTrtNRUFoAQGevi7MiVpewIDdWTh/ApC+iOJFWwK0f7+DzSb3p3drL/MT4bZB8AAK6aoU3XPy1NMKKFSxd1klmZG3CLzuL1708KJzaCvWrAoKfj8LmhQB0Oh2ffvopg++7D4zPalUUzx/HYG0ht6vXFReICevklOTQxbsLReVFONs6a/+AbvhvrWmJlXxc7CoCMev+wSX6tmeRiw26w//jpVbXWjWWEKJurVu3JiEhocrxf/3rX3z44YeXYEZCCHFpVFZMrFcj59JC2PqG9ufBz4CNHTbAhts2kFGUgZeDV613v5haejmx8uEBTF26m79PZXP3Z7t4784ejOhSUZjubAwsHV31jm5BEDlf+/Ov/4VOttxj44hPh4Hc/9Va0g+nM2z2MOaOmcvuHbt55JFHCAoK0vrzthmk3e/4Jviovxbg3fZ5kzzf5kYCsatMK7dWLB+9HFWtyO8N7KZ9WcBUOdHKgh2lN73ODz/ejEt6NC9ZNZIQwhK7d+8264148OBBhg8fXmO2gBBCNEdGo8o/ZytK19cnEItapK0AebSCHveZ3eTtWHUPV1PzdLbj62nX8ujX0Ww+nMr0ZXt5eVw4d/cLgexT1d8pNwm+q3gubsFwzRAY9iLX23mTOv5zQp8IpV9EP/r27Eu/Xv2IiYnhzTff1AKxSvbukH4Ecs9AWTHYWtaMWpxzRe0RE42nIf0bTJUTrSxhX/milV+WT4nByiqMQog6+fr6EhAQYPpat24doaGhXH/99Zd6akII0WROZhRQUGrAwVZHqK+FhTqKc+CvBdqfhzwPNnYXbX7WcLTT88m9vZjYpyVGFf7zw0He2RCLun5WDfc4r+BGxBwYvwjcgykrK6O8rJzn+j3HSwNeMn1e1Ov1GI1G8yFa9AK3FlCaD3G/XZwn1sxJIHaVMarn/SMqzoHDP0FGnEX3rVwRszYQc7Nzw1anlT+VXmLiSmcwquyIy+DHmDPsiMuovsGmxWMZ2J28m59P/Mzu5N0YjNX0h7FSaWkpy5YtY+rUqdJQUwhxVaks1NE50A0bvYUfgXd8BEVZ4NMBrplgOvzQxod4eNPDppZAlwMbvY7Xxnfl8WHtAdj1x08ouWernJdfqhKTbCAmuRyA+P3biYmJ4dSpU7i5uXH99dfz5ktv8tfWv4iPj2fx4sUsXrKY3hG9zd+nUvdi6DRGG/TQmiZ7ns2JpCZeZUb/MBo7nR3vDH2HNhmnYPldWsXEx/+u874+LtpVIGsDMWXfcrzKy0jRaYFYkEuQVeMJcamsP5jEnLWxJOUUm44Fujswe0wYkeH160W4KWET86LmkVJ4rgm9v5M/z/V9joiQiFruWT+rV68mOzubyZMnN9qYQghxJfinon+YxfvDCjNhR8U+2qH/MRW3KDWUEpUURblazovXvngxptpgiqIwY3gH/N3siVqzvdpz9pw1MHRpoennGXM/gLkfMGnSJJYsWcLy5ct5/vnnufvuu8nMzMQj0AOf8T78HPAz277bRnZJtum+/vaePOfkSMThn6G89LJdMbxcyYrYVSS/NJ/TeaeJy4nTNpaaGjlbVu3H11XL/bV2jxiGUnzKtDEqKzgKcaVZfzCJ6cuizYIwgOScYqYvi2b9waQa7lnVpoRNzNgywywIA0gtTGXGlhlsSthUv8kZDVqVrAMrtO/nrax9/vnnjBw5kqAguQAihLi6HEis2B9mQcXErVu3MuaOewl6Jx9lTi6rj5zLKDqWdYxytRy7dDsevuth3N3dcXZ2pk+fPpw6VcOerCZ2d78Q7onoW+1tQ1rboM52O/d1YiuqqrJkyRIAAgIC+OKLLzhz5gxFRUWcOHqCwXcPxqAazIIwgNSSbGb4+bBJX6pVlBT1IoHYVSQ+Jx4Abwdv3O3dIU3rf1FX6fpK51bErCxT6uSNt0F7QcsoltREceUxGFXmrI2luiTEymNz1sZalKZoMBqYFzUP9YLRjjx9hAOTD3Bg8gGGtx6OoigoisIjjzxS+4Cxa2BBuFYla+X92vcF4RC7hoSEBDZt2sS0adMse6JCCNFMqKrKwYpCHV1auNV5fkFBAd269+DDRV9oB3TnPjLHZsZSklrCP3P+oVOnTmzZsoX9+/fzwgsv4OBw+RSs6DloFCl4U9NbkVGFZLwxtOxf6zh2Orsat5KoqKAozPf2xPDPaitnfPWR1MSrSFyOlscc6hGqHTCtiHWy6P4+lcU6rF0Rc/LGu6KC24VXVoS4EkTFZ1ZZCTufCiTlFBMVn0n/0NorakWnRldZCQMInR2Ket6752OBj/HohEdrr3QYu6aiCtYF77oV1bG+SBuJn58fo0aNqnVOQgjR3JzKLCSvuBw7vY4O/q51nj8yMpKRI0dWe1tsRiypK1IJHxjO66+/bjoeGhraaPNtDFEJOSwpvZePbRdgVOH8/tWVby+zS+9lckJOre9VNb1PVVKBZBsbolt2o08jzf1qIStiV5ETOScAaOveVjuQdlj7buGKWGXVxLyScorLrCgi4OTNM5lZRCXlMK2rXJkXV57UvJqDsPqel1aYVu1xGzcbbD1sTV8bf9lYe6VDowHWz6JKEAaAilFV+eKbFUy6715sbOQanBDi0rkURY4qGzl3CnTFtq5CHVkJ8GFf2Lcc1Kpzi02LJW9/HmGdwhgxYgR+fn7069eP1atXN/h5XAypecVsMPZletmTJGPe6ywZb6aXPckGY98636tqep+qcp5ncIPnerWSd+OryIlsLRAL9QiF/DQozAAUrRKQBVztbbCz0VFabiQtr4SWXk4Nm4iTN25GVavaaCgDvW3DxhHiEvFztSz1xJLzfJ186zzHWG5ky49bePaZZ2uudJiwHaqpjlVp04lyTmWVM/XG7nU+nhBCXCyXqshRZcXEGvuHGQ3a62h+CsR8A+lHtUCs20Sz08oMZcQmxGIsNrLikxXMfWUu8+fPZ/369YwfP57ff//9smkNUvketMHYl40lvemrO4wf2aTiQZSxE8aK9Zi63qsseZ+qz3niHFkRu4pUllgN9Qg9txrmGQJ2lgVUiqLg2xgl7B09gIoPk0VZDR9HiEukbxsvAt0dqKn4u4L2waJvG68azjinp19P/J38a7xdQUF/UE9+bn7VSodGI5zaCb+9AnnJtT7OjaHa5uwOflLRSghxaVzKIkemRs7VFeq4cG9tXMV921QNqLJLsgnzCgNg3M3jeOqpp+jevTvPPfcco0ePZuHChRY/h4vt/PcqIzp2GsNYYxzATmMYRnQWv1dVvk8pNbzrKSgEOAXQs1yB318zKxAlaieB2FXCqBrp6tuV9p7taePeBvw6w22LYci/6zVO5T4xqyon6vScCQzjhZbteGnP63WfL8RlRq9TmD0mrNZzZo8JQ6+ru0+XXqfnub7PVXtb5Zue3V67c5UOjUbtqu3Pz8I7YbB4BGx9Q1thtoRLzUGfEEJcLE1R5KjgSAEn3znJoScPMbz1cFatWqWNr6qmFTHnwmTGjh17rtJheHtOfXpP9RkFm+doQdp5fJ18+d/t/8PGxoawMPP3gc6dO182VRPB/L2qpncjS96rzn+fujAYU1BQUZnV+2n0y26FP+ZpFwiFRSQQu0roFB2vD36dVWNX4ePoA84+EH4rdJtQ953P49tIlRNLJ37FaptSNpz9y6pxhLhUIsMDeWp41bReG53Cx/f0rFeKTURIBGFOVcvJexuNzHKO5O+//mbaHTfBT8/A253hi5EQ9QnkJYG9G1wzEVr2Bbcgan67VcCtBYQMsHheQgjRWOpT5KguNRWPMJYYcWjlQNC92utpZZGyM9lFZBeWQW4yU28bea7SYczfvNC3CAebWoK/9VUvlNnZ2dGnTx+OHDlidvzo0aOEhITUOf+mFBkeyMf39CTAvWr64Y1d/C1+r4oIieDtIW/j5+RndtzJ1gkXWxe6+vWAThWFoGJ/tHreVwvZIybqxacxUhMBb0etOk9+WT4lhhLs9fZWz02IppaUUwTA9R18GNElgP+uPki5USUs0MJmoRUKD3zPifxE0Ol4JS2daHt7fnB1oXtREceWvoeflzuj+neGZRUfCOzdtTe8sJshdCjYVPz7iZxfUTVRodqiHZHzTA1JhRCiKTVFkSPXa1xxveZcRcTcEq1AR2WhjtKdX3PTTTedq3QYv43QVnlUty6RX6pyPNMAydoKV3x8PDExMTi5OdGhbQdmzpzJhAkTGDx4MEOHDmX9+vWsXbuWLVu2WPQ8m1JkeCDDwwKIis8kNa+Y05mFvPnrUf44mkZKbjH+bpbte44IiWBoy6FEp0aTVpiGj6MPH/z9AX+n/c3H+z7mpc5jIeYrOLSm4v1G1nvqIr+hq0ReaR5G9VwzQnYtgmOboLx+AZVvY6QmAq62rtjqtCIdNfWmEOJyVlxmYN1+bT/DQ4NDuatfCNe21S4w/FKPfQ4YDThtfJENp8/yWmo6N+cXMiEvH1VR+NPensUxpUzqqsOm9QDo+yDc9T3MPA63fAwdI88FYQBhY+GOL8HtgiucDh7a8bCxVj5rIYRomKYucgTgZq/1Czt4JgdVNZJ+aCcdOnTQKh36+tJv9L2sPlxW7X33nDXQ45MCenxSAMCMGTPo0aMHAyYPYNSqUQyKHMTChQt5/fXX6dq1K5999hkrV65k4MCBFs2tqel1Cv1Dvbm5ewseGdqO3iGeFJcZWbDpWD3H0dMnoA83tb2JvoF9ear3UwCsPr6aeN82YOeqZWsk7r4YT6PZkUDsKvHiXy/S76t+rI1bCwUZ8MtM+OpWrWphPTTWipiy7S18yrXHTi9Kt2osIS6F3w+nkldcTqC7gykAGxkeAMAvB2svnGGmotqhl9HI6IJCADqXltGirJy0w4WczlGZ2qUYTu+Cm96ADjeCTS0FN8LGwpMHYdI6uPkjuG8tPHtCgjAhxCVVWTiiJvUtcuTn6Ffj7ZX7mELdtb5eB8/mYCzIoay4kHmvziXSJ5lfby3hlk42jP+2iD9OllcZY0hrrcCROtsN9cRWVFXlaOZRAu8PJKM4Ay8HL6ZOncqxY8coKioiJiaGm2++uc65Xw4URWHWSK2H7Hd7ThOXlt/gsXr49WBI8BAMqoH3938CHSt6rx1aU/sdBSCB2FUjLieOYkOxlhJYWTHRvRXYu9RrnMYKxCjNx7tMG0NWxMSV6Ie/zwAwtnsQuoqNziO6BKAoEHM625S2WBe1mmqHChBRWIhruCvPftCGDt56raSypXR6aDMIetwNbQdLOqIQ4pLT6xQeHdqu1nPqU+Soi0+XOs/T6XSoZcV4n97IKzafAnBzOwNPtT9J9wCF5yJDGB3mwsK9NV2UNt9bG5sRC0Anr07olCv7I3Sf1l4M6+SHwajy1q9H6r5DLR7v+TgKChsTNnKgVQ/tYOyP1fZgE+au7L9FwiJlhjJO5Wo5zqHuofVu5Hy+xkpNxMkbb4OWKplRLIGYuLJkF5by+5FUAG7p0cJ03M/NgV6tPAFYb+Gq2MLMvUwO8ONPR/MrxREVq2NbnRwpBeurHRqNdZ8jhBAX0Y4T2vu93QUNlRXgnQndLS4ccSr3FNvObAPA44Iqi85GlbdD7zT9XLpsIm8ZX+dO17+x0UFYiC8MeR4e3QsPbKbztTdyKsdI1UJHFT+ft7f2UOYhADp7dbZonpe7mZEdURT4+UAy+05nN3ic9p7tGRM6BoAFGVGots5QVgg5iY000+ZLArGrQEJuAgbVgIuti1btJq3iyodfp3qP5dNIVRO1QEzrM5Fdkm3dWEI0sXX7kygzqHQOdKNTgJvZbZH1SE9UVZU1GfvY6+hAzgWbmq8pKcWvvJx8nY6d3lZUO9z+AbzTFXZ+2LD7CyFEI9hzMpN1+5NQFFg5fQDfPHAt707oToCbAyravltLvbnnTcqN5VxXWMSWhNMsTkrh3hytIIedauT6TfNN557wGkSS6sUap1vo0+MajngOgyHPgY+2Onc000hI1+uq7q11C6qyt/ZQhhaIhXnX3r7kStEpwI3xPYIBmL/+MKoVK1iPdH8EW50t0Wn7OHnn/+Dpo+DRsrGm2mxJ1cSrQGX51rbubVEU5bwVsQYEYhUrYvkl5RSVGnC0a2DKk5MPz2Rk8bxtSxy6TmvYGEJcIqsr0hJv6VG15HxkeACv/HSI3SczScsrMa0iV2df2j4S8xNxVGwYWmieyqgDbigsYrmbKxvb9mFwQ9MLjWWQc0o2TgshLhljRQ8xgIl9WtI1+Fxl2ZS8Yl79+TDfRJ1iYt9WdY61M2knv5/+Hb2qMjMzCz3Qp7iE7sUlrNM7cDbDwGfZ2utl/Ik4tjuE8E3aC9wxpBcz/3Oi5kqHA/pre3bzU7QMhJABZmndBqPBtCLWXAIxgKeGt2ftvrNsj8tg27F0BnewrBDKhYJcgnjlule4xvcagl2DG3mWzZesiF0FTuScAKCtR1vtQOWKWAMCMVd7G+xstL82Vu0Tc/LGVVVxKMxq+BhCXAKnMgrZk5CFosDYbi2q3B7s6cQ1we6oKmyMrX1f17oT6wCIaDMSp1sXg0uA2e23Gp2Y0/oWZgxb0PAJt+itfU/c2/AxhBDCCqv+PsOBMzm42Nvw9I3m2yJu7RmMrV5hX2IO/5ytvTG9wWjg9d1a6fkJufmElp0rsmELdDuURdzsOP71rtaLbMbTz/DGI7eTte1rurZw45Zbbqm50mHl3tqut2nfL7j4lZCXQFF5EY42jrR2a239L+UyEezpxL39td5n8345jNGChto1uantTeZBmNEIZZbtl75ayYrYVeBEthaIhbqHQlEW5FekTDVgj5iiKPi62HMmu4i0/BJaejk1bFJOFVWRCmV/mLiyrI7RVsOuC/WptkEmaKti+xNz+OVgEnf1q/4Kb5mhjPUn1wMwOnQ0BA3Q+oKdd0W2U8gAOllbaCOoByg6yE2E3KSq6TdCCHERFZSU8/p6LRPnsRvamYp+VfJ2sefGLgH8tD+J5VGneXlczX0Yj2YdJTEvETe9A9Ozq+4/mu9byjuz3c59uL31c/qt9SAlt4TwFtq4U6dOZerUqfV+HnpFz/j24zGqRvTNrADSI0Pb8d3u08Qm5bJ2/1lu7l71ImN9Hdr+Fu12fo5ttzth2AuNMMvmSVbErgI9/XsyrNUwwn3Cwc4FHvgdblsM9q5137kalemJ6dYU7HDyJtGrFf8NCOSlv15s+DhCNCFVVU1pieN61PxGNbJiw/mOuAxyCquvxrXtzDZySnLw1TvSz7endrCOK7INYu8CfhVpNGf2WD+eEELUw8db4kjNKyHE24nJ17Wu9py7KlISV/99hsLSqqXkK3X27sy6W9bxRtgDeFRTgMhJVc1WGLL0nqTklqAoEBbkVuX8+ghxC2HOgDm8fN3LVo1zOfJytuPBwVrW1Fu/HqW03LriTvOi5nHHsSV8r+ZA7GqpnlgLCcSuAnd2upMFQxfQO6A36G2hRU8Iv7XB4/lWFOxIsyY10cGNsklr+NGmlA0JGxs+jhBNaH9iDifSC3Cw1ZmKclSnjY8znQJcKTeqbDxUfXriukPLAbgpMwV9/NYaxyoqL2JZ7DIe/+1xDEbLN7ObCa5MT5R9YkKIppOYVciibVpWzr9v6oy9TfUXl/q39SbE24m8knLW7U+qdUw/Jz8GdL8fXGte3S9HYYt3C/YaOwAQ6uuCk50kgdXm/kFt8HGx51RmIct3n7JqrDZubQD4xNOdwsw4SD3UGFNsliQQE/Xma1oRs65yorej1gQ3vyyfEoOV5fCFaAKVvcNuDAvAxb72N/XKQG39wWo+VKgqNyYd47rCIkZ7dYP2w2scx0ax4aOYj/j99O/EpMU0bOKyT0wIcQnM++UwpeVG+rf15sawmltw6HQKE/poFfaWR1UNAk7nniYqKercyopODyNfRysxb152XkXhriB/HnPT8/PJLQCEW7kaZlSNHMo4RJmhpn5jVz4nOxueGKZVknxv8zEKSmpemazL+A7jaeXaiky9nqXurtLcuRYSiDVzmcWZpBSknCtJunMh7Fqk7RVpoMZq6uxq64qtzhaQps7i8ldmMLJ231nAvHdYTSrTE7ceSyf/wje0/d8SeTKahRn5dBr1Hig1NzC11dsypOUQADYlbGrY5Fv2hcDu2mq4EEI0gd0V5ep1CrwwOkyr2lyL23oFY6NTiD6VzeHkXLPb3tjzBvf/ej+ffT8O/nhdC8jCxmrl5S/Y96q4BdE/JEKbQ8YvAKb9YQ2VmJfIHevu4Ppvr294ZsIVYGLfVoR4O5GeX8rnf8Y3eBxbnS2P9XgMgCXubmTGrm6kGTY/Eog1c6uOrSJiRQSzt8/WDvz1LvwyE3JON3jMxgrElJ+fwadcu7qUXpRu1VhCXGx/Hksno6AUb2c7BrX3qfP8Dv4utPVxprTcyG+HU8/dUJgJG/6j/fn6Z8GzdZ1jRVR8qNh0alPD+rz4doSH/oAbm9/eBiHE5cdoVPm/inL1E/q0smh/lp+rA8MrVs2WR537jGIqV4/CDcf+hN9fhZSD2o1hY+HJgzBpHdz6ufb9yQPc2n8WANnqQRTbTKsDsdgM7bm0dm/d7Ap1nM9WrzNVtVy09QQZVnzOu7H1jXT27EChTsen5UmQfqyxptmsSCDWzFVWTGzp2hKKcyBPu6KPT4cGj1mZmphmTbEOgIJ0vMu0MWRFTFzuVlWkJY7pFoSNvu6XTkVRqk1PTP71eRbblpDs1wH6P2rRYw8IGoCjjSPJBckcTD/YgNkLIUTTMS9Xb/nnjTsrinasik6kuMxAubGc+VFac+YJObm0LSuHmz+EgK7n7lRNkaNWbq3o5dcXFBVb9z10sTI1MTZTC8SaU/+wmozuGkiXIDfyS8r58Pe4Bo+jU3Q82ftpAJa7uZK4b1ljTbFZkUCsmTM1c/ZoC2lHtYOuQeDo0eAxG2tFDCdvvA1aZZ6MYgnExOUrr7iMX//R2j5YkpZYqTI98ffDaRSVGiA3iXUJG3jHy5N/B7UCGzuLxnGwcWBw8GAANp6yorhNWRFknmj4/YUQog51lauvzcB2PgR7OpJbXM7PB5JYdWwVx7OP42Yw8K/sHBj1NvS426KxurlHAuDotRdHu9rTIutSuSLW2auzVeNcCXQ6hVmRWp/ZZTsTSMwqbPBYA4IG0M+1Le56e077tWusKTYrEog1Y0bVSHyOluMb6h4KadoLY0P6h53Pp6JqYnq+dcU6cPLGx6DlWmeXZFs3lhAX0fqDyZSUG2nr68w1wZanuIS3cCPY05GiMgN/HE1DdQ1gbbD2Rj66i2UfJiqZ0hMTGpieePIveC0Yvp5Y//sKIYSFLClXXxOdTmFiRdGOZVGH+SDqDQD+lZ2D+/C50Od+i8fSF4djLHfGqM9hW+K2es3jfKqqcihDq/p3NayIAQxq78OAUG9KDUbe3njUqrFevnEhP0/cRv+u9zbS7JoXCcSasaSCJIrKi7DV2Wqdzk2BWCerxq1MTcwvKdeu8jeUkzdPZ2Sxx6E707pOs2pOQlxMlU2cb+neos4N5+dTFIXILufSEw9nHuZEfiJ2OjuGh9RcKbE6g1sMxtXOlbbubSkoK6jXfQHtAoyxHNKPQFF2/e8vhKiTwaiyIy6DH2POsCMuA4OxYf2TDEYDu5N38/OJn9mdvPuKKRBxOtOycvUX2rp1K2PGjCEoKIjHhnWg+PhOkguXkGUspk1pGRs2BqIMeARFUUxfkZGRtY55OKmQ8pxeAEQlRzX4OZ3JP0NuaS62OlvaeVwdqzqKcm5V7Ie/z1QpnlIfgS6BONk6NdbUmh0JxJqxuGwtLTHELQQbnU2jrYi52Ntgb6P91bEqPdHZB1dVxb4oy6r5CHExJecUsz1OS52trYlzTUZ2DSCQDJIO7WD1ca2E75CWQ3C1q19DdSdbJ7bcsYUPhn2Ai51LveeBs8+5wiBno+t/fyFErdYfTGLg/N+489OdPLE8hjs/3cnA+b9V38KiFpsSNjFi5QimbpjKrG2zmLphKiNWjmh41dQLnB/0KIrC6tWrazz34YcfRlEUFixYYNHY89ZbVq7+QgUFBXTr1o0PP/wQgK4t3EktCsdDdWJmi+Ho/MOJjIwkKSnJ9PXNN9/UOuaBMzmUZl7Hf7otYlbfWRbP5UKHMrXVsPae7bHV2zZ4nCtNt5Ye3NQ1AFWFN9YfsW4wQznGE1v45ZfH2Je2r3Em2ExIINaMmdISPUK1A2kV/5CsXBFTFMWU821VU2cnL+17YaZV8xHiYvox5gyqCn1ae9LSq/5X9Xq09OQ1x//xP/7Nz0dWAjC67egGzcVOb9meshpJPzEhLor1B5OYviyapJxis+PJOcVMXxZtcTC2KWETM7bMIKXQvBF8amEqM7bMaFAwduEqXW5evlnQU5MffviBnTt3EhQUdN5YNa/U7T6ZyU/1KFd/vpEjR/LKK69wyy23ADC4vQ/leV3JPTWbPsMXAGBvb09AQIDpy9PTs8bxcgrLOJ1ZhFruzsgOvS2eR3Xae7TniZ5PcFuH26wa50r0zI0d0esUNh9OZfdJKz6rFWbw6Zr7eDZ1C2/smNuw9PpmSgKxZqyrT1emdJnCDS1v0A48vA2m/gqB11g9dqNUTnT244xXK/7jovDiXy9aPSchLobKJs4NWQ0D0B39hSFqFDscHclWi/Cw92Bgi4FWzelM/pmGVRoN7qN9T9xt1eMLIc4xGFXmrI2luo+WlcfmrI2tM03RYDQwL2oeajUjVR6bHzW/XmmK1a3Szd1vz8CJj5iCnuqcOXOGxx57jK+++gpbW20VqLaVuoaUq6/WQe1iVRdvPUHuDuQUqmyoKJS0ZcsW/Pz86NixI9OnTycjo+bXwH/O5gDQyssJdydt/nmleQ1K8Wzt3pppXadxe4fb633fK11bXxdTo+15vxxueADl6s94t044Go3syzrE76d/b8RZVlXXqm9KSgqTJ08mKCgIJycnIiMjOXbs0pTXl0CsGevp35MZvWdwU9ubtAOOntCqH9g5Wz12o1RODAinbNJa1qi5/Jrwq9VzEqKxHUrK5XByHnZ6HaO7BtV9hwuVFsAvzwLwrb47GG24MWSEVektr+16jciVkaw6tqr+dw6uuDJ8Zo/WEFUIYbWo+MwqK2HnU4GknGKi4mtfUYhOja6yEmY+jkpyYTLRqZalFjd0lc5oNHLvvfcyc+ZMunTpAsDRzKO1rtS9suXbBpWrN3NoHeUrHwBg58Evub23dvHr612niIyM5Msvv2Tz5s3Mnz+fP/74g5EjR2IwVB9YHTijBWLhLbSA8I3db3DDdzfw19m/Gja3q9gTw9rjYKtjb0IWG2Nr/vtZF9+w8dyTmwfAe9HvUW4sb6wpVnFhquv5VFVl3LhxnDhxgh9//JG///6bkJAQIiIiKChowP5rK0kgJhrE17WicmKedZUTvR29ASgoK6C4vOY3MiEuhdUVq2FDO/marqrWyx/zIec0qkcrYooeIe/Yf+ntfodVc+rgqX3I2ZjQgDL2AV1BbweFGZAVb9U8hBCa1DzL3rvqOi+tMM2icSw57/xVOh1GrtXFMla3nWt1sShobWPmVKxgXWj+/PnY2Njw+OOPm45tOrWpxpU6Ffg+/kPAaHm5eqMB4rfBgRXa98O/wPeTWeXiCMDaokRu6u6BToFd8Zn0GTaasWPH0rVrV8aNG8e6devYvXs3W7ZsqXb4g2e14hJdgtxN8yw2FLPi6Iq653ae7OJsNpzcwOm803Wf3Ez5uzkw9bo2ALyx4UiDC9DQeQxTsnNxNxiIy4ljbdzaRpyluQtTXc937Ngxdu7cyccff0yfPn3o2LEjH3/8MUVFRXXuO7wYJBBrpvJL89mdvJvM4oorcNFfwvrn4dSuRhnf17RHzLrgycXWBTudFtRJLzFxOTEYVX6M0Rqg16d32JkzZ7jnnnvw9vLA8aaX6fpxPntbPsigsFZgdOCvo9b13xvaaig6RcehzEMk5iXW78429jDgMbhxLtSzWIgQonp+rg6Ncp6vk69F41hyXuUq3QhdFH/aP85yu1d4z+4Dltu9wp/2j3OjLqraVby9e/fy7rvvsmTJEtMer1JDKXmlebU8mgo22QQFJFlWrj52DSwIh6WjYeX92vflE8mlnA98/AAY2WYkHX0DGNpR+/nb3eaBUNu2bfHx8eH48ePVPsTBihWxri20QOy29tr+rq2JW0ktTK17jhX2pu7lmT+e4anfn7L4Ps3RQ9eH4u5oy7HUfFZG1/N9p5J7C1xb9OaBbC1I/jDmw0tyAb6kRHsPdnA49+9Rp9Nhb2/Pn3/+2eTzkUCsmdqfvp+pG6Yy6ZdJ2oFD62DnR5BysFHG96nYI2btipiy/G58yrQx0ovSrZ6XaN4aqzS0Nlbt5aF3ncggObcYNwcbhnbys2jMrKwsrrvuOmxtbPhlekdi/+XCW/cPobxDHyK7amXsN/yTgtGKeXs5eNHbX0sx3Hxqc/0HGPYiDHgUXCz70CeEqF3fNl4EujtQU2kKBQh0d6BvG69ax+np1xN/J3+UGkZSUAhwCqCnX88655SapwVhH9suIADzlMgAMvnYdgEjdFVLum/bto3U1FRatWqFjY0NNjY2JCUmkbw8mSNP1145b2xPl7rL1ceuge/ug9yzVW76xMOdLLR0tQEtBgBwZ99WAKzYm0hJ+bnX6MTERDIyMggMDKwyTl5xGfHpWopZeEUg1tajLT39emJQDaw+vrr2OZ6nsn9YZ+/m38i5Nu6OtjwyVCv89s6vR/jjaGrD3ofDbmZiXh4Bqp6UwhS+PvR1k7dp6NSpE61ateL5558nKyuL0tJS5s+fT2JiIklJ9atw2hhsmvwRRZM4ka318ThXMbFxeohVapQ9YgC5Z/CmhLN6+4YVHxBXjfUHk5izNtbsKm6guwOzx4QRGV71zbg2mxI2MS9qntl+B38nf57r+5ypcfKqirTEUdcEWdwLZ/78+bRs2ZIvFi+G6KWw9U1c715AxIZ7ae/ZAVfHe0jLK2HvqSz6tK79Q1ltIkIiiEqOYmPCRiZ1mdTgcYQQ1tPrFGaPCWP6spr3bs0eE4ZeV3sVQb1Oz3N9n2PGlhkoKFVSAVVUZvWdhV5X9+uRn7Mts22/BODCh9UpYFRhtu3/WAT8dTydm8qN2NnouPfee4mIiDA7/4bhN6D2VPEcVHOVQoC44t85ntWXdp419NoyGmD9LKgmxfEfg57Psm0wZBcBcDrhNDExMbR198DH3sixdQt5r3Uxtw/qSlxcHM8++yzt2rVjxIgRVceqSEts4eGIl/O5SrO3dbiN6NRoVh5dybSu09Apda9FxGZo6ZtXSyPn2tzXvzUfbYkjKbeESYvPFXyq1/tw57HY//pfHikyssivBUv+WUJWybkWRhe+D1vMaICE7ZCfAi7+EDIAavh3Ymtry6pVq7j//vvx8vJCr9cTERHByJEjL0k1R1kRa6ZO5GiBWFv3tlrBgOwE7YZGCsRMVROtDcScvPGu2GwrqYnNl7UrWec2nReid4rDxi0GvVMcyTmF9SoNDZaVhy4qNbD+oFapqz5piWvWrKF3797cPmECfjfNosf/bHl24TsYVAN2elsiOmlXd385kGzxmNUZ1moYAPvS9pFSUM/N06oK6cdh33Iok32ZQjSGyPBAPr6nZ7XB1v/d3MXii0URIRG8PeRt/JyqrsJ39+1u8QfUvvrDBCmZVYIwgPxSlf0pBlJTtBS9z3/ZRZ+nPuWNlX/i6OpOeHi42ZeTvRMePh7YB1a/96vys+vOpJ3csuYWHv/t8ep7RSVsr3YlDOC/eQ4cnX2CuNla/9MZM2bQo0cP/m/OS9zeuxWlqfG88MgkOnTowP3330+vXr3Ytm0b9vZV51SZltjlgsqNw0OG42rnytmCs+w4u6PaeVyosodYZ6+re0UMYMuRVLILy6ocr1eLBs8QmL4Dp5Fvkph/1iwIgwa2aagu1XVBuHa8Br169SImJobs7GySkpJYv349GRkZtG3b1vLHbSSyItZMVTZzbuvRFtKPagedfMDZu1HGN62IWVO+HrRALFvbOJxTkmPttMRlyNqVrMpN53rXg9j7r0Vne+7vibHMnZKUMcxZ68DwsIA6rzjXVR5aQWF+1Hwebd+R/JJygj0d6R1S+1Xg8504cYKPP/6YGTNm8O9//5vdu3cz/bHpBN4XyJinx+BpCOCHv8+w4Z9kXhjduV59ds7n5+RHd9/uxKTFsPnUZu7qfFf9BvgiEgrSwKsttOzboDkIIcwN7eRnuqI+Z2wYq6LPsC8xh4Nncus1TkRIBMXlxfya8Cuh7qEEuwbz/t/vExESgaqqFr1u6Atq3ge156yBoUsLTT9n/fYZWb99xpwtw/j6n2eZPKANkwaE4OF0bjUpyCWITKpWfVRVUBR4qudTHMw4yKaETfx++nd+P/07w0OG8/aQt8+dnH/uopEBiHawJ02vp1SB42286faFF6vOJNF27CfQ9VzPrsSsQhZOfBlVhS3PDKG1T+2Vny/cH1bJwcaBsaFj+erQV6w8tpLrWlxX6ziphamkF6WjU3R09OpY67nNXeX7cHVUtPTbOWtjLXsf9u3I6ysfr/N9eGjLoXWv/lamul44Vm6SdvyOL2u9u7u79nfk2LFj7Nmzh5dffrn2x7sIJBBrhlRVJS5HC8RC3UMhseLKVCOthgH4uGgv0AWlBgpLy3Gya+BfJSdvnsnM4vlO92DfdVqjzU9cHipXsi58ua28gvbxPT2rBGOqqpJXUk5mfikZBaVsP55OmnEPDi2WVRlfscnBocUy0s5AVHx3+oeaX2goM5aRXZyNj6MPiqJYXB76fzFbAC/GdW+Bro43lfNTIoyGcnq3sOPV+wZCpx64tXHD43sPsn7PYsT7I3DUu+Fkp+dMdhH7E3Po1tKj9rFr8cA1D1BUXsSgFoPqd0dF0Ro7H/0FEvdIICZEIzmRVoBRBVcHG+7r35rwFu7c+vEOVkYn8tiwdgR7Wt4Q/q+zf/H76d+5xvcabu1wK2PbjcVWV4/KrS7+Nd40pLUN6uyK1aJJ6ygOHsDK6EQ++eMEpzILeWfTURZtjeOufq2YNqgtew/tZeSqkVAOGJxBf67Et1ruzu1tH2Vq14na7yDnBF8c/IJ1cetMFV4B1NJCjId/Qg9scnJknrcnKTbnPjd4lRsYUlhI27LyKnMP9nTi+g6+bDmSxvLdp3luZO2fZSorJoZfEIgB3NHhDrwcvBjXblytY8C5/WFt3dviaONY5/nNWX1aNFz4Pnyhmt6HC44UkP5zOkUJRRzIPsDbi99m5pSZpttTUlKYNWsWv/76K9nZ2QweNIj3ex6nvX3VgC6/1MjxTBU+fxKA+Ph4YmJi8PLyolWrVnz//ff4+vrSqlUrDhw4wBNPPMG4ceO48cYbLfuFNCIJxJqhzOJMckpyUFBo7d4a/v5Wu8Gv8QIxF3sbHGx1FJcZSc8rpZV3wwMxF1WFouxGm5u4PFjS5PTp7/bx84EkMgvKyCgoJbOghKyCMkoNxvPONuLcTitze+GFYEXRrsjaB6zkk3/SWZ5QSmZxJlklWWQWZ5oqfe26axdOtk4Wl4fen3Qa8Kq7iXPsGm3PQ0W6TaCzkTCvctj9KXS6iZ9O/IR9kD0lf5fg6aCtrA3t6MdPB5L45WCyVYHY4ODBDb4vwZWBmDR2FqKxHE3RXm86+ruiKAq9QrwYEOrN9rgMFv4Rxyvjulo81rEsrblsOw9tv1W9gjDgrHsPXFVHXJWi2k/csxgHnw7c3S+ECb1b8tOBJD7eEsfh5Dw+3RbP0u0JdO7yB0XlRRiKgik8OR2900kUmzwKj6eQvXUnL6c8wkv5d/LDDz8wbtw4Xr7uZR7p/ghPT3+a6f+bbvZw7To54DirZZX3hSy9jh9cXRikOBERMqDKNCf2acWWI2ms2HuaGcM7YGdT/c6awtJy4tLygeoDsbYebXnQ48HafycVKveHSVpi47VogJrbLxhLjDi0csBzsCen3j9Fbsm5leTK3l+2trb8+OOPuLm58facmUR8HE/sv1xwtjP/cHBu1Vf7uzBjxgwAJk2axJIlS0hKSmLGjBmkpKQQGBjIfffdxwsvvGDRc2xsEog1Q5X7w1q4tNCu4mSf0m5oxBUxRVHwcbEnMauItPwSWnlbfqXPjFNFwYLC2htdiitPXVfQQFtRXbOv+rxyJzs93i524BBHtm3NaauKAopNEXuz1kNW1dt1io6skiycbJ0sLg9tKHPhmmB32vm51HxSNSkR17XUcyTDCHG/Y/xnNetOrKM0uZRWIa1M50SGB/DTgSTWH0xiVmTHBqcnWuX8xs5CiEZxJLkiEAs41xri8WHt2R6XwXe7E3l0aHsC3OsudV9uLDe9j1cGYgBG1cimhE2czD3Jg9fUHkz89cNH3F5jEKZgSij7ZxUc3wy3f4FNu2Hc3L0FY7sFseVIGh9tOc7uk1n8c8ILO19/StKGA3oMhVoRMEPeHmz92uJyzXDSfnjVrBpsgHMAtqpKZM8QvhiawSwfb3Y5OqCz1WmvmBe87qmKgqKqzPf2YihwYULasM5++Lrak5ZXwuZDKYzsWn1ae+zZXFQV/N3sTXvZG2p8+/GEeoRa/L7RnFnaouHTrSdQFIUbw/xxsK0+rbCm36frNa64XnPu386+9H2czj1NS7eWpt5fBw8e1JqM55zh41FOBPwI3xwsY1pPO7OxzFZ9b/3cLNUV4PHHHzfrk3cpSSDWDLVybcUL154X2d/6OUTOA30DGtLWojIQs6pyomsgZ7xa8ZGagu6vF3j5uqbPzxUXh6VX0MZ1D2JwB1+8nO3wdrbHy8UOb2c704v4urginregtUdEq+H0D7oWTwdPPO098XLwwtPBEzc7N1OeeWV56NTC1Grz0wH0Rk8MhW0Yd0Mtq2E1VP966lp7Biwu4NVtxXQ2PMOhtBKy/sjizU/fNJ0ztJMfdjY6TmYUcjg5j86BbjRUelE6K46uIKs4i+f7PW/5HYN6Aop2kSY/FVwsK88vhKhZdYHYtW296dvai6iTmXyyNY7ZY7rUOc6pvFOUGctwtHEkyCXIdPxQ5iGe/uNpbBQbRrUdRQuX6l+jUv/+mXGn5oECmS2H45Xzj3mRDLcg7TOBRytY+wRkHDe7UKsoCkM7+TG0kx+7T2Yy9yd3YuI7wwVl9R1De+MY2tv089HU/HM3Go1wbCP2BdkEuDjxUdho3vby5Lu41TU+b1VRSC7NITo1mj4Bfcxus9XruKN3MB/+HsfXUadqDMQq94eFB1VdDTvfltNb+PrQ10ztOpVrA6+t9hx/Z39udG76VLXLUWWLhuSc4hreOTUHz+by+Dd/4+5oyy09WjChT8sq73E9/Xri7+BNalE6ai0XIvel7uNY9jFaurU07/2VnwrvdkNnLMPeBv48ZWBabR0daknTvRxI1cRmyN/Znzs63sEdHe/QDiiK9kHL0fKiA5YwVU60pmBHp5som7SWNaUpbEzY2EgzE5cDS6+gTejTivE9gxnS0Y+uwe608HA0u5Lm72xZkNDTcxR3dLyD4SHD6R3Qm7YebfF08DTb7FtZHhqosVdP/tlR6HV6xnQLqvZ2oMbqX31a6PlhgiPfHCzjztfi0G0oY9p/pjH53smmc1zsbRjcXrsi+MtB66on5pXm8WHMh3x35Lv6FbtxcDv3wStRVsWEaAxHKlITO/ibN0t/bJi2qvX1rlMWXaA6nqU1KW7n0c6sxHoX7y5cG3gt5Wo5nx/4vPo7n43Bfe1UbBUDfzkOxWvKd/DkQZi0TrsoO2kdPHkAwsZCUHd44DeYuh7czwvqDqyAUq2YR5/WXky5rg3ax8XaV+9zis7rK6rTgW8ntiQY8ftAR8+ZG9n5cTTl+eV1Pv+aUtcm9NYyC7YdS+d0ZmG15xw4U/P+sPP9eeZPdiTtYMXRFXXOR5xr0QBV/xYoFV+vjAvn8WHtCXJ3IKeojCXbTzLy3W3c/MGffL3rFHnFZRVj6Xnu2v8C2iqo+ViK6b25T0AfBgUPgrJiOtml4h3ozdgHx7It6QglrQYz/2AAibkqSfkqBmC3gz0/Ozux28EeQ+XM3FpopewvYxKIiQZrrF5i3o7axs6CsgKKyuvIZxdXjMoraDWpb5PTGqla9cS5K4vZcqTmSmGVaioPHeAUwFDPmZTnhTOwvRcujsYaRsCs+teFRnew5cB0F4r/60bCmg/45IVPqpwzMlxr7lyfsvvVaePehnYe7ShXy/kj8Y/63bkyPVH2iQlhtfySchKztPevCwOxge186N7Sg5JyI59ti69zrGPZ5vvDzvfQNQ8BsPr4apILLriQk3USw7LbsDcW8aehC463L9QCIp0e2gzS0rPaDDLvr6TTQ8B5e9fiftNKgH90LR//9gxL/1mKu4U7D1rm/A3Hz5Udj7zrX3z51XI2/76V+fPnc2j3IRLeSkCto31JTalrrbydGNTeB4Dlu09Ve84/ZytWxOoIxG7vcDsAm09tJrO46taI2IxYPjvwGTGpMbWOczWpbNFwYXptgLsDH9/Tk3uuDWHG8A5sm3UDS6b0YWR4ALZ6hX2JOfz7hwP0nbuZZ77fx56TmQxrNYwXylvgZzBv4OxTbuBRjzEA3NP6Jmx/nwfvhKFbfjuhj7fhxLETDO4wGMf7V/NVsj0R13UjS69jRMsgpgb6M8vPh6mB/oxoGcQmJ0dt5deCvnuXkqQmNkNr49bS0rUlXXy6YHtsM+z9AjqMgN5TG/VxfCsqJ1obiLnYumCns6PUWEpGUQbBrsGNMT1xiVVeQXu4mianlVfU6tPk9KktT1UzjoKqQDv93ewrgwe+3MOCCT0YdU3tZfEjQiIY2nIo0anRpBWm4evkSw/fHtzw1jagAFvfNUzb8D4fRXyEu301b+iWpjrUcF5EZ39sdApHU/KJS8sn1LeWvWh1iAiJ4Hj2cTYmbGRs6FjL79hrCnQcCcFSNVEIax2rWA3zdbU3ayIMWqrf48PaMXXJHpbtTODh60OrnHO+yt6A1QVivQN608u/F3tT9vLFwS/MU5KPb0JfmMYhYyv+FzKXT9oGNOCZKOAWTHJeIp+eWk/Z6Q0sus7XlJamYKSv7jB+ZJOKB1HGTgSSSQIQdHgxrPkN/rUTHNyYeOedplG7du1Kl/AudGjfgcLDhTiHVS1Br6Dg7+RPT7+a88zu7NuKbcfS+X5PIk9GdMBWf249objMwLGK9MgLS9dfqKNXR8K9wzmYcZA1x9cwOXyy2e1/nvmT9/9+n5FtRtLdr3vdv7arRGR4IMPDAoiKzyQ1rxg/V+1i6vnv43qdwpCOfgzp6Ed6fgk/RJ/h2z2nOZ6az4q9iazYm8gEl7+ZV7aD8cq5Nga+BgPdi0qwOfUBDwGseRw6aUGUzr0lHw39F6sGHufn2J8pLilGdVP56/+O4tjahSC9ebCVqtczw9+Ht52dqGdr6CYnK2LNTE5JDv/+89/c+8u9lBpKITEKjq6HpP2N/liNkppoNKJ8NgyfMi2lQZo6Ny8jugSYWh2cr/IKWn2anE7pMqXKcX8nf94Z8jbf3/sQo68JpMyg8tg30Xy3+3SdY+p1evoE9OGmtjfRJ6AP+xJzOZVZiLNjPofytrI/fT9TNkwhvSi96p1DBmj7LGpI1XnVy5P3/YNJ9a36QQrA3cmWAe20K7vrrUxPjGilvc1sP7OdgrKCOs4+T3Av6DQKXGQjuhDWOr9iYnWGdvQjvIUbhaUGPv/zRK1j/d91/8efE/9kXPtx1d5euSq28thKszS++DZ38lT5I0wqncXDN3av/5MACB0Kj+zis47XUaYo9C4q5trvH+azsP1E6nbxp/3jLLd7hffsPmC53Sv8bf8gm+yf1u6rs4HeU8C2+lLv7du1x93LnZKUkiqp4ZU/z+o7q9beURGd/fFxsSM1r4TfDptnQBxKysVgVPFxscPfre5CHbd10Ao4rDi2wtT/zTRWRen6Lt517+m72uh1Cv1Dvbm5ewv6h3rXejHVx8WeBwa3ZeNTg1k5vT+39wrGyQaeKPscFa0oS5/iEm4qKKRPcQm2yvl1XIwQMhDu+B/K4zH06j6FuQPnsnXyVubcOIfg4mCK4otw7elabfEXKvqRGYzmq26XGwnEmpn4HC3tIcA5AGdbZ0g7ot3QiBUTK51LTSyt48xa6HSQcRzvMi2YyyiSQKw5iU3KJT2/FDu9wheT+/DuxO5888C1/DnrBouDsEqVfUdGhIxg/qD5LB6xmPW3riciJAI7Gx3vTuzBnX1bYlTh2ZX7+Wxb7R92LvTD32e08Tt3YknkF/g6+nIs6xj3/XIfZ/LPmJ+cfhRufLXiB/M3gGydnu/dXFjkpCO3lsDoXHqidYFYB88OtHJtRamxlG2J26waSwjRMEeStZWY8wt1nE9RFB67oT0AS7cnkFNYVut47vbuuNlVX8jn2sBr6ebbjRJDCUsOLoZS7XXm/c3H+KH8OsI7daRHq4bvCU8qy2NlSSIA/9L7oZTk0OXvl/jI7l0CFPM0PnelEEel4rmMeA0Gz6yxMFhiYiK5Wbk8NPChKqnh/k7+vD3kbSJCal+/sLPRcWsvLWvmmyjz9ERToY4W7hZVox3ZZiRONk4k5CawJ8V8r6yUrm9cle0c3ri9G8uGGwhSMrkwfssvVYlJNhCTrAVOu91vIqbHXE65dAe9Dd9//z1btmwhLTEN+8P27HtlH2493XANr/7fXGVf0OjUqlk5lxMJxJoRg9HApgQtP9vHwUe7CpB2WLuxEXuIVfJxbZw9Yjh5412RJywrYs3LLwe0IKOyApclV9BqcmenO7m7891M6TrFtIplXohD4dVbuvLg4LYAvPLTId7eeLTKlc7qlJYbWbdf2681vkcw7T3bszRyKS1cWnA67zT3/XIfJ7IrArvUQ/D5jRCzDMZ/Am7mAeUG70DKFYVOXp1o51n9ihjAjWH+6BQ4cCanxo3nllAUxfThpd4FbxL3wpZ5Zvs6hBD1dyRFKxJR04oYwPDO/nQKcCW/pJwvtte9V6wmiqLw0DUP0dUnnP6nD8CS0ZxMOMnqGO2C0VMRHeoYoXaLDiyi3FhOv4B+9Ll/q7bPpmLN6vwPjRd+cI7PKCYmJoZTp06Rn5/PzJkz2blzJydPnmTz5s3cfPPNtGvXjln3zmLDrRtYPGJxlYtqlpjYRyva8cfRNBKzzr12Hqws1FFHxcRKTrZO3NT2JgC+P/q96Xh2cTZnC7RiTJ28G/+z09XOmFf9xcc9Zw30+KSAHp9oFxZeXbSSHj168OKLLwKQlJTEvffeS6dOnXj88ce5/ubrCZ5e91YWS/uHXioSiDUTmxI2MWLlCJbGLgXgYMZBRqy8kU3FFZXdLuaKmDWpiVARiGmFEepV+U1c1lRV5eeKYhQj67n6VZ3uft15ru9ztaaKKIrC8yM7MXNERwDe23yMOWtjzfrbVGfLkVSyC8vwc7Wnf6hWPKalW0uWRi4l1D2U1MJUJq+fTOzpP+GrO6AkV7sK3fnmKhXJ1rXpAcDotqNrfUxvF3tToZIN/1i3KjY8ZDguti642dezFP7htbDlNYj90arHF+JqV7ki1qGGFTEAnU7h0Ru0izOL/4w3VZE73+aEzTy08SG+PfxtrY83sMVAvnLuwcADa+Hs32zY+DNGVUvd6xpsWSBSncS8RFYfWw3Av7r/Syt04B/Oha06oOoH5xlPP2P64KzX69m/fz9jx46lQ4cO3H///fTq1Ytt27Zhb29fJTW8tnTEC7XxcWZAqDeqCt/tSTQdP3DeipilbutwG918uzE4eLDp2KFMLS2xpWvLGlclRcM5elbfdqGy91fl18E/16GqKkuWLAG03l+nT5+mtLSUhIQEZvx3BroaGnuf73LvAyeBWDOwKWETM7bMMKVuVUotTGWGrzebPLwvSh+Fyj1iBaUGCkvrLklbIydvZmZmsTfsSaZ1ndZIsxOX2rHUfE6kFWCn13FD56brU6UoCo8Mbcf/3awFbEu2n2Tmiv2UG2qugliZlnhz9yCz1Tp/Z3++iPyCLt5dyC3NJWnDs5BzCrzawoSvwNbBrCLZae/WxKTtQ6fouKnNTXXOtTJAtbaMfRfvLvwx4Q9m959dvzsGV/TqkRL2QjRYRn6JKTOkfW1N4NH+zYf6OpNbXM6XOxKq3L4vfR/bz27nePZxs+Nbt25lzJgxBAUFoSgKP77zFMqWuQCkDnqZeXEhADwZ0Z6HH34YRVFYsGBBvZ/Lov2LKFfL6R/Yn57+FUUzaqgSe+EHZ3X/96YPzo6OjmzYsIHU1FRKS0s5efIkixYtwt+/cT6L3NlXWxX7bvdpyg1GSsoNpn164S0sD566eHdh2U3LzC6cVaYlhnmHNcpchblO/UaQgjc1XR81qpCMN536jah1nMqKyjW1olFQCHAKqLX4y+VAArErnMFoYF7UvGqb01Yeme/hikGtpRR3Aznb6XGw1f4KpedZsU/MyRtnVcWuWFbDmpPKtMSB7X1wc2h4M/EyQxnzo+azK2kXxnr8Pb6vf2vevqMbep3CyuhEHvk6mpLyqpt2c4rK2HxI2/R9S4+qaQ6eDp58FrGI9/QtGZb4j9aP7+4V4Oxd5dx18esAbQ+HJVfhRnTR9ontTcgiJdeyBtjVURQFO33NVdhq1KKihH3qISjJa/DjC3E1O5qirYa19HLE2b72YtT681bFPtt2goIS84uYx7K00vXtPdubHS8oKKBbt258+OGH2oGozwDIG/AYU8+mY+O5jcguARyL+o2dO3cSFFRLH8Ra3N35boa1GqathlWyskrsxXBjF388nWxJzi1my5E0jibnU25U8XCypYVH9cVCLHUkU9tbL/vDLg69jQ1nKy4aXhiMVf6c1H82epu6/i3V3BfU0uIvlwMJxK5w0anRVVbCzqcqCsmK8aJsVlQUxZSemGbNPjGnij5ShbI/rDn5xZSW2JASyudEJUex7NAyZm2dZdF+r/ON7xnMR3f3xE6vY8M/KUxbuqfK6u0vB5IoNRjp6O9K58Dq04pctr7O4GNbQW8HE7/mrL0jm09tNjtHVVXWxWmBWF1piZUC3B3o2coDsD49sXIORzKPUGaovRCAias/uLcCVDhzeW9oFuJyVVfFxAuNuSaIEG8nsgrL+GqX+apY5UrYhaXrR44cySuvvMItFStBYIRud7LCtzcJxlXY+2zm5k7w2GOP8dVXX2Fr27CLXx29OrJg6ALzku11VIm9FI1z7W303HZe0Y7KtMSuFhbquFBOSQ7LYpfxT/o/zB04l+9Gf8eotqMadc7inB4jJrFvwHukKeYXNJPx5pHyJ3HsdotF49TUF9TS4i+XAwnErnCWbkK8WJsVG6WEvVswZ7xD+HfeAf77538baWbiUjqRls/h5DxsdArDw6y7SlpZgGJYq2ENurI1oksAiyf3wclOz7Zj6dzz2S5yisowGFV2xGXwaUV1xbHdg6p/A89JhN2LtT/f/BHZ/mE88OsDzNgyg1XHVmEwGtidvJvVx1fT2q01vg6+DGs1zOL5mdITD1gfiE3ZMIXb1t7GzqSdlt8puJf2/YykJwrREEcqA7Fa9oedz0av45GhWqC1aGs8xWXaSn1eaZ6pSXOoR2jVOxqN8OOj2p8DusLY99l5oAWGEj9QinjqkbuZOXMmXbrUv+R6rRe5dHqInF/xw4WvkRU/X4LGuRMrgtLfDqfy/R6tZYmHkx2GOvYEV2dB9ALm757Pu9HvsjFhI/ll+fg6Xt57i650PUZMwue/R/ln+Nfs6f0G/wz/mv9r+w2/GPry71UH6tzbXSkiJMKq4i+XmgRiVzhLNyFerM2K50rYWxGIXfsw5ZPWsrYgvv5V38RlqXLPU/9QbzycGpAyV6HcWM5vp34DYHjr4Q0eZ2B7H/53fz/cHGyIPpXNTe9uo/9rm7nz053EpWkbzZduP8n6ilU8M+7BMPUX7YPINbfjaudK38C+GFUjs7fPZuDygUzdMJUXt7/I1jNb0el0bD+73eK5RVasGO6KzyDDygqklVfRN52qRxVE2ScmhFWOJmuBWAcLV8QAbunRgmBPR9LzS0xl2OOy4wDtar67rQvEb4MDK7TvRoPW7mXiV9oA1z3JPymFbIhNpSzjBtJ/TielOIVp0xu2z/qFv15gzo45pmbSVYSNhTu+rFIlFrcg7XhYPZrJN5JQXxfa+bmgAn+fzgZg7b6zDJz/W/Wv5bUIdtFW13Yk7WDWtllM3TCVEStHmCpRi4tDb2NDl+tG0Xv0g3S5bhSzx12Ds52e6FPZLLegH6hpHCuKv1xqEohd4S71ZsVGCcQAbwdtebqwvJDCsoaX8haXh18aqVri3pS9ZJVk4WHvQW//3laN1SvEk28f6o+rgw1nsotIvWAVNy2vhOnLos+9gZ9/hTiwG1z7MKC94L947YsMbTkUgPyyfLNxUgtTmbFlhsVv4C29nAhv4YZRhY2xNacZW6LyCuDvp36n3GhhAZ3KfWKVrS6EEBZTVbXeK2IAtnod04doq14L/4ijuMzAsWxtf1g7WzdYEA5LR8PK+7XvC8Ihdo1WKAjA1pEFm7TzexpDyN6Ujf9Uf747+l29n8OJ7BOsiVvDiqMram8hEza2SpVYnjxwSYIwgPUHkzieml/leHJOsflreR02JWzi3eh3qxyv72u5sF6guyNP36hVPZ73yyHrsq2uEBKIXeFq3ayoAqgXdbNio6QmAs62zjjoHQDpJXalO51ZyMEzuegUbUO1NSpXSG9odQM2uto37lqig78rDjbV/1soy0snbe2bjOnbEUdHR7oGu7Bn3dJqzzWqRlNlrQtVFs6ZHzVf6+Vngcaqntjbvzce9h5klWQRnWLhnq+g7jB9BzwqK2JC1FdSTjF5xeXY6BTa+tReMfFCt/UKJtDdgZTcEr7fm0hxeTGuegfaJ+yF3LPmJ+eehe/u04IxICG9gI2xKegUaGc8Q2lOKUeePsLUblOxsbEhISGBp59+mtatW9c5j4/3fYyKyg0tb6i7UuB5VWJpM6jJ0xErGYwqc9bW9BqsmbM2ts40xdoLntX/tVxYb9KA1oS3cCO3uJy5P1X//7g5kUCsGahxs6KhnLfL3S9qnqyvi5Z2ZtWKWO5ZlE+H4l2mjZFRJIHYlaxyNaxfG2/TimlDGFWjqSBGRKvG+TscFZ9ZbWEZQ3E+ycueBZ0NLW77N7ufDeOtG8Dz7/e0fRkXqLNIDirJhckWF8mpTE/cHpdOTpGFhTaqYaOzMa3UWZzma2MP/mGX7AOVEFeyytWwNj7O2FnQ0+h89jZ6HqpoQL9wSxwT2k3kr9R8HsvKrvlO67ULr2v2a4HauO4tmPGvaeyN2cuANwfQ7v/a8fLKlwkKCmLmzJls2LCh1jkczTrKhpPaOWaVEi9zUfGZJOXUXGlWRQuSo+Izax2nsV/LhfX0OoVXb+mKToHVMWf581j6pZ7SRSWBWDNRZbOi3zDWnz5LhE+3i/q451ITrShfb+MAZ//Gu1R7UZUVsStb5arOyK7WVUtMLkjGTmeHq60r1wZe2xhTIzWv+jfu3J0rsHHzwW/U43wa8ivhynFu7BpA6CMrtH0ZF2jsIjmhvi6093OhzKCy+VDjpCduPrW5XuX+hRD1Z9ofVo+0xPNN7NsKX1d7zmQX8edva1Byz1Ldrtr8UpWY5HJijmr7yf7+5yjlaScY39EBb29velzTg2dGP8Ptg29n4pCJ2NraEhAQQMeOHWt9/IX7FqKiMjxkOB29aj/3clLTa3l9z7vUBc9E9a4J9uC+/q0BeOHHg6aCNs2RBGLNiNlmxbws9AC+nS7qYzZKaqKDByg6vA3aPzRZEbtyJeUU8fepbBTlXI+shgpyCWL9retZMXYFtvqG9yE7n5+rQ7XHi47vwi6gPV4//ou7395Cj08K+FSdAF5tqj3/YhTJqSzz/9WuU/wYc4YdcRkNqv51beC1ONs4k1aUxif7PmF38u6602rSj8OqB2HF1Ho/nhBXsyP1LF1/IQfbc6ti26IP1njenrMGenxSQI9PtOJCWb99xpnFj/PZgnmmc25pfwuvDnqVNu7Vv25VmXvmETYmbERBYXq36Q2a/6VS02t5fc+71AXPRM2evrED/m72xKcX8NGWuEs9nYvG+k0X4vKUpjUkvNiBWKMU69DpwNHLFIjlluY2xtTEJbC+YjWsVytP/N0se6OsjaIoBLk0rDFpdfq28SLQ3YHknGIUjPTVHcaPbD7MTqLw73Xc2F/P7YOd2BVwD4+/9A52AR2ZNGlSlXEqi+SkFqZWu7dAQcHfyb9eRXJcK5pe703IYm9CFgCB7g7MHhNGZD2KnmxN3GraE/rRvo9gn1aF7bm+z9WcpqwosP9b0NtDeSnYNLzSpRBXk6MNKNRxobv6teKDHev50XM9NsWe/Ccjq8o5Q1rboM52A2Bi6X/ZTRd+f3oIrbydqh3z5MmTdT7u5wc+B2BE6xFVGkhf7s5/La/ucpWC1qexbxuvWse5GK/lonG4Otgye0wX/vVVNAu3xHFz9yBCfeu3D/NKICtizZGhDDK0ppD4XtxUA5+KFbHCUgMFJRZWaauOkzfPZGYTPfBdpnVtWPldcelV9sIa2dW6aol5pXmUGRu+V6omep3C7DFhjNBF8af94yy3e4X37D5Ar5bTNxBeHeaA0/CZPDxnIQ888AALFy6sYZxaiuRU/FyfIjnrDybx6s+HqhxvSPWvGVtmVLmYUWf1L6+24OgFhhJIOWDRYwlxtTMYVY6laFX7GroiBuBkZ8O1nUoos8snUe+IWkvj5Ay9L1HGTtzeK7jGIOxEzgme3/Y8Pxz7odbH/Xe/fzOt6zQe7vZwg+d+qVS+lkONnc2YPSYMva725s6N/VouGtfI8ACGdvSl1GDkPz8cqL3f3RVKArHmKPMEGMvAzgXcW17Uh3K20+Noq71AWbUq5uSNs6piW5TdOBMTTS41r5jdCdrG6MriEw21aP8ihnw7hO+O1L8Uc10idbv52O5dApRzm7gDXRU6++pQgY5h3QHo3Lkzp06dqnGcGovkOPnz9pC3LS6SU1n9q7q3lyar/qUoEFxRxl76iQlhkYSMAkrKjTjY6mjpVX1QZClvT20V7GRReMWRquGFCvy76G70er2pIXR1/jrzF+tOrOOT/Z/UekHLw8GDJ3o+UX3z6CtAZHggH9/TkwB38+yLAHcHPr6np8WZBI31Wi4an6Io/N/N4TjY6th5IpNV0Wcu9ZQanaQmNkcl+eDfFexdtQ9YF5GiKPi42nE6s4j0/BJCvJ0bNpBTRfpAoewPu1Jt+CcFVYVuLT1o4eHY4HFUVWVjwkZyS3PxdPBsxBmiNUVdPwvlgmvO17XUczTDqF0BXf88dBrN0aNHCQkJqXW4iJAIhrYcSnRqNGmFafg6+dLTr2e9rp7Wp/pX/1DvGs+rT/WvPgF9qp7Qojcc+1ULxPo9ZPH8hbhaVaYltvdzrXPlpS4n87Q9MMeKe/J/Tj15UbcEJf+8dhZuQbyjn8qGpM7c3a9lrYHfbR1u47MDn3Em/ww/n/iZm9vdbHZ7YVkhjjaOKBf580FTiAwPZHhYAFHxmaTmFePnqqUj1vf/R2O8louLo6WXE08M68D89YeZ+/Mhbujkh6dz80mfl0CsOQruBdP/NG9IexH5uNhzOrOItDwrKid6tOKMdwgfnN2E7s+TzB04t/EmKJrEelMTZ+tWww5lHuJM/hkcbRwZ2GJgY0ztnITtVfvzAE9da8+AxQW8uq2YO7qcJuq9OSxatIhFixbVOWRlkZyGumyqf5lWxHZbNI4QV7sjyVpaYgcr0hJBa9VxPEvbTuCoBvFFpg/97t5MpEs85KeAiz/byzvw3ud7sNPral0NA3C0cWRSl0m8s/cdPjvwGaPbjjYLKJ7+42mKyov4T7//XHF7w6qj1ym1XqSyfBzrXsvFxTNtUBt++DuRoyn5zPvlMPNvu+ZST6nRSGpic6YofPjhh7Ru3RoHBwf69etHVFRUoz+Mb0XBjur6M1ks8jXKJ61lXU6sdLG/AmUWlLLzhJbqZ20gVvn/f2CLgTjaNHxlrVr51a8Y9Wmh54cJjnxzsIzwj/J5+b3FLFiwgLvvvrtxH78al031rxa9tO9Z8VAgK9NC1OVcoQ7rCggkFSRRWF6Ijc6G+/poF0Te/z0etfVA6HobauuBLNh8AoCJfVsSZEHGwYSOE3C3d+dk7klTnzCAmNQY/jzzJzGpMdjrG97nUYimZKvX8eotXQH4ds/pOvvDXUkkEGuOKhrQfvvtt8yYMYPZs2cTHR1Nt27dGDFiBKmpqY36cJUFO9KtKWEPeDtoV7QKywspLCu0el6i6WyMTcZgVAkLdGt4eirn0hIBhocMb6zpnePiX+NNozvYcmC6C8X/dePQ5m944IEHGv/xq1FZ/au2RBovZzuLq39duOH8fHY6Ozp7da7+RkcPrcqqXxc4PyVKCFEtU+n6ADerxqlcDWvj3oZpA9vjbKenMOkIn2/cy48xZ/h0WzxRJzOxs9HxryG1r4ZVcrZ15t7O9wLwyb5P2JW0i59P/My8KK3c/djQsbRya2XVvIVoSr1bezGxj1b34D8/HKC0vHn0yZRArLkxlMP81vDxQN5+83UeeOABpkyZQlhYGAsXLsTJyYnFixc36kM2Sgl7tDcOB7121V+aOl9Zfq6olniTlU2cj2cf52TuSex0dgwOHtwYUzMXMgDcaiuHr4BbC+28JlJb9a9KuUVl7DpR+7+J2qp/VSo1ljJjywxKDDX8W334T/jXdvDvYtHchbhalZQbiE/XenpZUzERtL3W4d7hXONzDZ7Odgxo58Mntm8zbfswvv/uf6aKqte1865SmKI2d3W+Cwe9AydyTzDt12nM2jaLfzL+AaCLt/wbF1ee50Z2wtvZjmOp+Xy67cSlnk6jkECsucmKh5IcSlOOsffvfUREnKv2o9PpiIiIYMeOHY36kI3S1PnMXpRFQ6Sp8xUop7CMv46nA9aXra9cDRvQYgDOtg1fWauRTg8j5tVwY0XwEjlPO68J1VT9K9DdgfAWbpQbVe5fuqfOdIyaqn8FOAXwWI/HcLRxZHfybvan7a9+gEZqnC1EcxeXWoDBqOLmYIO/m3UpfoODB/PN6G94acBLrD+YxObYJEIULXPlpHpuFf/3w2kWt7IA2JW0i2JD9XtL5+6aK9sAxBXHw8mO/4zSsjre23yMUxlXfvaUFOtobtIOA5Du2BqDIRV/f/NULH9/fw4fPtyoD+nrolWvsXZFjKQYvINbcsZWkRWxK8imQymUG1U6+LtY3WxxROsRGFQD1/hcxI24piBLgfNLvbsFaUFY2NiL99i1qKn6V5nByIP/28vWo2lM+SKKL+/vR6+QmqtJ1lb9q4dfD/JK8+rekF5eCjobrdm6EKKK8xs5N1b1wcpWFkFKBvZKGSWqDWdVH9PtClori+FhAXVWBaxsZ1Gb+VHzGdpyqFQGFFeUW3q0YMXeRLbHZfDCjwdZMqXPFV0BVAKx5sRogKPrtT87eDTZw55LTbSiaqKTtj/Mu6wUbO1lRewK8oupWqJ1q2EAoR6hPNbjMavHqZGqwra3tD8PfBJCh5mqkhEyoMlXwi5UXfUvvU7Pont7cf/S3fx1PIPJi6P437R+dG/pUcs41Vf/uvBYelE67vbu2OoqVsJUFf53C5zaAQ9tvegN4YW4UlXuD2uMiokGowFbva2plcVAnZbqfUr1x3he4pKlrSygEdpZCHGZUhSFl8eFM3LBNv44msZPB5IYfU1tWw4ub3K5s7mIXQMLwuHvZQD4pO9Ar4OUPWvNTktJSSEgwLp9PBeqTE20tqEzgHe5FszlluZaPS9x8eUVl7H1WGVaYuP+vbooCjPBUAo2DnDtI9BmEHS9Tft+GV8VdrDV89l9fejXxou8knLu+3wXB8/kWDXmmfwz3PPzPfxn238oN5ZrBxUFykugvFgaOwtRi6PJ51bErHEy5yR9v+rLXT/dZWpR0UbRLm7Fq9W/plrS8sLqdhZCXMZCfV2YPkRrRD5nbSy5xTU3Lr/cSSDWHMSuge/uM+uPZKdX6BWoZ/P/3tJuB4xGI5s3b6Z///6N+vCVK2KFpQYKSsobNoidC+jtmJmZTfSYH5nWdVojzlBcLL8dTqW03EhbH2erN6y/F/0ev536jVKDFSurdXH21gpSPPgHuFhW7v1y4WinZ/HkPvQO8SS3uJx7Pt/FoaSGX7CIz4knpTCFX07+wot/vYjBqO3PlH5iQtTNVDHRyte9Y9nHKFe1983KFhVtFG1FrKZAzJKWF1a3sxDiMjd9SChtfJxJyyvh9fWH2RGXwY8xZ9gRl4HB2DR9dBuDBGJXOqMB1s/CbK9LhRnX2vFpdClLX36YQ/8cZPr06RQUFDBlypRGnYKzvQ2OttpqQoNXxRQFnLxxUlVsi2U17Eqx/qD2gSEyPMCqHO3Teaf59MCnzNgyg4KygsaaXvUUBfw6XdzHuEic7W34Ykofurf0ILuwjLs/22Xaq1JfA1sM5M3Bb6JX9Kw9sZY5O+ZgVI3nArEzsiImRHXyS8pJzCoCrE9NPJ6tla5v59HO1Mri3IqYebq3glbAp65WFlB3OwsFhQCnAHr69bRq/kJcKg62euaOCwdg2c5T3PnpTp5YHsOdn+5k4Pzf6lXY5lKSQOxKl7DdbCXsfBPCbXnzRgde/CWZ7j17EhMTw/r166sU8GgMjZmeSGF6I8xIXGyFpeX8fkSr7HWTldUSK6t39Q7ojadDzYUorHL4JyjJvzhjNyFXB1uWTu1LeAs3MgtKuevTXfw/e/cdHlWZPXD8OzOpk94LkAIkIJ1IkY4aFUWwYEEs2NZd24qsCroq6lpAV+w/WF3rYu+AigJSRKoEkBpCCAmE9JDeZ+7vj5uZtJlkWoDA+TwPT5KZe9/7Dspkzn3Pe86hfMde14WxF7Jg/AK0Gi3fHvqWZzc/i9KtMRDL2wt1nRwUC9EFmW5+hPt5EuTj4dRYph5ivQN7m1tZLDWM4cOGi9ll7GU+zhROzZvSr8NCHdB+OwvTz3NGzJFCHaJLs5aSmFtaw91LUrpEMCaBWFdXYX0zLsB9IzzInOVH7R+fsGXLFkaOHNkp0whtrJzoVAn7wFiyQ+KYm7qEx357zEUzE51lXWoBNfVGugd50z/auYam5ibOMZ3QxBkg/wB8NgNeGwTVJZ1zjZMowNudJXeM5JwofworapnxzmZzTyN7XRJ3Cc+PfR4NGr48+CUvHPgQxS8aFCMc3+naiTdjMBh44okniI+Px9vbm169evGvf/0LRek6KSXi7OSq/WHQtCKWEJQAqNVTL5nxdxb7/I39Sqz5uMgALxbdlMQkO4oiWWtnEaGPYOHEhSTHJls5U4jTn6nKqCWm3yJPL9t32qcpStXErs7XxtUtW49zkGmfWIEzlRNv+ISGskx++PZyvEv28TzPu2h2ojP8uMfUxDnKqbTEnIocdhfuRoOGC2MvdNX0Wvr9VfVrzCjwDuyca5xkgXoPPr5zJDe8vZnUvHJmvLOZL/46ih7BervHmtxzMg3GBp74/Qm25W6jottQ/A4cV/eJxY3phNnDggULWLRoER9++CH9+/fnjz/+4LbbbiMgIIC///3vnXJNIVzBVRUTaxpqyCrPApoCMbDeysKWlbDW2mtnIURXZqoyao09VUZPJQnEurrY0Wr/o7IcLO0TA436fOzoTp2GOTXRmRUxIMRL/cdS3VBNVX0Venf7P1SKzldTb+DX/epq7KUDnKuWuCpLTUscGj6UUO/QDo52QEkW7P5S/X7cbNePfwoF+3iw5M6RTH97E+kFlUx/ezOf//U8ugfZ/+/mit5X4OXmxfDI4fjtXQpoIKRXh+c5auPGjVxxxRVMnjwZgLi4OD799FO2bt3aadcUwhUOuqhQR0ZpBkbFSKBnoPl3H2XHoTwXXUgvl314tNbOQoiuzJbqofYcd6pIamJXp9XBpAWNP7S+W9b486T5nV6au2lFzLlAzMfdBy+dWhFKeomdvn5LK6SyzkBUgBeDuwc6NZZpf9jFcRe7YGYWbHwDjA0QPwG6nds51ziFwvw8+fQv5xEf6kN2STUz3tnCsRNVDlWQuiTuEoK9guHcW2H6x+wP743BaGBb7jZ+PPwj23K3NVVXdNLo0aNZvXo1Bw8eBGDXrl1s2LCBSy+91CXjC9FZUnPVPZnOpia6ad24NP5Szu9xflNWwZ5v4J3zYdkDzk5TiDOaLdVD7TnuVJEVsTNBv6lw3Udq9cTmhTv8o9UgrN/UTp9CqCtWxA78iGbdfEL0kA0U1RTRw7+HayYoXMrUxHnSgEi0DqTLmNQZ6sxVEi+M6YS0xIoCSPlI/f4MWw1rLtzfi0/+MpLr/7OZrOIqJry0tkXwFRXgxbwp/ezaX/L1wa95atNT+Lj7tKhkGaGPYO6IuY7tLzEa1AJDFXnMvX4MZaUl9O3bF51Oh8Fg4LnnnuPGG2+0f1whTpKiilpzUaqECF+nxkoISuDF8S+2fLA4Xf0a3Hmr0UKcCUxVRnNLa6zlgxFpY5XRU0kCsTNFv6nQd7L5Qw6+EWo64knKAw9rLNbhVNXE+irI2UVIXG+yNbIidrqqazCycp8pLdG5aokeOg++mvoVxyuOE+nTCQ2htyxSmxNHJ6krYmewqABv/jq+J//8bk+bFTBTBSl7Nvun5KUAtGknkF+Vz+y1s+3f7L9vaYubRV/sqefjVfV88uJs+l8yk507dzJr1iyio6OZOXOm7eMKcRKZ9ofFBOvRe3TCR6gitXgHIb1dP7YQZxBTldG7l6SgoeXmHHurjJ5Kkpp4JtHqIH4cDLxG/XoSN+Oa9og5lZrYWL4+xKCmPhVWSxn709HG9ELKaxoI8/Pk3FjXlJqP9o12yThtVBYAGnU1zImCIl2Bwajw5ppDFp+zt4KUwWhgy5FfwEIFQ6VxtAVbF9iepmih6fzDK2uYO9qN6RX/ZaAug5tvvpkHH3yQF154wbYxhTgFTBUTnS3UAWr/xDb/hooaV8Q6cX+mEGeKSQOiWHRTEpEBLdMPHakyeqrIiphwCdMescJyJ6ommgKx+jpw01Fe71ijWtG5ftqtVku8pH+EU3eaqhuqURSlcwuyTH0DxsyCoPjOu8ZpwpUVpFLyU8gz1lgNXhUUcqtySclP6bgIgJWm81X1YP7fZ8Vc6DsZnU6H0WhsfzwhTqHUPNP+MOfSEsvryrnsm8vw0nmx7vp16vtgXRWUZasHyIqYEDZxZZXRU0ECMeESpkCsut5AZW0DPp4O/K/lo1bMe7ggn8ceO467zrlGmcL1GgxGftnXWLbeyTtNPxz+gQVbF3BTv5t4IKkTN6afJXeWba0MlV5Q0WEgVlBVYNNYNh1npen8lEQ3nvutlpgADf3Dj7Lj7fksXPgqt99+u03XFuJUOOii0vXpJerKV4BnQNPNqOLD6levQNCf3vtahDid6LSa07pEfXskEBMu4ePpht5DR1WdgYLyWscCMW/1F4/eUA/11SCB2GlnS0YxJ6rqCdK7O70BdmXmSmoMNfi4+7hods0c2QD+3SD4zF8JM7G1MtS/lu8jp7Sau8b1IkDvbvGYMH2YxccVo0L+t/mUbCqhobSBu6Lv4qobruK1515Dq7WS6X4iw+LDb1zqxRNrarnnxxryKxWiI9/gr3/9K08++aRNr0OIk01RFHNqYt9I55rYp5WkAdA7qNnKl6lQh6yGCXHWkD1iwmXM6YmO7hNz9wKPxnSPKinUcTr6cbdaLfGS/pG46Rx/+yitLWVrjtovKjnGgep77TE0wHd3wxtJcGiVa8c+jZkqSLWXjOGu01DbYOStNemMffFXXl+dRkVtQ5vjksKTiNBHtBmr4IcCitcUE31TNKNfGc2sJ2bxf6/+HyPvGcm23G0tD64shNXPwE9zLM7Fz1PDq5O8yJzlR/U//Ulf/yXPPvssHh6n7gZMeXk5s2bNIjY2Fm9vb0aPHs22bds6PlGcFXJKayivbcBNqyE+1LkbSIdOqPs5EwKbGjkTMQAueR6GyaqwEGcLCcSEy4S6onJiUDzZIfHM+eNFHv3tURfNTLiCwajw8161WuIkJ5s4rzm6hgalgYSgBOIC4lwwu2b2fK02cfYOhpjObWR+OjFVkALLHQU1wOvTh/Kfm8+lT4Qf5TUNLFx5kHELfuXt9elU1xmajaVj7oi56rnNCnZUH6rGf6g//kP8eeryp+g5vif+A/xJ+zON23++nb/88hd2ZayEn+bCKwPgt5fVaqhadwuzasY3vNObztvizjvvZOXKlfzvf/9j9+7dXHzxxSQnJ5OdnX2qpyZOA6aKiT3DfPBwc+7j06ESNRDrHdhs9SukF4y6F4ZKCwchzhZdLhB76623iIuLw8vLi5EjR7J169Z2j//yyy/p27cvXl5eDBw4kB9//LHF84qi8OSTTxIVFYW3tzfJycmkpaV15ks4Y5krJzrTS+zuDRhmLuXHnN9ZnbXaRTMTrvDHkWIKK2rx93JjdK9Qp8YyNXG+KPYiV0ytidEIG15Rvz/vbvDoxEIgp6GOKkhdOjCKS/pH8tMD43j9hqH0DPXhRFU9z/94gPEvreHDjUeobVADsuTYZBYmziTc0BSgeff2pvpANbNjZpMcm0yvql64Zbpx0SUX4aZxY3POZm5aP5v7jnzFfm0DRA+F6z+Gae8CYEDDNi9PfvTRs83LE/PI1aWwf+nJ+Cuyqrq6mq+//poXX3yR8ePH07t3b5566il69+7NokWLTuncxOkh1UUVExVFIe2E+jkjISihg6OFEGeyLrVH7PPPP2f27NksXryYkSNH8uqrr3LJJZeQmppKeHh4m+M3btzIDTfcwAsvvMDll1/OJ598wpVXXklKSgoDBgwA4MUXX+T111/nww8/JD4+nieeeIJLLrmEffv24eV1enfjPt2YUhMLKpyonAiEeqsf8qsbqqmqr+rcqnrCZj/tUYt0XNQv0qm7weV15Ww8vlEdK8bFgdjBFVCwHzz8YPidrh27i7ClgpRWq2Hq4GguGxDJNzuyeW1VGtkl1cxbupe31x/m7xf25uqk7mg8LuO27BR2aWvJ1PkSOzCEHQXHuP3C2/mL7i/mJsyPPvoo2Sse5j+HvmKprw/r9N4cCIxixXUrcdOp+9BWnZjD/IMfk6drmkeEQWFuvTfJOQfh279BzCjw64R+cjZoaGjAYDC0ed/39vZmw4YNp2RO4vRi2h/Wx8lArKimiBO1J9CgoWdAz6Yn9i2FoFgI7w+6LvXxTAjhoC71L33hwoX85S9/4bbbbgNg8eLF/PDDD7z33nvMnTu3zfGvvfYakyZN4uGHHwbgX//6FytXruTNN99k8eLFKIrCq6++yuOPP84VV1wBwEcffURERATfffcd06dPP3kv7gzg9B6xRnp3Pd5u3lQ3VFNUXSSB2GnAaFRY0RiIXepkWuK6Y+uoN9YTHxBPr0AXVjRUFNiwUP1++B3gHei6sbsYWytIuem0XDesB1cO6cbnfxzlzV/VgGzO17v598+pJFVtYJ77Jm40FkMDfLannpSddVww9SpunXoBSsUJZj39b7UJ87SHeaY0h9uHXMeivN8ZHjncHIT9cuQX/pH+Cehapifm67TM1tWycOg1anNoG4Mwg9FASn4KBVUFhOnDSApPQudo30SjATI34leRx6ik/vzrX89wzjnnEBERwaeffsqmTZvo3VuKJ4im1MTESOcCMQ0a/jror5TUluDl1hj4V5fAFzer3z96DHTO9ykTQpz+ukwgVldXx/bt23n00aZ9Q1qtluTkZDZt2mTxnE2bNjF79uwWj11yySV89913AGRkZJCbm0tyclOxgICAAEaOHMmmTZusBmK1tbXU1jYFG2VlZY6+rDOKS1IT/3gPtn9AsK+ObNQ7hz38e7hmgsJhO4+VkFtWg6+nG2MTnEtLHBYxjNnnzsbfwx+NK5ssH9kAx7aBm5e6z0LYzMNNy83nxXLtud1ZsjmT/1tziKSqDSxyf7XFcQ+vrOGxMZ7cO3gVmqxVKHHjyWxswjxz5ky4fglxwII+U83nGIwGnt70tMXrmptD12Vx/qDrMIdSx3eA1g0iB7Y5Z1XmKuZvnU9eVZ75sRBNCMFrg9m+ejv5+fkMHTqU1157jeHDO+hxtm8phhVzSKkrokCn4+EL6njlm8N069YNnU5HUlISN9xwA9u3b+/gb1Cc6QxGhbR8tYdYXycDsRDvEO4bel/LB00VE30jwFOCMCHOFl0mECssLMRgMBAREdHi8YiICA4cOGDxnNzcXIvH5+bmmp83PWbtGEteeOEFnn7a8geLs5lLVsSqiiFnFyG9+5MNFFYXumZywik/NVZLvKBvOF7uDq48NIr0ieS2Abe5YlotlWWDZwAMulYt/iDs5uWu485xPekV4k2fz/8KNGu6jNqEWadR+zwrChyoCaakqhaDwXoT5pT8FMrq2r9Z1aI5dEU+fHaj+l5wxZsw8BrzcasyV/Hg2gfV3tDN5rXjzR3UZtfy/CvPMzVpKkuWLCE5OZl9+/bRrVs3yxfdt5RVy//K/JBA8twafweEQ0TfBpbmFDNs3AKiJtzK9ddfT8+ePS2PIc4amUWV1DUY8XLX0iOoE7I0ihp7iEnpeiHOKl0mEDudPProoy1W2srKyujRQ1ZtwvxcUDVRr6ZThTZ+riuqljL2p5qiKOb9YZcNPDX7d2wyeDr0uVQtXy+c4p69mWhNcZvHWzZh1vGXPbDpp9fxHXQRw55dSbdAb7oH6ekW5E23QPVPenWmTdfMq8wH4P6NT3A4xItovS/R6x4m6uDnRA+aQaRvN57c8C8URQ0ETYx1Rsq2lxHz91i+bVjOAz0f4KmnnmLZsmUsWrSIZ599tu3FjAZW/TqX2eEhKK2eytfp+Gf3MBbufhGvAZfz888/8+KLL9r6VyfOUM0bOWu1zq3k78zfSaRPpNoiwvQ/c5FaRfFsaUAvhFB1mUAsNDQUnU5HXl5ei8fz8vKIjLT84TAyMrLd401f8/LyiIqKanHMkCFDrM7F09MTT09PR17GGS3MV811LyyvQ1EUx9LOGgOxEIMBjVZDeX25K6coHLAnu4xjJ6rxdtcxIdG5laYP935IsFcw5/c4H19TzzhX8gpw/ZhnoXBNicXHWzdh9vZbRvC5l6E/73oKK+oorKhj17HSFufo9MfRx3Z8zTV7a/CqzWNfSRb51JPl7a0+UXEANjY1eW79tqIYFDCC1kNDSX0Br2x/lUFhA2nQNbQoslHdUI2nzhOtRovhyAbmezcmRjYbsHx3OSjgFenBIzk1GMedR9++fc37ksXZ64ALKyb+deVfqWqo4rsrvmvaJ2tKTQyWQEyIs0mXCcQ8PDw499xzWb16NVdeeSUARqOR1atXc99991k8Z9SoUaxevZpZs2aZH1u5ciWjRo0CID4+nsjISFavXm0OvMrKytiyZQt33313Z76cM1Jo44pYdb2ByjoDvp4O/O/VGIg9VFHPY/em4KbtMv+LnnEMRoWtGcW8t0FNmZnYJxRvD8fSEg1GA5tzNvNaymvUG+v5+LKPGRQ2yDUTLT4MxRnQ64K2n9KFQ3r17AUWCgWamjC/Okm96WK45Tu08eMora7n2Ilqjp2oJrukmuwT1Rw7UUV2STUZhb0x1gegcSu1+J9HUUBpCODrjR58vfEPNO4z0LqfQONeQh+P3Qzy3EGBm4ZUdw9KLFTr1Hnr8O7tTf73+XhGefLBnvcp3VzKsT+OkZiQaD7uzp/v5M/CP/HReuBuaKDEre17i7HaSO6XuTScaEDno+OqC0fwzns/4u7u7vhfpjgjmFbEnK2YeLzyOFUNVbhr3Ynxj2l6wrwiJqmJQpxNutSn3NmzZzNz5kyGDRvGiBEjePXVV6msrDTfrbzlllvo1q0bL7zwAgAPPPAAEyZM4OWXX2by5Ml89tln/PHHH7z99tsAaDQaZs2axbPPPktCQoK5fH10dLQ52BO203u4offQUVVnoLC81qlATF9VrG7WF6fEij05PL1sHzmlNebHNqUXs2JPDpMGRLVzZluWiivMXjubuSPmqpXyHPTUU0+12avZp08fq3tGhe10cWOo9o7EsyoXS1lYRgVq9ZF4x40BjYZAvQeBeg8GdGu7IrkpvYibP5uCV7clbdIKTb2ia/OmMCA6EJ1WQ3mtDxU1UVRUN7C39FzqNRfytvtCCvQF3B4V0WZ8gO53dSf73WxSH0xFo9UQ3DuYvhf2hWPA7q/g0GoqTvwJOqg01lntLR0wIoCAEU2v4da+0wgIkFVW0ayHmJOFOg6dUAOu+IB43LWNAb6iyB4xIc5SXeqT7vXXX09BQQFPPvkkubm5DBkyhBUrVpiLbWRlZaHVNt0xHT16NJ988gmPP/44jz32GAkJCXz33XfmHmIAjzzyCJWVldx1112UlJQwduxYVqxYIT3EHBTm50lmURWFFbXEhfrYP0BjIEZ1ibrXR3qpnHQr9uRw95KUNntnSqvruXtJCotuSrI5GFuVuYrZa2ebq+OZ5FflM3vtbBZOXOhUMNb/nERWTc4HpQFu+AK32A6q5AnbaHV4T3kJ5YtbMKLQfB3KiHoTy3vKS2BDyfgR8cGEaYdRkA2eEcvQuDelLioNAdTmTSFMO4zv7xvbotcZqKuyFbUNVJZegf+PT+BZv4s6t2qUVktrnuGe9Jobj3ulO6+EzmT89bO4/vrrqfCogJSPIGMdX2igQutOZWR/toT24JmyXR3OPazH6A6PEWe+mnoDR4qqAOdXxNJK1EbOvQObBVyKAlctUlfFguKcGl8I0bV0uU+59913n9VUxLVr17Z57Nprr+Xaa6+1Op5Go+GZZ57hmWeecdUUz2qhvmog5nAJe+8g8A4iWx/Ia+sfRuvmyfxx8107SWGVwajw9LJ9bYIwaCpU9/SyfVzUL7LNh+a2YxmYv3V+myBMHUtBg4YFWxdwfo/zHe4B5VZbQqSPEeImwLmXOjSGsKLfVDTXfQQr5kDZcfPDGv9uaCbNh35T2zm5iU6rYd6Ufty9pIaq8n5o9Rlo3MpRGvwwVsUDWubd1M/i/086rYYAb3cCvKMw3LKYuQvP4ZlwTzSK0iIY0zQurS2ozGF8wTxOHJ3cVGRjsB90OxfPuDF49hhJiKcf3YwG/vPZePLrStsEdabxIjwDSYqUwF7A4YJKDEaFAG93Ivyd2x9+qERdEUsISmh6UKuFvpOdGlcI0TV1uUBMnN5CfZ2snKhzgzlHMJRl8dO3k/F283bh7ERHtmYUt0hHbE0Bckpr2JpR3GHD4JT8lBbpiG3HUlqWLbdXXRVpRwuIfhm8glIYtfJGXnjhBWJiYjo+V9im31Q0fSdD5kaoyAPfCDSxo21aCWtu0oAoFt2U1Jju2lSMICrAi3lT+tm0wqo7uolrqvIJzPdmfkgQec32eLntKuXasgp6+Taw0tidhy+d0lRkw8L+Lp1Wx9wxTzN77YNtgjpT/uSc0U853iRanFGa7w9ztvdh2gkLK2JCiLOWBGLCpcxNnSvqnBon1FttGlzdUE1VfRV6907o2yLayC+3HoTZe1xBVYFNY9l6HABGgzkoGKndzQdXeNGn7znkjHmOp595hnHjxrFnzx78/KQhqstodRA/zulhJg2I4qJ+kWzNKCa/vIZwPy9GxAd3uLJqVqEG9clV1ZxfVU2KlycFOh1hBgPpxyr45+oanipTCA7KZdr1N/Lcc8+1W2QjOTaZhRNfabN/0Vuj4/mJLzuVMivOLKmm0vWRzlV6rTfWk1GaAbQKxDJ+g+pi6HYuBHR36hpCiK5FAjHhUqamzg6nJjbSu+vxdvOmuqGaouoiCcROknA/2/ZG2nJcmD7MprFsPY59S1ukyV3qBvR3h9GXMujiSYw87zxiY2P54osvuOOOO2wbU5xUOq2mw5VUq3ybCnXogOE1Te8xw/u7M71/Y9A1c6nNgWNybDLn9ziflPwUNh34mncyf0AxGhgedI5jcxRnJFOhDmf3hymKwlOjnyK9JJ1o3+imJ7a+DfuXwqT5cJ5UbBbibNK2FrAQTjAFYk41dV7zPCweR7BWHauoRpo6nywj4oOJCvCyVlQODWo62Yj44A7HSgpPUhuWWhlNg4ZIfSRJ4UkdT2zfUvjilhZ7lcw2vgn7lhIYGEhiYiKHDh3qeDzR9cSOBv9orJU8NAKKfzf1ODvotDqGRw7n/vHP08egoUar4cuNzzs/X3HGSHVRDzEPnQdTe03lwXMfRKtp9vGrqLGHmFRMFOKsI4GYcClTaqJTgVhZNuT+SahGvcNdWF3oiqkJG5gKK1hi+vg7b4rlwgptx9Ixd8TcxnNbHm/6ec6IOR3vwzEa1JUwiyVEGq2YS0VZKenp6S2as4sziFYHkxY0/tDy/ycjgAKbEh+2e/+aiUar5ZbIsQB8mr+ZekO943MVZ4zymnqyS6oB6ONk6XqLjMZmzZx7un58IcRpTQIx4VIuSU1sLGEfgvqBqqhaVsROJlNhBc9WzXMjA7zsKl0Ppn04CwnXh7d4PEIfYXvp+syNFlfCHvqlhnVHGjhSYmDj3kyuuiwZnU7HDTfcYPP8RBfTbypc9xH4t/x/sNIzgrvrZ/HMoV4oSjsBewcuHfcEoZ6B5Ct1rDiywtnZijNAWn4FABH+ngTqPZwaa/2x9WzL3UZlfWXTg+XHoaFG7ZsZGOvU+EKIrkf2iAmXCmuWmqgoimMVpkyBmFEtcV5RX+HKKQobTBoQRYjPPo6X1nD/Bb0Z3SvUvsIKzbhr3enu252J3SeSFJFEmD6MpPAk2yvSVViuvHiszMgNX1dTVK0QptcwdowHmzdvJizMxj1nomvqN1Ut9d2skqMxbDjrF6ylOrecjelFjOkd6tDQ7n5R3NDvZt7Y8Qb/2/c/Lu95udNV8kTXdtBFaYkAL257kcyyTN6+6G1GRY9SHyxqTKUOipO+mUKcheRfvXCpUD/1jmFNvZHKOgO+ng78L9YYiD1k8Oexm1fgppX/TU+28pp6jjeWsb9jbLxTd4J3F+5me/52YgNiuaznZfYP0KxIQ3OfXdOqgMvM+RDfy+Kx4gzTqpJjAHDtsO58tCmTdzdkOByIAVybeC3/2/c/BgQlUltfjZeHFAo6m6XmuaZQR01DDVllWUCrHmKyP0yIs5qkJgqX0nu44eOhrnQ4nJ7YGIjpq09IEHaKHMxzXTqOqW9OQmBCB0da0UGRBtCAA0UaxJnltjHxaDTw64F8DuU7vooe5BXEKt9hPLn2HbyObnHhDEVXZC7U4eT+sMOlh1FQCPQMJMSrWeVQUyAWLDeRhDgbSSAmXC7U2YIdjYEYVbI37FQxl2uO9Hd6rLSSxkAsyMFAzFykwdLen8bgbNJ8h4s0iDNDfKgPyeeoq6fv/Z7h1FieaNR9Ozs/dsXURBd20EUrYodK1BTEhKCElumuI++C6/4Hg65zanwhRNckgZhwOfM+MWdWxLyDyNb78ci6R5izfo4LZydskZpbBkBfJ+8CV9VXcaz8GOBEIAYQmojFFTH/aLV4Q7+pjo8tzhh3jI0H4JuUYxRXOtFUfuiNAOxJ/4nv93/miqmJLqiwopbCijo0GkiIcK6Z86ETaiDWopEzqHvD+k2F6CFOjS+E6Jok70u4nLlyoqMrYiG9YM4RjGVH+enby/B283a88IdwyAEXNTBNL0lHQSHEK4Rgr457j1m18glAgT6T1YanjUUaiB0tK2HCbGR8MAO6+bMnu4xPtmRy3wUOBv/RSeyOSGCGvhbvbQuY2PNSAjwDXDtZcdozrYbFBOvRezj3ccmUGdAmEBNCnNVkRUy4nKlgh8MrYo1CvNUUxeqGaqoaqpyel7CNoihNG9SdXBEzf/gIcuLDR/oaSPtFLe980TNqkYaB16hfJQgTzWg0Gu4cq/Zi+nBTJrUNBkcHYsDAm0msraNaaeCrg1+5cJaiq3BlxcTmqYlm5bnw+2tw8BenxxdCdE0SiAmXa1oRcyI1CNC76/F28wakl9jJlF9eS0lVPVoN9A53Lh2n3lBPqHeo44U6AAJjoO/lMOwOCJW7yaJ9lw2MIsLfk4LyWpbvynF4HM3g6dxcrvZ7+mTfR9QbpcHz2Sa1sWiRs5kBAC+Nf4knRz1JYlBi04M5f8LKJ2HVU06PL4TomiQQEy4X5ueCps5L/w6LxxLipgYCRTUSiJ0sprTEuFAfvNydW3G6vu/1rLluDf8Y9g/HBwnpBdM/hkkvODUXcXbwcNMyc3QcAP/dkOF4g2e/CC6LHEVIg4H8mmJ+OSKrFmcbU2qisxUTAYaED+HaxGvxcfdpetDUQyxEKiYKcbaSQEy4XKivk1UTQS3pm7ubUJ2XOlZ1oSumJmzgqkIdzTnUhqD1B2hJQxQ2mjEiBm93HftzytiU7vhNHI/z7uGG8OEAfLTvI8eDOtHlKIpiTk10xYqYRcXSQ0yIs50EYsLlXBKI6dXCDiFadb+ZpCaePKm5pnQc50rXO/2hdf2/4bt7oczx9DJxdgrUe3DNud0BeHeDE6Xse53PdRe9iqfOk31F+0jJT3HRDMXp7nhpDeW1DbhpNcSH+nR8QjtWZq7k64Nfk12R3fIJWRET4qwngZhwufBmqYkOfxhv7CUWomjRoKGi3vEGrcI+qXnqipizhTq25G7hwi8v5KmNT9l/cnkubHgFdi6BrI1OzUOcnW4bE4dGA6sP5JNe4FyD5ym9phDpE0lpbakLZyhOZ6bVsF5hvni4OfdR6dMDn/LUpqfYnre95RNFh9WvsiImxFlLAjHhcqYVsdoGIxW1DY4N0hiIPeQVx46bd3DnwDtdNT3RDoNRIa1xg7qzqYlpJ9LIr8rnRM0J+0/+9Vmor4Tuw6H/1U7NQ5ydeob5cmHfxgbPzqyKGY086NmTH6v9uSBsqItmJ053qS7aH6YoCmknLJSur6+B0qPq9xKICXHWkkBMuJy3hw4fD3U/T6GjlRMbAzHv6hJ0sjfopDlSVEltgxFvdx0xwXqnxrJYrtkWuXtgxxL1+4ufA+kfJxxkavD8dcoxTjja4FmjwX/LYtzTV8Ger104O3E6a9of5lzl2KKaIkpqS9CgoWdAz6YnTmQACngGmH/fCSHOPhKIiU5hqpzo8D4x0y+mKtkbdjKlmvvm+KLVOhcAme4C2xWIKQr88jigQL8rIWakU3MQZ7fzegbTP9qfmnojn2zNcmwQjQaG3AhA/Y4l/JTxk6QongXMK2JOFuowvQ/G+Mfg5ebV9ERwT/jrb3DdB3KzSYizmARiolOYe4k5WsLeJxS8g8h2c+fhdQ/zyLpHXDg7Yc0BFzUwNSpGx1bEDq2Gw2tA6w7JTzk1ByE0Gg13jlNXxT7ceIS6BqNjAw26DrRu/N1wjEfWP8LXabIydiZrMBhJy28sWuRkaqL5fbB1L0U3T4gaBL0ucGp8IUTXJoGY6BROV07sfSHMOYLx8ldYcWQFa46ukdLRJ4GpdL2zHz6yy7OpbqjGQ+tBjF+M7SdueEX9OvKvEBzv1ByEAJg8MJpwP0/yy2tZ/udxxwbxCYXESVxcWQXAx/s/lgbPZ7DM4irqGlO0ewS5JkW7d5DsAxNCtCWBmOgU5tREZ5o6AyHeaopijaGGqoYqp+cl2mdKTewb6Vzp+oMlBwHoFdjLvh5i0z+GcQ/B+Iecur4QJi0aPP/mRIPnITOYXFFJiEEhvyqflUdWum6S4rRy0IUp2odONAZiga0Csd9fh41vQpmDNweEEGcECcREpzCnJjrTSwzQu+vxdvMGpJdYZ6uqayCzWA12nV0R89B6kBSexJDwIfad6B0IFz4B3kFOXV+I5m4cGYOXu5Z9OWVsPlzs2CAJF+OhD2V6mbo/TBo8n7lctT8M4PULXue/F/+X4ZHDWz6x6U345Z9qqw4hxFlLAjHRKUL91EbMBeUOVioD+OR6WDSWEI8AQK0+JTrPofwKFAVCfDzMK5qOGtd9HB9e+iGPjXzMthMKDqqFOoToBC0bPB92bBCdOwyeznUB/fDQuLG3aC878ne4cJbidHGwMRBz9oYUqFkdI6NGEuwV3PRgTRlU5DUeIM2chTibSSAmOkWYs3vEAHJ3Q95uQt3V8sGF1YWumJqwwlSowxUfPuxSmg3/GQ/vXwrVDvQcE8IGt49R9xyu2p/PYUcbPF/0L4Jv+5kpva8A1FUxceZJdVHRIquKG28G+ISBV0DnXEMI0SVIICY6Raifk1UTAfTqHcQQnaQmngypLgrEDEYD1Q3Vtp/w67NgOt4r0KlrC2GN2uA5HID3fz/i2CBa9Vfmzf1uBqC0tlSKdpxhauoNHClyTYr2L0d+4ZXtr5CSl9LyiSJ135g0chZCSCAmOkXzFTGH91E09hIL0bij1WiprK901fSEBU2FOpzsm1OSxsiPRzLjhxkdH5yzC3Z9qn4vzZtFJ7ujsZT9l9uPUlLleNp0L/cAlvX9K+9Peh93rburpidOA+kFFRiMCgHe7oQ7maK9Oms17+15j5T8VoGYaUUsWNIShTjbSSAmOoWpWEdtg5GK2gbHBmkMxB4OOpeUm1K4Y+AdrpqesMBVPcTSTqShoOCh82j/QEWBn/8JKDDgGuh+rlPXFaIjo3qG0C9KbfD88RYHGzzXVcGrg4j76Z9q+rQ4ozTfH6Zx8saQ1R5i5hUxCcSEONtJICY6hbeHDl9PtWy5w+mJ+lAAvGpK0Gl1rpqasKCoota8n88VgRhY+PDR6KmnnkKj0aDRatHc9gOap8vo+9hap64phC00Gg13jFVXxT7a5GCDZw89JCSr3+/8hBM1J9iZv9N1k2xl/fr1TJkyhejoaDQaDd99912L5xVF4cknnyQqKgpvb2+Sk5NJS0vrtPmc6VJzGxs5O/k+WG+sJ6M0A7DQQ0wCMSFEIwnERKcJ9VVXRAorHEwBalwRo0r2hnU2U1piTLAeH087+n5ZYOohlhBkORAD6N+/HznPDSbnH77kfPYgGzZuceqaQthqymC1wXNeWS0/7Hawh9OQGwHYsf9LLvrqIh5a91Cn7RWrrKxk8ODBvPXWWxaff/HFF3n99ddZvHgxW7ZswcfHh0suuYSamppOmc+ZzrQiluhkivbRsqPUG+vRu+mJ8olq+eTN38JdayF+vFPXEEJ0fXYHYkePHuXYsWPmn7du3cqsWbN4++23XTox0fWZmzo7WjnRJxS8g8mmgYfWPcTD6x524exEc66smGhaEUsMSrR6jJsGIgO9iQwPI/KKeYSGhjp9XSFs4ZIGz70uBN8I+pUV4KNxJ68qj1WZq1w70UaXXnopzz77LFdddVWb5xRF4dVXX+Xxxx/niiuuYNCgQXz00UccP368zcqZsI25aJGzmQEl6vtg78DeaDWtPmp5BUD0UOmXKISwPxCbMWMGa9asASA3N5eLLrqIrVu38s9//pNnnnnG5RMUXZe5qbOjqYnD74A5GRgnzuXnIz+z5ugaaaDaSUx3gZ0t1FFaW0p+VT6gfgCxJu3wEaKfzaTnW/XceMc9ZGU5uF9HCAfMGKE2eN57vIwtGQ40eNa5waDr8VRguqIH4KO9J7/Bc0ZGBrm5uSQnJ5sfCwgIYOTIkWzatOmkzuVMUF5TT3aJWsE1McLXqbHMKdrtZAYIIYTdgdiePXsYMWIEAF988QUDBgxg48aNfPzxx3zwwQeunp/owkJd0UsMCPFSUxRrDbVSObGTuGpFzPThI9onGl8Pyx9kRo4cyQcffMCKFStY9PZ/ycjIYNy4cZSXlzt1bSFsFeTjwbQktcHzO+sPsym9iO93ZrMpvQiD0cZgqjE98bqMXXho3dlTtIdPD3zKj4d/ZFvuNgxGg+MTNBog4zfY/ZX61cpYubm5AERERLR4PCIiwvycsN3BPHV/WIS/J4H6DooNdSCrTL251OaGVPqv8MNDsH+ZU+MLIc4Mdm8Gqa+vx9NT/YC9atUqpk6dCkDfvn3Jyclx7exEl+Z0amIjvbsebzdvqhuqKaopsvoBXzjGaFRctiLm6+HL1F5TCfBs1aTUaIDMjZC3l0vr98HUF8DTh0GDBjFy5EhiY2P54osvuOMOqYwpTo7bx8bz8ZYsVh/IZ/WBfPPjUQFezJvSj0kDoto5GwjvC93OJSTnT5J8Y9hcls4LW18wPx2hj2DuiLkkxya3M4gF+5bCijlQ1mz/mn80TFpg3zjCbub9YS5o5Lxg/AIePPdBvNy8Wj5xZANsewcUA5wzxenrCCG6NrtXxPr378/ixYv57bffWLlyJZMmTQLg+PHjhISEuHyCoutyOjWxugQ+nAqLxxHqre4hKqwudNHshMmxE9VU1RnwcNMSF+Lj1Fh9g/vy3NjneGT4I00P7lsKrw6ADy9XP2CmfAj/7qU+DgQGBpKYmMihQ4ecurYQ9kjLs7wCm1taw91LUlixx4Ybi1PfZNX0/7K5LL3NUxk7Mrj6iqsJiQixvdrhT4vhi1taBmEAZTnq461ERkYCkJeX1+LxvLw883PCdq7qpQhqhc4o3yiCvFrtAytq/H9FmjkLIXAgEFuwYAH/+c9/mDhxIjfccAODBw8GYOnSpeaURSGgqWpigaNVE929IWMd5P5JiIe6wlJULRUUXe1AbhkAvcN8cdO5uJDqvqWWP1jWV6uP71tKRUUF6enpREV1sAIhhIsYjApPL9tn8TlTYuLTy/Z1mKZoCOvD/F1vWn6u1oBXjBfdb+lu8fk21Q71ei656e/UWCyp32wexqbn4+PjiYyMZPXq1ebHysrK2LJlC6NGjWp37qItV66IWWUKxKSZsxACB1ITJ06cSGFhIWVlZQQFNd3pueuuu9Dr9S6dnOjazKmJjq6IuXmChx/UlRPipq7UFNVIIOZqqS7aH6YoCodKDhEXEIe71l1NR1wxhxYfIoGHfqlhSqIbsYE6ji/6O/P290an03HDDTc4dX0hbLU1o5icUuvl3RUgp7SGrRnFjOplPdMjJT+FvKo8i8/5DfLDb5AfRtoGVq2rHQJ89K+7iTh3Gd8dcGP6AHfzsRV1CoeKm8bISFnDzp49CQ4OJiYmhlmzZvHss8+SkJBAfHw8TzzxBNHR0Vx55ZUd/C0IE4NRYWtGMbuPlQDQO9zx9HeD0cC7u99lzbE1jIwcyf1D72/qg6koUCwrYkKIJg41DFIUhe3bt5Oens6MGTPw8/PDw8NDAjHRgjk1saIWRVHQaDT2D6IPVgMxnRc6jU6KdXSCA3muCcRyKnO4eunVeLt5s/GGjbhlbmq7EgYcKzNyw9fVFFUrhOkrGDuhF5s3byYsLMyp6wthq/xy23psdXRcQVWBQ9e3WO0wfwsju+vYdNTQIhD747iB8z+sMv88+7k34bk3mTlzJh988AGPPPIIlZWV3HXXXZSUlDB27FhWrFiBl1ervUnCohV7cnh62b4Wgfnflmzn6an9O94n2MqqzFXM3zrfHJzvKdzD8sPLm/YKludAfRVodBAU69LXIYTomuwOxDIzM5k0aRJZWVnU1tZy0UUX4efnx4IFC6itrWXx4sWdMU/RBZlWxOoajJTXNuDv5d7BGRboQ6Akk4e7XcQ/k19v249FOM1VK2KHStQ9Xt18u+GmdYMKyysFn13T6obNtLuhl6TpiJMn3M+2IKWj48L0jt08MFc7DA9vejB/HxE+GnIrW66gTYxzQ5nn3/TAzOUQP878o0aj4ZlnnpH2MQ5YsSeHu5ek0DoBNb+slruXpLDopiSbg7FVmauYvXY2SqvR8qvymb12NgsnLiTZ2FiJMSgWdA78PhRCnHHs/lT7wAMPMGzYME6cOIG3t7f58auuuqpFnroQXu46/DzVWN/h9ES9mhbkVVMmQVgnqG0wkFGorjI6u0H94ImDQLO+Ob4R7RzdjK3HCeEiI+KDiQrwor01ei93bYe9pJLCk4jQR7Q7jqb5s4Z6OLQK1v9b/fn4zqbnxjwA2vbujWrAvxvEjm53TsI2pn2ClnYB2rNPUB3LwPyt89sEYepY6mMLti7AUJyhPihpiUKIRnZ/sv3tt994/PHH8fBo2WMjLi6O7Oxsl01MnBlCzSXsHSzY0RiIUSV7wzpDen4lBqOCv5cbkf7OpTKZG5gGNgZisaPVsttWP6bKB0txaui0GuZN6QdY/7+zpt7I5Nc3sPGQ9UqtOq2OuSPmquO0bubc+LPpg/j/1s+j/OVEWDKNyJyVAOT9sbTp+Lgx5Hn1ItJHa2FWjT9Pmg+m/UbCKfbsE+xIe3sF1bEUcqtySenWDx7JgMkLHZmyEOIMZHcgZjQaMRjaNpc8duwYfn6dWGlIdEnmyomOroj5hoE+hOz6cv6x9h88tO4hF85OpOapFRP7Rvo7toevmbSSxkDMtCKm1TXrfSQfLMXpZdKAKBbdlERkQMsbEFEBXjx6aV96hvqQW1bDjP9u4fkf91PbYLmpcnJlFQvzCglv9Xsx0mDg33mF3F1WDcAfDSVcE+zFjsAI4i/6C5FhwayuaErJLSsrY8vuQ4y69n7wb5UO5x8N130E/aa64JULcN0+QbB9r2BBVYG67zmwh03HCyHOfHbvEbv44ot59dVXefvttwE1P72iooJ58+Zx2WWXuXyComszFexwuKnzxc/Cxc+ilB/jl28uxVPn6XjhDwteeOEFvvnmGw4cOIC3tzejR49mwYIF9OnTxyXjn+4OuGh/WL2xnoxSNe3GHIiB+sHxuo+sNKidLx8sxSk1aUAUF/WLZGtGMfnlNYT7eTEiPhidVsPNo2J59of9fLIli7fXH2ZDWiGv3zCE3uHN/q00VgZNrqri/KoqUrw8KdDpCDMYSCyrIaNYIYIKALyLjKQfr2fHhLkMnXAns/4RwbPPPU9CYp+W1Q7vexY8FqgN0Cvy1NTd2NGQsxMq8sE33PKLEXZx1T5BsH2voKN7CoUQZy67A7GXX36ZSy65hH79+lFTU8OMGTNIS0sjNDSUTz/9tDPmKLowcwl7RwOxRiHeaopiraGWyvpKfD0cLy/c3Lp167j33nsZPnw4DQ0NPPbYY1x88cXs27cPHx/nmht3Ba4q1JFZmkmDsQEfdx+ifaJbPtlvKvSd3PaDpayEidOATquxWKJe7+HG81cNZGJiGHO/2c2+nDImv76Bxyefw03nxao3gzI3mm8w6IDhNU3vc2tbVTtM/eQYAOtnbuD2CXfyyCOPUF5Rbr3aYbOCHGx8A355AgZdD1f/x/V/CWch0z7B3NIai/vENEBkgBqYd8S0V9BaeqIGDRH6cJJWvwTB8XDhk+Bx5v9+EUJ0zO5ArHv37uzatYvPPvuMP//8k4qKCu644w5uvPHGFsU7hAAI9lFTE/84Usym9CLz3WZ7ebt5463zptpQzTdp33BOyDkkhSc19Wdx0IoVK1r8/MEHHxAeHs727dsZP368U2N3Ba4KxPw8/Lh/6P3UGmotr1a+exG462Haf8Ev0qlrCXEyXdw/kiE9Annoqz9Zf7CAJ77fy5rUAl68ZhChViqDQqtqh9PehYHXtHi+pLaEXUm7WPTbIq7sfWX7q/wxjfso//wMkm6GuLHOvqyznmmf4N+WpLR5zvRfYt6Ufjb9vjLtFZy9djZAi6IdpmItc/rdhu7Le0DnCZe84PwLEEKcERzqI+bm5sZNN93k6rmIM8yKPTm8t+EIAJsOF7Pp8GaiAryYN6Wf7f1ZCg7Cj/9gla6BOqNa8OOlP14CIEIf0dSfxUVKS0sBCA7u+C5oV1daVW/erJ4Y4VwgFuETwV2D7rL8ZH01ZG9Xv3eXmzWi6wn39+KDW4fz4aYjvPDTAX49kM+kV9fzzjhPhtoygIXKoJ8c+IQjZUd4cuOT/Jb9G/NGzSPAMwBQq/Cl5KdQUFVAmD6MpOgkdOfeCtvfhx8egr/9JuXPXWDSgCgSwn1Jy69o8Xikvb+ngOTYZBZOXNiijxiov6fmjJhDcn3jA8E9QSsVgIUQKrsDsY8++qjd52+55RaHJyPOHNb6s+SW1tjZn0VhVd42ZoeHorS6Y9yiP4sLgjGj0cisWbMYM2YMAwYMcHq8011qYyPn6AAvArw78UOdadXAzQs8/ds/VojTlFar4bYx8YzqFcKsz3ZyILecaT/BDr8w/OsL0VgsXa5B4x9tsTLo3wb9DU+dJ2/teIuVmSvZVbCL58c+T3lducUP83MH30fy/qVQsB82L4Ixf+/U13s22Hu8lLT8CrQaeOOGoTQYlRb7BO2xNH0pg8MG8/O0n1sG0abMjS2NKaUh0jNRCNHE7kDsgQceaPFzfX09VVVVeHh4oNfrJRATHfZn0aD2Z7moX2SHv+wM3oHMDwmyMpaCBg0Lti7g/B7n256maDRY3K907733smfPHjZs2GDbOF2cKRBzNi0R4LdjvxHrH0t3v+5t+71V5KtffcPBRUVWhDhV+kb68929Y3hxRSrv/Z7BI5U3ssj9VRSg+duZ2n5KYWf/OQy18N6k0+q4c+CdjIoexdz1czlSdoQ7f7nT4jXzq/KZvelJFo64keS1r8Pa+TDgagjo3imv8Wzxwe9HALhsYBSTB0W3f3A78qvymff7PAyKgeVXLWd45PC2BxWpDe8lEBNCNGf3+viJEyda/KmoqCA1NZWxY8dKsQ4BuLg/S1kGeW5uVj/Am/uz5LfN87do31J4dQB8eDl8fYf69dUB3DdjMsuXL2fNmjV07352fLhJzVVL1/eJdG6VqrK+kntW38PkbydTVlvW9gDTipg0bhZnCC93HU9O6ccHtw5npTKCu+tnkUvLdOZcQrinfhb3pHRvtylw/5D+fH7551yTcI3VY8xNgQs2YegxEuorYcWjrnkxZ6miilq+36UWWrltTJxTY32R+gUNSgNDwocQ4x9j5YLp6ldp5iyEaMahPWKtJSQkMH/+fG666SYOHDjgiiFFF2Zrf5a8Mhv6s9R0HKyBjX1c9i2FL26BZutriqJw/2eH+fZAKms//z/i4+Ntut6ZwFSoo6+TK2KmRs5h3mEEegW2PUACMXGG8nTXYVTgZ2UEK2uHMUJ7gHBKyCeQrca+GNFC400nS5UZTfTuei7reRlfpX1l9Rj1plMeKaOeYHjxYeh9odo0up1VZoNRsVia3xHN960d3XWUZe8uIyUlhZycHL799luuvPJK87HffPMNixcvZvv27RQXF7Njxw6GDBni0HU7y6dbs6hrMDKoewBJMUEOj1NrqOXLg18CMOOcGdYPNK2IBcuKmBCiiUsCMVALeBw/frzjA8UZz9b+LM//uJ/CilquHdbD6h4lW/uufJ76OWH6MIZFDLNcfayx3w+tkhzv/bGGT3bX8/10H/y2LCR38BTQ6ggICDijq4AqiuKyHmJtGjm31jw1UYgzSPObTka0bDb26/A4a2xuCuzlC7P2gHv777Mr9uTw9LJ9LbIT7C6W1GhV5qoW+9bK/yxH46nhrnl38fTfnm5zfGVlJWPHjuW6667jL3/5i13XOhnqDUb+tzkTUFfDnOlL+VPGTxTXFBOhj+DCmAstH2RogFr1/VZWxIQQzdkdiC1durTFz4qikJOTw5tvvsmYMWNcNjHRdXXUnwXUfWL55bU8+8N+Xv7lIFcldWPmqLg2QUFSeBIRipZ8DG2KdTSXkp/C7T/fTkJQAjf0vYHJ8ZPRu+ubDmjW76e5RX+opawmflgJpMHTalri+++/z6233mrHq+5ackprKK9pwE2roVeYcz3ZTCtiCYFWAjGNDnzCwM++D39CnO5sven0y95ckmKC6BGst3qMrTedDpUcoj72Isy3rozGNlX4XFcsSQ3CZq+d3aIku98gPzSDNHzDNxbPufnmmwE4cuSITdc42X7cnUNeWS1hfp5MHuj43jBFUfh4/8cATO87HXetlaJHOjd45DBUFYP+zK/IK4Swnd2BWPP0AwCNRkNYWBgXXHABL7/8sqvmJbowU3+Wu5ekoKHlGpQplHp1+hAqaw18uPEIqXnlfLIli0+2ZDGqZwgzR8eRfE44bjqt2p/Fowez645YGEsd7eFhD5NRlsHyw8tJO5HGM5ue4a0db/HzNT/jqVMbStOs348BSPHypECnY+sLniTV1GLeSm+h38+ZyJSWGB/qg4ebc6WUD5WoKTdWV8QmzlH/CHGGseWmE8APu3P5cU8uF/aN4LYxcYzuFdJmFcbUFDi/Kr9F0NPaO7vf4dtD33Jd4rVcqw0kdN3LcOOXall0XFwsyWhg/tb5FudjKpYEasXZruT9xiIdN42Mder9b3vedg4UH8BL59XuHj9ATSH1sZ6eKoQ4O9kdiHW1N1xxakwaEMWim5LapMa07s9yw4gebMko5sONR/hlXx6bDhex6XAR3QK9uem8WKYP70HyDcu4ecNX/C/tddCVNF2kIYCbE//Ozf2vBeCBpAf47tB3fHbgM4aED2kKwoDdxmoGAKv13swPCVILgDSKaGhgbtEJkquqz5p9TK5KS1QUpWlFzFogJsQZypabTvec34vd2WWsP1jAqv15rNqfR0K4LzNHx3F1Ujf0Hm6NYzU1BdagadMUWEFhUtwktudtp6C6gP/btYjBRBJadAh+mgMzvgCNplWxJCM6fQYat3KUBj8MVfEoaM3FktrbtwZqoNG8jH5rpjmml6bb+Td36uzIOsHOoyV46LTMGGmlsIaNcqty8ffw56LYiyzvjxVCiA64bI+YEK1NGhDFRf0i290srtFoOK9nCOf1DOF4STVLNmfy6dYsskuqWbDiAK+uOsi5sUFsTNcDj7T4UGGsiuf/0rQMDMph0oAoAjwDmNl/JjedcxOVDZXma6SdSGPGzhcJj+lBvoWbn/k6HbPDQ1lYYSTZQr+fM5GpYqKzhToKqwspqS1Bq9HSM6CnK6YmRJdi602nQ/kVfLTpCF9tP0ZafgWPf7eHF1cc4PrhPbhlVBw9gvUkxyZzc88nLN50uiXx7zw87lrqDfWsylrFumPrGNX3dpRFo9Gk/cILX81mnyGRQxnqv0M3vz14RixD615qHsZYH0Bt3hQaygdY3LdW01CDl1tTuuVTm56y6e/AYrXU05RpNezywVGE+Xm2f3AHLu95ORf0uIAaQwd7ANe8ADk7YfhfIMH5npdCiDOHTYHY7NmzbR5w4cKFDk9GnHl0Wk2Hd11NogO9eWRSX/5+YQLLdh3nw01H2JNdxsb0osYjtBiqWlacspRmo9Pq8PdoKsmeXpqO3k1PPlUWr6toNGgUhQUhwZwP2NiNrEtrWhFzrnS93l3PS+NfIq8qr8UHODNFgUVj1H0R130k+yPEGcmWm069w3155ooBPHRJH7784xgfbTpCZlEV7/yWwX83ZJB8TgT9o/z5v9V6lHZuOg2LC8a9OomQqnhu+r6YCYbLuVn7HcvKV1KuW4Ux3A8vn3jc/P9sM0+NWyle3ZZQk30TIb7DSC1O5c/CP/mzQP1TUF3Ab9f/Zu7J2M23G0fLj3b4+v27SKP2vLIaftydA8DtY1xTIVfvrm+5H9mSIxsgcwP0v9ol1xRCnDlsCsR27Nhh02DOVB4SwsTLXce1w3pwzbnd+WjTEX5c9jV/d/uGw0oUTzTc3uLY5j3JrAV8k+ImoT/wM/fmrbJ6TUWjIbeulJT8FMvNOM8g9QYjhwvUFUNnV8R83H2YFD/J+gHVJyB/r/q9h49T1xLidGbrTSd/L3fuGBvPbaPjWHswn/d/P8JvaYWs3JfHyn2mNMC2N50A7v04BUOr7Vrbmcr5Xhu4payUJYHhlLqVow3402Jle41GvTfi3e0zHtz8lcWVnKzyLOID1CDl+bHPM/27KymoK7VYLEmjqJPpFdA1SrIv2ZxJg1FheFwQA7oFODxOVX0Vuwp2cV7UebZ97ik29RDrGn9PQoiTx6ZAbM2aNZ09DyHa0Gg0BOo90GtqGKPbi6+x2uqx7ZaHLkilYu/XENrxL15bS0h3ZUcKK6kzGPHx0NEtsJNL9JtK13sFgptzaUBCnEm0Wg0X9I3ggr4RHMqv4MUVB/hln/X9WIA5CEsI92VIj0CGxgQxpEcgPUteJeGLG7mjrIr/XHA//0n/2mp7MfXxBmoMDfi4+zAgdACDQgcxOGwwA0IHEOLdFEyGeQXzaPEJZvtq0SiKORgz1Bioz6s1H5d5JIOdO3cSHBxMTEwMxcXFZGVlmVvapKamAhAZGUlkZKRjf2FOqqk38MmWLABuc3I1bPnh5fxr87+Y0H0Cb174ZvsH11ZAuboKZyqoIoQQJrJHTJzWwv28OKGoqzYhGuv7EKyWkTYa4Pv7CKuvAToOxGwtId2VmdISEyP90DrY3NXk+0PfE+odytDwoZbTc0zVKv1OzYcvIbqC3uG+TB4U1WEgBjB/2kCmD29VZCL6cki8FPeDP9GzLN+ma85Oms0t/W8xpyFalLmR5MJsFla1LHJUnVHNkQVHmsb6x0MAzJw5kw8++IClS5dy2223mZ+fPn06APPmzeOpp56yaX6utnTXcYoq64gO8OLifo4XZWpesn5k1MiOTyg+rH7Vh0hqthCiDYcCsT/++IMvvviCrKws6urqWjz3zTeW+4oI4YgR8cG4+YVCHQRR3uZ5Deqm+BHxVn7BbfkPHNtKkocfEV6h5NcUWSzFrEFDhD6CpPAkF7+C04+pdL2zaYkGo4F/bf4XtYZall+1nFj32LYHmQIxaeYsRLts7UkWG2wlxffSBTDiTsJ8A+Dn3yweUplaSeGPhVRnVnN7ye0EfRvUoiXNN998w+LFi9m+fTvFxcXseGMmQ4DkqmrOr6o2t/0ICzSQNM/fatuPW2+99bTqw6goirlIx82j4nDTOV6yflPOJg6XHkbvpufK3ld2fEKR2t6DYElLFEK0Zfe70Weffcbo0aPZv38/3377LfX19ezdu5dff/2VgADHc66FsESn1fC3S9U9Wz6aWjypa3PMvCn9LPfDKT4Mq59Rx7n4X8w9759AU/8xE3Wfg8KcEXPavzt8hjCviEU4F4hllWdRa6jFS+dFd9/ulg8yB2JnR1sAIRxl6klmbY1aA0S1d9MpKBZ6J5v7kbV+nwMw1hrxivGi3539LA5RWVnJ2LFjWbBggfrAnq/Mz+mA4TW19K2rY43em0WBzX7fn+b/vrdmFLM/pwwvdy03jOjh1Fim1bAre1+Jn4cN76FFpv1hvZ26rhDizGR3IPb888/zyiuvsGzZMjw8PHjttdc4cOAA1113HTExzvXkEMKS5CEJGDXq4m3rVbEZI2PM5aFbMBph6d+hoRrix8O5t5Icm8zCiQsJ17dcnfE1KoRrvRgdfZaUrs9TUzyd7SFm6h/WK7CX9QBWAjEhbGLqSQa0CaFMP1u96dRiHB1zB/4VmjVcNvEd6EfEtAhevu/lticaDdw8bTJPPvkkycmNJdY9/MHDr8WMCnU6/hfgz1d+vhjRgH83OM3bfphWw64a2p1AvYfD42SWZbL+2HoAbuh7g20nGerUv0Mp1CGEsMDuQCw9PZ3JkycD4OHhQWVlJRqNhgcffJC3337b5RMUAo0GrY+6gfw/0+J5bfoQbjlPTYNbsSeXspp6i+cw6Drwi4Ipr5vLhyXHJvPztJ9575L3WDBuAYt73oCf0UiesYb39rx30l7SqVJR28DRYrXoSV8nS9enldjQyFnrDj7hskdMCBuYepJFBrRMU4wM8GLRTUmWbzq1VpZD8jcPsjC/kHDPoBZPKQ0B9He7n+TYZr2sDA2w63N4ayQsf7DlWLd8B1f+X+MP6nvo0JpavI1Gitx0pHq4w6T5cBpnEhwtruKXfbkA3DYmzqmxPtn/CQDjuo0jLsDGsS74Jzx6FEb/3alrCyHOTHbvEQsKCqK8XF2V6NatG3v27GHgwIGUlJRQVWW5T5MQTvMJB6OBwREeDI7pxmUDo/g9vZD0gkre/PUQj112TsvjNRpIugUGXd+mWp9Oq2sqUR88gIc2vc7siDA+2Ps+VydcTbRv9El6USffwTz1326YnyfBPo7fGYamFbGEwHYCseR56h8hhE1s6UnWLv8oSEgmee+3nF+uI+XcBygoP0p1QygPr4zhgN4bg7Fxn2zGenjrmaby6tXFUF3SNJabB/SbqvYAXDEHyo7jDoysrmGtj57fR9zCOf2muvLlu9z/NmdiVGBs71Cn0rEVRWFP4R4AbjrnJvtO1mjUv0shhGjF5kBsz549DBgwgPHjx7Ny5UoGDhzItddeywMPPMCvv/7KypUrufDCCztzruJs9rffWjTFcddpefzyftz2/jbe/z2DGSNiiAv1UZvk1FWCp696YEcl0wNjSHYPZVh1DX94wyvbX+GlCS914gs5tQ66qFAHNAVivYNk74MQrmRrTzKrLnkeUn9Cl72d4dnbzQ+P8QrhmZoZHPs1Q31gy2Lo6w7ewTD6fhjxF/D0A0pajtdvKvSdDJkbYeUTjC1PY62Png0NRdzp+Cw7XVVdA59tNZWsj3NqLI1Gw5LLlvBH3h8MixjmgtkJIYQdqYmDBg1i5MiR5gAM4J///CezZ88mLy+PadOm8e6773baRMVZzkJTnPP7hDMhMYx6g8JzP+5XH9z5Cbw1AtKsN29uM3TsGOYUn0ADrDiygh35tjUw74pMhTr6OFmoo7qhmqPlRwFIDEp0el5CCBc69gc0tO2tGEERb7m/QeyGR9QHPP0h+WmYtRvGzW4MwqzQ6iB+HMSNZXS1mt68M38n5XVtq9meLr5OyaaspoHYED3n93G+cqtGo2F45HDbmjgDZKeoKZ9LJS1RCGGZzYHYunXr6N+/Py+88ALnnHMOM2fO5Pfff2fu3LksXbqUl19+maCgoI4HEsKFnrj8HHRaDSv35bHtz73w86NQlg15e2wfJHY0fevqudqoloWev3U+RsXYSTM+tUyl650t1OGudefTyz/l+bHPE+Jl5c59Qx28MQzen6w2NRVCdD6jQU0jtEADKECDqfD85a/C2FlNGQS2iJ9AjwYDcQYwKAa25GxxcsKdQ1EUPvhdXfmbOSrOqZ6J2RXZVDdU239i4UEoONDUS0wIIVqxORAbN24c7733Hjk5ObzxxhscOXKECRMmkJiYyIIFC8jNze3MeYqz3Z6v4YPLYf2/WzzcO9yPm8+LBRQalj4INaUQPRRG3Wf72HFjIX4898VNwcfdh9TiVPNegDOJoiik5plSE50r1OGmdaN/SH+m9Jpi/e5wZQEUpcHRzWCp2bMQwvUyN0LZcYtPVdQp/JlnYE+u2gYk41gOO3fuJCtLTd8rLi5m586d7Nu3D4DU1FR27tzZ8vd7zCjQujGmopxwrxCqGk7PveG/pal7iH093bh2mJX2Gjaat3EeyV8mmysm2szUQ0wqJgohrLC7aqKPjw+33XYb69at4+DBg1x77bW89dZbxMTEMHXq6b1pV3RhFQVw5DeLK12zkhO43nsboxq2YNC4wRVvgc6OOjQhvWDmMkLP/yfPjnmWr6d+zaCwQS6c/OmhoKKW4so6NBroHW7HHXBHmUrX+4SD1vEGqkIIO5j+3Vnwx3EDQ/9TydD/VAIwe/Zshg4dypNPPgnA0qVLGTp0qLky8vTp0xk6dCiLFy9uGsTTF7oN44ETJazqdStTe9n3e99gVNiUXsT3O7PZlF7UVDjEAQajgW252/jx8I9sy92GwWgwP/d+42rYNed2x8/L3eFrpJ1IY0vOFirqK+gdaOd+WFMPMWnmLISwwu6qic317t2bxx57jNjYWB599FF++OEHV81LiJb0jelvVUVtngpUynja7UOoh7eZxgz/RBxtLd6irPMZxpSWGBfig7eHc+Wml+xbgk6rIzkmmTB9mOWDKvLVr77O780QQtionZ59E+PcUOapq+H/F/sa99x2a4vnb731Vm699da2J7bWcwLeRzerN8eG2XB8oxV7cnh62T5ySpv2r0UFeDFvSj/bSvM3sypzFfO3zievqinwjNBHMHfEXHrqz2NNagEaDdw6Os6ucVszNXC+oMcF9lfUNa+ISUEjIYRlDt+mXr9+PbfeeiuRkZE8/PDDXH311fz++++unJsQTfTB6teqYgBeeOEFhg8fjp+fH+HRPZj+v2x+KY7i5erJvLE6zbFrVBZB5ibzjwdPHCSnIsfZmZ82Ul1UqAPgv7v/y/Nbniensp2/H2nmLMTJFzsa/KNp2xZapaDhuBLCB8eiMDq6GhU/Xv2asR6DoYGi6rY3yFpbsSeHu5ektAjCAHJLa7h7SQor9tj+XrsqcxWz185uEYQB5FflM3vtbJ5f+wWgFnSKC/WxedzWSmpK+OGweoP5xnNutO9kRWnaGyapiUIIK+wKxI4fP87zzz9PYmIiEydO5NChQ7z++uscP36cd955h/POO6+z5inOdq1WxNatW8e9997L5g2/sfLxi6k3wswvT1BX18AHG49wuMDO4hCFafBST1gyDQz1fHrgU65ddi3//uPfHZ/bRRxwUaGO4ppiimrU/w7tpuqYVsT8JBAT4qTR6mDSgsYfWgdj6s/zlZnkVzawL6fMsWt0Hw7D7+S3MXcy8cvzmfvb3HYPNxgVnl62D0thn+mxp5ftsylN0WA0MH/rfBQLoymNj24ufR8wOl2y/uu0r6kx1NA3uC/nRpxr38kVeVBXARotBDk3DyHEmcvmQOzSSy8lNjaWN954g6uuuor9+/ezYcMGbrvtNnx8HL/jJIRNfELVr1VFoCisWLGCW2+9lf6DhzD44e/54Pv15ObmM8CzkAajwnM/7Ldv/OBe4B0E9ZWQs4uk8CQAfsn8hT9y/3Dxizk1Dua5pofYoRNquk133+7o2yvCIStiQpwapibM/q3S/fyj0Vz3EVW9LgNg3cECx8Z384TJL9O9/3WU1JawPW87VfXWi3ZszShusxLWnALklNawNaO4w0un5Ke0WQlrPZrGvYSY6FzG9g7tcDxrGowNfJb6GaCuhtlcst6kphQiBkJY3477WQohzlo2B2Lu7u589dVXHDt2jAULFtCnT5/OnJcQLXk3piYa6tS7jK2Uuqv7lO6/dChuWg2rD+Sz3p4PGVotxIxWv8/8nT7BfZiWMA2AF7e92GITeFdkMCrmQMzZFbG0EjX1MyEoof0D3TzBNxL87Nv7IYRwgX5TYdYemLkcpr2rfp21G/pNZUKi+n7pcCDWKM4/jm6+3ag31vNHnvUbVvnl1oMwe48rqLJtzuPO8bQ/eGpmZ/5OcitzCfYK5tL4S+0fIKwP3L0B7t7o8ByEEGc+mwOxpUuXcsUVV6DTObfJXwiHeOjV5qM+YVBTBmkr4YtboCIfo9HIrFmzGDNmDJeOH8Eto+IAePaHfTQY7OgHFmsKxNRfnPcOuRdfd1/2F+9nafpSF7+gkyuruIqaeiNe7lpiQ5xbwU47YWMgdslz8FAqDL/DqesJIRxkasI88Br1q1b9/T0hUS2gk5J5grKaesfGNhrRHN3KGI1agXVD9garh4b7edk0ZKC+4+qGVosDtTKpr3ON5odFDmP5Vcv515h/4alzYkXLiWBQCHHmk5rSout4JAOueR/SV8O3f4N938Pm/+Pee+9lz549fPaZmkbywIUJBOndOZhXwSdbs2wf3xyIbQKjgRDvEP42+G8AvJbyGhUWVuK6itRcdS9IQrgfOicam0KzQCywg0BMCHFaignR0zPUhwajwsZDHRfasEyBj69lzCE1AGsvEBsRH0xUgJeV8iFN5n71J9/uONZuEZGk8CQi9BFoOhhtd1FKB1frWKx/LOO7j3d6HCGEsEYCMdE17FsKrw2EDy+HpfdDVSFodNz3380sX76cNWvW0L272rQzQO/O7IvUu6ELVx6ktMrGO76Rg8DDD2pLIW8vADP6ziDWP5aimiL+u/u/nfLSTgZToY5EJysmKorCoRJ1j1iHK2JCiNPWeHN6Yr5jA2h1EDeWkdU1uKHlaPlRssos3/jSaTXMm9LP4nOmcCpI705OWS0Pfr6LqW9tYFO65QBRp9Uxd8TcxnNbBmOKov7RoGFst7GOvS6grM7BIibNvX0+6x8cwJSLJhAdHY1Go+G7775rcchTTz1F37598fHxISgoiOTkZLZs2eL8tYUQXYYEYuL0t2+pmoZYdtz8kKIo3PdDBd/++Au/vv1P4uPjW5xyw4gY+kT4UVJVz6urD9p2HZ0bxIxUv29MT3TXufPQsIfw8/Aj0ifSJS/nVDCVrne2UIdGo2HltSv5cNKHxPrHWj+wthzeGAbvT4aGOqeuKYRwvQl9GgOx1AIUxfEy9j6KQhJq6l57q2KTBkQxLalbm8cjA7xYfFMSmx69kEcm9cHX04092WXc8M5m7vxwG4fy22YiTOwxkdsH3N4mTVFpCOAc3X2smLaCQWGDzI//d/d/+WjvR9QZOn4vKqwuJPnLZGavnU1Ng21729owGiBvL5X5hxk8aCBvvfWWxcMSExN588032b17Nxs2bCAuLo6LL76YggLn9u4JIboOpxo6C9HpjAZYMQdalSq+98caPtldz/fTffDbspDcwVNAqyMgIABvb2/cdFoev/wcbn53K//blMmNI2PpHe7b8fVG3AX9r4Ze55sfmtB9AiumrcDfw9/FL+7kSXVR6XoAfw9/kiKS2j+oIh+K0qA8B9w8nL6mEMK1zosPwcNNy/HSGg7lV5DgyGp5zwkAXFmUx+DxsxgeOdzqoYqisONoCQB3jI1jUPdAwv28GBEfbE6Xvmdib64b1oPXV6fx8ZYsVu3PZ01qATNGxPBAcgKhvmrA93v277y75116B/bmhbEvkFmSyxPfZFFTHsvDfx1DtG+w+bq5lbks2rmIOmMdnx74lAfPfZCLYi+yWsjjy9QvqW6oJq8qDy832/a2tVF6DAy1XNpHz6WPv2bem9fajBkzWvy8cOFC3n33Xf78808uvPBCx64thOhSZEVMnN4yN7ZYCTNZ9Ec9pbUw8cNKop5OI6pbd6Kiovj888/Nx4xLCCP5nPDGcvb7bLte4iUw9MbGhqgqjUbTpYOwmnoDR4oqAedXxGxmLl0ffnKuJ4Swi7eHjvN6qv0ZHa6eGNYXfMKZUlbC30NHtJuuvO3ICdILKtF76JiVnMgVQ7oxqldImz2rob6ePHPFAH6eNZ6L+kVgMCr8b3MmE19ay1trDlFTb+Crg18BMDp6NIaqXqzb0Z2a8nj6RQUwPC6o5XjeoTw28jFCvUM5VnGMf6z7Bzf/dDM783eajzEYDWzL3cbSQ0tZsm8JADf2tbOBc3PF6erX4J5Wg7DW6urqePvttwkICGDw4MGOX1sI0aXIipg4vVVY7hejzGsVGE17V60M1so/J/dj3cEC1qQWsDY1n4l9HA8MFEVh3bF1LE1fykvjX0Jn4y/YU+1QfgVGRd2DEebnXD+bd/58h+KaYq7sfSV9gttpYSE9xIQ47U1IDGP9wQLWphZw57ie9g+g0UD8eNjzFWSsg7gxVg/9tLFw0tTB0fh5dVwdsXe4L+/cMozNh4t47of97M4u5aWfU/lo6y6qI9cD8NWabrxVvNl8TnZJDT/vzWXSgKaWGW5aN6YlTuPS+Ev5YO8HfLD3A3YV7OLmn27m4tiLOS/6PP6z6z8tepNp0aLVOnif2miAgz+r33sHqj+387ti+fLlTJ8+naqqKqKioli5ciWhoY73PxNCdC2yIiZOb7Z+kLdyXHyoD7eOjgPgX8v3UW9LOfvCNNj0Fhxa3eLhivoKHtvwGCszV/LtoW9tm5cDFi1axKBBg/D398ff359Ro0bx008/OTzegWZpic701QH44fAPLNm/hPyqDjb4VzQ+L4GYEKctUz+xrRnFVNU1ODZIvFpVsCprE2uPrmVV5qo2h5RU1fHD7hxA3b9rj/N6hvD9vWN49fohdAv05oRuAwpGGirjySsOaHFsWXU9dy9JYcWenDbj6N313DPkHpZftZyrE65Gg4Y1R9fwzKZn2jSINmLkkXWPWHwt7dq3FF4dAFsWqz8f3aL+vM96+5Pzzz+fnTt3snHjRiZNmsR1111Hfr6DBVSEEF2OBGLi9BY7ujFN0FoAoQH/bk2l5y2474IEgn08SC+o5OPNmR1fc/dX8PNjsOvTFg/7efhxz+B7AHhjxxuU15Xb+CLs0717d+bPn8/27dv5448/uOCCC7jiiivYu3evQ+OZStf3jXQuvbLOUMeRsiOADRUTy3PVrxKICXHa6hXmQ7dAb+oMRjYfdrCMfd/L4Y5VrB93N/f/ej9v7nizzSHfpGRT12CkX5Q/g7oHWBikfVqthiuHduOXB8cSErkTgPqSkW2OM+0kfnrZPgxWSuCH68N5evTTfHb5Z+jd9O1ed8HWBRiMBtsmaaGoFABlOerjVvj4+NC7d2/OO+883n33Xdzc3Hj33Xdtu6YQosuTQEyc3rQ6mLSg8YfWwVjjz5Pmt5v6EeDtzj8uVsvZv7IqjROVHVTOMgV1R35XayE3c33f64nzj6O4pph3/nzHxhdhnylTpnDZZZeRkJBAYmIizz33HL6+vmzevLnjky044KJCHRmlGRgUA34efkToOwiwzCtiskdMiNOVRqNpUT3RIT4h0GM4o7qNQavRkl6aTk5F04qUoih8tk1NS7xhZIxTq/LbCzZTYShEadDTUN7f4jEKkFNaw9aM4nbHqqyvpLSu1OrzCgq5Vbmk5NvQj8xKUammGZmO6zgjw2g0Ultb2/E1hRBnBAnExOmv31S47iPwj2r5uH+0+ni/qR0OMX14DH0j/SitrmfhylQ2pRfx/c5sNqUXtb1z2n04aN2h/DicONLiKXetOw8PfxiA/+3/HxmlGWzL3caPh39kW+422++e2shgMPDZZ59RWVnJqFGjHBoj1UU9xA6eUNsAJAQmdPxhykMPflEtip4IIU4/E839xJwrmR7gGcCgULVk/O/Hfzc/npJ1goN5FXi767hiiHPvB1tztgJQX5oESvv7zPLL2y89X1Bl2+u16TgrRaUq6hR25hrYmaumfWakrGHnzp1kZWVRWVnJY489xubNm8nMzGT79u3cfvvtZGdnc+2119o0NyFE1yfFOkTX0G8q9J2s/sKryFNT3mJH21yRSqfV8OTl/Zjx3y38b3MW/9vc1Hg0KsCLeVP6NW3w9tBDtyQ1vz9zIwS37FE2vvt4xnQbw+/Zv3PtsmupNTTdvYzQRzB3xFySY5Pte31GQ4vXtrvMj1FjxlJTU4Ovry/ffvst/fpZbojanhOVdeSXq/NzdkUsrSQNsLGR82UvqX+EEKe10b1DcdNqOFJUxZHCSuJCfewfpOQo/PZvxpTmsBO1n9g1iWrxpE+2HAVgyuAo/G0o0tGeh4Y/RA+Pscz9Mr3DY8P92i8937oHWXOVqZUU/lhIdWY1k0sm8+2333LllVean3/qqaf47LPPOHr0KB4eHpzbpwfPDWhgZPeWH6n+OG7g/A+rzD/Pfu5NeO5NZs6cyeLFizlw4AAffvghhYWFhISEMHz4cH777Tf697e82ieEOPPIipjoOrQ6iB+nVkeMH2dzEGZSVlNv8fHc0pq2G7xN6YmZv1s8Z1z0OIAWQRhAflU+s9fOtm+Tt2mD94eXw9d3wIeX0+fn6ez88mW2bNnC3XffzcyZM9m3z8YS/M2Y0hK7B3nj6+ncfZe0E42BWKANgZgQokvw9XRjWGPJd4dXxXQesP0Dxmb9CcDmnM3UG+sprapn+Z/qSpG9RTqsuWbgSCJ9ItvbNUxUgNqfrD1J4UlE6CPQWBjJWGvEK8aLfndavvllbsT8559sWDKfOG0uFy+poqCyZerhxDg3lHn+TX8Or0dRFD744AO8vLz45ptvyM7Opra2luPHj/P9998zfLj1XmxCiDNPlwnEiouLufHGG/H39ycwMJA77riDioqKds+pqanh3nvvJSQkBF9fX6ZNm0ZeXsvqSBqNps2fzz77rDNfijgFDEaFp5dZDmQsbvCObSzDbCEQMxgNvL/3fStjqefbvMnbygZvj6pcem+Zw7ne2bzwwgsMHjyY1157rePxWmkq1OF8/zBTio5NK2JCiC5jQqK6l9PhQMwvAsL60q+uliA3PZX1lezK38V3O7OpbTDSN9KPIT0CHZ6fwWigrE59L9NpNcybogZIVnYNM29Kvzb9yVrTaXXMHTG38byWx/oP8idyWiQv3/eyxXNnTL+e5MhSev4yk/7bHmHhhBrKauHPPGt7wDouKiWEODt1mUDsxhtvZO/evaxcuZLly5ezfv167rrrrnbPefDBB1m2bBlffvkl69at4/jx41x99dVtjnv//ffJyckx/2megiDODFsziskptb5noM0G7x4jQaOF0myoLGxxbEp+Sptyxy3HsnGTty0bvFfMBaPB4Q3cqXmuKdQB8OWUL1lz3RoGhA5o/8CKAnjjXPjg8jbFToQQp5+JjQU7NqUXUVPv4D7X+AlogdE6tSrizvyd5t5hM5ws0rEpZxMXfnEhC7aqhZsmDYhi0U1JRAa0TD+MDPBi0U1JLfqItSc5NpmFExcSrm9ZVChCH8HCiQstp5gb6mHxWPjqdsjbTZ3Wh7eLRhLgq2dwpA5Hi0oJIc5OXWKP2P79+1mxYgXbtm1j2LBhALzxxhtcdtll/Pvf/yY6uu0G4NLSUt59910++eQTLrjgAkANuM455xw2b97MeeedZz42MDCQyMhIm+dTW1vb4kNxWVmZoy9NnCQdbdxuc5yXP9yxCsLPUfeMNeOyTd5WNng/uqqGSxPciAnQUp6XxSf3zmTt2rX8/PPPNl23uVRzxUTnSteDunoc6m1Do9GKXCg6BDWlasNXIcRprW+kH+F+nuSX17LtSDHjEqzvn7Iqfjxs/Q93FRVyz80/UFjix7O5G/Fy13LFkG5Oze+rg19RY2j5Hj5pQBQX9Ytka0Yx+eU1hPup6YgdrYS1lhybzPndxpOy+38UlGUR5h9D0sCb0bl5NB1kaJbWrnOHbueyfGs60z8vpaq2nKgoDSt/XUuoT456c635+7p/tBqE2VBUSghx9ukSK2KbNm0iMDDQHIQBJCcno9Vq2bJli8Vztm/fTn19PcnJTXe0+vbtS0xMDJs2bWpx7L333ktoaCgjRozgvffeQ+ngLv4LL7xAQECA+U+PHj2ceHXiZOho47bF47qf2yYIg/Y3edt1XIXlVbX8SoVbvq2mz5sVXPhRFdt2/MnPP//MRRddZNN1TRRF4WCemr7ritREm5lel6/tNzeEEKeORqMxN3d2uIx93FjQaOlZkE4Mbny6RV0Nu3xQNAHejhfpKKgqYO3RtQBMS5jW4jmdVsOoXiFcMaQbo3qF2B2EAbBvKbrXBzP8+9lctuZVhn8/G93rg9W08eoS9Zil90Pu7qZzkp/i/IW72bl7b8tGzKHnwaw9MHM5THtX/TprtwRhQgirusSKWG5uLuHhLVMH3NzcCA4OJjc31+o5Hh4eBAYGtng8IiKixTnPPPMMF1xwAXq9nl9++YV77rmHiooK/v73v1udz6OPPsrs2bPNP5eVlUkwdpobER9MVIAXuaU1FhMBNahpLR1t8IamTd75VfnmPWEtx9IQoY8gKTyp/YGsNDt+9wrvlg/MfEstTmKnYyeqqahtwF2nId6RSmjN/N/O/2Nf0T6m953O2G5j2z+43BSISQ8xIbqKCX3C+HL7MdYdLOBxRwbwDoSowXB8B9UH17DsT/W91NkiHd8d+g6DYmBo+FB6B/V2aqw2THt0W7+Pl+XAFzeDW+N7cW0ZpHzUVAnWJxQfH+gdHGFuxpyQkMC7777Lo48+6tD7tRDi7HRKV8Tmzp1rsVhG8z8HDhzo1Dk88cQTjBkzhqFDhzJnzhweeeQRXnqp/bLbnp6e+Pv7t/gjTm8ObfA2GmHFY7B4nLrvyTyW9U3epp/njJiDrqP9ALGjG/tstVP/y4kN3qa0xF5hvrjrnPunviVnC+uOraOktqTjg80rYh00fRZCnDbG9g5Fq4G0/AqyS6odGyR+AoT05tv0VAj/kIj4ZSTFBDo8J6Ni5Ou0rwHM5fBdxpY9ug2Nfw/n3QuXvND+cNKIWQjhgFMaiP3jH/9g//797f7p2bMnkZGR5Ofntzi3oaGB4uJiq3u7IiMjqauro6SkpMXjeXl57e4HGzlyJMeOHZM31DOQ3Ru8tVo4vAZy/4SslumsDm3ybk2rg0kLGn9w/QZvVxXqUBTFvtL1FY3/VmVFTIguI1DvwdAYtYz9ekerJ17wBMp9f/BOfjzu/nsx6v/EqFirJNixzcc3k12RjZ+HHxfHXuzwOBZZ2aMLzRsxq4VLMpRodu7eI42YhRAud0pTE8PCwggL63i/zahRoygpKWH79u2ce+65APz6668YjUZGjhxp8Zxzzz0Xd3d3Vq9ezbRpal55amoqWVlZjBo1yuq1du7cSVBQEJ6eng68InG6M23w/nF3Dvd/ugOtBn79x0S8PawEO7GjIX+f+ku7VZ5/cmwy5/c4n9lrZ/Pr0V+ZFDeJ+ePmd7wS1lxAd0ABNy9oaLYZ3QUbvA/kuiYQy6vKo7y+HJ1GR3xAfMcnyIqYEF3ShMQwtmeeYG1qvmMphTo3dh0tISM7BF8fb2ooZ0/RHgaHDXZoPl+lfQXAlJ5T8HKzbZ+vzazs0QULjZgbtyJII2YhhKt1iT1i55xzDpMmTeIvf/kLixcvpr6+nvvuu4/p06ebKyZmZ2dz4YUX8tFHHzFixAgCAgK44447mD17NsHBwfj7+3P//fczatQoc8XEZcuWkZeXx3nnnYeXlxcrV67k+eef56GHHjqVL1d0Mp1Ww+WDonj0m91U1DZw9EQViRFWgpXY0bDtv5C5wcpYOsZ0G8OvR3+lsr7SviAMYN2L6td+V0JgLKxfAOH94W+/OV3q2FU9xEyrYXH+cXjoPDo4GvD0A79o8LethLQQ4vQwITGMhSsP8vuhIuoNRodSmj/dkoUbCt3c+nJc2cHv2b87HIjNHTGXvsF9uTDmQofOb1c7N4pMjZgBteBGqz1f33zzjevnI4Q4K3WJQAzg448/5r777uPCCy9Eq9Uybdo0Xn/9dfPz9fX1pKamUlXVdBfrlVdeMR9bW1vLJZdcwv/93/+Zn3d3d+ett97iwQcfRFEUevfuzcKFC/nLX/5yUl+bOPk0Gg0JEb7syCrhYF55O4FYY2Pn3D1qBS3vwDaH9ArsBcChkkP2TSJnFxz8Se1XNv5hdUWsMBUiBzodhNU1GDlcUAk4X7o+raQxLdHWRs5TX+/4GCHEaWdgtwCCfTworqwjJfMEI3uG2HV+eU09xj8/Z5fnO3xjTOJFDfye/Tv3DLnHofmE68O5a1D7/UIdZtqjayU9Ud2jGy1NmIUQnarLBGLBwcF88sknVp+Pi4trU3bey8uLt956i7feesviOZMmTWLSpEkunafoOhLD/RoDsQrrB/lFQnAvKE6HrM3Qp+3/L70De6PVaPHUeVJnqLNt1QiaVsMGTIPQxmpg131o56uw7HBhBQ1GBT8vN6IDnEvpMe8PszUQE0J0SVqthvEJoXy38zjrDhbYHYh9v/M4GfXB+HjWclHhIV4M82Z34W5O1JwgyCuok2btIK0Oht4C6+ZbeFKaMAshTo4u0UdMiM6QEOELwMHGvVRWme6IZv5u8ekAzwC23biNZVctsz0Iy90DB5YDGhjn+lRYcyPnCD80TjZV1mq0eLt521aoQwjRpU3o09hPzM6CHYqi8MmWLHYpvanXehFZUUCiXwwKCpuOb+p4gGY252zmL7/8xdw/rFNUn1BL0gO4t+oX6R8N130k/b+EEJ2uy6yICeFqpnTEg/kdBWJjIP1X8LDei8vmAMxkfWOLhP5XQnjfpseNRqgsUPdZWWgmbQuDUWH1frVyYaDeHYNRcajRqcFoICU/hTHRY5jaaypDwoZ0fFLJUfjoCgiMgVu+s/uaQohTa1yCGojtPV5GfnlNyyb37didXcq+nDI83DzUm1cZvzLePQSf8BC83bw7HqCZL1O/ZHPOZuL845jYY6K9L6FjigLLZ0P5cTXj4a61aqp4RZ66dyx2tKyECSFOCgnExFnLFIhlFlVR22DA083KL95B18Hg6eDkypJZbTkc26Z+P/7hls+9d7H63PRPoe9ldg+9Yk8OTy/bR06pWoFx1f58xi74lXlT+rUtz9+OVZmrmL91PnlVTZXFIvQRzB0xt/3S/OW5ahqnsd7uuQshTr1QX08Gdgtgd3Yp6w8Wcs253W0679OtWQBcNiAS9x4TIeNX/l5Wi+bGz+26fmF1Ib9m/Qp0Qu8wk91fwt5vQKODq98BL39pwiyEOCUkNVGctSL8PfHzcsNgVMyFLSzS6joMwrbnbeemH2/iH2v/0fGFPf3g/hSY8SVEtCp3bKrkVZbd8TitrNiTw91LUsxBmEluaQ13L0lhxZ4cm8ZZlbmK2WtntwjCAPKr8pm9djarMldZP7kiV/0qpeuF6LIm2pmeWFHbwPc71aIXN4yIURs7A5qsjWBosOvaS9OX0qA0MDB0IH2C+9h1rk1KsuCHxvfpiXOh+7muv4YQQthIAjFx1tJoNPQxpSfmdZCeCI1pg0UWn9JpdOwq2MWugl22XdzdCxItNCj176Z+tVrJyzKDUeHpZftQLDxneuzpZfswGC0d0XwcA/O3zkexMJLpsQVbF2AwGiwPID3EhOjyJiSqgdhvaQUdvmcALN15nKo6Az3DfBgRH6xWfvUKhNoyyNlJaW0ph0sPdziOUTHy9cGvgU5cDdv4pjqv7sNh7OzOuYYQQthIAjFxVktoDMTS2qucCHBoNbzUE7642eLTPQN7Amrz47K6MuvjHN0K1oIYUDeJg92B2NaM4jYrYc0pQE5pDVszitsdJyU/pc1KWMtxFHKrcknJT7F8QIW6Nw3f8I6mLIQ4TQ3pEYiflxslVfXsOlbS4fGmtMQZI2LU4kBaHZx3D1zwBCvLDjH+8/E8vfHpDsfZlruNrPIsfNx9mBTXSRWNL3kOJj4GV78NOtmdIYQ4tSQQE2e1xMbKiakdrYgFxqpVto79AfVtAx5/D38i9Ooq0OESK3d+i9LhvUvgrZFQYyVYM6+I2ZeamF9uPQiz57iCKttSkaweJytiQnR5bjot4xJCAViX2v57wp7sUnZnl+Kh03J1UrP9ZBPnwPiH6NtjDEbFyK6CXZTXtf8++9XBrwCYHD8ZfetKhq6ic1fnFtyzc8YXQgg7SCAmzmqJ5hWxDgKxkF7gEw6GWjhueTWod6DaC8xqY+ffFoJiVD8AeFlpsuzgipitlc06Oi5MH2bTOFaPkxUxIc4IpvTEjvaJmVbDJg2IJNinbfXYHn49iPOPw6AY2JKzpf1r9pjAkLAhTEuc5uCsraivht9fh4Y6144rhBBOkkBMnNVMvcQyi6uoqW8nZVCjaeondsRyP7Fegb0ASC9Jb/tkcQbs+lT9fsIj1q/j31jZsOy4WmLZRiPig4kK8MJaSRENEBXgpe7faEdSeBIR+gg0VkbSoCFSH0lSeJLlAbwCwC9a/SOE6LImJKo3U3YdK+FEpeUAprJ1kY7WKgpg91eMDeoHwIbsDe1e8/Kel/O/y/5Hv5B+TszcglVPw8on4LMZrh1XCCGcJIGYOKuF+XoSqHdHUeBQfgf7xOLGql+tNHY2rYillaS1fXLDQlAM0OtC6D7M+jX8oqHflTD8DjDYXgJep9Uwb4rlDy+mkGrelH4d9hPTaXXMHTHXyjjquXNGzEFnrcfOVYvhH/uhTyft7xBCnBSRAV70jfRDUeC3Q4UWj1n+53EqahuID/XhvJ4WbvL88k/4+g7GVKoZB78f/x3FjhtMLpH+K2xZpH4/4q6Te20hhOiABGLirKbRaJrSEzts7Ny4InZ0q8UgqXdgb6J8osx7xcxKsmDnJ+r3E+a0fw13L7juQ3VDuZt9TaInDYjirRltV6oiA7xYdFOSzX3EkmOTWThxIX4efi0ej9BHsHDiwvb7iAkhzhim9MS1qfkWn/9k61EAbhjRQy3S0Vr8eACG5aTiqfMktzLXYvXE3QW7+WjvR5TUlLhm4iZVxfDdPer3w++0XKlWCCFOISkZJM56iRG+bM0o5mBHlRPDzlFLMteUQM6uNitbA8MG8ss1v7Q9b8MrYGxQe+vEjHTZvC0ZGhsIgFYDL187mMgAb0bEB3e4EtZacmwypbWlvLvnXfoG9eWGc24gKTzJ+kqYEOKMMyExjP+sP8z6g4UYjQraZu8je4+XsutoCe46DdOSrDR9bgzEvLJ3MOy8q/k9dwsbsjeY07hNluxfwo8ZP3Kk7AhPjnrSNZNXFFg+C8pzICQBLvqXa8YVQggXkkBMnPVMK2IHcztYEdNqYdjt6n4xfYhtgxuNUNiYqtjRaljzcyoLQOsGPjZep1FGodqYOiZYz1XWPhzZaFriNPs2zRemwcfXQmgi3PiFU9cWQpx6w+KC0XvoKKyoZV9OGQO6BZif+6xxNeyS/pGE+HpaHiAwBoLi4UQGMwL6kxw/iXHdxrU4pKSmhJWZKwFcW6Rj12ew73v1ffTqt8Gjk6owCiGEEyQ1UZz1EsIbA7GOUhMBkufBhU9CcHy7h9UbG1MXtVqYuQzu/BXixtg2oZ8ehpcTYcti245vJrOoCoC4UB+7z3Va2XE4kQEnjpz8awshXM7DTcvoXo1l7JtVT6yqa+C7HWqLjRmWinQ013MCAONLCrgm8RoifFqmbi9NX0q9sZ5zgs+hf0h/h+e6fv16pkyZQnR0NBqNhu9ee1h9YuJc6sMHMmfOHAYOHIiPjw/R0dHccsstHD9uX3VaIYRwNQnExFnP1EvsaHE1VXUNTo31ReoXTPh8Ai9ufbHpQY0Gup9r+yB+kepXO0vYAxxpXBGLC3EuEFMUBaNitO8kKV0vxBlnQp/GMvbN+okt/zOH8toG4kL0nNezg1X7xvREMta1eUpRFL5KU3uHXZN4jVPzrKysZPDgwbz11lvqAxc8ASP+CmMepKqqipSUFJ544glSUlL45ptvSE1NZerUqU5dUwghnCWpieKsF+LrSYiPB0WVdRzKr2BQ98D2T6gugaNbIKI/BLRM//PUeVJcU0x6aTqkrVIDMO8g+ybkYFNngCNFpkDMuTSco+VHuXrp1fQO7M2nkz+1vBG/NWnmLMQZZ0KCGohtzzpBWU09/l7u5t5h00fEtNg3ZlFcYyCWt4f8ooOszN+Gu9ad6/pcR0p+ChmlGXi7eXNZ/GVOzfPSSy/l0ksvbXrALwIu+ysAAQEBrFy5ssXxb775JiNGjCArK4uYmA5W9YQQopPIipgQNNsn1lHBDoCv74BProP9y9s8ZSphn34iDT6/EV4ZqPYQs4eDTZ0BjhSqqYmxTqYmZpVnUWuopdZQa1sQBlCRq341regJIbq8mBA9PUN9MBgVNh4qZH9OGTuy1CId15xrwz5U3zC4/mN4cB97K7OZv3U+H+z9AICvDqqrYZfFX4avh6/zk83ZBYfX2nRoaWkpGo2GwMBA568rhBAOkkBMCJrSE9PybNgnZipjb6GfWHyAunesuLaEYmMdhPWBoDj7JmNeEbMvEDMaFTKL1RWxeCdTEzPLMgGI9Y+1/SRJTRTijGRKT/zij6M8/+N+AC46J4JQa0U6WjvncgjoxoioEeg0Oo6WH+WjvR9RVF2EDp3TaYkA1FXB13fCR1d0eGhNTQ1z5szhhhtuwN/f3/lrCyGEgyQ1UQggoXFFLNWmQKyx6EbmRrVEcrMVI727nu4+0RyrPE66hzvBE+a0eN4mfo39vurKoaYMvGz7oJBXXkNNvRGdVkO3IG/7rtnK0XK1IlqMnx0pO5KaKMQZycdDbVvx64GmfWKbM4pZsSfH5v6EAJuOb0Kn0WFQDLz0x0sATxL0lQAASApJREFUhHmHkVORw4DQAfZPzGhQ34cr8mDvt1B4EHwjgTKrp9TX13PdddehKAqLFi2y/5pCCOFCsiImBE2piWm2pCZGDwU3L6gqVH/xt9LboKhjhcZDwkX2T8bTF7way0TbsSpmSkvsEeSNu865f9qmFbEYfzsCMX2IuprnZ/sHMyHE6W3FnhzeWpPe5vETlXXcvSSFFXtybBpn1S8PMXvtg9QZ61o8XlhdyD/W/YNVmavsm9i+pfDqAPjwcjVd/EBjqnjSzVZPMQVhmZmZrFy5UlbDhBCnnKyICUFTamJ2STUVtQ34erbzT8PNE7oPhyO/qemJYX0AWLRoEYveepOD6fupR8OcuFCCuq1ouYHcVkMbP0zY0fvGVKgj1sm0RICsMnUzvl0rYte85/R1hRCnD4NR4ell+1AsPKcAGuDpZfu4qF9ku03jDUYD84+vREFpkyGgoKBBw4KtCzi/x/m2NY3ftxS+uKVxFq2s/7fFU0xBWFpaGmvWrCEkxL4ejUII0RkkEBMCCNR7EObnSUF5LWl55QyN6aDSYeyYxkBso9rkGejevTvzbzyXghN5LA8Moy4zkSuuuIIdO3bQv7+d/XEuec7u12AqXR/vZKGOemM9xyvUlTi7VsSEEGeUrRnF5JTWWH1eAXJKa9iaUcyoXtYDm5T8FPI0RtTQzdI4CrlVuaTkpzA8cnj7kzIaYMUcWgdhFXUKh4qbrpFxOJ2dO3cSHBxMVFQU11xzDSkpKSxfvhyDwUBurlpcKDg4GA8Pj/avKYQQnUQCMSEa9YnwawzEKmwIxBoLdhz53bxPbMqUKeC+EbYqzLzqRThnCsFfBrN582b7AzEHuKp0fVV9FRN7TCSnModwvRTeEOJslV9uPQiz57iCqoJ2n7fruMyNFlO2/zhu4PwPq8w/z/7HQwDMnDmTp556iqVLlwIwZMiQFuetWbOGiRMn2jQ/IYRwNQnEhGiUEOHLhkOFHLSlYEf34TDltabCHSaTXoDz7sbgE8WXn31GZWUlo0aNsn8yRgNUFoChDgJtW5VyVen6AM8AXjn/FftOytmlpgpFDIDpHzt1fSHE6SHcz8slx4Xpw6w+V5laSeGPhVRnVjO5ZDLffvstV155JaCmEz7++OP8+OOPHD58mICAAJIHRDB/oJFov5b7YCfGuaHMa7bna9q7MLCpGqOiWEqwFEKIU0uKdQjRKNGeyokeejj3VghNaLHnYffu3fh274entzd/+9vf+OSLT+jXr5/9k9n5MbzcB5bPtulwV5aud0hZDpw4AqXHTv61hRCdYkR8MFEBXlYSCtUkwKgAL0bEB7c7TlJ4EhH6CDQWYiFjrRGvGC/63dn2fbKqqoqUlBSe+Oc/SfnsBb6Z7k/qvt1M/bSq7UCtSfVWIUQXIIGYEI2aeonZUDnRxGiAjN9gxWOQsoQ+Cb3ZuXMnt/3nNtzHunPbbbexb98++ydjZ1NnV5aur6yvtP/usZSuF+KMo9NqmDdFDZBaB2Omn+dN6dduoQ51HB1zR8wFDWhavbf4D/InclokL9/3cpvzAvz9WfnGLK478QZ9tj/Bef45vHlFKNtzjGSVWnuP0qjVW03p40IIcRqTQEyIRr3D1RWx3LIaSqvrOz5h1+fwYrxaPnnzW7D0XjxeH0Dvun0MHDqQyGsjCe0VymuvvWb/ZMxNnbNtOtyVpesfWvcQIz8Zyc9Hfrb9JGnmLMQZadKAKBbdlERkQMv0w8gALxbdlGRzH7Hk2GQWDriHcIOxxeMR+ggWTlxIcmxy04OKAodWwTvnw2czIG8PePrDxMconfwfNBoNgV4arIaHk+aDLdUXhRDiFJM9YkI0CvB2J9Lfi9yyGg7ll3NubDvpNvuWwrd/pU355Koi+OIWel/4D/XHuipqa2vtn4xpRaymBOoqwaP9dENXl66vbqgmyLODgiXNyYqYEGesSQOiuKhfJFsziskvryHcT01H7GglrLXkoXdxfr8bSTnwJQVlWYT5x5A08GZ0bq2qFtZVwFd3qO9/7j5w3t9g1H3UaPXMGTOGG264Af+br1erJzbPGvCPVoOwflOdf9FCCHESSCAmRDOJkX7kltVwMK/CeiBmpXzyo6tquDTBjZgAHQ3L3yd3bzmFuwuZ8dIM+yfi6Q8evuoHkrIcCO3d7uGmQOyUla6XQEyIM5pOq2m3RL1NDvyAbsUchjcPntb8GyYtgOD4psc8/WDCI1CaDWMfBN8wtQ/YtGkoisKiRYvA3x/6TlarKFbkqe89saNlJUwI0aVIICZEM4nhvqw/WNB+5UQr5ZPzKxVu+baanAqFAM8KauJ8iPtHHIPHDLZ/IprGfQ6FqWp6YkeBWKFpRcy50vW5Fbk0KA146jztK11vSk30k0BMCGGBtSbMZcfhi5vbHj/qXvO3pmbMmZmZ/Prrr/j7N1ZH1OogflznzVkIITqZBGJCNGOqnNhuIGZa/Wnl3StaFsmY2jeJjNpC0kvSifBxIEDxj24MxDou2JFZpO4Ri3NyRSyzPBOAHn490Grs2GvmGwb+3cHPtv0iQoiziJUsAluYgrC0tDTWrFlDSIiTq3JCCHEakUBMiGYSGisnHmyvcqKN6Xe9/XqQUVtIWkkao7s5UMHrnMshor9aIr8dRqPSrJmzc4FYVlkWADF+dqQlAly/xKnrCiHOYFayCAAq6hQOFTcV8MjIyGDnzp0EBwcTFRXFNddcQ0pKCsuXL8dgMJCbmwtAcHAwHh4eFscUQoiuQgIxIZpJaFwRKyivpaSqjkC9hV/0saPV1aqyHCzf4dWAfzTjEq4gMLg3fYL7ODaZ4XfadFh+ea25dH13J0vXZ5WrgVisf6xT4wghhJmVLAKAP44bOP/Dpr5gs2ervRNnzpzJU089xdKlSwEYMmRIi/PWrFnDxIkTXT5VIYQ4mSQQE6IZX083ugV6k11SzcG8CsuNSrU6dXP5F7eglktuHow1lU++KnEqVzGt0+ec0bg/rLsLStf3CerD+T3OZ2DYQFdMTQgh2s0imBjnhjKvcc/XzOVt9nzZ3dNQCCG6EOkjJkQrieb0xHb2ifWbCtd9BP6t9kT5R6uPu6J8stEI5bmQv7/dwzJdlJYIcFXCVbx+wetcFHuR7Scd3QqvDoIvb3P6+kKIM5Api6BN3y8TacIshDg7yYqYEK0kRvixJrWDyomgBlsdlE+uaajhcOlhYvxi8PXwtW8i+Xth8VjQh8Ij6VYPyzAHYs5VTHRYWTaUZDb1PhNCiOZszCKQ0vNCiLONrIgJ0UqCLZUTTUzlkwdeo35t9UFixo8zuH759ezI32H/RPy7qV+rCqG+xuphptL1zlZMrGmoobC60P5UIFPpel87yt0LIc4uJyOLQAghuhhZEROiFVNqYlp7lRNt1DOgJ2kn0jhUcohx3e3sd+MdBG5e0FAD5TktG542Yy5d72Rq4h95f3D3qrsZGDqQTyZ/YvuJ0sxZCGELG7IIhBDibCKBmBCt9A5XA7GiyjqKKmoJ8fV0eKxegb0AOFRyyP6TNWr1RYoPq6WfLQRiLUrXO7kiZipdH+YdZt+J5kBMVsSEEB2QJsxCCGEmqYlCtKL3cKNHsFoGvt1+YjboHdgbgPQS63u82mVKT7TSg+e0KF1vTk2MdOr6QgghhBBnEwnEhLCgT+M+sbR8G/aJtcO0Ina49DBGxdjB0RaYCmCUZVt82pWl600rYj38e9h3YrnaYFVSE4UQQgghbCeBmBAWmAp2pOY6F4jF+MXgrnWnuqGa4xWWV7XaZQ7ELJ/rytL15hUxPztXxPyiIKAH+MmKmBBCCCGErWSPmBAWuKpgh5vWjfiAeA6eOEh6STrd/brbN0DcODDUQ9xYi0+7qnR9g7GB7HJ11S3GP8a+k2/8wqlrCyGEEEKcjSQQE8KChPDGEvb55SiKgkZjrRFpx67vcz2V9ZXEB1iuetiu3heqf6zILGysmOhkoY6cihwalAY8dZ6E66XohhBCCCFEZ5NATAgLeof7otVASVU9BRW1hPt5OTzWdX2uc+HMWjriotREd507N/e7mTpDHVqNZCwLIYQQQnQ2CcSEsMDLXUdMsJ4jRVWk5VU4FYg5RVHU8vCl2RA1GHRuzZ5yXen6SJ9IHhn+iP0nHl4HS++HmFFw9X+cmoMQQgghxNlEbn0LYUViY8GOg3nOFewwKkbSS9JZcWQFBqPBvpMVBV4dCP+9QG3q3ExemetK1zus7DiUZDb1EhNCCCGEEDaRQEwIK1wViCmKwvXLr+fhdQ+TXWG5DL1VWm1TNcJWlRNNq2GuKF1/uPQwxTXFKIpi34kVjaXrpWKiEEIIIYRdJBATwoqExsqJzjZ11ml19AzoCUBaSZr9A5ibOrcM4o409hCLdUHp+gd+fYAJn09gW+42+040N3OWAh9CCCGEEPaQQEwIK5qviNm9UtSKqbFzekm6/Sdb6SV2pEitmBjvgtL1x8qPAQ6UrjelJEozZyGEEEIIu0ggJoQVPcN80Gk1lNc0kFdW69RYpkDsUMkh+0+2Foi5aEUsp9KJ0vXmFTEJxIQQQggh7CGBmBBWeLrpiG1cbXJ2n1jvwN6AoytiVlITG/eIxTtZMTGrLAuAHn497C9dX964R0wCMSGEEEIIu0ggJkQ7+rioYIdpRSyjNIMGY4N9J1tYEVMUhczG1MRYJ1MTM8syATUQs1tAdwiIkWIdQgghhBB2kj5iQrQjIcKPn/bkOh2IdfPthrebN9UN1RwtP0p8QLztJ0cMgNH3Q1hf80N5ZbVU1xsaS9c7F4gdLT8KQKx/rP0n3/KdU9cWQgghhDhbSSAmRDsSXVQ5UavR8sjwRwjyDCLMO8y+k0N6wcXPtnjIlJbYLdAbDzfnFradWhETQgghhBAOkUBMiHaYKiceyq9AURQ0Go3DY12TeI2rpmUu1BHn5P4wgMt6XkaMfwyDwgY5PZYQQgghhLCNBGJCtCMuxAc3rYaK2gaOl9bQLdD71EykPA9Kj0FwPOiDzaXr45zcHwZwec/Lubzn5fafePBn+PEhiJ8AV7zp9DyEEEIIIc4mUqxDiHZ4uGnNVQmd3SdWVV/Fmqw1fHnwS/tP/vxG+O8FcGQD0GxFzAXNnB1WegxKsqCq+NTNQQghhBCii5JATIgOJEaq6YlpTgZiJbUl/H3N33l+y/PUG+vtO7lV5URXla7Pr8rnz4I/Ka0ttf9kUw8xPyldL4QQQghhLwnEhOhAYrgaiKXmOlewI8onCr2bngZjg7l3l81MvcTKj7u0dP3qrNXc+OONPP774/afXCE9xIQQQgghHCWBmBAdMFVOTMt3bkVMo9GYGzsfKjlk38nNVsTyy11Xut4UEMb6OVC63rQi5hvu1ByEEEIIIc5GEogJ0YGECFNqYgVGo+LUWKbGzs4EYhmFritdn1WuBmIx/jH2n1yRp36VFTEhhBBCCLtJICZEB+JC9HjotFTXG8guqXZqLFMgll6Sbt+JptTEsmwyi1xXut60IuZYIGZaEZNATAghhBDCXhKICdEBN52WnmGuqZzoitTEjAJTxUTn0hIbjA0cqzgGOJiaGBgLgTESiAkhhBBCOED6iAlhg8QIPw7klnMwr4ILz3E88DCtiGWVZVFnqMND52Hbib6RMPp+8O/O0bQywPnS9TmVOTQYG/DQehDh48Bruu0Hp64vhBBCCHE2k0BMCBuYCnY4uyIWoY/gpfEv0TOwJzqNzvYT3Tzg4mcBSN+8HoC4UOdWxI6WHQWgh18PtBpZHBdCCCGEOJkkEBPCBqaCHc4GYhqNhknxkxw+v3npemdXxGIDYpkzfI7tq3JCCCGEEMJlJBATwgaJjYHYofwKDEYFnVZz8idRWUTxsVRCG46TrYlwunR9N99u3NTvJsdO3vsd/PIEJF4Mk192ah5CCCGEEGcjyUcSwgYxwXo83bTUNhg5Wlzl1FjZFdl8uPdDPj3wqX0nrptPyKeXcr1uLd2D9E6XrndKWTaUZkF1yambgxBCCCFEFyaBmBA20Gk19ApzzT6xrLIs/v3Hv/l4/8f2ndhYOTFKU0yskxUTAdYdXcfeor3UG+rtP7k8V/0qFROFEEIIIRwigZgQNuoT2djYOb/CqXFMJeyPlh+l1lBr+4mNvcQiKSbeyR5iDcYGZq2dxfTl0ymsLrR/AHMPsXCn5iGEEEIIcbaSQEwIGyU0Vk5MzXVuRSzUOxR/D3+MipGM0gzbT2xcEYvUFBN7qkvXV+SpX2VFTAghhBDCIRKICWGjxHDXVU50qLFzs9TE+BBvp+bgdOl6WRETQgghhHCKBGJC2MhUOfFwQSUNBqNTY5kDsRO2B2KKXxQAek0t8b4NTl0/qzwLgB7+PRwbQFbEhBBCCCGcIoGYEDbqHuSNt7uOOoORTCcrJ/YK7AVAekm6zefkV2soVtT0yO66E05dP7MsE4BYv1j7TzYaIaQ3BMZKICaEEEII4SDpIyaEjbRaDQkRvvx5rJS0vHJzFUVHmFbE0kttD8SOFFbyS8MV+Om9mOXnXErg0XI1NTHGP8b+k7VauONnp64vhBBCCHG2k0BMCDskhPvx57FSUnMrmDTA8XEGhA7g08mf0jOgp83nHCmq5F3DZMZFhoKfcytRphUxhwIxIYQQQgjhNAnEhLBDYmPlxIP5zhXs0LvrGRBqXyR3pEhNh3S2dD3AI8Mf4XDpYRKDEp0eSwghhBBC2E/2iAlhB1PBjjQnKyc64khhJX5UMcztMBzf4dRY47qPY2b/mQR7Bdt/8s5P4JUBsOIxp+YghBBCCHE2k0BMCDuYeollFFZS72TlxD9y/+DZzc/yReoXNh1/pKiKS3TbmLrtZlj9jFPXdkppNpQehdqyUzcHIYQQQoguTgIxIezQLdAbHw8d9QaFI4WVTo2VXpLO56mfs/bo2g6PVRSFzKJKcpTGFayy4w5fd2/RXn4+8rO5l5jdpHS9EEIIIYTTJBATwg4ajYaECFNj5wqnxrKnhH1BeS1VdQbycD4QW56+nIfWPcTnqZ87NoAEYkIIIYQQTpNATAg7mQp2pDq5T8xUwv545XGq6tvvS5bRuPqmDeimPlBbBjWOpQY6VboeoCJf/errXAl9IYQQQoizmQRiQtjJVQU7Ar0CCfEKATpeFctsrJgYERoKngHqg+U5Dl3X6dL1siImhBBCCOE0CcSEsFNTaqLzlRN7B6mrYodKDrV7XEaRuiIWF+ID/tHqg2XZdl+vwdjAsYpjAMT4yYqYEEIIIcSpIoGYEHYypSYeKaqitsHg1Fim9MSOArFMUyAW2jwQs3+fWG5lLg3GBjz+v707j4+quv8//prJRhKyEMgqSQg7iKBhK36rbBGCSBVo6xIrtIhVQWSrqGgBvyqI4o9iKVhF0SKgVkFFRQEbQEWCpGGRRcg37AkJW0IIWZi5vz+GjAzZt5kkvJ8+8oC599xzPzm5PB5+cs79HLMnYb5hVb6eSwUQ1gWatdKMmIiIiEgNaENnkSoK82+Cn5c75wsukXbqAh3D/KvdV3HBjqy8rHLbpZ2yLU1s1dwHmv0B2g2Clj2rfL8jOUcAaOnXErOpGr+HcfeCMV9X/ToRERERcaBETKSKTCYT7cP82H74LD+fzK1RIjak1RAGRQ8ioPi9r1IUl66HyzNiwcOrfb8j522JWLXfDxMRERGRWtFgliaeOXOGhIQE/P39CQwMZMyYMeTmll8+/J///Cf9+vXD398fk8nEuXPnaqVfkeLliT9n1Ow9saaeTctNwuCX0vVmE0Q286nR/fpH9md+//k80PmBGvUjIiIiIjXTYBKxhIQEfvrpJ9atW8eaNWvYtGkTDz30ULnX5OXlER8fz9NPP12r/Yq0C6m9gh0VKS5df10zbzzdzVB0EY79CKnfVLmvUN9QBkYNpGdY1Zc1ArBtCbx6PaybUb3rRURERARoIEsT9+7dy9q1a9m2bRs9evQA4LXXXuP222/nlVdeISIiotTrJk6cCEBiYmKt9itiL2GfWfPZ0w9//pB1h9YxvN1whsQMKXG+uHR9q+a+tgNn0uDNgeDdDKYdqvH9qyTnOOQcgwr2PRMRERGR8jWIGbEtW7YQGBhoT5YA4uLiMJvNbN261en9FhQUkJOT4/Al15bipYmHT18gv6hmlRPTstPYkr6FnVk7Sz9/Zel6+KVq4sWzUFj5hMhitbBk1xLWHV5HkbWoesHa9xBT6XoRERGRmmgQiVhGRgYhIY7/4+fu7k5QUBAZGRlO73f27NkEBATYvyIjI6sdgzRMwX5eBHh7YDUgNatms2IVlbAvLtQR3fzy+2FNAsDjclJWhU2dM/IymJ88n2mbpmGu7j99+x5iKl0vIiIiUhMuTcSefPJJTCZTuV/79u1zZYileuqpp8jOzrZ/HT161NUhiZOZTCY6FC9PPFmzRKy4hH3qudRSzxeXro9p4Vt882pt6nw45zAAkX6RuJndqhesfUZMiZiIiIhITbj0HbEpU6YwevToctu0bt2asLAwMjMzHY5funSJM2fOEBZWjU1pL6tuv15eXnh5eVX7vtI4tAttStKhM+yvYcGONgGX9xK7mEV2QbZDFcUSpeuL+UfA6QNV2tS5eA+xKL8alK63z4hpaaKIiIhITbg0EQsODiY4OLjCdn369OHcuXNs376d7t27A/DNN99gtVrp3bt3te9fV/3KtcFesKOGiVhTz6aE+YaRcSGD1HOpxIbG2s+VWbo+oKXtzyrMiNV4DzGr9YpErPq/ABERERGRBvKOWKdOnYiPj2fs2LEkJSXx3XffMX78eO655x57ZcPjx4/TsWNHkpKS7NdlZGSQkpLCwYO2d2927dpFSkoKZ86cqXS/ImVpd7lgx85j2XyScpwtqaexWI1q9VU8K7b64Gq2ZWzDYrUVADl0uWKivXR9MfvSRCfOiBVdgJY9oVkM+LaoXh8iIiIiAjSQ8vUA7733HuPHj2fgwIGYzWZGjhzJggUL7OeLiorYv38/eXm/VJFbvHgxs2bNsn++9dZbAXj77bftSyIr6lekLMfOXgQg83wBj69MASA8oAkzhnUmvkt4pftZf3g9/838LwCrDq5i1cFVhPqE8mSvJzlzqgNwRcXEYu0Gg28wRNxU6fvUeEbMyw/GfFW9a0VERETEgckwjOr9Cl/scnJyCAgIIDs7G39/f1eHI06wdnc6jyxL5up/PKbLfy66P7ZSydj6w+uZnDgZ46qeTJd7ujVgCmt+aMEffhXN/97VpdrxWqwWer7XkyJrEWtHruW6ptdVuy8RERERKVtlc4MGsTRRpD6xWA1mfbanRBIG2I/N+mxPhcsULVYLc5LmlEjCbP3Yjv2Q/RZg/aV0fTWZTCZWDF3Bq/1eJcxH73eJiIiIuJoSMZEqSko7Q3p2fpnnDSA9O5+ktDPl9pOcmczJvJPl9GNQwBncfNJ+KV1fzGqFo0nw0yq4VFhhzGaTmQ5BHbgt+rbql67fshBe7Qz/ebF614uIiIiIXYN5R0ykvsg8X3YSVpV2WXlZlerH5H6e6KvfETOZYOkdYCmAx3dCs+hK9VUj2cdtVRqLLtb9vUREREQaOc2IiVRRiF+TWmkX7FPx1g0AWPyIDPJ2POawqXPFlRO/PvQ1S3cv5eezP1funqXRZs4iIiIitUaJmEgV9YoJIjygib0wx9VM2Kon9ooJKref2JBYQn1C7YU5SmMtCiDUszNe7qUsJ/S/XHCjEnuJfZr6KfO2zyMlM6XCtmUqTsT89I6ZiIiISE0pEROpIjeziRnDOgOUmULNGNYZN3PZCZatHzee7PXk5X5Kb1twchitW/iV3oF9RqziRKy4dH2kX2SFbctknxELqX4fIiIiIgIoEROplvgu4Sy6P5awgJLLD18ccUOl9xGLi47j1X6vEuJTMrkJ8+jCpfNdyq6YWMmliRarhWPnjwE12EMMtDRRREREpBapWIdINcV3Cee2zmEkpZ0hMyeffyQeZP/JXHYdz+beKvQTFx1H/8j+JGcmk5WXRXZBNi8mvUhG0U+YPLNo1bxT6RdWcmliRl4GRdYiPMwe1S9dX5QP+dm2v2tGTERERKTGlIiJ1ICb2USfNs0BCA/05vevb+GDbUd56JbWtLq65Hy5/bjRM6yn/fP3J74n8ehG3H3+j1bNh5R+USVnxI7k2JYltvRrWf3S9YUXIKoP5J2BJoHV60NERERE7JSIOYnVaqWwsOL9nqR+8vDwwM2t/CSmV0wQ/ToEk7g/i/+3/mf+ds9N1b7flB5T2PB9D4outCg7oYu4EYbMhaA25fZVnIhF+9WgxL1vc/jT2upfLyIiIiIOlIg5QWFhIWlpaVitVleHIjUQGBhIWFgYJlPZRTimDupA4v4sPt1xgof7tqFTuH+17uVjDiPvQgvMJkqWri8W0BJ6/7nCvuyFOvxrUKhDRERERGqVErE6ZhgG6enpuLm5ERkZidms+igNjWEY5OXlkZmZCUB4eNmFOLpcF8DQruF8vjOdeV/v581RPctsW55Dp/IAiAj05viFw1yyXqJ9s/bV6uvRGx/ljtZ30NSjabWuFxEREZHap0Ssjl26dIm8vDwiIiLw8Smj+p3Ue97etlmpzMxMQkJCyl2mOOW29qzdncH6vZlsP3yG7tHl7ydWmkOnLwDg32Inwz+ZxI3BN7I0fmnJ2bgTKXA2DSJ7//LO2FV8PXzpVFbBj8ra9DJsewt6joFbp9asLxERERFR+fq6ZrFYAPD09HRxJFJTxYl0UVFRue1aBzflt7EtAZi7dj+GYVT5XodO2RKxTs1uwsPsQXJmMt8e/7Zkwy+nwYej4ejWKt+jSrKPw/kTYCn/excRERGRylEi5iTlvVckDUNVfoaPx7XD083M1rQzbD5wqsr3OnzatjSxU3Ak93a0FcNf8N8FWI2r3jOsoHJiVl4Wz//wPMv3Lq9yDA5ybcsyVbpeREREpHYoEROpAxGB3tz/K1uVwpe/qvqsWNrlGbFWzX0Z02UMvh6+7Duzj68Pf+3YsIJE7OC5g7y//31W7l9ZtW/gasWbOftVcx8yEREREXGgRKyBsFgNtqSe5pOU42xJPY3FWvXlbo2FyWRi9erVrg6jQuP6t8HX041dx7NZuzuj0tcZhsHhy++ItWrhS2CTQEZdPwqAhf9dyCXrpV8aV7Cpc62UrodfErGmoTXrR0REREQAJWINwtrd6fz6pW+4940feHxlCve+8QO/fukb1u5Or/N7b9myBTc3N4YOHVql61q1asX8+fPrJqgGonlTL8b8OgaAV77eX+nkOSu3gAuFFofS9Q90foBmXs04lHOITw5+8kvjCmbEDp8/DNSwdL1hXJGIaWmiiIiISG1QIlbPrd2dziPLkknPznc4npGdzyPLkus8GVuyZAmPPfYYmzZt4sSJ0v9nX8r24K2tCfTxIDXrAh8nH6vUNcXvh0UEeuPlbqvO6Ovhy4M3PIifpx9WrnhPzD4jVvrP5mjOUaCGM2L558ByeTNyXyViIiIiIrVBiZiTGYZBXuGlSn2dzy9ixqc/Udo8SvGxmZ/u4Xx+UaX6q+p7Srm5ubz//vs88sgjDB06lKVLlzqc/+yzz+jZsydNmjShRYsWDB8+HIB+/fpx+PBhJk2ahMlkshe5mDlzJjfeeKNDH/Pnz6dVq1b2z9u2beO2226jRYsWBAQE0LdvX5KTk6sUd33i38SDR/q2AWD++gMUXLJUeM2V74dd6e6Od7N25Fp+1/53V9zg8ozY+XQoZcPwWpkRK7oIUTdDeDfwaFL9fkRERETETvuIOdnFIgud//pVrfRlABk5+dww8+sK2wLseW4wPp6V/5F/8MEHdOzYkQ4dOnD//fczceJEnnrqKUwmE59//jnDhw9n+vTpvPvuuxQWFvLFF18A8PHHH9OtWzceeughxo4dW6Xv6fz584waNYrXXnsNwzCYN28et99+OwcOHMDPz69KfdUXo25uxVvfpXH83EVWJh1l1M2tym3/y/thjvvOebl54eXm5di4aSgMmWubGTOsXPm7FYvVwrHztlm4aP8azIj5R8Cfvqz+9SIiIiJSghIxKdOSJUu4//77AYiPjyc7O5uNGzfSr18/XnjhBe655x5mzZplb9+tWzcAgoKCcHNzw8/Pj7CwqlXZGzBggMPnf/7znwQGBrJx40buuOOOGn5HrtHEw43HBrTjmdW7ee2bg/yuR8tyE+JDp2xLE6+eEStmGAabjm3iTP4ZhrcbDr3/XGq7zLxMiqxFeJg9CPNRtUMRERGR+kSJmJN5e7ix57nBlWqblHaG0W9vq7Dd0j/2pFdMUKXuXVn79+8nKSmJVatWAeDu7s7dd9/NkiVL6NevHykpKVWe7aqMkydP8swzz5CYmEhmZiYWi4W8vDyOHDlS6/dyprt7RvLPTf/HkTN5vP3dIcb1b1tm27KWJhb7/sT3jP9mPL4evvSP7E9gk8BS24U3Defbe77lZN5J3MyV/9mLiIiISN1TIuZkJpOp0ssDb2kXTHhAEzKy80t9T8wEhAU04ZZ2wbiZa3fD6CVLlnDp0iUiIiLsxwzDwMvLi7///e94e3tXuU+z2VziPbWioiKHz6NGjeL06dP87W9/Izo6Gi8vL/r06UNhYWH1vpF6wsPNzOTb2jPx/RRe35jK/b2jCfDxKNHOsXS9T4nzAH0i+tAxqCP7zuxjye4lTGn1Gzi5G4Ja297jukKAVwABXgE1C37Dc5CyHPqMg5sfq1lfIiIiIgKoWEe95mY2MWNYZ8CWdF2p+POMYZ1rPQm7dOkS7777LvPmzSMlJcX+tWPHDiIiIlixYgVdu3Zlw4YNZfbh6emJxeJYmCI4OJiMjAyHZCwlJcWhzXfffceECRO4/fbbuf766/Hy8uLUqVO1+v25ym+6RdAxzI+c/Eu8vim11DbFpetNJogMKj0RM5vMPHaTLSFasW8FJ39YCB+Oht0f1U3gOScuFwOpuNCIiIiIiFSOErF6Lr5LOIvujyUswLFaXVhAExbdH0t8l/Bav+eaNWs4e/YsY8aMoUuXLg5fI0eOZMmSJcyYMYMVK1YwY8YM9u7dy65du3jppZfsfbRq1YpNmzZx/PhxeyLVr18/srKymDt3LqmpqSxcuJAvv3QsAtGuXTv+9a9/sXfvXrZu3UpCQkK1Zt/qI7PZxJRBHQB4+7tDZJ7PL9HGXro+4JfS9aW55bpbiA2JpcBSwOtFlzdzvqqE/aKURby49UX2n9lfs8C1mbOIiIhIrVMi1gDEdwnn22kDWDH2V/ztnhtZMfZXfDttQJ0kYWBblhgXF0dAQMklbSNHjuTHH38kKCiIDz/8kE8//ZQbb7yRAQMGkJSUZG/33HPPcejQIdq0aUNwcDAAnTp14h//+AcLFy6kW7duJCUlMXXq1BL3Pnv2LLGxsfzhD39gwoQJhIQ0nr2r4jqFcFNUIBeLLCz85mCJ88Xvh8W0KP39sGImk4kJsRMAWJXzM0fc3SHHcU+5tYfWsmLfCk7nn65Z0Oe1mbOIiIhIbTMZVd1cSkrIyckhICCA7Oxs/P39Hc7l5+eTlpZGTEwMTZpoD6aGrLZ+lt+nnuK+N7bi4Wbimyn9HJYgvvzVPhb+J5WE3lG8MPyGCvt6eP3DfHf8O27PvcBLl/zh8RTAVrq+53s9KbIW8eWIL2np17La8TK3DeSdgoe/g7Au1e9HRERE5BpQXm5wJc2IiTjZzW1acEu7FhRZDOavP+Bwrrh0fUUzYsUm3DSBtn7RDL6QZ1uaePn3KifzTlJkLcLd7E64bw1mTi1FkHd5Ru2KpYlz5szBZDIxceLE6vctIiIicg1TIibiAlMvvyu26r/HOHDyvP34ocsVE6PLKF1/tc7NO/PxsI8YkHcRLAWQdwaAwzmHAWjZtGXNStdfOAUYYHIDH9sWCdu2beP111+na9eu1e9XRERE5BqnREzEBbpFBhJ/fRhWA+Z9/TNgK11/yP6OWOkVE0tj8vAC38vvb+XYCnccPX8UgGj/6JoFaimAqJuhZQ8wu5Gbm0tCQgJvvPEGzZo1q1nfIiIiItcwJWIiLjJlUHvMJlj7UwY7jp7jVG5hhaXry5I/6DneufVhpux507YX2eUZsUi/yJoF2awV/OlLGPM1AOPGjWPo0KHExcXVrF8RERGRa5w2dBZxkXahfgy/qSUfJR/j5a/2EdfJ9g5Wcx9P3M1V+x3J2Tb9+NvOlymyFvH9ie/Zd3qf/ZzFaqne8kSrBQ5/bytf3zSUlVuOkpyczLZt26rel4iIiIg40IyYiAtNjGuHmxm+PXiamZ/tAeDUhUJ+/dI3rN2dXsHVvwhvGs7dHe4GYPw340k6adtKYNneZQz+aDDrD6+vWmB7PoX5XeCdO+CjMRxdcDuP//kB3nturKp/ioiIiNQCJWIiLvTTiWws1pLHM7LzeWRZcuWTsezjtM+zFf24ZL3kcCozL5PJiZMrn4zt+RQ+eMBhg+jt6RYycy3Ejnwcd3c33N3d2bhxIwsWLMDd3R2LxVK5vkVEREQEUCIm4jIWq8Gsy7NgVyve3G/WZ3uwWCve6s+StomFqR+V0Zft+peSXsJirSBhslpg7bQrIrAZGOPOrkd8SXm4KSmToklJ3k6PHj1ISEggJSUFN7caVGYUERERuQYpERNxkaS0M6Rn55d53gDSs/NJSjtTYV/JRh4n3ct+5dPAICMvg+TM5PI7Ovy9w0xYMT8vE11C3OgSYqaL72m6+OXg6+tL8+bN6dJFmzyLiIiIVJUSsYbCaoG0zbDr37Y/K5rZaCBGjx7NXXfdZf/cr18/l2wSnJiYiMlk4ty5c067Z+b5spOwqrbLcqvcP+WsvKzyG+SerFQ/lW4nIiIiIqVS1cSGYM+ntuViV85U+EdA/EvQ+Td1csvRo0fzzjvvAODh4UFUVBQPPPAATz/9NO7lzLzU1Mcff4yHh0el2iYmJtK/f3/Onj1LYGBgncVUV0L8Klf0ojLtgoPaVaqvYJ/g8hs0Da1UPzQNJTExsXJtRURERKQEzYjVd6UUTgAgJ912fM+ndXbr+Ph40tPTOXDgAFOmTGHmzJm8/PLLJdoVFhbW2j2DgoLw8/Ortf7qs14xQYQHNMFUxnkTEB7QhF4xQRX2FRvRh1CLFZNR+vtkJkyE+YQRGxJbfkfRN9uS/DKZwP86WzsRERERqTYlYq5SeKHsr6LLS9HKKJxgc/nY2mmOyxTL6rMavLy8CAsLIzo6mkceeYS4uDg+/fRT+3LCF154gYiICDp06ADA0aNH+f3vf09gYCBBQUHceeedHDp0yN6fxWJh8uTJBAYG0rx5c5544gmMqxKHq5cmFhQUMG3aNCIjI/Hy8qJt27YsWbKEQ4cO0b9/fwCaNWuGyWRi9OjRtmGzWpk9ezYxMTF4e3vTrVs3/v3vfzvc54svvqB9+/Z4e3vTv39/hzidxc1sYsawzgAlkrHizzOGdcbNXFaqdmVfbjx5ybeMvmxHpvWaVvF+YmY3GPBsGScv9xw/x9ZORERERKpNSxNd5cVyZh3aDYKED8ssnPALw3b+8PcQc4vt0PwbIO90yaYzs2sULoC3tzenT9v63rBhA/7+/qxbtw6AoqIiBg8eTJ8+fdi8eTPu7u48//zzxMfHs3PnTjw9PZk3bx5Lly7lrbfeolOnTsybN49Vq1YxYMCAMu/5wAMPsGXLFhYsWEC3bt1IS0vj1KlTREZG8tFHHzFy5Ej279+Pv78/3t7eAMyePZtly5axePFi2rVrx6ZNm7j//vsJDg6mb9++HD16lBEjRjBu3DgeeughfvzxR6ZMmVLj8amO+C7hLLo/llmf7XEo3BEW0IQZwzoT3yW80n3F+Ubz6vHNzLkuhpOXcu3HQ31CmdZrGnHRcZXr6Mb7wOxhS/KvfJb8I2xJWB0thxURERG5ligRq8/qSeEEwzDYsGEDX331FY899hhZWVn4+vry5ptv4unpCcCyZcuwWq28+eabmEy2mZO3336bwMBAEhMTGTRoEPPnz+epp55ixIgRACxevJivvvqqzPv+/PPPfPDBB6xbt464OFsS0bp1a/v5oCDbkr2QkBD7O2IFBQW8+OKLrF+/nj59+tiv+fbbb3n99dfp27cvixYtok2bNsybNw+ADh06sGvXLl566aVaHLXKi+8Szm2dw0hKO0Pm+XxC/GzLESszE+bg5seIyx9F//CuJOefJCsvi2CfYGJDYiueCbta199BlxG2JD/3pO3dseibNRMmIiIiUkuUiLnK0+XMdJku/89uFQon2E3cVf2YrrJmzRqaNm1KUVERVquV++67j5kzZzJu3DhuuOEGexIGsGPHDg4ePFji/a78/HxSU1PJzs4mPT2d3r1728+5u7vTo0ePEssTixXvT9W3b99Kx3zw4EHy8vK47bbbHI4XFhZy0003AbB3716HOAB70uYqbmYTfdo0r1knMbfa+gJ6ElX169c+DX5h0Gc8mM22pKt4plVEREREapUSMVfx9K24TXHhhJx0Sn9PzGQ7f2XhhMr0W0n9+/dn0aJFeHp6EhER4VAt0dfX8T65ubl0796d9957r0Q/wcEVVOorQ/FSw6rIzbUtyfv888+57rrrHM55eXlVK45rwt418MNC29+jb4aWPVwbj4iIiEgjp2Id9ZnZzVaiHiiznEMdFk7w9fWlbdu2REVFVViyPjY2lgMHDhASEkLbtm0dvgICAggICCA8PJytW7far7l06RLbt28vs88bbrgBq9XKxo0bSz1fPCNnsfxSrKRz5854eXlx5MiREnFERkYC0KlTJ5KSkhz6+uGHH8ofjIbg4jnY/TH8t2QyXK7sY/DJONvfb35MSZiIiIiIEygRq+86/wZ+/y74X1W0wT/CdryeFE5ISEigRYsW3HnnnWzevJm0tDQSExOZMGECx44dA+Dxxx9nzpw5rF69mn379vHoo4+Wu4Fyq1atGDVqFH/6059YvXq1vc8PPvgAgOjoaEwmE2vWrCErK4vc3Fz8/PyYOnUqkyZN4p133iE1NZXk5GRee+01+75oDz/8MAcOHOAvf/kL+/fvZ/ny5SxdurSuh6ju5WbCv/8Ia5+q/DWWS/DRg5B/DiJiYcBf6yw8EREREfmFErGGoPNvYOJuGLUGRi6x/TlxV71JwgB8fHzYtGkTUVFRjBgxgk6dOjFmzBjy8/Px9/cHYMqUKfzhD39g1KhR9OnTBz8/P4YPH15uv4sWLeK3v/0tjz76KB07dmTs2LFcuGArx3/dddcxa9YsnnzySUJDQxk/fjwA//u//8uzzz7L7Nmz6dSpE/Hx8Xz++efExMQAEBUVxUcffcTq1avp1q0bixcv5sUXX6zD0XGS4mS9IBsKzlfumk1z4cgW8PSD3y4Bd8+KrxERERGRGjMZZVVKkErLyckhICCA7Oxse9JRLD8/n7S0NGJiYmjSpImLIpTa0CB+lrMjoSAHxm2D4Pbltz30LbwzDAwrjHjTVilRRERERGqkvNzgSpoRE2lM/C/vT5dzvOK2Z/7PVqHzxgQlYSIiIiJOpqqJIo2JfwRk7atgI/DLYh+A8G4Q1Kbu4xIRERERB0rERBoT+4xYOYmY1WrbJwxsiZiIiIiIOJ2WJoo0Jv6X9047X0Yilr4TFv8a0nc4LyYRERERKUGJmEhjcv1wuGc59Blf4tScF57DFNGNie9uh83zXBCciIiIiBTT0kSRxiSkk+3rKtu2beP1Ba/QNdQMnr5wx3znxyYiIiIidpoRE2nkcnNzSfjtnbwx2EKzJiZoGwc+Qa4OS0REROSapkRMpDGxWmH3R/D9a1CUD8C4Bx9gaMsc4lq7Q2DULwU9RERERMRltDRRpDExmeCT8VCUBx1uZ+XaLSRv/pptfzRD1M0QkOfqCEVEREQEzYg1GBarhW0Z2/ji/75gW8Y2LFaLq0Oqc61atWL+/Pn2zyaTidWrV7ssngbBZAK/cACOfr2Yxx9/jPce6UGTps1g5Bu28yIiIiLicpoRawDWH17PnKQ5nMw7aT8W6hPKk72eJC46rk7uOXr0aN555x3756CgIHr27MncuXPp2rVrndyzIunp6TRr1swl924w9nwK2UcB2P7JQjJPXyR2xkYwmeGZVlgsFjZt2sTf//53CgoKcHNzc3HAIiIiItcmzYjVc+sPr2dy4mSHJAwgMy+TyYmTWX94fZ3dOz4+nvT0dNLT09mwYQPu7u7ccccddXa/ioSFheHl5eWy+9d7ez6FDx4ASyEAA2Pc2fWILyl/bkrKQz6kfPT/6NGjBwkJCaSkpCgJExEREXEhJWIukleUV+ZXgaUAsC1HnJM0BwOjxPXG5f/mJM1xWKZYVp/V4eXlRVhYGGFhYdx44408+eSTHD16lKysLACmTZtG+/bt8fHxoXXr1jz77LMUFRXZr9+xYwf9+/fHz88Pf39/unfvzo8//mg//+2333LLLbfg7e1NZGQkEyZM4MKFC2XGc+XSxEOHDmEymfj444/p378/Pj4+dOvWjS1btjhcU9V7NFhWC6ydBlc8K35eJrqEuNElxGz7M3URvr4+NG/enC5durguVhERERHR0kRX6b28d5nnbrnuFv4R9w+SM5NLzIRd7WTeSZIzk+kZ1hOA+I/iOVtwtkS7XaN21Sje3Nxcli1bRtu2bWnevDkAfn5+LF26lIiICHbt2sXYsWPx8/PjiSeeACAhIYGbbrqJRYsW4ebmRkpKCh4eHgCkpqYSHx/P888/z1tvvUVWVhbjx49n/PjxvP3225WOa/r06bzyyiu0a9eO6dOnc++993Lw4EHc3d1r7R4NwuHvIedEOQ0MyDkO+ZpRFBEREakPlIjVY1l5WbXarqrWrFlD06ZNAbhw4QLh4eGsWbMGs9k2kfrMM8/Y27Zq1YqpU6eycuVKeyJ25MgR/vKXv9CxY0cA2rVrZ28/e/ZsEhISmDhxov3cggUL6Nu3L4sWLaJJkyaVinHq1KkMHToUgFmzZnH99ddz8OBBOnbsWGv3aBByy0/YiyW+MR1u+G0dByMiIiIiFVEi5iJb79ta5jk3s+3dnWCf4Er1dWW7tSPX1iywK/Tv359FixYBcPbsWf7xj38wZMgQkpKSiI6O5v3332fBggWkpqaSm5vLpUuX8Pf3t18/efJkHnzwQf71r38RFxfH7373O9q0aQPYli3u3LmT9957z97eMAysVitpaWl06tSpUjFeWTgkPNxWLTAzM5OOHTvW2j0ahKahtdtOREREROqUEjEX8fHwqbBNbEgsoT6hZOZllvqemAkToT6hxIbEVqnfyvL19aVt27b2z2+++SYBAQG88cYbDB06lISEBGbNmsXgwYMJCAhg5cqVzJs3z95+5syZ3HfffXz++ed8+eWXzJgxg5UrVzJ8+HByc3P585//zIQJE0rcNyoqqtIxFi91BNs7ZABWqxWg1u7RIETfbNuoOScdSnlWwGQ7H32zsyMTERERkVIoEavH3MxuPNnrSSYnTsaEySEZM2FLOqb1mmafQatrJpMJs9nMxYsX+f7774mOjmb69On284cPHy5xTfv27Wnfvj2TJk3i3nvv5e2332b48OHExsayZ88eh0SvtjnjHvWG2Q3iX7JVTcSEYzJ2ee+w+Dm2diIiIiLicqqaWM/FRcfxar9XCfEJcTge6hPKq/1erbN9xAAKCgrIyMggIyODvXv38thjj5Gbm8uwYcNo164dR44cYeXKlaSmprJgwQJWrVplv/bixYuMHz+exMREDh8+zHfffce2bdvsywGnTZvG999/z/jx40lJSeHAgQN88sknjB8/vtbid8Y96pXOv4Hfvwv+4Y7H/SNsxzv/xjVxiYiIiEgJmhFrAOKi4+gf2Z/kzGSy8rII9gkmNiS2zmfC1q5da3/vys/Pj44dO/Lhhx/Sr18/ACZNmsT48eMpKChg6NChPPvss8ycORMANzc3Tp8+zQMPPMDJkydp0aIFI0aMYNasWYDt3a6NGzcyffp0brnlFgzDoE2bNtx99921Fr8z7lHvdP4NdBxqq6KYe9L2Tlj0zZoJExEREalnTIZhlPZCiVRBTk4OAQEBZGdnOxSrAMjPzyctLY2YmJjGVaXvGqSfpYiIiIhUpLzc4EpamigiIiIiIuJkSsREREREREScTImYiIiIiIiIkykRExERERERcTIlYk6imigNn36GIiIiIlJblIjVMTc3W9nwwsJCF0ciNZWXlweAh4eHiyMRERERkYZO+4jVMXd3d3x8fMjKysLDwwOzWblvQ2MYBnl5eWRmZhIYGGhPrkVEREREqkuJWB0zmUyEh4eTlpbG4cOHXR2O1EBgYCBhYWGuDkNEREREGgElYk7g6elJu3bttDyxAfPw8NBMmIiIiIjUGiViTmI2m2nSpImrwxARERERkXpALyyJiIiIiIg4mRIxERERERERJ1MiJiIiIiIi4mR6R6wWFG/0m5OT4+JIRERERETElYpzguIcoSxKxGrB+fPnAYiMjHRxJCIiIiIiUh+cP3+egICAMs+bjIpSNamQ1WrlxIkT+Pn5YTKZXBpLTk4OkZGRHD16FH9/f5fGcq3QmDuXxtv5NObOpzF3Lo2382nMnU9j7jyGYXD+/HkiIiIwm8t+E0wzYrXAbDbTsmVLV4fhwN/fX//InExj7lwab+fTmDufxty5NN7OpzF3Po25c5Q3E1ZMxTpEREREREScTImYiIiIiIiIkykRa2S8vLyYMWMGXl5erg7lmqExdy6Nt/NpzJ1PY+5cGm/n05g7n8a8/lGxDhERERERESfTjJiIiIiIiIiTKRETERERERFxMiViIiIiIiIiTqZETERERERExMmUiDUiCxcupFWrVjRp0oTevXuTlJTk6pAarZkzZ2IymRy+Onbs6OqwGpVNmzYxbNgwIiIiMJlMrF692uG8YRj89a9/JTw8HG9vb+Li4jhw4IBrgm0kKhrz0aNHl3ju4+PjXRNsIzB79mx69uyJn58fISEh3HXXXezfv9+hTX5+PuPGjaN58+Y0bdqUkSNHcvLkSRdF3PBVZsz79etX4jl/+OGHXRRxw7Zo0SK6du1q30C4T58+fPnll/bzer5rX0Vjrue7flEi1ki8//77TJ48mRkzZpCcnEy3bt0YPHgwmZmZrg6t0br++utJT0+3f3377beuDqlRuXDhAt26dWPhwoWlnp87dy4LFixg8eLFbN26FV9fXwYPHkx+fr6TI208KhpzgPj4eIfnfsWKFU6MsHHZuHEj48aN44cffmDdunUUFRUxaNAgLly4YG8zadIkPvvsMz788EM2btzIiRMnGDFihAujbtgqM+YAY8eOdXjO586d66KIG7aWLVsyZ84ctm/fzo8//siAAQO48847+emnnwA933WhojEHPd/1iiGNQq9evYxx48bZP1ssFiMiIsKYPXu2C6NqvGbMmGF069bN1WFcMwBj1apV9s9Wq9UICwszXn75Zfuxc+fOGV5eXsaKFStcEGHjc/WYG4ZhjBo1yrjzzjtdEs+1IDMz0wCMjRs3GoZhe6Y9PDyMDz/80N5m7969BmBs2bLFVWE2KlePuWEYRt++fY3HH3/cdUE1cs2aNTPefPNNPd9OVDzmhqHnu77RjFgjUFhYyPbt24mLi7MfM5vNxMXFsWXLFhdG1rgdOHCAiIgIWrduTUJCAkeOHHF1SNeMtLQ0MjIyHJ75gIAAevfurWe+jiUmJhISEkKHDh145JFHOH36tKtDajSys7MBCAoKAmD79u0UFRU5POcdO3YkKipKz3ktuXrMi7333nu0aNGCLl268NRTT5GXl+eK8BoVi8XCypUruXDhAn369NHz7QRXj3kxPd/1h7urA5CaO3XqFBaLhdDQUIfjoaGh7Nu3z0VRNW69e/dm6dKldOjQgfT0dGbNmsUtt9zC7t278fPzc3V4jV5GRgZAqc988TmpffHx8YwYMYKYmBhSU1N5+umnGTJkCFu2bMHNzc3V4TVoVquViRMn8j//8z906dIFsD3nnp6eBAYGOrTVc147ShtzgPvuu4/o6GgiIiLYuXMn06ZNY//+/Xz88ccujLbh2rVrF3369CE/P5+mTZuyatUqOnfuTEpKip7vOlLWmIOe7/pGiZhINQwZMsT+965du9K7d2+io6P54IMPGDNmjAsjE6k799xzj/3vN9xwA127dqVNmzYkJiYycOBAF0bW8I0bN47du3frXVMnKmvMH3roIfvfb7jhBsLDwxk4cCCpqam0adPG2WE2eB06dCAlJYXs7Gz+/e9/M2rUKDZu3OjqsBq1ssa8c+fOer7rGS1NbARatGiBm5tbiUpDJ0+eJCwszEVRXVsCAwNp3749Bw8edHUo14Ti51rPvGu1bt2aFi1a6LmvofHjx7NmzRr+85//0LJlS/vxsLAwCgsLOXfunEN7Pec1V9aYl6Z3794Aes6rydPTk7Zt29K9e3dmz55Nt27d+Nvf/qbnuw6VNeal0fPtWkrEGgFPT0+6d+/Ohg0b7MesVisbNmxwWBMsdSc3N5fU1FTCw8NdHco1ISYmhrCwMIdnPicnh61bt+qZd6Jjx45x+vRpPffVZBgG48ePZ9WqVXzzzTfExMQ4nO/evTseHh4Oz/n+/fs5cuSInvNqqmjMS5OSkgKg57yWWK1WCgoK9Hw7UfGYl0bPt2tpaWIjMXnyZEaNGkWPHj3o1asX8+fP58KFC/zxj390dWiN0tSpUxk2bBjR0dGcOHGCGTNm4Obmxr333uvq0BqN3Nxch9/QpaWlkZKSQlBQEFFRUUycOJHnn3+edu3aERMTw7PPPktERAR33XWX64Ju4Mob86CgIGbNmsXIkSMJCwsjNTWVJ554grZt2zJ48GAXRt1wjRs3juXLl/PJJ5/g5+dnfy8mICAAb29vAgICGDNmDJMnTyYoKAh/f38ee+wx+vTpw69+9SsXR98wVTTmqampLF++nNtvv53mzZuzc+dOJk2axK233krXrl1dHH3D89RTTzFkyBCioqI4f/48y5cvJzExka+++krPdx0pb8z1fNdDri7bKLXntddeM6KiogxPT0+jV69exg8//ODqkBqtu+++2wgPDzc8PT2N6667zrj77ruNgwcPujqsRuU///mPAZT4GjVqlGEYthL2zz77rBEaGmp4eXkZAwcONPbv3+/aoBu48sY8Ly/PGDRokBEcHGx4eHgY0dHRxtixY42MjAxXh91glTbWgPH222/b21y8eNF49NFHjWbNmhk+Pj7G8OHDjfT0dNcF3cBVNOZHjhwxbr31ViMoKMjw8vIy2rZta/zlL38xsrOzXRt4A/WnP/3JiI6ONjw9PY3g4GBj4MCBxtdff20/r+e79pU35nq+6x+TYRiGMxM/ERERERGRa53eERMREREREXEyJWIiIiIiIiJOpkRMRERERETEyZSIiYiIiIiIOJkSMRERERERESdTIiYiIiIiIuJkSsREREREREScTImYiIiIiIiIkykRExERqQUmk4nVq1e7OgwREWkglIiJiMg1b/To0dx1112uDkNERK4hSsREREREREScTImYiIjIFfr168eECRN44oknCAoKIiwsjJkzZzq0OXDgALfeeitNmjShc+fOrFu3rkQ/R48e5fe//z2BgYEEBQVx5513cujQIQD27duHj48Py5cvt7f/4IMP8Pb2Zs+ePXX57YmISD2hRExEROQq77zzDr6+vmzdupW5c+fy3HPP2ZMtq9XKiBEj8PT0ZOvWrSxevJhp06Y5XF9UVMTgwYPx8/Nj8+bNfPfddzRt2pT4+HgKCwvp2LEjr7zyCo8++ihHjhzh2LFjPPzww7z00kt07tzZFd+yiIg4mckwDMPVQYiIiLjS6NGjOXfuHKtXr6Zfv35YLBY2b95sP9+rVy8GDBjAnDlz+Prrrxk6dCiHDx8mIiICgLVr1zJkyBBWrVrFXXfdxbJly3j++efZu3cvJpMJgMLCQgIDA1m9ejWDBg0C4I477iAnJwdPT0/c3NxYu3atvb2IiDRu7q4OQEREpL7p2rWrw+fw8HAyMzMB2Lt3L5GRkfYkDKBPnz4O7Xfs2MHBgwfx8/NzOJ6fn09qaqr981tvvUX79u0xm8389NNPSsJERK4hSsRERESu4uHh4fDZZDJhtVorfX1ubi7du3fnvffeK3EuODjY/vcdO3Zw4cIFzGYz6enphIeHVz9oERFpUJSIiYiIVEGnTp04evSoQ+L0ww8/OLSJjY3l/fffJyQkBH9//1L7OXPmDKNHj2b69Omkp6eTkJBAcnIy3t7edf49iIiI66lYh4iISBXExcXRvn17Ro0axY4dO9i8eTPTp093aJOQkECLFi2488472bx5M2lpaSQmJjJhwgSOHTsGwMMPP0xkZCTPPPMMr776KhaLhalTp7riWxIRERdQIiYiIlIFZrOZVatWcfHiRXr16sWDDz7ICy+84NDGx8eHTZs2ERUVxYgRI+jUqRNjxowhPz8ff39/3n33Xb744gv+9a9/4e7ujq+vL8uWLeONN97gyy+/dNF3JiIizqSqiSIiIiIiIk6mGTEREREREREnUyImIiIiIiLiZErEREREREREnEyJmIiIiIiIiJMpERMREREREXEyJWIiIiIiIiJOpkRMRERERETEyZSIiYiIiIiIOJkSMRERERERESdTIiYiIiIiIuJkSsRERERERESc7P8DisCMkn0ZN9UAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_actual_vs_predicted(val['y'][1:].reset_index(drop=True), val['NBEATS'][1:].reset_index(drop=True), val['y'].shift(1)[1:].reset_index(drop=True), val['modelID'][1:].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x18d82845870>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot of target_5 from val_set_all\n",
    "import matplotlib.pyplot as plt\n",
    "val_set_all = pd.read_csv('csv/NFLX/val_set_full.csv')\n",
    "plt.plot(val_set_all['target_5'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_all = pd.read_csv('csv/'+prefix+'/train_set_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8, 14],\n",
       "       [ 6, 11]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_signs_matrix(val['y'].reset_index(drop=True), val['NBEATS'].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14, 13],\n",
       "       [12, 17]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# p['y'][:-1],p['y'].shift(-1)[:(len(p['y'])-1)]\n",
    "count_signs_matrix(test['y'][1:],test['y'].shift(1)[:(len(test['y'])-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_nbeats = pd.read_csv('results/NFLX/financial/NBEATS/val_pred.csv')\n",
    "test_nbeats = pd.read_csv('results/NFLX/financial/NBEATS/test_pred.csv')\n",
    "val_nhits = pd.read_csv('results/NFLX/financial/NHITS/val_pred.csv')\n",
    "test_nhits = pd.read_csv('results/NFLX/financial/NHITS/test_pred.csv')\n",
    "val_tft = pd.read_csv('results/NFLX/financial/TFT/val_pred.csv')\n",
    "test_tft = pd.read_csv('results/NFLX/financial/TFT/test_pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame({'NBEATS': val_nbeats['NBEATS'], 'NHITS': val_nhits['NHITS'], 'TFT': val_tft['TFT'], 'y': val_nbeats['y']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame({'NBEATS': test_nbeats['NBEATS'], 'NHITS': test_nhits['NHITS'], 'TFT': test_tft['TFT'], 'y': test_nbeats['y']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_train, df_test])\n",
    "df_train = df.iloc[:-5]\n",
    "df_test = df.iloc[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 28.2594311\ttotal: 1.23ms\tremaining: 12.3s\n",
      "1:\tlearn: 26.4876187\ttotal: 1.94ms\tremaining: 9.69s\n",
      "2:\tlearn: 24.9852089\ttotal: 2.63ms\tremaining: 8.76s\n",
      "3:\tlearn: 23.4364856\ttotal: 3.24ms\tremaining: 8.09s\n",
      "4:\tlearn: 22.0049523\ttotal: 4.01ms\tremaining: 8.01s\n",
      "5:\tlearn: 20.6765867\ttotal: 4.79ms\tremaining: 7.98s\n",
      "6:\tlearn: 19.6505677\ttotal: 5.7ms\tremaining: 8.14s\n",
      "7:\tlearn: 18.5831818\ttotal: 6.4ms\tremaining: 8s\n",
      "8:\tlearn: 17.8545284\ttotal: 7.02ms\tremaining: 7.79s\n",
      "9:\tlearn: 17.1473301\ttotal: 8.41ms\tremaining: 8.4s\n",
      "10:\tlearn: 16.5067299\ttotal: 9.19ms\tremaining: 8.34s\n",
      "11:\tlearn: 15.8215345\ttotal: 9.87ms\tremaining: 8.22s\n",
      "12:\tlearn: 15.1911378\ttotal: 10.5ms\tremaining: 8.09s\n",
      "13:\tlearn: 14.7390586\ttotal: 11.1ms\tremaining: 7.95s\n",
      "14:\tlearn: 14.2191616\ttotal: 11.8ms\tremaining: 7.89s\n",
      "15:\tlearn: 13.7583191\ttotal: 12.7ms\tremaining: 7.91s\n",
      "16:\tlearn: 13.3736033\ttotal: 13.3ms\tremaining: 7.79s\n",
      "17:\tlearn: 12.9253942\ttotal: 14ms\tremaining: 7.77s\n",
      "18:\tlearn: 12.5642868\ttotal: 14.7ms\tremaining: 7.71s\n",
      "19:\tlearn: 12.2345238\ttotal: 15.3ms\tremaining: 7.63s\n",
      "20:\tlearn: 11.9581788\ttotal: 16ms\tremaining: 7.58s\n",
      "21:\tlearn: 11.6908863\ttotal: 16.6ms\tremaining: 7.54s\n",
      "22:\tlearn: 11.4482086\ttotal: 17.3ms\tremaining: 7.51s\n",
      "23:\tlearn: 11.1970471\ttotal: 18ms\tremaining: 7.5s\n",
      "24:\tlearn: 11.0331815\ttotal: 18.8ms\tremaining: 7.48s\n",
      "25:\tlearn: 10.6881901\ttotal: 20ms\tremaining: 7.66s\n",
      "26:\tlearn: 10.5182899\ttotal: 20.8ms\tremaining: 7.7s\n",
      "27:\tlearn: 10.3638345\ttotal: 21.6ms\tremaining: 7.71s\n",
      "28:\tlearn: 10.1527904\ttotal: 22.3ms\tremaining: 7.68s\n",
      "29:\tlearn: 9.9146788\ttotal: 23.2ms\tremaining: 7.72s\n",
      "30:\tlearn: 9.7471848\ttotal: 24.3ms\tremaining: 7.83s\n",
      "31:\tlearn: 9.5324056\ttotal: 25.1ms\tremaining: 7.82s\n",
      "32:\tlearn: 9.4133587\ttotal: 25.7ms\tremaining: 7.77s\n",
      "33:\tlearn: 9.2610343\ttotal: 26.4ms\tremaining: 7.73s\n",
      "34:\tlearn: 9.0907644\ttotal: 27.1ms\tremaining: 7.72s\n",
      "35:\tlearn: 8.8900471\ttotal: 27.8ms\tremaining: 7.69s\n",
      "36:\tlearn: 8.8064312\ttotal: 28.4ms\tremaining: 7.66s\n",
      "37:\tlearn: 8.6832201\ttotal: 29.1ms\tremaining: 7.64s\n",
      "38:\tlearn: 8.5638708\ttotal: 29.8ms\tremaining: 7.62s\n",
      "39:\tlearn: 8.4380743\ttotal: 30.5ms\tremaining: 7.59s\n",
      "40:\tlearn: 8.3186716\ttotal: 31.1ms\tremaining: 7.56s\n",
      "41:\tlearn: 8.2180850\ttotal: 32ms\tremaining: 7.58s\n",
      "42:\tlearn: 8.1043186\ttotal: 32.7ms\tremaining: 7.57s\n",
      "43:\tlearn: 7.9851256\ttotal: 34.6ms\tremaining: 7.82s\n",
      "44:\tlearn: 7.8407169\ttotal: 35.3ms\tremaining: 7.81s\n",
      "45:\tlearn: 7.7288327\ttotal: 35.9ms\tremaining: 7.77s\n",
      "46:\tlearn: 7.5977365\ttotal: 36.6ms\tremaining: 7.75s\n",
      "47:\tlearn: 7.5525474\ttotal: 37.1ms\tremaining: 7.69s\n",
      "48:\tlearn: 7.4978377\ttotal: 37.7ms\tremaining: 7.66s\n",
      "49:\tlearn: 7.4408300\ttotal: 38.4ms\tremaining: 7.63s\n",
      "50:\tlearn: 7.3623470\ttotal: 39ms\tremaining: 7.61s\n",
      "51:\tlearn: 7.2513970\ttotal: 39.7ms\tremaining: 7.59s\n",
      "52:\tlearn: 7.1874598\ttotal: 40.4ms\tremaining: 7.58s\n",
      "53:\tlearn: 7.0806548\ttotal: 41ms\tremaining: 7.56s\n",
      "54:\tlearn: 7.0129685\ttotal: 41.7ms\tremaining: 7.55s\n",
      "55:\tlearn: 6.8910429\ttotal: 42.5ms\tremaining: 7.54s\n",
      "56:\tlearn: 6.8131591\ttotal: 43.1ms\tremaining: 7.53s\n",
      "57:\tlearn: 6.7459537\ttotal: 43.9ms\tremaining: 7.53s\n",
      "58:\tlearn: 6.6676348\ttotal: 44.7ms\tremaining: 7.53s\n",
      "59:\tlearn: 6.5684507\ttotal: 45.6ms\tremaining: 7.55s\n",
      "60:\tlearn: 6.4499829\ttotal: 46.9ms\tremaining: 7.64s\n",
      "61:\tlearn: 6.3720455\ttotal: 48.8ms\tremaining: 7.81s\n",
      "62:\tlearn: 6.2812122\ttotal: 49.8ms\tremaining: 7.86s\n",
      "63:\tlearn: 6.2059816\ttotal: 50.5ms\tremaining: 7.83s\n",
      "64:\tlearn: 6.1142648\ttotal: 51.2ms\tremaining: 7.83s\n",
      "65:\tlearn: 6.0248953\ttotal: 51.8ms\tremaining: 7.8s\n",
      "66:\tlearn: 5.9373898\ttotal: 52.5ms\tremaining: 7.78s\n",
      "67:\tlearn: 5.8546810\ttotal: 53.2ms\tremaining: 7.76s\n",
      "68:\tlearn: 5.8014580\ttotal: 53.8ms\tremaining: 7.74s\n",
      "69:\tlearn: 5.7398422\ttotal: 54.4ms\tremaining: 7.72s\n",
      "70:\tlearn: 5.6806362\ttotal: 55.1ms\tremaining: 7.7s\n",
      "71:\tlearn: 5.5899172\ttotal: 55.8ms\tremaining: 7.69s\n",
      "72:\tlearn: 5.5335604\ttotal: 56.4ms\tremaining: 7.67s\n",
      "73:\tlearn: 5.4832243\ttotal: 57ms\tremaining: 7.64s\n",
      "74:\tlearn: 5.4120933\ttotal: 57.6ms\tremaining: 7.62s\n",
      "75:\tlearn: 5.3628586\ttotal: 58.3ms\tremaining: 7.61s\n",
      "76:\tlearn: 5.2907041\ttotal: 59.1ms\tremaining: 7.62s\n",
      "77:\tlearn: 5.2315315\ttotal: 60ms\tremaining: 7.63s\n",
      "78:\tlearn: 5.2043559\ttotal: 61ms\tremaining: 7.66s\n",
      "79:\tlearn: 5.1502337\ttotal: 62ms\tremaining: 7.69s\n",
      "80:\tlearn: 5.0917519\ttotal: 62.8ms\tremaining: 7.69s\n",
      "81:\tlearn: 5.0186754\ttotal: 63.4ms\tremaining: 7.67s\n",
      "82:\tlearn: 4.9605614\ttotal: 64ms\tremaining: 7.64s\n",
      "83:\tlearn: 4.9103958\ttotal: 64.5ms\tremaining: 7.61s\n",
      "84:\tlearn: 4.8697144\ttotal: 65ms\tremaining: 7.58s\n",
      "85:\tlearn: 4.8154120\ttotal: 65.4ms\tremaining: 7.54s\n",
      "86:\tlearn: 4.7773655\ttotal: 65.9ms\tremaining: 7.51s\n",
      "87:\tlearn: 4.7235488\ttotal: 66.4ms\tremaining: 7.47s\n",
      "88:\tlearn: 4.6784445\ttotal: 66.8ms\tremaining: 7.44s\n",
      "89:\tlearn: 4.6382248\ttotal: 67.3ms\tremaining: 7.41s\n",
      "90:\tlearn: 4.5893154\ttotal: 67.7ms\tremaining: 7.37s\n",
      "91:\tlearn: 4.5501226\ttotal: 68.2ms\tremaining: 7.34s\n",
      "92:\tlearn: 4.5198550\ttotal: 68.6ms\tremaining: 7.31s\n",
      "93:\tlearn: 4.4796634\ttotal: 69.1ms\tremaining: 7.28s\n",
      "94:\tlearn: 4.4412542\ttotal: 69.6ms\tremaining: 7.25s\n",
      "95:\tlearn: 4.4259743\ttotal: 70ms\tremaining: 7.22s\n",
      "96:\tlearn: 4.3876813\ttotal: 70.5ms\tremaining: 7.19s\n",
      "97:\tlearn: 4.3711749\ttotal: 70.9ms\tremaining: 7.17s\n",
      "98:\tlearn: 4.3410779\ttotal: 71.4ms\tremaining: 7.14s\n",
      "99:\tlearn: 4.3277699\ttotal: 71.9ms\tremaining: 7.11s\n",
      "100:\tlearn: 4.2802199\ttotal: 72.3ms\tremaining: 7.09s\n",
      "101:\tlearn: 4.2481014\ttotal: 73ms\tremaining: 7.08s\n",
      "102:\tlearn: 4.2055492\ttotal: 73.7ms\tremaining: 7.08s\n",
      "103:\tlearn: 4.1690051\ttotal: 74.5ms\tremaining: 7.09s\n",
      "104:\tlearn: 4.1362552\ttotal: 75.1ms\tremaining: 7.08s\n",
      "105:\tlearn: 4.1065529\ttotal: 75.7ms\tremaining: 7.06s\n",
      "106:\tlearn: 4.0822168\ttotal: 76.2ms\tremaining: 7.05s\n",
      "107:\tlearn: 4.0457630\ttotal: 76.8ms\tremaining: 7.04s\n",
      "108:\tlearn: 4.0090944\ttotal: 77.4ms\tremaining: 7.03s\n",
      "109:\tlearn: 3.9824282\ttotal: 78.1ms\tremaining: 7.02s\n",
      "110:\tlearn: 3.9642473\ttotal: 78.7ms\tremaining: 7.01s\n",
      "111:\tlearn: 3.9312162\ttotal: 79.2ms\tremaining: 6.99s\n",
      "112:\tlearn: 3.9195920\ttotal: 79.9ms\tremaining: 6.99s\n",
      "113:\tlearn: 3.9055847\ttotal: 80.5ms\tremaining: 6.98s\n",
      "114:\tlearn: 3.8795574\ttotal: 81.1ms\tremaining: 6.97s\n",
      "115:\tlearn: 3.8704776\ttotal: 81.6ms\tremaining: 6.95s\n",
      "116:\tlearn: 3.8605558\ttotal: 82.2ms\tremaining: 6.94s\n",
      "117:\tlearn: 3.8250180\ttotal: 82.8ms\tremaining: 6.94s\n",
      "118:\tlearn: 3.7922933\ttotal: 83.4ms\tremaining: 6.92s\n",
      "119:\tlearn: 3.7711143\ttotal: 83.9ms\tremaining: 6.9s\n",
      "120:\tlearn: 3.7635313\ttotal: 84.3ms\tremaining: 6.88s\n",
      "121:\tlearn: 3.7356671\ttotal: 84.8ms\tremaining: 6.86s\n",
      "122:\tlearn: 3.7095816\ttotal: 85.3ms\tremaining: 6.84s\n",
      "123:\tlearn: 3.6695693\ttotal: 85.7ms\tremaining: 6.83s\n",
      "124:\tlearn: 3.6491124\ttotal: 86.2ms\tremaining: 6.81s\n",
      "125:\tlearn: 3.6418490\ttotal: 86.7ms\tremaining: 6.79s\n",
      "126:\tlearn: 3.6036584\ttotal: 87.2ms\tremaining: 6.78s\n",
      "127:\tlearn: 3.5882889\ttotal: 88ms\tremaining: 6.78s\n",
      "128:\tlearn: 3.5505065\ttotal: 88.7ms\tremaining: 6.79s\n",
      "129:\tlearn: 3.5277966\ttotal: 89.3ms\tremaining: 6.78s\n",
      "130:\tlearn: 3.5027413\ttotal: 89.8ms\tremaining: 6.77s\n",
      "131:\tlearn: 3.4887023\ttotal: 90.4ms\tremaining: 6.75s\n",
      "132:\tlearn: 3.4614721\ttotal: 90.9ms\tremaining: 6.75s\n",
      "133:\tlearn: 3.4269650\ttotal: 91.4ms\tremaining: 6.73s\n",
      "134:\tlearn: 3.3925913\ttotal: 91.9ms\tremaining: 6.72s\n",
      "135:\tlearn: 3.3653636\ttotal: 92.5ms\tremaining: 6.71s\n",
      "136:\tlearn: 3.3486851\ttotal: 93ms\tremaining: 6.7s\n",
      "137:\tlearn: 3.3243732\ttotal: 93.6ms\tremaining: 6.69s\n",
      "138:\tlearn: 3.3128977\ttotal: 94.1ms\tremaining: 6.67s\n",
      "139:\tlearn: 3.2912872\ttotal: 94.5ms\tremaining: 6.66s\n",
      "140:\tlearn: 3.2834699\ttotal: 95ms\tremaining: 6.64s\n",
      "141:\tlearn: 3.2663336\ttotal: 95.4ms\tremaining: 6.62s\n",
      "142:\tlearn: 3.2487785\ttotal: 95.9ms\tremaining: 6.61s\n",
      "143:\tlearn: 3.2198116\ttotal: 96.4ms\tremaining: 6.59s\n",
      "144:\tlearn: 3.2025692\ttotal: 96.8ms\tremaining: 6.58s\n",
      "145:\tlearn: 3.1941001\ttotal: 97.3ms\tremaining: 6.57s\n",
      "146:\tlearn: 3.1878465\ttotal: 97.8ms\tremaining: 6.55s\n",
      "147:\tlearn: 3.1698002\ttotal: 98.2ms\tremaining: 6.54s\n",
      "148:\tlearn: 3.1387146\ttotal: 98.7ms\tremaining: 6.52s\n",
      "149:\tlearn: 3.1234995\ttotal: 99.1ms\tremaining: 6.51s\n",
      "150:\tlearn: 3.1111786\ttotal: 99.6ms\tremaining: 6.5s\n",
      "151:\tlearn: 3.1070845\ttotal: 99.9ms\tremaining: 6.47s\n",
      "152:\tlearn: 3.0854257\ttotal: 100ms\tremaining: 6.46s\n",
      "153:\tlearn: 3.0649846\ttotal: 101ms\tremaining: 6.45s\n",
      "154:\tlearn: 3.0443456\ttotal: 102ms\tremaining: 6.45s\n",
      "155:\tlearn: 3.0239755\ttotal: 102ms\tremaining: 6.46s\n",
      "156:\tlearn: 3.0052328\ttotal: 103ms\tremaining: 6.46s\n",
      "157:\tlearn: 2.9903765\ttotal: 104ms\tremaining: 6.45s\n",
      "158:\tlearn: 2.9691279\ttotal: 104ms\tremaining: 6.44s\n",
      "159:\tlearn: 2.9629626\ttotal: 105ms\tremaining: 6.44s\n",
      "160:\tlearn: 2.9459251\ttotal: 105ms\tremaining: 6.42s\n",
      "161:\tlearn: 2.9300042\ttotal: 106ms\tremaining: 6.41s\n",
      "162:\tlearn: 2.9056497\ttotal: 106ms\tremaining: 6.4s\n",
      "163:\tlearn: 2.8886970\ttotal: 107ms\tremaining: 6.39s\n",
      "164:\tlearn: 2.8834107\ttotal: 107ms\tremaining: 6.37s\n",
      "165:\tlearn: 2.8572294\ttotal: 107ms\tremaining: 6.36s\n",
      "166:\tlearn: 2.8368829\ttotal: 108ms\tremaining: 6.35s\n",
      "167:\tlearn: 2.8158342\ttotal: 108ms\tremaining: 6.34s\n",
      "168:\tlearn: 2.7955937\ttotal: 109ms\tremaining: 6.33s\n",
      "169:\tlearn: 2.7882057\ttotal: 109ms\tremaining: 6.32s\n",
      "170:\tlearn: 2.7746125\ttotal: 110ms\tremaining: 6.31s\n",
      "171:\tlearn: 2.7636373\ttotal: 110ms\tremaining: 6.3s\n",
      "172:\tlearn: 2.7487394\ttotal: 111ms\tremaining: 6.29s\n",
      "173:\tlearn: 2.7416927\ttotal: 111ms\tremaining: 6.28s\n",
      "174:\tlearn: 2.7261717\ttotal: 112ms\tremaining: 6.26s\n",
      "175:\tlearn: 2.7058433\ttotal: 112ms\tremaining: 6.25s\n",
      "176:\tlearn: 2.6871708\ttotal: 112ms\tremaining: 6.24s\n",
      "177:\tlearn: 2.6727263\ttotal: 113ms\tremaining: 6.23s\n",
      "178:\tlearn: 2.6631745\ttotal: 113ms\tremaining: 6.22s\n",
      "179:\tlearn: 2.6366011\ttotal: 114ms\tremaining: 6.22s\n",
      "180:\tlearn: 2.6209620\ttotal: 115ms\tremaining: 6.21s\n",
      "181:\tlearn: 2.6000270\ttotal: 115ms\tremaining: 6.2s\n",
      "182:\tlearn: 2.5952953\ttotal: 116ms\tremaining: 6.2s\n",
      "183:\tlearn: 2.5671741\ttotal: 116ms\tremaining: 6.2s\n",
      "184:\tlearn: 2.5379610\ttotal: 117ms\tremaining: 6.2s\n",
      "185:\tlearn: 2.5247331\ttotal: 117ms\tremaining: 6.2s\n",
      "186:\tlearn: 2.5010984\ttotal: 118ms\tremaining: 6.19s\n",
      "187:\tlearn: 2.4835716\ttotal: 119ms\tremaining: 6.19s\n",
      "188:\tlearn: 2.4750208\ttotal: 119ms\tremaining: 6.18s\n",
      "189:\tlearn: 2.4695630\ttotal: 120ms\tremaining: 6.17s\n",
      "190:\tlearn: 2.4518682\ttotal: 120ms\tremaining: 6.16s\n",
      "191:\tlearn: 2.4412460\ttotal: 120ms\tremaining: 6.15s\n",
      "192:\tlearn: 2.4339219\ttotal: 121ms\tremaining: 6.14s\n",
      "193:\tlearn: 2.4262742\ttotal: 121ms\tremaining: 6.13s\n",
      "194:\tlearn: 2.4051241\ttotal: 122ms\tremaining: 6.13s\n",
      "195:\tlearn: 2.3947098\ttotal: 122ms\tremaining: 6.12s\n",
      "196:\tlearn: 2.3763148\ttotal: 123ms\tremaining: 6.11s\n",
      "197:\tlearn: 2.3605723\ttotal: 123ms\tremaining: 6.1s\n",
      "198:\tlearn: 2.3480005\ttotal: 124ms\tremaining: 6.09s\n",
      "199:\tlearn: 2.3274512\ttotal: 124ms\tremaining: 6.08s\n",
      "200:\tlearn: 2.3169003\ttotal: 125ms\tremaining: 6.07s\n",
      "201:\tlearn: 2.3000719\ttotal: 125ms\tremaining: 6.06s\n",
      "202:\tlearn: 2.2813307\ttotal: 126ms\tremaining: 6.06s\n",
      "203:\tlearn: 2.2664435\ttotal: 126ms\tremaining: 6.05s\n",
      "204:\tlearn: 2.2515531\ttotal: 127ms\tremaining: 6.04s\n",
      "205:\tlearn: 2.2415422\ttotal: 127ms\tremaining: 6.04s\n",
      "206:\tlearn: 2.2345960\ttotal: 128ms\tremaining: 6.04s\n",
      "207:\tlearn: 2.2304223\ttotal: 128ms\tremaining: 6.03s\n",
      "208:\tlearn: 2.2029859\ttotal: 129ms\tremaining: 6.03s\n",
      "209:\tlearn: 2.1909728\ttotal: 129ms\tremaining: 6.02s\n",
      "210:\tlearn: 2.1754112\ttotal: 130ms\tremaining: 6.02s\n",
      "211:\tlearn: 2.1658695\ttotal: 130ms\tremaining: 6.02s\n",
      "212:\tlearn: 2.1610196\ttotal: 131ms\tremaining: 6.02s\n",
      "213:\tlearn: 2.1574571\ttotal: 132ms\tremaining: 6.02s\n",
      "214:\tlearn: 2.1442410\ttotal: 132ms\tremaining: 6.02s\n",
      "215:\tlearn: 2.1377772\ttotal: 133ms\tremaining: 6.02s\n",
      "216:\tlearn: 2.1342285\ttotal: 133ms\tremaining: 6.01s\n",
      "217:\tlearn: 2.1244427\ttotal: 134ms\tremaining: 6.01s\n",
      "218:\tlearn: 2.1082324\ttotal: 134ms\tremaining: 6s\n",
      "219:\tlearn: 2.1013181\ttotal: 135ms\tremaining: 6s\n",
      "220:\tlearn: 2.0924417\ttotal: 135ms\tremaining: 5.99s\n",
      "221:\tlearn: 2.0815590\ttotal: 136ms\tremaining: 5.98s\n",
      "222:\tlearn: 2.0655243\ttotal: 136ms\tremaining: 5.97s\n",
      "223:\tlearn: 2.0576273\ttotal: 137ms\tremaining: 5.96s\n",
      "224:\tlearn: 2.0498427\ttotal: 137ms\tremaining: 5.96s\n",
      "225:\tlearn: 2.0460662\ttotal: 138ms\tremaining: 5.95s\n",
      "226:\tlearn: 2.0388144\ttotal: 138ms\tremaining: 5.94s\n",
      "227:\tlearn: 2.0356476\ttotal: 139ms\tremaining: 5.94s\n",
      "228:\tlearn: 2.0329540\ttotal: 139ms\tremaining: 5.93s\n",
      "229:\tlearn: 2.0190037\ttotal: 139ms\tremaining: 5.92s\n",
      "230:\tlearn: 2.0154740\ttotal: 140ms\tremaining: 5.92s\n",
      "231:\tlearn: 2.0091057\ttotal: 140ms\tremaining: 5.91s\n",
      "232:\tlearn: 1.9873410\ttotal: 141ms\tremaining: 5.9s\n",
      "233:\tlearn: 1.9686651\ttotal: 141ms\tremaining: 5.9s\n",
      "234:\tlearn: 1.9588487\ttotal: 142ms\tremaining: 5.89s\n",
      "235:\tlearn: 1.9539717\ttotal: 142ms\tremaining: 5.88s\n",
      "236:\tlearn: 1.9409147\ttotal: 143ms\tremaining: 5.88s\n",
      "237:\tlearn: 1.9354244\ttotal: 143ms\tremaining: 5.88s\n",
      "238:\tlearn: 1.9230355\ttotal: 144ms\tremaining: 5.87s\n",
      "239:\tlearn: 1.9030833\ttotal: 144ms\tremaining: 5.86s\n",
      "240:\tlearn: 1.8897011\ttotal: 145ms\tremaining: 5.85s\n",
      "241:\tlearn: 1.8781981\ttotal: 145ms\tremaining: 5.86s\n",
      "242:\tlearn: 1.8755566\ttotal: 146ms\tremaining: 5.85s\n",
      "243:\tlearn: 1.8580569\ttotal: 146ms\tremaining: 5.85s\n",
      "244:\tlearn: 1.8521927\ttotal: 147ms\tremaining: 5.84s\n",
      "245:\tlearn: 1.8471303\ttotal: 147ms\tremaining: 5.84s\n",
      "246:\tlearn: 1.8308526\ttotal: 148ms\tremaining: 5.83s\n",
      "247:\tlearn: 1.8196491\ttotal: 148ms\tremaining: 5.83s\n",
      "248:\tlearn: 1.8122279\ttotal: 149ms\tremaining: 5.82s\n",
      "249:\tlearn: 1.8074373\ttotal: 149ms\tremaining: 5.82s\n",
      "250:\tlearn: 1.8014296\ttotal: 150ms\tremaining: 5.81s\n",
      "251:\tlearn: 1.7953050\ttotal: 150ms\tremaining: 5.8s\n",
      "252:\tlearn: 1.7813373\ttotal: 150ms\tremaining: 5.8s\n",
      "253:\tlearn: 1.7629478\ttotal: 151ms\tremaining: 5.79s\n",
      "254:\tlearn: 1.7533971\ttotal: 151ms\tremaining: 5.79s\n",
      "255:\tlearn: 1.7424654\ttotal: 152ms\tremaining: 5.78s\n",
      "256:\tlearn: 1.7393462\ttotal: 152ms\tremaining: 5.78s\n",
      "257:\tlearn: 1.7261993\ttotal: 153ms\tremaining: 5.77s\n",
      "258:\tlearn: 1.7199997\ttotal: 153ms\tremaining: 5.76s\n",
      "259:\tlearn: 1.6954754\ttotal: 154ms\tremaining: 5.76s\n",
      "260:\tlearn: 1.6904283\ttotal: 154ms\tremaining: 5.76s\n",
      "261:\tlearn: 1.6830157\ttotal: 155ms\tremaining: 5.75s\n",
      "262:\tlearn: 1.6770153\ttotal: 155ms\tremaining: 5.75s\n",
      "263:\tlearn: 1.6558143\ttotal: 156ms\tremaining: 5.74s\n",
      "264:\tlearn: 1.6487809\ttotal: 156ms\tremaining: 5.74s\n",
      "265:\tlearn: 1.6380905\ttotal: 157ms\tremaining: 5.73s\n",
      "266:\tlearn: 1.6337782\ttotal: 157ms\tremaining: 5.72s\n",
      "267:\tlearn: 1.6249888\ttotal: 158ms\tremaining: 5.72s\n",
      "268:\tlearn: 1.6123192\ttotal: 158ms\tremaining: 5.72s\n",
      "269:\tlearn: 1.6061403\ttotal: 159ms\tremaining: 5.71s\n",
      "270:\tlearn: 1.5972732\ttotal: 159ms\tremaining: 5.71s\n",
      "271:\tlearn: 1.5917379\ttotal: 160ms\tremaining: 5.72s\n",
      "272:\tlearn: 1.5871124\ttotal: 160ms\tremaining: 5.72s\n",
      "273:\tlearn: 1.5827820\ttotal: 161ms\tremaining: 5.71s\n",
      "274:\tlearn: 1.5752017\ttotal: 161ms\tremaining: 5.71s\n",
      "275:\tlearn: 1.5708528\ttotal: 162ms\tremaining: 5.7s\n",
      "276:\tlearn: 1.5560557\ttotal: 162ms\tremaining: 5.7s\n",
      "277:\tlearn: 1.5488332\ttotal: 163ms\tremaining: 5.69s\n",
      "278:\tlearn: 1.5410670\ttotal: 163ms\tremaining: 5.69s\n",
      "279:\tlearn: 1.5333212\ttotal: 164ms\tremaining: 5.68s\n",
      "280:\tlearn: 1.5230681\ttotal: 164ms\tremaining: 5.67s\n",
      "281:\tlearn: 1.5199303\ttotal: 165ms\tremaining: 5.67s\n",
      "282:\tlearn: 1.5135684\ttotal: 165ms\tremaining: 5.67s\n",
      "283:\tlearn: 1.5045253\ttotal: 165ms\tremaining: 5.66s\n",
      "284:\tlearn: 1.5027107\ttotal: 166ms\tremaining: 5.66s\n",
      "285:\tlearn: 1.4993133\ttotal: 166ms\tremaining: 5.65s\n",
      "286:\tlearn: 1.4822023\ttotal: 167ms\tremaining: 5.65s\n",
      "287:\tlearn: 1.4761375\ttotal: 167ms\tremaining: 5.64s\n",
      "288:\tlearn: 1.4683840\ttotal: 168ms\tremaining: 5.64s\n",
      "289:\tlearn: 1.4547613\ttotal: 168ms\tremaining: 5.64s\n",
      "290:\tlearn: 1.4451647\ttotal: 169ms\tremaining: 5.63s\n",
      "291:\tlearn: 1.4389968\ttotal: 169ms\tremaining: 5.63s\n",
      "292:\tlearn: 1.4262374\ttotal: 170ms\tremaining: 5.63s\n",
      "293:\tlearn: 1.4181105\ttotal: 170ms\tremaining: 5.62s\n",
      "294:\tlearn: 1.4136330\ttotal: 171ms\tremaining: 5.62s\n",
      "295:\tlearn: 1.4101452\ttotal: 171ms\tremaining: 5.62s\n",
      "296:\tlearn: 1.3998229\ttotal: 172ms\tremaining: 5.61s\n",
      "297:\tlearn: 1.3973519\ttotal: 172ms\tremaining: 5.61s\n",
      "298:\tlearn: 1.3951563\ttotal: 173ms\tremaining: 5.61s\n",
      "299:\tlearn: 1.3894217\ttotal: 174ms\tremaining: 5.61s\n",
      "300:\tlearn: 1.3774044\ttotal: 174ms\tremaining: 5.61s\n",
      "301:\tlearn: 1.3659400\ttotal: 175ms\tremaining: 5.61s\n",
      "302:\tlearn: 1.3571540\ttotal: 175ms\tremaining: 5.61s\n",
      "303:\tlearn: 1.3533167\ttotal: 176ms\tremaining: 5.61s\n",
      "304:\tlearn: 1.3504435\ttotal: 176ms\tremaining: 5.6s\n",
      "305:\tlearn: 1.3466767\ttotal: 177ms\tremaining: 5.6s\n",
      "306:\tlearn: 1.3429384\ttotal: 177ms\tremaining: 5.59s\n",
      "307:\tlearn: 1.3321005\ttotal: 178ms\tremaining: 5.59s\n",
      "308:\tlearn: 1.3271456\ttotal: 178ms\tremaining: 5.58s\n",
      "309:\tlearn: 1.3227450\ttotal: 179ms\tremaining: 5.58s\n",
      "310:\tlearn: 1.3125103\ttotal: 179ms\tremaining: 5.58s\n",
      "311:\tlearn: 1.3080418\ttotal: 179ms\tremaining: 5.57s\n",
      "312:\tlearn: 1.2959259\ttotal: 180ms\tremaining: 5.57s\n",
      "313:\tlearn: 1.2845068\ttotal: 180ms\tremaining: 5.56s\n",
      "314:\tlearn: 1.2818567\ttotal: 181ms\tremaining: 5.56s\n",
      "315:\tlearn: 1.2697854\ttotal: 181ms\tremaining: 5.55s\n",
      "316:\tlearn: 1.2569421\ttotal: 183ms\tremaining: 5.58s\n",
      "317:\tlearn: 1.2533025\ttotal: 183ms\tremaining: 5.58s\n",
      "318:\tlearn: 1.2472512\ttotal: 184ms\tremaining: 5.58s\n",
      "319:\tlearn: 1.2445673\ttotal: 185ms\tremaining: 5.58s\n",
      "320:\tlearn: 1.2375833\ttotal: 185ms\tremaining: 5.58s\n",
      "321:\tlearn: 1.2267459\ttotal: 186ms\tremaining: 5.58s\n",
      "322:\tlearn: 1.2235690\ttotal: 186ms\tremaining: 5.58s\n",
      "323:\tlearn: 1.2144526\ttotal: 187ms\tremaining: 5.58s\n",
      "324:\tlearn: 1.2059296\ttotal: 187ms\tremaining: 5.57s\n",
      "325:\tlearn: 1.2043049\ttotal: 188ms\tremaining: 5.57s\n",
      "326:\tlearn: 1.2017029\ttotal: 188ms\tremaining: 5.58s\n",
      "327:\tlearn: 1.1912363\ttotal: 189ms\tremaining: 5.58s\n",
      "328:\tlearn: 1.1850999\ttotal: 190ms\tremaining: 5.57s\n",
      "329:\tlearn: 1.1755642\ttotal: 190ms\tremaining: 5.57s\n",
      "330:\tlearn: 1.1666181\ttotal: 191ms\tremaining: 5.57s\n",
      "331:\tlearn: 1.1633864\ttotal: 191ms\tremaining: 5.57s\n",
      "332:\tlearn: 1.1533807\ttotal: 192ms\tremaining: 5.56s\n",
      "333:\tlearn: 1.1437238\ttotal: 192ms\tremaining: 5.56s\n",
      "334:\tlearn: 1.1365639\ttotal: 193ms\tremaining: 5.56s\n",
      "335:\tlearn: 1.1346855\ttotal: 193ms\tremaining: 5.56s\n",
      "336:\tlearn: 1.1311654\ttotal: 194ms\tremaining: 5.56s\n",
      "337:\tlearn: 1.1296715\ttotal: 195ms\tremaining: 5.56s\n",
      "338:\tlearn: 1.1226333\ttotal: 195ms\tremaining: 5.56s\n",
      "339:\tlearn: 1.1150477\ttotal: 196ms\tremaining: 5.56s\n",
      "340:\tlearn: 1.1126682\ttotal: 196ms\tremaining: 5.55s\n",
      "341:\tlearn: 1.1061106\ttotal: 197ms\tremaining: 5.55s\n",
      "342:\tlearn: 1.1044809\ttotal: 197ms\tremaining: 5.56s\n",
      "343:\tlearn: 1.1026723\ttotal: 198ms\tremaining: 5.56s\n",
      "344:\tlearn: 1.0946929\ttotal: 199ms\tremaining: 5.56s\n",
      "345:\tlearn: 1.0932204\ttotal: 199ms\tremaining: 5.55s\n",
      "346:\tlearn: 1.0877135\ttotal: 199ms\tremaining: 5.55s\n",
      "347:\tlearn: 1.0854380\ttotal: 200ms\tremaining: 5.54s\n",
      "348:\tlearn: 1.0827449\ttotal: 200ms\tremaining: 5.54s\n",
      "349:\tlearn: 1.0751246\ttotal: 201ms\tremaining: 5.54s\n",
      "350:\tlearn: 1.0738043\ttotal: 201ms\tremaining: 5.54s\n",
      "351:\tlearn: 1.0725343\ttotal: 202ms\tremaining: 5.54s\n",
      "352:\tlearn: 1.0710824\ttotal: 203ms\tremaining: 5.54s\n",
      "353:\tlearn: 1.0684103\ttotal: 203ms\tremaining: 5.54s\n",
      "354:\tlearn: 1.0664865\ttotal: 204ms\tremaining: 5.54s\n",
      "355:\tlearn: 1.0617382\ttotal: 204ms\tremaining: 5.54s\n",
      "356:\tlearn: 1.0596093\ttotal: 205ms\tremaining: 5.54s\n",
      "357:\tlearn: 1.0540460\ttotal: 206ms\tremaining: 5.54s\n",
      "358:\tlearn: 1.0461679\ttotal: 206ms\tremaining: 5.54s\n",
      "359:\tlearn: 1.0386075\ttotal: 207ms\tremaining: 5.54s\n",
      "360:\tlearn: 1.0262356\ttotal: 207ms\tremaining: 5.54s\n",
      "361:\tlearn: 1.0228604\ttotal: 208ms\tremaining: 5.54s\n",
      "362:\tlearn: 1.0216805\ttotal: 208ms\tremaining: 5.53s\n",
      "363:\tlearn: 1.0169774\ttotal: 209ms\tremaining: 5.53s\n",
      "364:\tlearn: 1.0110683\ttotal: 209ms\tremaining: 5.52s\n",
      "365:\tlearn: 1.0074619\ttotal: 210ms\tremaining: 5.52s\n",
      "366:\tlearn: 1.0055791\ttotal: 210ms\tremaining: 5.52s\n",
      "367:\tlearn: 1.0003543\ttotal: 211ms\tremaining: 5.51s\n",
      "368:\tlearn: 0.9987299\ttotal: 211ms\tremaining: 5.51s\n",
      "369:\tlearn: 0.9956029\ttotal: 212ms\tremaining: 5.51s\n",
      "370:\tlearn: 0.9904939\ttotal: 212ms\tremaining: 5.5s\n",
      "371:\tlearn: 0.9870460\ttotal: 212ms\tremaining: 5.5s\n",
      "372:\tlearn: 0.9792219\ttotal: 213ms\tremaining: 5.5s\n",
      "373:\tlearn: 0.9712897\ttotal: 213ms\tremaining: 5.49s\n",
      "374:\tlearn: 0.9690600\ttotal: 214ms\tremaining: 5.49s\n",
      "375:\tlearn: 0.9607755\ttotal: 214ms\tremaining: 5.48s\n",
      "376:\tlearn: 0.9545027\ttotal: 215ms\tremaining: 5.48s\n",
      "377:\tlearn: 0.9494605\ttotal: 215ms\tremaining: 5.48s\n",
      "378:\tlearn: 0.9472686\ttotal: 216ms\tremaining: 5.48s\n",
      "379:\tlearn: 0.9424797\ttotal: 217ms\tremaining: 5.48s\n",
      "380:\tlearn: 0.9356620\ttotal: 217ms\tremaining: 5.48s\n",
      "381:\tlearn: 0.9296985\ttotal: 218ms\tremaining: 5.48s\n",
      "382:\tlearn: 0.9270372\ttotal: 218ms\tremaining: 5.47s\n",
      "383:\tlearn: 0.9230965\ttotal: 218ms\tremaining: 5.47s\n",
      "384:\tlearn: 0.9200139\ttotal: 219ms\tremaining: 5.47s\n",
      "385:\tlearn: 0.9148171\ttotal: 219ms\tremaining: 5.46s\n",
      "386:\tlearn: 0.9052541\ttotal: 220ms\tremaining: 5.46s\n",
      "387:\tlearn: 0.9033740\ttotal: 220ms\tremaining: 5.46s\n",
      "388:\tlearn: 0.8993116\ttotal: 221ms\tremaining: 5.45s\n",
      "389:\tlearn: 0.8905403\ttotal: 222ms\tremaining: 5.46s\n",
      "390:\tlearn: 0.8802605\ttotal: 222ms\tremaining: 5.46s\n",
      "391:\tlearn: 0.8728095\ttotal: 223ms\tremaining: 5.46s\n",
      "392:\tlearn: 0.8706057\ttotal: 223ms\tremaining: 5.46s\n",
      "393:\tlearn: 0.8689496\ttotal: 224ms\tremaining: 5.46s\n",
      "394:\tlearn: 0.8645788\ttotal: 225ms\tremaining: 5.46s\n",
      "395:\tlearn: 0.8588013\ttotal: 225ms\tremaining: 5.46s\n",
      "396:\tlearn: 0.8575696\ttotal: 226ms\tremaining: 5.46s\n",
      "397:\tlearn: 0.8564123\ttotal: 226ms\tremaining: 5.45s\n",
      "398:\tlearn: 0.8541835\ttotal: 227ms\tremaining: 5.45s\n",
      "399:\tlearn: 0.8495440\ttotal: 227ms\tremaining: 5.45s\n",
      "400:\tlearn: 0.8430161\ttotal: 228ms\tremaining: 5.45s\n",
      "401:\tlearn: 0.8416383\ttotal: 228ms\tremaining: 5.44s\n",
      "402:\tlearn: 0.8405508\ttotal: 228ms\tremaining: 5.44s\n",
      "403:\tlearn: 0.8399089\ttotal: 229ms\tremaining: 5.44s\n",
      "404:\tlearn: 0.8375983\ttotal: 229ms\tremaining: 5.44s\n",
      "405:\tlearn: 0.8277868\ttotal: 230ms\tremaining: 5.44s\n",
      "406:\tlearn: 0.8218852\ttotal: 231ms\tremaining: 5.44s\n",
      "407:\tlearn: 0.8162663\ttotal: 231ms\tremaining: 5.44s\n",
      "408:\tlearn: 0.8154220\ttotal: 232ms\tremaining: 5.43s\n",
      "409:\tlearn: 0.8133986\ttotal: 232ms\tremaining: 5.43s\n",
      "410:\tlearn: 0.8093547\ttotal: 233ms\tremaining: 5.43s\n",
      "411:\tlearn: 0.8085058\ttotal: 233ms\tremaining: 5.42s\n",
      "412:\tlearn: 0.8074519\ttotal: 234ms\tremaining: 5.42s\n",
      "413:\tlearn: 0.8062260\ttotal: 234ms\tremaining: 5.42s\n",
      "414:\tlearn: 0.8026371\ttotal: 234ms\tremaining: 5.41s\n",
      "415:\tlearn: 0.7970848\ttotal: 235ms\tremaining: 5.41s\n",
      "416:\tlearn: 0.7911687\ttotal: 235ms\tremaining: 5.41s\n",
      "417:\tlearn: 0.7859291\ttotal: 236ms\tremaining: 5.4s\n",
      "418:\tlearn: 0.7853753\ttotal: 236ms\tremaining: 5.4s\n",
      "419:\tlearn: 0.7829477\ttotal: 237ms\tremaining: 5.4s\n",
      "420:\tlearn: 0.7748124\ttotal: 237ms\tremaining: 5.39s\n",
      "421:\tlearn: 0.7674965\ttotal: 238ms\tremaining: 5.39s\n",
      "422:\tlearn: 0.7612197\ttotal: 238ms\tremaining: 5.39s\n",
      "423:\tlearn: 0.7554333\ttotal: 238ms\tremaining: 5.38s\n",
      "424:\tlearn: 0.7524330\ttotal: 239ms\tremaining: 5.38s\n",
      "425:\tlearn: 0.7452943\ttotal: 239ms\tremaining: 5.37s\n",
      "426:\tlearn: 0.7397171\ttotal: 240ms\tremaining: 5.37s\n",
      "427:\tlearn: 0.7389404\ttotal: 240ms\tremaining: 5.37s\n",
      "428:\tlearn: 0.7371427\ttotal: 241ms\tremaining: 5.37s\n",
      "429:\tlearn: 0.7291595\ttotal: 241ms\tremaining: 5.36s\n",
      "430:\tlearn: 0.7281544\ttotal: 241ms\tremaining: 5.36s\n",
      "431:\tlearn: 0.7226378\ttotal: 242ms\tremaining: 5.36s\n",
      "432:\tlearn: 0.7197841\ttotal: 242ms\tremaining: 5.35s\n",
      "433:\tlearn: 0.7187675\ttotal: 244ms\tremaining: 5.37s\n",
      "434:\tlearn: 0.7160803\ttotal: 244ms\tremaining: 5.37s\n",
      "435:\tlearn: 0.7150177\ttotal: 245ms\tremaining: 5.38s\n",
      "436:\tlearn: 0.7089270\ttotal: 246ms\tremaining: 5.38s\n",
      "437:\tlearn: 0.7075981\ttotal: 247ms\tremaining: 5.38s\n",
      "438:\tlearn: 0.7000424\ttotal: 247ms\tremaining: 5.38s\n",
      "439:\tlearn: 0.6946388\ttotal: 248ms\tremaining: 5.38s\n",
      "440:\tlearn: 0.6902144\ttotal: 248ms\tremaining: 5.38s\n",
      "441:\tlearn: 0.6896527\ttotal: 249ms\tremaining: 5.38s\n",
      "442:\tlearn: 0.6851866\ttotal: 249ms\tremaining: 5.38s\n",
      "443:\tlearn: 0.6822141\ttotal: 250ms\tremaining: 5.37s\n",
      "444:\tlearn: 0.6793258\ttotal: 250ms\tremaining: 5.37s\n",
      "445:\tlearn: 0.6742333\ttotal: 251ms\tremaining: 5.37s\n",
      "446:\tlearn: 0.6694324\ttotal: 251ms\tremaining: 5.37s\n",
      "447:\tlearn: 0.6667047\ttotal: 252ms\tremaining: 5.36s\n",
      "448:\tlearn: 0.6619563\ttotal: 252ms\tremaining: 5.36s\n",
      "449:\tlearn: 0.6609605\ttotal: 252ms\tremaining: 5.36s\n",
      "450:\tlearn: 0.6573998\ttotal: 253ms\tremaining: 5.35s\n",
      "451:\tlearn: 0.6556889\ttotal: 253ms\tremaining: 5.35s\n",
      "452:\tlearn: 0.6544184\ttotal: 254ms\tremaining: 5.35s\n",
      "453:\tlearn: 0.6499553\ttotal: 254ms\tremaining: 5.35s\n",
      "454:\tlearn: 0.6491731\ttotal: 255ms\tremaining: 5.34s\n",
      "455:\tlearn: 0.6454844\ttotal: 255ms\tremaining: 5.34s\n",
      "456:\tlearn: 0.6438345\ttotal: 256ms\tremaining: 5.34s\n",
      "457:\tlearn: 0.6396445\ttotal: 256ms\tremaining: 5.33s\n",
      "458:\tlearn: 0.6366852\ttotal: 257ms\tremaining: 5.33s\n",
      "459:\tlearn: 0.6351944\ttotal: 257ms\tremaining: 5.33s\n",
      "460:\tlearn: 0.6310878\ttotal: 258ms\tremaining: 5.33s\n",
      "461:\tlearn: 0.6265985\ttotal: 258ms\tremaining: 5.33s\n",
      "462:\tlearn: 0.6228090\ttotal: 259ms\tremaining: 5.33s\n",
      "463:\tlearn: 0.6185271\ttotal: 260ms\tremaining: 5.33s\n",
      "464:\tlearn: 0.6153931\ttotal: 260ms\tremaining: 5.33s\n",
      "465:\tlearn: 0.6096823\ttotal: 260ms\tremaining: 5.33s\n",
      "466:\tlearn: 0.6062367\ttotal: 261ms\tremaining: 5.32s\n",
      "467:\tlearn: 0.6051591\ttotal: 261ms\tremaining: 5.32s\n",
      "468:\tlearn: 0.6030944\ttotal: 262ms\tremaining: 5.32s\n",
      "469:\tlearn: 0.5988220\ttotal: 262ms\tremaining: 5.32s\n",
      "470:\tlearn: 0.5974727\ttotal: 263ms\tremaining: 5.31s\n",
      "471:\tlearn: 0.5968548\ttotal: 263ms\tremaining: 5.31s\n",
      "472:\tlearn: 0.5959910\ttotal: 263ms\tremaining: 5.31s\n",
      "473:\tlearn: 0.5917415\ttotal: 264ms\tremaining: 5.3s\n",
      "474:\tlearn: 0.5897475\ttotal: 264ms\tremaining: 5.3s\n",
      "475:\tlearn: 0.5862770\ttotal: 265ms\tremaining: 5.3s\n",
      "476:\tlearn: 0.5833066\ttotal: 265ms\tremaining: 5.3s\n",
      "477:\tlearn: 0.5801827\ttotal: 266ms\tremaining: 5.3s\n",
      "478:\tlearn: 0.5796517\ttotal: 266ms\tremaining: 5.29s\n",
      "479:\tlearn: 0.5756972\ttotal: 267ms\tremaining: 5.29s\n",
      "480:\tlearn: 0.5718832\ttotal: 267ms\tremaining: 5.29s\n",
      "481:\tlearn: 0.5684120\ttotal: 268ms\tremaining: 5.29s\n",
      "482:\tlearn: 0.5668561\ttotal: 268ms\tremaining: 5.29s\n",
      "483:\tlearn: 0.5632950\ttotal: 269ms\tremaining: 5.28s\n",
      "484:\tlearn: 0.5608461\ttotal: 269ms\tremaining: 5.28s\n",
      "485:\tlearn: 0.5582202\ttotal: 270ms\tremaining: 5.28s\n",
      "486:\tlearn: 0.5547919\ttotal: 270ms\tremaining: 5.28s\n",
      "487:\tlearn: 0.5518323\ttotal: 270ms\tremaining: 5.27s\n",
      "488:\tlearn: 0.5479030\ttotal: 271ms\tremaining: 5.27s\n",
      "489:\tlearn: 0.5443912\ttotal: 272ms\tremaining: 5.27s\n",
      "490:\tlearn: 0.5433103\ttotal: 272ms\tremaining: 5.27s\n",
      "491:\tlearn: 0.5420436\ttotal: 273ms\tremaining: 5.27s\n",
      "492:\tlearn: 0.5381337\ttotal: 273ms\tremaining: 5.27s\n",
      "493:\tlearn: 0.5351792\ttotal: 274ms\tremaining: 5.27s\n",
      "494:\tlearn: 0.5307612\ttotal: 274ms\tremaining: 5.26s\n",
      "495:\tlearn: 0.5273092\ttotal: 275ms\tremaining: 5.26s\n",
      "496:\tlearn: 0.5241103\ttotal: 275ms\tremaining: 5.26s\n",
      "497:\tlearn: 0.5195781\ttotal: 276ms\tremaining: 5.26s\n",
      "498:\tlearn: 0.5153800\ttotal: 276ms\tremaining: 5.25s\n",
      "499:\tlearn: 0.5109881\ttotal: 276ms\tremaining: 5.25s\n",
      "500:\tlearn: 0.5096040\ttotal: 277ms\tremaining: 5.25s\n",
      "501:\tlearn: 0.5086323\ttotal: 277ms\tremaining: 5.24s\n",
      "502:\tlearn: 0.5048057\ttotal: 278ms\tremaining: 5.24s\n",
      "503:\tlearn: 0.5003777\ttotal: 278ms\tremaining: 5.24s\n",
      "504:\tlearn: 0.4991546\ttotal: 279ms\tremaining: 5.24s\n",
      "505:\tlearn: 0.4972435\ttotal: 279ms\tremaining: 5.23s\n",
      "506:\tlearn: 0.4934630\ttotal: 279ms\tremaining: 5.23s\n",
      "507:\tlearn: 0.4907668\ttotal: 280ms\tremaining: 5.23s\n",
      "508:\tlearn: 0.4884906\ttotal: 280ms\tremaining: 5.23s\n",
      "509:\tlearn: 0.4845892\ttotal: 281ms\tremaining: 5.22s\n",
      "510:\tlearn: 0.4804416\ttotal: 281ms\tremaining: 5.22s\n",
      "511:\tlearn: 0.4772450\ttotal: 282ms\tremaining: 5.22s\n",
      "512:\tlearn: 0.4763449\ttotal: 282ms\tremaining: 5.22s\n",
      "513:\tlearn: 0.4746963\ttotal: 283ms\tremaining: 5.21s\n",
      "514:\tlearn: 0.4716488\ttotal: 283ms\tremaining: 5.21s\n",
      "515:\tlearn: 0.4702443\ttotal: 283ms\tremaining: 5.21s\n",
      "516:\tlearn: 0.4691735\ttotal: 284ms\tremaining: 5.21s\n",
      "517:\tlearn: 0.4679067\ttotal: 284ms\tremaining: 5.21s\n",
      "518:\tlearn: 0.4649771\ttotal: 285ms\tremaining: 5.2s\n",
      "519:\tlearn: 0.4640885\ttotal: 285ms\tremaining: 5.2s\n",
      "520:\tlearn: 0.4624383\ttotal: 286ms\tremaining: 5.2s\n",
      "521:\tlearn: 0.4602322\ttotal: 288ms\tremaining: 5.23s\n",
      "522:\tlearn: 0.4591498\ttotal: 289ms\tremaining: 5.23s\n",
      "523:\tlearn: 0.4566638\ttotal: 289ms\tremaining: 5.23s\n",
      "524:\tlearn: 0.4539673\ttotal: 290ms\tremaining: 5.23s\n",
      "525:\tlearn: 0.4528727\ttotal: 290ms\tremaining: 5.23s\n",
      "526:\tlearn: 0.4498852\ttotal: 291ms\tremaining: 5.23s\n",
      "527:\tlearn: 0.4470926\ttotal: 291ms\tremaining: 5.23s\n",
      "528:\tlearn: 0.4456877\ttotal: 292ms\tremaining: 5.23s\n",
      "529:\tlearn: 0.4431886\ttotal: 293ms\tremaining: 5.23s\n",
      "530:\tlearn: 0.4425490\ttotal: 293ms\tremaining: 5.22s\n",
      "531:\tlearn: 0.4386075\ttotal: 293ms\tremaining: 5.22s\n",
      "532:\tlearn: 0.4378987\ttotal: 294ms\tremaining: 5.22s\n",
      "533:\tlearn: 0.4373921\ttotal: 294ms\tremaining: 5.22s\n",
      "534:\tlearn: 0.4360832\ttotal: 295ms\tremaining: 5.22s\n",
      "535:\tlearn: 0.4327293\ttotal: 295ms\tremaining: 5.22s\n",
      "536:\tlearn: 0.4284692\ttotal: 296ms\tremaining: 5.21s\n",
      "537:\tlearn: 0.4266343\ttotal: 296ms\tremaining: 5.21s\n",
      "538:\tlearn: 0.4258746\ttotal: 297ms\tremaining: 5.21s\n",
      "539:\tlearn: 0.4250267\ttotal: 297ms\tremaining: 5.21s\n",
      "540:\tlearn: 0.4242279\ttotal: 298ms\tremaining: 5.21s\n",
      "541:\tlearn: 0.4235955\ttotal: 298ms\tremaining: 5.2s\n",
      "542:\tlearn: 0.4215947\ttotal: 299ms\tremaining: 5.2s\n",
      "543:\tlearn: 0.4210697\ttotal: 299ms\tremaining: 5.2s\n",
      "544:\tlearn: 0.4182881\ttotal: 299ms\tremaining: 5.2s\n",
      "545:\tlearn: 0.4152326\ttotal: 300ms\tremaining: 5.2s\n",
      "546:\tlearn: 0.4127960\ttotal: 301ms\tremaining: 5.21s\n",
      "547:\tlearn: 0.4110165\ttotal: 302ms\tremaining: 5.21s\n",
      "548:\tlearn: 0.4104553\ttotal: 303ms\tremaining: 5.21s\n",
      "549:\tlearn: 0.4074798\ttotal: 303ms\tremaining: 5.21s\n",
      "550:\tlearn: 0.4049963\ttotal: 304ms\tremaining: 5.21s\n",
      "551:\tlearn: 0.4040999\ttotal: 304ms\tremaining: 5.21s\n",
      "552:\tlearn: 0.4029842\ttotal: 305ms\tremaining: 5.21s\n",
      "553:\tlearn: 0.4011403\ttotal: 305ms\tremaining: 5.2s\n",
      "554:\tlearn: 0.4007158\ttotal: 306ms\tremaining: 5.2s\n",
      "555:\tlearn: 0.3965807\ttotal: 306ms\tremaining: 5.2s\n",
      "556:\tlearn: 0.3949405\ttotal: 307ms\tremaining: 5.2s\n",
      "557:\tlearn: 0.3923537\ttotal: 307ms\tremaining: 5.2s\n",
      "558:\tlearn: 0.3912388\ttotal: 308ms\tremaining: 5.2s\n",
      "559:\tlearn: 0.3895927\ttotal: 308ms\tremaining: 5.19s\n",
      "560:\tlearn: 0.3869264\ttotal: 308ms\tremaining: 5.19s\n",
      "561:\tlearn: 0.3850331\ttotal: 309ms\tremaining: 5.19s\n",
      "562:\tlearn: 0.3836864\ttotal: 309ms\tremaining: 5.19s\n",
      "563:\tlearn: 0.3809461\ttotal: 310ms\tremaining: 5.18s\n",
      "564:\tlearn: 0.3786141\ttotal: 310ms\tremaining: 5.18s\n",
      "565:\tlearn: 0.3775585\ttotal: 311ms\tremaining: 5.18s\n",
      "566:\tlearn: 0.3771319\ttotal: 311ms\tremaining: 5.18s\n",
      "567:\tlearn: 0.3750577\ttotal: 312ms\tremaining: 5.17s\n",
      "568:\tlearn: 0.3745832\ttotal: 312ms\tremaining: 5.17s\n",
      "569:\tlearn: 0.3722844\ttotal: 313ms\tremaining: 5.17s\n",
      "570:\tlearn: 0.3703382\ttotal: 313ms\tremaining: 5.17s\n",
      "571:\tlearn: 0.3689318\ttotal: 313ms\tremaining: 5.17s\n",
      "572:\tlearn: 0.3674043\ttotal: 314ms\tremaining: 5.16s\n",
      "573:\tlearn: 0.3656849\ttotal: 315ms\tremaining: 5.16s\n",
      "574:\tlearn: 0.3638094\ttotal: 315ms\tremaining: 5.17s\n",
      "575:\tlearn: 0.3632629\ttotal: 316ms\tremaining: 5.17s\n",
      "576:\tlearn: 0.3623857\ttotal: 316ms\tremaining: 5.16s\n",
      "577:\tlearn: 0.3601833\ttotal: 317ms\tremaining: 5.16s\n",
      "578:\tlearn: 0.3597539\ttotal: 317ms\tremaining: 5.16s\n",
      "579:\tlearn: 0.3593976\ttotal: 318ms\tremaining: 5.16s\n",
      "580:\tlearn: 0.3572405\ttotal: 318ms\tremaining: 5.16s\n",
      "581:\tlearn: 0.3566930\ttotal: 318ms\tremaining: 5.15s\n",
      "582:\tlearn: 0.3541869\ttotal: 319ms\tremaining: 5.15s\n",
      "583:\tlearn: 0.3539008\ttotal: 319ms\tremaining: 5.15s\n",
      "584:\tlearn: 0.3535681\ttotal: 320ms\tremaining: 5.15s\n",
      "585:\tlearn: 0.3524072\ttotal: 320ms\tremaining: 5.15s\n",
      "586:\tlearn: 0.3505707\ttotal: 321ms\tremaining: 5.14s\n",
      "587:\tlearn: 0.3486158\ttotal: 321ms\tremaining: 5.14s\n",
      "588:\tlearn: 0.3459766\ttotal: 322ms\tremaining: 5.14s\n",
      "589:\tlearn: 0.3439746\ttotal: 322ms\tremaining: 5.14s\n",
      "590:\tlearn: 0.3425947\ttotal: 322ms\tremaining: 5.13s\n",
      "591:\tlearn: 0.3401127\ttotal: 323ms\tremaining: 5.13s\n",
      "592:\tlearn: 0.3393239\ttotal: 323ms\tremaining: 5.13s\n",
      "593:\tlearn: 0.3369030\ttotal: 324ms\tremaining: 5.13s\n",
      "594:\tlearn: 0.3344829\ttotal: 324ms\tremaining: 5.12s\n",
      "595:\tlearn: 0.3322562\ttotal: 325ms\tremaining: 5.12s\n",
      "596:\tlearn: 0.3299994\ttotal: 325ms\tremaining: 5.12s\n",
      "597:\tlearn: 0.3275747\ttotal: 325ms\tremaining: 5.12s\n",
      "598:\tlearn: 0.3251083\ttotal: 326ms\tremaining: 5.11s\n",
      "599:\tlearn: 0.3245742\ttotal: 326ms\tremaining: 5.11s\n",
      "600:\tlearn: 0.3224273\ttotal: 327ms\tremaining: 5.11s\n",
      "601:\tlearn: 0.3205000\ttotal: 327ms\tremaining: 5.11s\n",
      "602:\tlearn: 0.3192445\ttotal: 327ms\tremaining: 5.1s\n",
      "603:\tlearn: 0.3170923\ttotal: 328ms\tremaining: 5.1s\n",
      "604:\tlearn: 0.3155681\ttotal: 329ms\tremaining: 5.1s\n",
      "605:\tlearn: 0.3134272\ttotal: 329ms\tremaining: 5.1s\n",
      "606:\tlearn: 0.3116173\ttotal: 330ms\tremaining: 5.1s\n",
      "607:\tlearn: 0.3111290\ttotal: 330ms\tremaining: 5.1s\n",
      "608:\tlearn: 0.3091592\ttotal: 331ms\tremaining: 5.1s\n",
      "609:\tlearn: 0.3084520\ttotal: 331ms\tremaining: 5.1s\n",
      "610:\tlearn: 0.3081654\ttotal: 332ms\tremaining: 5.1s\n",
      "611:\tlearn: 0.3073972\ttotal: 332ms\tremaining: 5.09s\n",
      "612:\tlearn: 0.3066503\ttotal: 333ms\tremaining: 5.09s\n",
      "613:\tlearn: 0.3051033\ttotal: 333ms\tremaining: 5.09s\n",
      "614:\tlearn: 0.3038552\ttotal: 334ms\tremaining: 5.09s\n",
      "615:\tlearn: 0.3015798\ttotal: 334ms\tremaining: 5.09s\n",
      "616:\tlearn: 0.3011290\ttotal: 335ms\tremaining: 5.09s\n",
      "617:\tlearn: 0.2983864\ttotal: 335ms\tremaining: 5.09s\n",
      "618:\tlearn: 0.2961879\ttotal: 336ms\tremaining: 5.08s\n",
      "619:\tlearn: 0.2942440\ttotal: 336ms\tremaining: 5.08s\n",
      "620:\tlearn: 0.2938139\ttotal: 336ms\tremaining: 5.08s\n",
      "621:\tlearn: 0.2920497\ttotal: 337ms\tremaining: 5.08s\n",
      "622:\tlearn: 0.2915264\ttotal: 337ms\tremaining: 5.08s\n",
      "623:\tlearn: 0.2890574\ttotal: 338ms\tremaining: 5.08s\n",
      "624:\tlearn: 0.2876584\ttotal: 338ms\tremaining: 5.07s\n",
      "625:\tlearn: 0.2851568\ttotal: 339ms\tremaining: 5.07s\n",
      "626:\tlearn: 0.2846387\ttotal: 339ms\tremaining: 5.07s\n",
      "627:\tlearn: 0.2821195\ttotal: 340ms\tremaining: 5.07s\n",
      "628:\tlearn: 0.2815738\ttotal: 340ms\tremaining: 5.07s\n",
      "629:\tlearn: 0.2793846\ttotal: 340ms\tremaining: 5.06s\n",
      "630:\tlearn: 0.2777106\ttotal: 341ms\tremaining: 5.06s\n",
      "631:\tlearn: 0.2753251\ttotal: 341ms\tremaining: 5.06s\n",
      "632:\tlearn: 0.2748709\ttotal: 342ms\tremaining: 5.06s\n",
      "633:\tlearn: 0.2729741\ttotal: 342ms\tremaining: 5.06s\n",
      "634:\tlearn: 0.2722253\ttotal: 343ms\tremaining: 5.06s\n",
      "635:\tlearn: 0.2700107\ttotal: 344ms\tremaining: 5.06s\n",
      "636:\tlearn: 0.2692653\ttotal: 344ms\tremaining: 5.06s\n",
      "637:\tlearn: 0.2680964\ttotal: 345ms\tremaining: 5.06s\n",
      "638:\tlearn: 0.2670718\ttotal: 345ms\tremaining: 5.05s\n",
      "639:\tlearn: 0.2667326\ttotal: 346ms\tremaining: 5.05s\n",
      "640:\tlearn: 0.2662301\ttotal: 346ms\tremaining: 5.05s\n",
      "641:\tlearn: 0.2640956\ttotal: 346ms\tremaining: 5.05s\n",
      "642:\tlearn: 0.2611991\ttotal: 347ms\tremaining: 5.05s\n",
      "643:\tlearn: 0.2605212\ttotal: 347ms\tremaining: 5.05s\n",
      "644:\tlearn: 0.2598920\ttotal: 348ms\tremaining: 5.04s\n",
      "645:\tlearn: 0.2592780\ttotal: 348ms\tremaining: 5.04s\n",
      "646:\tlearn: 0.2588730\ttotal: 349ms\tremaining: 5.04s\n",
      "647:\tlearn: 0.2573141\ttotal: 349ms\tremaining: 5.04s\n",
      "648:\tlearn: 0.2569990\ttotal: 350ms\tremaining: 5.04s\n",
      "649:\tlearn: 0.2555326\ttotal: 350ms\tremaining: 5.04s\n",
      "650:\tlearn: 0.2538832\ttotal: 351ms\tremaining: 5.03s\n",
      "651:\tlearn: 0.2520088\ttotal: 351ms\tremaining: 5.03s\n",
      "652:\tlearn: 0.2514119\ttotal: 351ms\tremaining: 5.03s\n",
      "653:\tlearn: 0.2497356\ttotal: 352ms\tremaining: 5.03s\n",
      "654:\tlearn: 0.2479280\ttotal: 352ms\tremaining: 5.03s\n",
      "655:\tlearn: 0.2453002\ttotal: 353ms\tremaining: 5.03s\n",
      "656:\tlearn: 0.2437459\ttotal: 353ms\tremaining: 5.02s\n",
      "657:\tlearn: 0.2431860\ttotal: 354ms\tremaining: 5.02s\n",
      "658:\tlearn: 0.2411085\ttotal: 354ms\tremaining: 5.02s\n",
      "659:\tlearn: 0.2389969\ttotal: 355ms\tremaining: 5.02s\n",
      "660:\tlearn: 0.2374168\ttotal: 355ms\tremaining: 5.02s\n",
      "661:\tlearn: 0.2370151\ttotal: 355ms\tremaining: 5.01s\n",
      "662:\tlearn: 0.2366532\ttotal: 356ms\tremaining: 5.01s\n",
      "663:\tlearn: 0.2348231\ttotal: 356ms\tremaining: 5.01s\n",
      "664:\tlearn: 0.2345803\ttotal: 357ms\tremaining: 5.01s\n",
      "665:\tlearn: 0.2325726\ttotal: 358ms\tremaining: 5.01s\n",
      "666:\tlearn: 0.2322767\ttotal: 358ms\tremaining: 5.01s\n",
      "667:\tlearn: 0.2310273\ttotal: 359ms\tremaining: 5.01s\n",
      "668:\tlearn: 0.2293468\ttotal: 359ms\tremaining: 5.01s\n",
      "669:\tlearn: 0.2279743\ttotal: 360ms\tremaining: 5.01s\n",
      "670:\tlearn: 0.2267396\ttotal: 360ms\tremaining: 5.01s\n",
      "671:\tlearn: 0.2254140\ttotal: 361ms\tremaining: 5.01s\n",
      "672:\tlearn: 0.2243991\ttotal: 362ms\tremaining: 5.02s\n",
      "673:\tlearn: 0.2229462\ttotal: 363ms\tremaining: 5.02s\n",
      "674:\tlearn: 0.2226025\ttotal: 363ms\tremaining: 5.02s\n",
      "675:\tlearn: 0.2218854\ttotal: 364ms\tremaining: 5.01s\n",
      "676:\tlearn: 0.2214602\ttotal: 364ms\tremaining: 5.01s\n",
      "677:\tlearn: 0.2207755\ttotal: 365ms\tremaining: 5.01s\n",
      "678:\tlearn: 0.2200692\ttotal: 365ms\tremaining: 5.01s\n",
      "679:\tlearn: 0.2193702\ttotal: 366ms\tremaining: 5.01s\n",
      "680:\tlearn: 0.2184394\ttotal: 366ms\tremaining: 5.01s\n",
      "681:\tlearn: 0.2182022\ttotal: 367ms\tremaining: 5.01s\n",
      "682:\tlearn: 0.2166555\ttotal: 367ms\tremaining: 5.01s\n",
      "683:\tlearn: 0.2163650\ttotal: 368ms\tremaining: 5.01s\n",
      "684:\tlearn: 0.2149787\ttotal: 368ms\tremaining: 5s\n",
      "685:\tlearn: 0.2128232\ttotal: 369ms\tremaining: 5s\n",
      "686:\tlearn: 0.2116841\ttotal: 369ms\tremaining: 5s\n",
      "687:\tlearn: 0.2103448\ttotal: 369ms\tremaining: 5s\n",
      "688:\tlearn: 0.2092594\ttotal: 370ms\tremaining: 5s\n",
      "689:\tlearn: 0.2075191\ttotal: 370ms\tremaining: 5s\n",
      "690:\tlearn: 0.2060806\ttotal: 371ms\tremaining: 5s\n",
      "691:\tlearn: 0.2048873\ttotal: 371ms\tremaining: 5s\n",
      "692:\tlearn: 0.2045655\ttotal: 372ms\tremaining: 4.99s\n",
      "693:\tlearn: 0.2036770\ttotal: 372ms\tremaining: 4.99s\n",
      "694:\tlearn: 0.2029140\ttotal: 373ms\tremaining: 4.99s\n",
      "695:\tlearn: 0.2017074\ttotal: 373ms\tremaining: 4.99s\n",
      "696:\tlearn: 0.2005202\ttotal: 374ms\tremaining: 4.99s\n",
      "697:\tlearn: 0.1994946\ttotal: 375ms\tremaining: 4.99s\n",
      "698:\tlearn: 0.1976135\ttotal: 375ms\tremaining: 4.99s\n",
      "699:\tlearn: 0.1962357\ttotal: 376ms\tremaining: 4.99s\n",
      "700:\tlearn: 0.1952433\ttotal: 376ms\tremaining: 4.99s\n",
      "701:\tlearn: 0.1943522\ttotal: 377ms\tremaining: 4.99s\n",
      "702:\tlearn: 0.1926965\ttotal: 377ms\tremaining: 4.99s\n",
      "703:\tlearn: 0.1923245\ttotal: 378ms\tremaining: 4.99s\n",
      "704:\tlearn: 0.1915347\ttotal: 378ms\tremaining: 4.99s\n",
      "705:\tlearn: 0.1912101\ttotal: 379ms\tremaining: 4.99s\n",
      "706:\tlearn: 0.1910025\ttotal: 379ms\tremaining: 4.99s\n",
      "707:\tlearn: 0.1907499\ttotal: 380ms\tremaining: 4.99s\n",
      "708:\tlearn: 0.1906053\ttotal: 380ms\tremaining: 4.99s\n",
      "709:\tlearn: 0.1894817\ttotal: 381ms\tremaining: 4.98s\n",
      "710:\tlearn: 0.1892677\ttotal: 381ms\tremaining: 4.98s\n",
      "711:\tlearn: 0.1885537\ttotal: 382ms\tremaining: 4.98s\n",
      "712:\tlearn: 0.1883343\ttotal: 382ms\tremaining: 4.98s\n",
      "713:\tlearn: 0.1872693\ttotal: 383ms\tremaining: 4.98s\n",
      "714:\tlearn: 0.1860270\ttotal: 383ms\tremaining: 4.97s\n",
      "715:\tlearn: 0.1848680\ttotal: 384ms\tremaining: 4.97s\n",
      "716:\tlearn: 0.1843954\ttotal: 384ms\tremaining: 4.97s\n",
      "717:\tlearn: 0.1839133\ttotal: 385ms\tremaining: 4.97s\n",
      "718:\tlearn: 0.1821365\ttotal: 385ms\tremaining: 4.97s\n",
      "719:\tlearn: 0.1809448\ttotal: 386ms\tremaining: 4.97s\n",
      "720:\tlearn: 0.1798314\ttotal: 387ms\tremaining: 4.98s\n",
      "721:\tlearn: 0.1786882\ttotal: 387ms\tremaining: 4.98s\n",
      "722:\tlearn: 0.1776430\ttotal: 388ms\tremaining: 4.98s\n",
      "723:\tlearn: 0.1765282\ttotal: 388ms\tremaining: 4.98s\n",
      "724:\tlearn: 0.1762202\ttotal: 389ms\tremaining: 4.98s\n",
      "725:\tlearn: 0.1756395\ttotal: 390ms\tremaining: 4.97s\n",
      "726:\tlearn: 0.1751681\ttotal: 390ms\tremaining: 4.97s\n",
      "727:\tlearn: 0.1749139\ttotal: 391ms\tremaining: 4.97s\n",
      "728:\tlearn: 0.1747116\ttotal: 391ms\tremaining: 4.97s\n",
      "729:\tlearn: 0.1734579\ttotal: 392ms\tremaining: 4.97s\n",
      "730:\tlearn: 0.1732064\ttotal: 392ms\tremaining: 4.97s\n",
      "731:\tlearn: 0.1724468\ttotal: 393ms\tremaining: 4.97s\n",
      "732:\tlearn: 0.1721625\ttotal: 393ms\tremaining: 4.97s\n",
      "733:\tlearn: 0.1711507\ttotal: 394ms\tremaining: 4.97s\n",
      "734:\tlearn: 0.1703736\ttotal: 394ms\tremaining: 4.97s\n",
      "735:\tlearn: 0.1697698\ttotal: 394ms\tremaining: 4.96s\n",
      "736:\tlearn: 0.1685836\ttotal: 395ms\tremaining: 4.96s\n",
      "737:\tlearn: 0.1683913\ttotal: 395ms\tremaining: 4.96s\n",
      "738:\tlearn: 0.1673739\ttotal: 396ms\tremaining: 4.96s\n",
      "739:\tlearn: 0.1662449\ttotal: 396ms\tremaining: 4.96s\n",
      "740:\tlearn: 0.1644075\ttotal: 397ms\tremaining: 4.96s\n",
      "741:\tlearn: 0.1640006\ttotal: 397ms\tremaining: 4.96s\n",
      "742:\tlearn: 0.1629036\ttotal: 398ms\tremaining: 4.96s\n",
      "743:\tlearn: 0.1617550\ttotal: 398ms\tremaining: 4.95s\n",
      "744:\tlearn: 0.1615463\ttotal: 399ms\tremaining: 4.95s\n",
      "745:\tlearn: 0.1612740\ttotal: 399ms\tremaining: 4.95s\n",
      "746:\tlearn: 0.1601794\ttotal: 400ms\tremaining: 4.95s\n",
      "747:\tlearn: 0.1595042\ttotal: 401ms\tremaining: 4.96s\n",
      "748:\tlearn: 0.1585245\ttotal: 401ms\tremaining: 4.96s\n",
      "749:\tlearn: 0.1583163\ttotal: 402ms\tremaining: 4.96s\n",
      "750:\tlearn: 0.1580522\ttotal: 402ms\tremaining: 4.96s\n",
      "751:\tlearn: 0.1566172\ttotal: 403ms\tremaining: 4.96s\n",
      "752:\tlearn: 0.1556620\ttotal: 403ms\tremaining: 4.95s\n",
      "753:\tlearn: 0.1552655\ttotal: 404ms\tremaining: 4.95s\n",
      "754:\tlearn: 0.1547859\ttotal: 404ms\tremaining: 4.95s\n",
      "755:\tlearn: 0.1538909\ttotal: 405ms\tremaining: 4.95s\n",
      "756:\tlearn: 0.1527967\ttotal: 405ms\tremaining: 4.95s\n",
      "757:\tlearn: 0.1525603\ttotal: 406ms\tremaining: 4.95s\n",
      "758:\tlearn: 0.1519820\ttotal: 406ms\tremaining: 4.95s\n",
      "759:\tlearn: 0.1518194\ttotal: 407ms\tremaining: 4.94s\n",
      "760:\tlearn: 0.1506327\ttotal: 407ms\tremaining: 4.94s\n",
      "761:\tlearn: 0.1504252\ttotal: 408ms\tremaining: 4.94s\n",
      "762:\tlearn: 0.1493017\ttotal: 408ms\tremaining: 4.94s\n",
      "763:\tlearn: 0.1482719\ttotal: 408ms\tremaining: 4.94s\n",
      "764:\tlearn: 0.1478752\ttotal: 409ms\tremaining: 4.93s\n",
      "765:\tlearn: 0.1470644\ttotal: 409ms\tremaining: 4.93s\n",
      "766:\tlearn: 0.1468651\ttotal: 410ms\tremaining: 4.93s\n",
      "767:\tlearn: 0.1462420\ttotal: 410ms\tremaining: 4.93s\n",
      "768:\tlearn: 0.1453477\ttotal: 411ms\tremaining: 4.93s\n",
      "769:\tlearn: 0.1447573\ttotal: 411ms\tremaining: 4.93s\n",
      "770:\tlearn: 0.1442064\ttotal: 412ms\tremaining: 4.93s\n",
      "771:\tlearn: 0.1430713\ttotal: 412ms\tremaining: 4.92s\n",
      "772:\tlearn: 0.1421653\ttotal: 412ms\tremaining: 4.92s\n",
      "773:\tlearn: 0.1417091\ttotal: 413ms\tremaining: 4.92s\n",
      "774:\tlearn: 0.1415307\ttotal: 414ms\tremaining: 4.93s\n",
      "775:\tlearn: 0.1409298\ttotal: 415ms\tremaining: 4.93s\n",
      "776:\tlearn: 0.1401557\ttotal: 416ms\tremaining: 4.93s\n",
      "777:\tlearn: 0.1399393\ttotal: 416ms\tremaining: 4.93s\n",
      "778:\tlearn: 0.1394213\ttotal: 417ms\tremaining: 4.93s\n",
      "779:\tlearn: 0.1390088\ttotal: 417ms\tremaining: 4.93s\n",
      "780:\tlearn: 0.1381645\ttotal: 418ms\tremaining: 4.93s\n",
      "781:\tlearn: 0.1374448\ttotal: 418ms\tremaining: 4.93s\n",
      "782:\tlearn: 0.1365386\ttotal: 419ms\tremaining: 4.93s\n",
      "783:\tlearn: 0.1361834\ttotal: 419ms\tremaining: 4.93s\n",
      "784:\tlearn: 0.1357805\ttotal: 420ms\tremaining: 4.93s\n",
      "785:\tlearn: 0.1349242\ttotal: 420ms\tremaining: 4.93s\n",
      "786:\tlearn: 0.1341170\ttotal: 421ms\tremaining: 4.93s\n",
      "787:\tlearn: 0.1332944\ttotal: 421ms\tremaining: 4.92s\n",
      "788:\tlearn: 0.1329588\ttotal: 422ms\tremaining: 4.92s\n",
      "789:\tlearn: 0.1320262\ttotal: 422ms\tremaining: 4.92s\n",
      "790:\tlearn: 0.1310488\ttotal: 423ms\tremaining: 4.92s\n",
      "791:\tlearn: 0.1308870\ttotal: 423ms\tremaining: 4.92s\n",
      "792:\tlearn: 0.1301027\ttotal: 424ms\tremaining: 4.92s\n",
      "793:\tlearn: 0.1294642\ttotal: 424ms\tremaining: 4.92s\n",
      "794:\tlearn: 0.1292932\ttotal: 424ms\tremaining: 4.91s\n",
      "795:\tlearn: 0.1291544\ttotal: 425ms\tremaining: 4.91s\n",
      "796:\tlearn: 0.1284821\ttotal: 425ms\tremaining: 4.91s\n",
      "797:\tlearn: 0.1278101\ttotal: 426ms\tremaining: 4.91s\n",
      "798:\tlearn: 0.1271736\ttotal: 426ms\tremaining: 4.91s\n",
      "799:\tlearn: 0.1267442\ttotal: 427ms\tremaining: 4.91s\n",
      "800:\tlearn: 0.1263067\ttotal: 427ms\tremaining: 4.91s\n",
      "801:\tlearn: 0.1254748\ttotal: 428ms\tremaining: 4.91s\n",
      "802:\tlearn: 0.1247135\ttotal: 429ms\tremaining: 4.91s\n",
      "803:\tlearn: 0.1244200\ttotal: 429ms\tremaining: 4.91s\n",
      "804:\tlearn: 0.1234219\ttotal: 430ms\tremaining: 4.91s\n",
      "805:\tlearn: 0.1230434\ttotal: 431ms\tremaining: 4.91s\n",
      "806:\tlearn: 0.1216799\ttotal: 431ms\tremaining: 4.91s\n",
      "807:\tlearn: 0.1214191\ttotal: 432ms\tremaining: 4.91s\n",
      "808:\tlearn: 0.1209598\ttotal: 432ms\tremaining: 4.91s\n",
      "809:\tlearn: 0.1206926\ttotal: 433ms\tremaining: 4.91s\n",
      "810:\tlearn: 0.1205304\ttotal: 433ms\tremaining: 4.91s\n",
      "811:\tlearn: 0.1204028\ttotal: 434ms\tremaining: 4.91s\n",
      "812:\tlearn: 0.1194448\ttotal: 434ms\tremaining: 4.91s\n",
      "813:\tlearn: 0.1192715\ttotal: 435ms\tremaining: 4.9s\n",
      "814:\tlearn: 0.1190469\ttotal: 435ms\tremaining: 4.9s\n",
      "815:\tlearn: 0.1179538\ttotal: 435ms\tremaining: 4.9s\n",
      "816:\tlearn: 0.1169437\ttotal: 436ms\tremaining: 4.9s\n",
      "817:\tlearn: 0.1162175\ttotal: 436ms\tremaining: 4.9s\n",
      "818:\tlearn: 0.1160489\ttotal: 437ms\tremaining: 4.9s\n",
      "819:\tlearn: 0.1158562\ttotal: 437ms\tremaining: 4.89s\n",
      "820:\tlearn: 0.1153145\ttotal: 438ms\tremaining: 4.89s\n",
      "821:\tlearn: 0.1145187\ttotal: 438ms\tremaining: 4.89s\n",
      "822:\tlearn: 0.1141507\ttotal: 439ms\tremaining: 4.89s\n",
      "823:\tlearn: 0.1129155\ttotal: 439ms\tremaining: 4.89s\n",
      "824:\tlearn: 0.1121395\ttotal: 440ms\tremaining: 4.89s\n",
      "825:\tlearn: 0.1112591\ttotal: 440ms\tremaining: 4.89s\n",
      "826:\tlearn: 0.1111730\ttotal: 441ms\tremaining: 4.89s\n",
      "827:\tlearn: 0.1110355\ttotal: 441ms\tremaining: 4.88s\n",
      "828:\tlearn: 0.1105739\ttotal: 442ms\tremaining: 4.88s\n",
      "829:\tlearn: 0.1102461\ttotal: 442ms\tremaining: 4.89s\n",
      "830:\tlearn: 0.1095392\ttotal: 443ms\tremaining: 4.89s\n",
      "831:\tlearn: 0.1088414\ttotal: 444ms\tremaining: 4.89s\n",
      "832:\tlearn: 0.1078059\ttotal: 445ms\tremaining: 4.9s\n",
      "833:\tlearn: 0.1076823\ttotal: 446ms\tremaining: 4.91s\n",
      "834:\tlearn: 0.1075062\ttotal: 447ms\tremaining: 4.91s\n",
      "835:\tlearn: 0.1072995\ttotal: 448ms\tremaining: 4.91s\n",
      "836:\tlearn: 0.1071443\ttotal: 448ms\tremaining: 4.91s\n",
      "837:\tlearn: 0.1070119\ttotal: 449ms\tremaining: 4.91s\n",
      "838:\tlearn: 0.1064061\ttotal: 449ms\tremaining: 4.91s\n",
      "839:\tlearn: 0.1056061\ttotal: 450ms\tremaining: 4.91s\n",
      "840:\tlearn: 0.1048694\ttotal: 450ms\tremaining: 4.9s\n",
      "841:\tlearn: 0.1042684\ttotal: 451ms\tremaining: 4.9s\n",
      "842:\tlearn: 0.1040971\ttotal: 451ms\tremaining: 4.9s\n",
      "843:\tlearn: 0.1035171\ttotal: 452ms\tremaining: 4.9s\n",
      "844:\tlearn: 0.1033703\ttotal: 452ms\tremaining: 4.9s\n",
      "845:\tlearn: 0.1028583\ttotal: 453ms\tremaining: 4.9s\n",
      "846:\tlearn: 0.1020540\ttotal: 453ms\tremaining: 4.89s\n",
      "847:\tlearn: 0.1012886\ttotal: 453ms\tremaining: 4.89s\n",
      "848:\tlearn: 0.1011042\ttotal: 454ms\tremaining: 4.89s\n",
      "849:\tlearn: 0.1009807\ttotal: 454ms\tremaining: 4.89s\n",
      "850:\tlearn: 0.1003319\ttotal: 455ms\tremaining: 4.89s\n",
      "851:\tlearn: 0.0995738\ttotal: 455ms\tremaining: 4.89s\n",
      "852:\tlearn: 0.0988855\ttotal: 456ms\tremaining: 4.89s\n",
      "853:\tlearn: 0.0986269\ttotal: 456ms\tremaining: 4.89s\n",
      "854:\tlearn: 0.0978822\ttotal: 457ms\tremaining: 4.89s\n",
      "855:\tlearn: 0.0976236\ttotal: 458ms\tremaining: 4.89s\n",
      "856:\tlearn: 0.0966403\ttotal: 459ms\tremaining: 4.89s\n",
      "857:\tlearn: 0.0957264\ttotal: 460ms\tremaining: 4.9s\n",
      "858:\tlearn: 0.0951217\ttotal: 461ms\tremaining: 4.9s\n",
      "859:\tlearn: 0.0950054\ttotal: 461ms\tremaining: 4.9s\n",
      "860:\tlearn: 0.0947682\ttotal: 461ms\tremaining: 4.9s\n",
      "861:\tlearn: 0.0938967\ttotal: 462ms\tremaining: 4.9s\n",
      "862:\tlearn: 0.0932107\ttotal: 462ms\tremaining: 4.89s\n",
      "863:\tlearn: 0.0927667\ttotal: 463ms\tremaining: 4.89s\n",
      "864:\tlearn: 0.0922013\ttotal: 463ms\tremaining: 4.89s\n",
      "865:\tlearn: 0.0917349\ttotal: 464ms\tremaining: 4.89s\n",
      "866:\tlearn: 0.0914112\ttotal: 464ms\tremaining: 4.89s\n",
      "867:\tlearn: 0.0912078\ttotal: 465ms\tremaining: 4.89s\n",
      "868:\tlearn: 0.0906628\ttotal: 465ms\tremaining: 4.89s\n",
      "869:\tlearn: 0.0901766\ttotal: 466ms\tremaining: 4.88s\n",
      "870:\tlearn: 0.0900289\ttotal: 466ms\tremaining: 4.88s\n",
      "871:\tlearn: 0.0899124\ttotal: 467ms\tremaining: 4.88s\n",
      "872:\tlearn: 0.0897059\ttotal: 467ms\tremaining: 4.88s\n",
      "873:\tlearn: 0.0895585\ttotal: 468ms\tremaining: 4.88s\n",
      "874:\tlearn: 0.0892543\ttotal: 468ms\tremaining: 4.88s\n",
      "875:\tlearn: 0.0889740\ttotal: 468ms\tremaining: 4.88s\n",
      "876:\tlearn: 0.0884520\ttotal: 469ms\tremaining: 4.88s\n",
      "877:\tlearn: 0.0881151\ttotal: 469ms\tremaining: 4.88s\n",
      "878:\tlearn: 0.0874347\ttotal: 470ms\tremaining: 4.88s\n",
      "879:\tlearn: 0.0872761\ttotal: 471ms\tremaining: 4.88s\n",
      "880:\tlearn: 0.0868948\ttotal: 471ms\tremaining: 4.88s\n",
      "881:\tlearn: 0.0867934\ttotal: 472ms\tremaining: 4.88s\n",
      "882:\tlearn: 0.0862398\ttotal: 473ms\tremaining: 4.88s\n",
      "883:\tlearn: 0.0856851\ttotal: 474ms\tremaining: 4.89s\n",
      "884:\tlearn: 0.0850564\ttotal: 475ms\tremaining: 4.89s\n",
      "885:\tlearn: 0.0849359\ttotal: 476ms\tremaining: 4.89s\n",
      "886:\tlearn: 0.0843112\ttotal: 476ms\tremaining: 4.89s\n",
      "887:\tlearn: 0.0838168\ttotal: 477ms\tremaining: 4.89s\n",
      "888:\tlearn: 0.0834582\ttotal: 477ms\tremaining: 4.89s\n",
      "889:\tlearn: 0.0831185\ttotal: 477ms\tremaining: 4.89s\n",
      "890:\tlearn: 0.0825910\ttotal: 478ms\tremaining: 4.88s\n",
      "891:\tlearn: 0.0822036\ttotal: 478ms\tremaining: 4.88s\n",
      "892:\tlearn: 0.0817217\ttotal: 479ms\tremaining: 4.88s\n",
      "893:\tlearn: 0.0811653\ttotal: 479ms\tremaining: 4.88s\n",
      "894:\tlearn: 0.0808220\ttotal: 480ms\tremaining: 4.88s\n",
      "895:\tlearn: 0.0805711\ttotal: 480ms\tremaining: 4.88s\n",
      "896:\tlearn: 0.0799213\ttotal: 481ms\tremaining: 4.88s\n",
      "897:\tlearn: 0.0794046\ttotal: 481ms\tremaining: 4.88s\n",
      "898:\tlearn: 0.0792843\ttotal: 482ms\tremaining: 4.87s\n",
      "899:\tlearn: 0.0787869\ttotal: 482ms\tremaining: 4.87s\n",
      "900:\tlearn: 0.0783667\ttotal: 482ms\tremaining: 4.87s\n",
      "901:\tlearn: 0.0781766\ttotal: 483ms\tremaining: 4.87s\n",
      "902:\tlearn: 0.0777069\ttotal: 483ms\tremaining: 4.87s\n",
      "903:\tlearn: 0.0769149\ttotal: 484ms\tremaining: 4.87s\n",
      "904:\tlearn: 0.0764823\ttotal: 485ms\tremaining: 4.87s\n",
      "905:\tlearn: 0.0760064\ttotal: 485ms\tremaining: 4.87s\n",
      "906:\tlearn: 0.0759194\ttotal: 486ms\tremaining: 4.87s\n",
      "907:\tlearn: 0.0758437\ttotal: 487ms\tremaining: 4.88s\n",
      "908:\tlearn: 0.0757302\ttotal: 488ms\tremaining: 4.88s\n",
      "909:\tlearn: 0.0755581\ttotal: 488ms\tremaining: 4.88s\n",
      "910:\tlearn: 0.0754459\ttotal: 489ms\tremaining: 4.87s\n",
      "911:\tlearn: 0.0751922\ttotal: 489ms\tremaining: 4.87s\n",
      "912:\tlearn: 0.0744544\ttotal: 490ms\tremaining: 4.87s\n",
      "913:\tlearn: 0.0737346\ttotal: 490ms\tremaining: 4.87s\n",
      "914:\tlearn: 0.0732864\ttotal: 491ms\tremaining: 4.87s\n",
      "915:\tlearn: 0.0726093\ttotal: 491ms\tremaining: 4.87s\n",
      "916:\tlearn: 0.0724942\ttotal: 492ms\tremaining: 4.87s\n",
      "917:\tlearn: 0.0722513\ttotal: 492ms\tremaining: 4.87s\n",
      "918:\tlearn: 0.0720989\ttotal: 492ms\tremaining: 4.87s\n",
      "919:\tlearn: 0.0720361\ttotal: 493ms\tremaining: 4.86s\n",
      "920:\tlearn: 0.0719381\ttotal: 493ms\tremaining: 4.86s\n",
      "921:\tlearn: 0.0718513\ttotal: 494ms\tremaining: 4.86s\n",
      "922:\tlearn: 0.0713226\ttotal: 494ms\tremaining: 4.86s\n",
      "923:\tlearn: 0.0708833\ttotal: 495ms\tremaining: 4.86s\n",
      "924:\tlearn: 0.0703378\ttotal: 495ms\tremaining: 4.86s\n",
      "925:\tlearn: 0.0702428\ttotal: 496ms\tremaining: 4.86s\n",
      "926:\tlearn: 0.0697590\ttotal: 496ms\tremaining: 4.86s\n",
      "927:\tlearn: 0.0694483\ttotal: 497ms\tremaining: 4.85s\n",
      "928:\tlearn: 0.0692252\ttotal: 497ms\tremaining: 4.85s\n",
      "929:\tlearn: 0.0685751\ttotal: 497ms\tremaining: 4.85s\n",
      "930:\tlearn: 0.0679649\ttotal: 498ms\tremaining: 4.85s\n",
      "931:\tlearn: 0.0675247\ttotal: 499ms\tremaining: 4.85s\n",
      "932:\tlearn: 0.0670431\ttotal: 499ms\tremaining: 4.85s\n",
      "933:\tlearn: 0.0668680\ttotal: 500ms\tremaining: 4.85s\n",
      "934:\tlearn: 0.0665514\ttotal: 501ms\tremaining: 4.86s\n",
      "935:\tlearn: 0.0664968\ttotal: 502ms\tremaining: 4.86s\n",
      "936:\tlearn: 0.0664475\ttotal: 503ms\tremaining: 4.86s\n",
      "937:\tlearn: 0.0663946\ttotal: 503ms\tremaining: 4.86s\n",
      "938:\tlearn: 0.0663126\ttotal: 504ms\tremaining: 4.86s\n",
      "939:\tlearn: 0.0662539\ttotal: 504ms\tremaining: 4.86s\n",
      "940:\tlearn: 0.0658395\ttotal: 505ms\tremaining: 4.86s\n",
      "941:\tlearn: 0.0655306\ttotal: 505ms\tremaining: 4.86s\n",
      "942:\tlearn: 0.0651330\ttotal: 505ms\tremaining: 4.85s\n",
      "943:\tlearn: 0.0650268\ttotal: 506ms\tremaining: 4.85s\n",
      "944:\tlearn: 0.0643787\ttotal: 506ms\tremaining: 4.85s\n",
      "945:\tlearn: 0.0642750\ttotal: 507ms\tremaining: 4.85s\n",
      "946:\tlearn: 0.0636466\ttotal: 507ms\tremaining: 4.85s\n",
      "947:\tlearn: 0.0632640\ttotal: 508ms\tremaining: 4.85s\n",
      "948:\tlearn: 0.0629030\ttotal: 508ms\tremaining: 4.85s\n",
      "949:\tlearn: 0.0627108\ttotal: 509ms\tremaining: 4.84s\n",
      "950:\tlearn: 0.0623276\ttotal: 509ms\tremaining: 4.84s\n",
      "951:\tlearn: 0.0620816\ttotal: 509ms\tremaining: 4.84s\n",
      "952:\tlearn: 0.0619532\ttotal: 510ms\tremaining: 4.84s\n",
      "953:\tlearn: 0.0618259\ttotal: 510ms\tremaining: 4.84s\n",
      "954:\tlearn: 0.0617553\ttotal: 511ms\tremaining: 4.84s\n",
      "955:\tlearn: 0.0614186\ttotal: 511ms\tremaining: 4.84s\n",
      "956:\tlearn: 0.0610231\ttotal: 512ms\tremaining: 4.84s\n",
      "957:\tlearn: 0.0604484\ttotal: 512ms\tremaining: 4.84s\n",
      "958:\tlearn: 0.0603598\ttotal: 513ms\tremaining: 4.84s\n",
      "959:\tlearn: 0.0602488\ttotal: 514ms\tremaining: 4.84s\n",
      "960:\tlearn: 0.0598244\ttotal: 515ms\tremaining: 4.85s\n",
      "961:\tlearn: 0.0596426\ttotal: 516ms\tremaining: 4.85s\n",
      "962:\tlearn: 0.0592906\ttotal: 517ms\tremaining: 4.85s\n",
      "963:\tlearn: 0.0590004\ttotal: 518ms\tremaining: 4.85s\n",
      "964:\tlearn: 0.0589177\ttotal: 518ms\tremaining: 4.85s\n",
      "965:\tlearn: 0.0585978\ttotal: 519ms\tremaining: 4.85s\n",
      "966:\tlearn: 0.0585334\ttotal: 519ms\tremaining: 4.85s\n",
      "967:\tlearn: 0.0581733\ttotal: 520ms\tremaining: 4.85s\n",
      "968:\tlearn: 0.0580351\ttotal: 520ms\tremaining: 4.85s\n",
      "969:\tlearn: 0.0579488\ttotal: 521ms\tremaining: 4.85s\n",
      "970:\tlearn: 0.0578590\ttotal: 521ms\tremaining: 4.85s\n",
      "971:\tlearn: 0.0575744\ttotal: 522ms\tremaining: 4.84s\n",
      "972:\tlearn: 0.0572279\ttotal: 522ms\tremaining: 4.84s\n",
      "973:\tlearn: 0.0566863\ttotal: 523ms\tremaining: 4.84s\n",
      "974:\tlearn: 0.0562630\ttotal: 523ms\tremaining: 4.84s\n",
      "975:\tlearn: 0.0559617\ttotal: 524ms\tremaining: 4.84s\n",
      "976:\tlearn: 0.0558711\ttotal: 524ms\tremaining: 4.84s\n",
      "977:\tlearn: 0.0553781\ttotal: 524ms\tremaining: 4.84s\n",
      "978:\tlearn: 0.0550367\ttotal: 525ms\tremaining: 4.84s\n",
      "979:\tlearn: 0.0548580\ttotal: 525ms\tremaining: 4.83s\n",
      "980:\tlearn: 0.0546617\ttotal: 526ms\tremaining: 4.83s\n",
      "981:\tlearn: 0.0542283\ttotal: 527ms\tremaining: 4.84s\n",
      "982:\tlearn: 0.0539722\ttotal: 528ms\tremaining: 4.84s\n",
      "983:\tlearn: 0.0539254\ttotal: 529ms\tremaining: 4.85s\n",
      "984:\tlearn: 0.0538840\ttotal: 530ms\tremaining: 4.85s\n",
      "985:\tlearn: 0.0535886\ttotal: 530ms\tremaining: 4.85s\n",
      "986:\tlearn: 0.0532942\ttotal: 532ms\tremaining: 4.86s\n",
      "987:\tlearn: 0.0529196\ttotal: 533ms\tremaining: 4.86s\n",
      "988:\tlearn: 0.0525145\ttotal: 533ms\tremaining: 4.86s\n",
      "989:\tlearn: 0.0522557\ttotal: 534ms\tremaining: 4.86s\n",
      "990:\tlearn: 0.0518580\ttotal: 535ms\tremaining: 4.86s\n",
      "991:\tlearn: 0.0516118\ttotal: 535ms\tremaining: 4.86s\n",
      "992:\tlearn: 0.0512043\ttotal: 536ms\tremaining: 4.86s\n",
      "993:\tlearn: 0.0508738\ttotal: 537ms\tremaining: 4.86s\n",
      "994:\tlearn: 0.0505390\ttotal: 537ms\tremaining: 4.86s\n",
      "995:\tlearn: 0.0504665\ttotal: 538ms\tremaining: 4.86s\n",
      "996:\tlearn: 0.0501728\ttotal: 538ms\tremaining: 4.86s\n",
      "997:\tlearn: 0.0500912\ttotal: 539ms\tremaining: 4.86s\n",
      "998:\tlearn: 0.0499777\ttotal: 540ms\tremaining: 4.86s\n",
      "999:\tlearn: 0.0499071\ttotal: 541ms\tremaining: 4.87s\n",
      "1000:\tlearn: 0.0497069\ttotal: 542ms\tremaining: 4.87s\n",
      "1001:\tlearn: 0.0495716\ttotal: 543ms\tremaining: 4.87s\n",
      "1002:\tlearn: 0.0492599\ttotal: 544ms\tremaining: 4.88s\n",
      "1003:\tlearn: 0.0490413\ttotal: 545ms\tremaining: 4.88s\n",
      "1004:\tlearn: 0.0489897\ttotal: 546ms\tremaining: 4.88s\n",
      "1005:\tlearn: 0.0489098\ttotal: 546ms\tremaining: 4.88s\n",
      "1006:\tlearn: 0.0487174\ttotal: 547ms\tremaining: 4.88s\n",
      "1007:\tlearn: 0.0486752\ttotal: 547ms\tremaining: 4.88s\n",
      "1008:\tlearn: 0.0481875\ttotal: 548ms\tremaining: 4.88s\n",
      "1009:\tlearn: 0.0481416\ttotal: 549ms\tremaining: 4.88s\n",
      "1010:\tlearn: 0.0476475\ttotal: 549ms\tremaining: 4.88s\n",
      "1011:\tlearn: 0.0476111\ttotal: 550ms\tremaining: 4.88s\n",
      "1012:\tlearn: 0.0475620\ttotal: 550ms\tremaining: 4.88s\n",
      "1013:\tlearn: 0.0473843\ttotal: 551ms\tremaining: 4.88s\n",
      "1014:\tlearn: 0.0472759\ttotal: 551ms\tremaining: 4.88s\n",
      "1015:\tlearn: 0.0470548\ttotal: 552ms\tremaining: 4.88s\n",
      "1016:\tlearn: 0.0468684\ttotal: 552ms\tremaining: 4.88s\n",
      "1017:\tlearn: 0.0467923\ttotal: 552ms\tremaining: 4.87s\n",
      "1018:\tlearn: 0.0464644\ttotal: 553ms\tremaining: 4.88s\n",
      "1019:\tlearn: 0.0461677\ttotal: 554ms\tremaining: 4.88s\n",
      "1020:\tlearn: 0.0461228\ttotal: 555ms\tremaining: 4.88s\n",
      "1021:\tlearn: 0.0459309\ttotal: 556ms\tremaining: 4.88s\n",
      "1022:\tlearn: 0.0458702\ttotal: 556ms\tremaining: 4.88s\n",
      "1023:\tlearn: 0.0457991\ttotal: 557ms\tremaining: 4.88s\n",
      "1024:\tlearn: 0.0454458\ttotal: 558ms\tremaining: 4.88s\n",
      "1025:\tlearn: 0.0452816\ttotal: 559ms\tremaining: 4.89s\n",
      "1026:\tlearn: 0.0450938\ttotal: 559ms\tremaining: 4.89s\n",
      "1027:\tlearn: 0.0448975\ttotal: 560ms\tremaining: 4.89s\n",
      "1028:\tlearn: 0.0447037\ttotal: 561ms\tremaining: 4.89s\n",
      "1029:\tlearn: 0.0445525\ttotal: 561ms\tremaining: 4.89s\n",
      "1030:\tlearn: 0.0443080\ttotal: 562ms\tremaining: 4.88s\n",
      "1031:\tlearn: 0.0439788\ttotal: 562ms\tremaining: 4.88s\n",
      "1032:\tlearn: 0.0436052\ttotal: 563ms\tremaining: 4.88s\n",
      "1033:\tlearn: 0.0434710\ttotal: 563ms\tremaining: 4.88s\n",
      "1034:\tlearn: 0.0431467\ttotal: 564ms\tremaining: 4.88s\n",
      "1035:\tlearn: 0.0430981\ttotal: 564ms\tremaining: 4.88s\n",
      "1036:\tlearn: 0.0430749\ttotal: 565ms\tremaining: 4.88s\n",
      "1037:\tlearn: 0.0429293\ttotal: 565ms\tremaining: 4.88s\n",
      "1038:\tlearn: 0.0428730\ttotal: 566ms\tremaining: 4.88s\n",
      "1039:\tlearn: 0.0424328\ttotal: 566ms\tremaining: 4.88s\n",
      "1040:\tlearn: 0.0421826\ttotal: 566ms\tremaining: 4.88s\n",
      "1041:\tlearn: 0.0420982\ttotal: 567ms\tremaining: 4.87s\n",
      "1042:\tlearn: 0.0419103\ttotal: 568ms\tremaining: 4.88s\n",
      "1043:\tlearn: 0.0416438\ttotal: 569ms\tremaining: 4.88s\n",
      "1044:\tlearn: 0.0414914\ttotal: 570ms\tremaining: 4.89s\n",
      "1045:\tlearn: 0.0414428\ttotal: 571ms\tremaining: 4.89s\n",
      "1046:\tlearn: 0.0411261\ttotal: 572ms\tremaining: 4.89s\n",
      "1047:\tlearn: 0.0411019\ttotal: 572ms\tremaining: 4.89s\n",
      "1048:\tlearn: 0.0408737\ttotal: 573ms\tremaining: 4.89s\n",
      "1049:\tlearn: 0.0408181\ttotal: 574ms\tremaining: 4.89s\n",
      "1050:\tlearn: 0.0406090\ttotal: 574ms\tremaining: 4.89s\n",
      "1051:\tlearn: 0.0402087\ttotal: 574ms\tremaining: 4.89s\n",
      "1052:\tlearn: 0.0397370\ttotal: 575ms\tremaining: 4.88s\n",
      "1053:\tlearn: 0.0396709\ttotal: 575ms\tremaining: 4.88s\n",
      "1054:\tlearn: 0.0392938\ttotal: 576ms\tremaining: 4.88s\n",
      "1055:\tlearn: 0.0388434\ttotal: 576ms\tremaining: 4.88s\n",
      "1056:\tlearn: 0.0388005\ttotal: 577ms\tremaining: 4.88s\n",
      "1057:\tlearn: 0.0384600\ttotal: 577ms\tremaining: 4.88s\n",
      "1058:\tlearn: 0.0381930\ttotal: 578ms\tremaining: 4.88s\n",
      "1059:\tlearn: 0.0378632\ttotal: 578ms\tremaining: 4.88s\n",
      "1060:\tlearn: 0.0375535\ttotal: 579ms\tremaining: 4.88s\n",
      "1061:\tlearn: 0.0371567\ttotal: 579ms\tremaining: 4.88s\n",
      "1062:\tlearn: 0.0369112\ttotal: 580ms\tremaining: 4.87s\n",
      "1063:\tlearn: 0.0367129\ttotal: 580ms\tremaining: 4.87s\n",
      "1064:\tlearn: 0.0366755\ttotal: 580ms\tremaining: 4.87s\n",
      "1065:\tlearn: 0.0365329\ttotal: 581ms\tremaining: 4.87s\n",
      "1066:\tlearn: 0.0363945\ttotal: 582ms\tremaining: 4.87s\n",
      "1067:\tlearn: 0.0360209\ttotal: 582ms\tremaining: 4.87s\n",
      "1068:\tlearn: 0.0357456\ttotal: 584ms\tremaining: 4.88s\n",
      "1069:\tlearn: 0.0357000\ttotal: 585ms\tremaining: 4.88s\n",
      "1070:\tlearn: 0.0355252\ttotal: 586ms\tremaining: 4.88s\n",
      "1071:\tlearn: 0.0354806\ttotal: 587ms\tremaining: 4.89s\n",
      "1072:\tlearn: 0.0354384\ttotal: 587ms\tremaining: 4.89s\n",
      "1073:\tlearn: 0.0352214\ttotal: 588ms\tremaining: 4.89s\n",
      "1074:\tlearn: 0.0349988\ttotal: 588ms\tremaining: 4.88s\n",
      "1075:\tlearn: 0.0348176\ttotal: 589ms\tremaining: 4.88s\n",
      "1076:\tlearn: 0.0347840\ttotal: 590ms\tremaining: 4.88s\n",
      "1077:\tlearn: 0.0346676\ttotal: 590ms\tremaining: 4.88s\n",
      "1078:\tlearn: 0.0342802\ttotal: 591ms\tremaining: 4.88s\n",
      "1079:\tlearn: 0.0342324\ttotal: 591ms\tremaining: 4.88s\n",
      "1080:\tlearn: 0.0341938\ttotal: 592ms\tremaining: 4.88s\n",
      "1081:\tlearn: 0.0340629\ttotal: 592ms\tremaining: 4.88s\n",
      "1082:\tlearn: 0.0340259\ttotal: 593ms\tremaining: 4.88s\n",
      "1083:\tlearn: 0.0337849\ttotal: 593ms\tremaining: 4.88s\n",
      "1084:\tlearn: 0.0335286\ttotal: 594ms\tremaining: 4.88s\n",
      "1085:\tlearn: 0.0334275\ttotal: 594ms\tremaining: 4.88s\n",
      "1086:\tlearn: 0.0331127\ttotal: 595ms\tremaining: 4.88s\n",
      "1087:\tlearn: 0.0329181\ttotal: 596ms\tremaining: 4.88s\n",
      "1088:\tlearn: 0.0328883\ttotal: 596ms\tremaining: 4.88s\n",
      "1089:\tlearn: 0.0327354\ttotal: 597ms\tremaining: 4.88s\n",
      "1090:\tlearn: 0.0324924\ttotal: 598ms\tremaining: 4.89s\n",
      "1091:\tlearn: 0.0322381\ttotal: 599ms\tremaining: 4.89s\n",
      "1092:\tlearn: 0.0321643\ttotal: 600ms\tremaining: 4.89s\n",
      "1093:\tlearn: 0.0320589\ttotal: 601ms\tremaining: 4.89s\n",
      "1094:\tlearn: 0.0317894\ttotal: 601ms\tremaining: 4.89s\n",
      "1095:\tlearn: 0.0316331\ttotal: 602ms\tremaining: 4.89s\n",
      "1096:\tlearn: 0.0314727\ttotal: 602ms\tremaining: 4.89s\n",
      "1097:\tlearn: 0.0313618\ttotal: 603ms\tremaining: 4.89s\n",
      "1098:\tlearn: 0.0313280\ttotal: 603ms\tremaining: 4.89s\n",
      "1099:\tlearn: 0.0312970\ttotal: 604ms\tremaining: 4.88s\n",
      "1100:\tlearn: 0.0312651\ttotal: 604ms\tremaining: 4.88s\n",
      "1101:\tlearn: 0.0310316\ttotal: 605ms\tremaining: 4.88s\n",
      "1102:\tlearn: 0.0309958\ttotal: 605ms\tremaining: 4.88s\n",
      "1103:\tlearn: 0.0308832\ttotal: 606ms\tremaining: 4.88s\n",
      "1104:\tlearn: 0.0306900\ttotal: 606ms\tremaining: 4.88s\n",
      "1105:\tlearn: 0.0305761\ttotal: 607ms\tremaining: 4.88s\n",
      "1106:\tlearn: 0.0304813\ttotal: 607ms\tremaining: 4.88s\n",
      "1107:\tlearn: 0.0303340\ttotal: 608ms\tremaining: 4.88s\n",
      "1108:\tlearn: 0.0301544\ttotal: 608ms\tremaining: 4.88s\n",
      "1109:\tlearn: 0.0299034\ttotal: 609ms\tremaining: 4.88s\n",
      "1110:\tlearn: 0.0296657\ttotal: 610ms\tremaining: 4.88s\n",
      "1111:\tlearn: 0.0296394\ttotal: 611ms\tremaining: 4.88s\n",
      "1112:\tlearn: 0.0296025\ttotal: 612ms\tremaining: 4.88s\n",
      "1113:\tlearn: 0.0294442\ttotal: 613ms\tremaining: 4.88s\n",
      "1114:\tlearn: 0.0294161\ttotal: 613ms\tremaining: 4.89s\n",
      "1115:\tlearn: 0.0293229\ttotal: 614ms\tremaining: 4.89s\n",
      "1116:\tlearn: 0.0291338\ttotal: 615ms\tremaining: 4.89s\n",
      "1117:\tlearn: 0.0290476\ttotal: 615ms\tremaining: 4.89s\n",
      "1118:\tlearn: 0.0288492\ttotal: 616ms\tremaining: 4.89s\n",
      "1119:\tlearn: 0.0286524\ttotal: 616ms\tremaining: 4.89s\n",
      "1120:\tlearn: 0.0285035\ttotal: 617ms\tremaining: 4.88s\n",
      "1121:\tlearn: 0.0282711\ttotal: 617ms\tremaining: 4.88s\n",
      "1122:\tlearn: 0.0282085\ttotal: 618ms\tremaining: 4.88s\n",
      "1123:\tlearn: 0.0280010\ttotal: 618ms\tremaining: 4.88s\n",
      "1124:\tlearn: 0.0278116\ttotal: 619ms\tremaining: 4.88s\n",
      "1125:\tlearn: 0.0276688\ttotal: 620ms\tremaining: 4.88s\n",
      "1126:\tlearn: 0.0275206\ttotal: 620ms\tremaining: 4.88s\n",
      "1127:\tlearn: 0.0274594\ttotal: 621ms\tremaining: 4.88s\n",
      "1128:\tlearn: 0.0274301\ttotal: 621ms\tremaining: 4.88s\n",
      "1129:\tlearn: 0.0272231\ttotal: 622ms\tremaining: 4.88s\n",
      "1130:\tlearn: 0.0271037\ttotal: 622ms\tremaining: 4.88s\n",
      "1131:\tlearn: 0.0269732\ttotal: 623ms\tremaining: 4.88s\n",
      "1132:\tlearn: 0.0267841\ttotal: 623ms\tremaining: 4.88s\n",
      "1133:\tlearn: 0.0267500\ttotal: 624ms\tremaining: 4.88s\n",
      "1134:\tlearn: 0.0265728\ttotal: 625ms\tremaining: 4.88s\n",
      "1135:\tlearn: 0.0264595\ttotal: 626ms\tremaining: 4.88s\n",
      "1136:\tlearn: 0.0264176\ttotal: 627ms\tremaining: 4.88s\n",
      "1137:\tlearn: 0.0263397\ttotal: 628ms\tremaining: 4.89s\n",
      "1138:\tlearn: 0.0263105\ttotal: 628ms\tremaining: 4.89s\n",
      "1139:\tlearn: 0.0262873\ttotal: 629ms\tremaining: 4.89s\n",
      "1140:\tlearn: 0.0261035\ttotal: 629ms\tremaining: 4.89s\n",
      "1141:\tlearn: 0.0259576\ttotal: 630ms\tremaining: 4.89s\n",
      "1142:\tlearn: 0.0258141\ttotal: 631ms\tremaining: 4.88s\n",
      "1143:\tlearn: 0.0256120\ttotal: 631ms\tremaining: 4.88s\n",
      "1144:\tlearn: 0.0254662\ttotal: 632ms\tremaining: 4.88s\n",
      "1145:\tlearn: 0.0254500\ttotal: 632ms\tremaining: 4.88s\n",
      "1146:\tlearn: 0.0253063\ttotal: 633ms\tremaining: 4.88s\n",
      "1147:\tlearn: 0.0252728\ttotal: 634ms\tremaining: 4.89s\n",
      "1148:\tlearn: 0.0252130\ttotal: 634ms\tremaining: 4.89s\n",
      "1149:\tlearn: 0.0251809\ttotal: 635ms\tremaining: 4.89s\n",
      "1150:\tlearn: 0.0251560\ttotal: 636ms\tremaining: 4.89s\n",
      "1151:\tlearn: 0.0249512\ttotal: 636ms\tremaining: 4.89s\n",
      "1152:\tlearn: 0.0247735\ttotal: 637ms\tremaining: 4.89s\n",
      "1153:\tlearn: 0.0247483\ttotal: 639ms\tremaining: 4.9s\n",
      "1154:\tlearn: 0.0245608\ttotal: 640ms\tremaining: 4.9s\n",
      "1155:\tlearn: 0.0244332\ttotal: 641ms\tremaining: 4.9s\n",
      "1156:\tlearn: 0.0242670\ttotal: 642ms\tremaining: 4.9s\n",
      "1157:\tlearn: 0.0241147\ttotal: 642ms\tremaining: 4.9s\n",
      "1158:\tlearn: 0.0239407\ttotal: 643ms\tremaining: 4.9s\n",
      "1159:\tlearn: 0.0239112\ttotal: 643ms\tremaining: 4.9s\n",
      "1160:\tlearn: 0.0238808\ttotal: 644ms\tremaining: 4.9s\n",
      "1161:\tlearn: 0.0237490\ttotal: 644ms\tremaining: 4.9s\n",
      "1162:\tlearn: 0.0236504\ttotal: 645ms\tremaining: 4.9s\n",
      "1163:\tlearn: 0.0236051\ttotal: 645ms\tremaining: 4.9s\n",
      "1164:\tlearn: 0.0234749\ttotal: 646ms\tremaining: 4.9s\n",
      "1165:\tlearn: 0.0234370\ttotal: 646ms\tremaining: 4.89s\n",
      "1166:\tlearn: 0.0233141\ttotal: 647ms\tremaining: 4.89s\n",
      "1167:\tlearn: 0.0232911\ttotal: 647ms\tremaining: 4.89s\n",
      "1168:\tlearn: 0.0231412\ttotal: 648ms\tremaining: 4.89s\n",
      "1169:\tlearn: 0.0229729\ttotal: 648ms\tremaining: 4.89s\n",
      "1170:\tlearn: 0.0227914\ttotal: 648ms\tremaining: 4.89s\n",
      "1171:\tlearn: 0.0226541\ttotal: 649ms\tremaining: 4.89s\n",
      "1172:\tlearn: 0.0225290\ttotal: 649ms\tremaining: 4.89s\n",
      "1173:\tlearn: 0.0224040\ttotal: 650ms\tremaining: 4.88s\n",
      "1174:\tlearn: 0.0222566\ttotal: 650ms\tremaining: 4.88s\n",
      "1175:\tlearn: 0.0221470\ttotal: 651ms\tremaining: 4.88s\n",
      "1176:\tlearn: 0.0219575\ttotal: 652ms\tremaining: 4.88s\n",
      "1177:\tlearn: 0.0218301\ttotal: 652ms\tremaining: 4.89s\n",
      "1178:\tlearn: 0.0216987\ttotal: 653ms\tremaining: 4.89s\n",
      "1179:\tlearn: 0.0216735\ttotal: 654ms\tremaining: 4.89s\n",
      "1180:\tlearn: 0.0216426\ttotal: 655ms\tremaining: 4.89s\n",
      "1181:\tlearn: 0.0215351\ttotal: 656ms\tremaining: 4.89s\n",
      "1182:\tlearn: 0.0214722\ttotal: 656ms\tremaining: 4.89s\n",
      "1183:\tlearn: 0.0213613\ttotal: 657ms\tremaining: 4.89s\n",
      "1184:\tlearn: 0.0212524\ttotal: 657ms\tremaining: 4.89s\n",
      "1185:\tlearn: 0.0211134\ttotal: 658ms\tremaining: 4.89s\n",
      "1186:\tlearn: 0.0209999\ttotal: 658ms\tremaining: 4.88s\n",
      "1187:\tlearn: 0.0208926\ttotal: 658ms\tremaining: 4.88s\n",
      "1188:\tlearn: 0.0208570\ttotal: 659ms\tremaining: 4.88s\n",
      "1189:\tlearn: 0.0207455\ttotal: 659ms\tremaining: 4.88s\n",
      "1190:\tlearn: 0.0205912\ttotal: 660ms\tremaining: 4.88s\n",
      "1191:\tlearn: 0.0204661\ttotal: 660ms\tremaining: 4.88s\n",
      "1192:\tlearn: 0.0203942\ttotal: 661ms\tremaining: 4.88s\n",
      "1193:\tlearn: 0.0202100\ttotal: 661ms\tremaining: 4.88s\n",
      "1194:\tlearn: 0.0201749\ttotal: 662ms\tremaining: 4.87s\n",
      "1195:\tlearn: 0.0201047\ttotal: 662ms\tremaining: 4.87s\n",
      "1196:\tlearn: 0.0199881\ttotal: 663ms\tremaining: 4.87s\n",
      "1197:\tlearn: 0.0198344\ttotal: 663ms\tremaining: 4.87s\n",
      "1198:\tlearn: 0.0198069\ttotal: 663ms\tremaining: 4.87s\n",
      "1199:\tlearn: 0.0196528\ttotal: 664ms\tremaining: 4.87s\n",
      "1200:\tlearn: 0.0196298\ttotal: 664ms\tremaining: 4.87s\n",
      "1201:\tlearn: 0.0194844\ttotal: 665ms\tremaining: 4.87s\n",
      "1202:\tlearn: 0.0194477\ttotal: 665ms\tremaining: 4.86s\n",
      "1203:\tlearn: 0.0194102\ttotal: 666ms\tremaining: 4.87s\n",
      "1204:\tlearn: 0.0193732\ttotal: 667ms\tremaining: 4.87s\n",
      "1205:\tlearn: 0.0193525\ttotal: 668ms\tremaining: 4.87s\n",
      "1206:\tlearn: 0.0192810\ttotal: 669ms\tremaining: 4.87s\n",
      "1207:\tlearn: 0.0191826\ttotal: 670ms\tremaining: 4.87s\n",
      "1208:\tlearn: 0.0190475\ttotal: 670ms\tremaining: 4.87s\n",
      "1209:\tlearn: 0.0188896\ttotal: 671ms\tremaining: 4.87s\n",
      "1210:\tlearn: 0.0187984\ttotal: 671ms\tremaining: 4.87s\n",
      "1211:\tlearn: 0.0187430\ttotal: 672ms\tremaining: 4.87s\n",
      "1212:\tlearn: 0.0186519\ttotal: 672ms\tremaining: 4.87s\n",
      "1213:\tlearn: 0.0185651\ttotal: 673ms\tremaining: 4.87s\n",
      "1214:\tlearn: 0.0185495\ttotal: 673ms\tremaining: 4.87s\n",
      "1215:\tlearn: 0.0185268\ttotal: 674ms\tremaining: 4.87s\n",
      "1216:\tlearn: 0.0184614\ttotal: 674ms\tremaining: 4.87s\n",
      "1217:\tlearn: 0.0184403\ttotal: 675ms\tremaining: 4.86s\n",
      "1218:\tlearn: 0.0183108\ttotal: 675ms\tremaining: 4.86s\n",
      "1219:\tlearn: 0.0181878\ttotal: 675ms\tremaining: 4.86s\n",
      "1220:\tlearn: 0.0181323\ttotal: 676ms\tremaining: 4.86s\n",
      "1221:\tlearn: 0.0180347\ttotal: 676ms\tremaining: 4.86s\n",
      "1222:\tlearn: 0.0180116\ttotal: 677ms\tremaining: 4.86s\n",
      "1223:\tlearn: 0.0178405\ttotal: 677ms\tremaining: 4.86s\n",
      "1224:\tlearn: 0.0177019\ttotal: 678ms\tremaining: 4.85s\n",
      "1225:\tlearn: 0.0175838\ttotal: 678ms\tremaining: 4.85s\n",
      "1226:\tlearn: 0.0175537\ttotal: 679ms\tremaining: 4.85s\n",
      "1227:\tlearn: 0.0174549\ttotal: 679ms\tremaining: 4.85s\n",
      "1228:\tlearn: 0.0173270\ttotal: 680ms\tremaining: 4.85s\n",
      "1229:\tlearn: 0.0172085\ttotal: 681ms\tremaining: 4.86s\n",
      "1230:\tlearn: 0.0170915\ttotal: 682ms\tremaining: 4.86s\n",
      "1231:\tlearn: 0.0170599\ttotal: 683ms\tremaining: 4.86s\n",
      "1232:\tlearn: 0.0169262\ttotal: 683ms\tremaining: 4.86s\n",
      "1233:\tlearn: 0.0169041\ttotal: 684ms\tremaining: 4.86s\n",
      "1234:\tlearn: 0.0168831\ttotal: 685ms\tremaining: 4.86s\n",
      "1235:\tlearn: 0.0167952\ttotal: 685ms\tremaining: 4.86s\n",
      "1236:\tlearn: 0.0166662\ttotal: 686ms\tremaining: 4.86s\n",
      "1237:\tlearn: 0.0165591\ttotal: 686ms\tremaining: 4.86s\n",
      "1238:\tlearn: 0.0165300\ttotal: 687ms\tremaining: 4.86s\n",
      "1239:\tlearn: 0.0164515\ttotal: 687ms\tremaining: 4.85s\n",
      "1240:\tlearn: 0.0163364\ttotal: 688ms\tremaining: 4.85s\n",
      "1241:\tlearn: 0.0162590\ttotal: 688ms\tremaining: 4.85s\n",
      "1242:\tlearn: 0.0162469\ttotal: 689ms\tremaining: 4.85s\n",
      "1243:\tlearn: 0.0161584\ttotal: 689ms\tremaining: 4.85s\n",
      "1244:\tlearn: 0.0161450\ttotal: 690ms\tremaining: 4.85s\n",
      "1245:\tlearn: 0.0160786\ttotal: 690ms\tremaining: 4.85s\n",
      "1246:\tlearn: 0.0159610\ttotal: 691ms\tremaining: 4.85s\n",
      "1247:\tlearn: 0.0159198\ttotal: 691ms\tremaining: 4.85s\n",
      "1248:\tlearn: 0.0159025\ttotal: 691ms\tremaining: 4.84s\n",
      "1249:\tlearn: 0.0158922\ttotal: 692ms\tremaining: 4.84s\n",
      "1250:\tlearn: 0.0158328\ttotal: 692ms\tremaining: 4.84s\n",
      "1251:\tlearn: 0.0157531\ttotal: 693ms\tremaining: 4.84s\n",
      "1252:\tlearn: 0.0156772\ttotal: 694ms\tremaining: 4.84s\n",
      "1253:\tlearn: 0.0156089\ttotal: 695ms\tremaining: 4.84s\n",
      "1254:\tlearn: 0.0155433\ttotal: 696ms\tremaining: 4.85s\n",
      "1255:\tlearn: 0.0154273\ttotal: 696ms\tremaining: 4.85s\n",
      "1256:\tlearn: 0.0153935\ttotal: 697ms\tremaining: 4.85s\n",
      "1257:\tlearn: 0.0152388\ttotal: 698ms\tremaining: 4.85s\n",
      "1258:\tlearn: 0.0151985\ttotal: 699ms\tremaining: 4.85s\n",
      "1259:\tlearn: 0.0151155\ttotal: 699ms\tremaining: 4.85s\n",
      "1260:\tlearn: 0.0150679\ttotal: 700ms\tremaining: 4.85s\n",
      "1261:\tlearn: 0.0150147\ttotal: 700ms\tremaining: 4.85s\n",
      "1262:\tlearn: 0.0149959\ttotal: 701ms\tremaining: 4.85s\n",
      "1263:\tlearn: 0.0149216\ttotal: 702ms\tremaining: 4.85s\n",
      "1264:\tlearn: 0.0148513\ttotal: 702ms\tremaining: 4.85s\n",
      "1265:\tlearn: 0.0148309\ttotal: 703ms\tremaining: 4.85s\n",
      "1266:\tlearn: 0.0147784\ttotal: 703ms\tremaining: 4.85s\n",
      "1267:\tlearn: 0.0147536\ttotal: 704ms\tremaining: 4.85s\n",
      "1268:\tlearn: 0.0146843\ttotal: 704ms\tremaining: 4.85s\n",
      "1269:\tlearn: 0.0145887\ttotal: 705ms\tremaining: 4.84s\n",
      "1270:\tlearn: 0.0144847\ttotal: 705ms\tremaining: 4.84s\n",
      "1271:\tlearn: 0.0144220\ttotal: 706ms\tremaining: 4.84s\n",
      "1272:\tlearn: 0.0143105\ttotal: 706ms\tremaining: 4.84s\n",
      "1273:\tlearn: 0.0142326\ttotal: 707ms\tremaining: 4.84s\n",
      "1274:\tlearn: 0.0141102\ttotal: 707ms\tremaining: 4.84s\n",
      "1275:\tlearn: 0.0140453\ttotal: 709ms\tremaining: 4.84s\n",
      "1276:\tlearn: 0.0140198\ttotal: 710ms\tremaining: 4.85s\n",
      "1277:\tlearn: 0.0139914\ttotal: 710ms\tremaining: 4.85s\n",
      "1278:\tlearn: 0.0139035\ttotal: 711ms\tremaining: 4.85s\n",
      "1279:\tlearn: 0.0138087\ttotal: 712ms\tremaining: 4.85s\n",
      "1280:\tlearn: 0.0137502\ttotal: 713ms\tremaining: 4.85s\n",
      "1281:\tlearn: 0.0137167\ttotal: 713ms\tremaining: 4.85s\n",
      "1282:\tlearn: 0.0136311\ttotal: 714ms\tremaining: 4.85s\n",
      "1283:\tlearn: 0.0135200\ttotal: 714ms\tremaining: 4.85s\n",
      "1284:\tlearn: 0.0134239\ttotal: 715ms\tremaining: 4.85s\n",
      "1285:\tlearn: 0.0133416\ttotal: 715ms\tremaining: 4.85s\n",
      "1286:\tlearn: 0.0133000\ttotal: 716ms\tremaining: 4.85s\n",
      "1287:\tlearn: 0.0132329\ttotal: 717ms\tremaining: 4.85s\n",
      "1288:\tlearn: 0.0131450\ttotal: 717ms\tremaining: 4.85s\n",
      "1289:\tlearn: 0.0130878\ttotal: 718ms\tremaining: 4.85s\n",
      "1290:\tlearn: 0.0130047\ttotal: 719ms\tremaining: 4.85s\n",
      "1291:\tlearn: 0.0129869\ttotal: 719ms\tremaining: 4.85s\n",
      "1292:\tlearn: 0.0128821\ttotal: 720ms\tremaining: 4.84s\n",
      "1293:\tlearn: 0.0128345\ttotal: 720ms\tremaining: 4.84s\n",
      "1294:\tlearn: 0.0128047\ttotal: 721ms\tremaining: 4.84s\n",
      "1295:\tlearn: 0.0127282\ttotal: 721ms\tremaining: 4.84s\n",
      "1296:\tlearn: 0.0126690\ttotal: 722ms\tremaining: 4.85s\n",
      "1297:\tlearn: 0.0126163\ttotal: 724ms\tremaining: 4.85s\n",
      "1298:\tlearn: 0.0125741\ttotal: 724ms\tremaining: 4.85s\n",
      "1299:\tlearn: 0.0125327\ttotal: 725ms\tremaining: 4.85s\n",
      "1300:\tlearn: 0.0124679\ttotal: 726ms\tremaining: 4.85s\n",
      "1301:\tlearn: 0.0123858\ttotal: 726ms\tremaining: 4.85s\n",
      "1302:\tlearn: 0.0123434\ttotal: 727ms\tremaining: 4.85s\n",
      "1303:\tlearn: 0.0123220\ttotal: 728ms\tremaining: 4.86s\n",
      "1304:\tlearn: 0.0122449\ttotal: 729ms\tremaining: 4.85s\n",
      "1305:\tlearn: 0.0121472\ttotal: 729ms\tremaining: 4.85s\n",
      "1306:\tlearn: 0.0120870\ttotal: 730ms\tremaining: 4.85s\n",
      "1307:\tlearn: 0.0120607\ttotal: 730ms\tremaining: 4.85s\n",
      "1308:\tlearn: 0.0120513\ttotal: 731ms\tremaining: 4.85s\n",
      "1309:\tlearn: 0.0120395\ttotal: 731ms\tremaining: 4.85s\n",
      "1310:\tlearn: 0.0120219\ttotal: 732ms\tremaining: 4.85s\n",
      "1311:\tlearn: 0.0119159\ttotal: 733ms\tremaining: 4.85s\n",
      "1312:\tlearn: 0.0119034\ttotal: 734ms\tremaining: 4.85s\n",
      "1313:\tlearn: 0.0118580\ttotal: 734ms\tremaining: 4.85s\n",
      "1314:\tlearn: 0.0117958\ttotal: 735ms\tremaining: 4.85s\n",
      "1315:\tlearn: 0.0117823\ttotal: 736ms\tremaining: 4.86s\n",
      "1316:\tlearn: 0.0117685\ttotal: 738ms\tremaining: 4.86s\n",
      "1317:\tlearn: 0.0117028\ttotal: 738ms\tremaining: 4.86s\n",
      "1318:\tlearn: 0.0116483\ttotal: 740ms\tremaining: 4.87s\n",
      "1319:\tlearn: 0.0115827\ttotal: 740ms\tremaining: 4.87s\n",
      "1320:\tlearn: 0.0114841\ttotal: 741ms\tremaining: 4.87s\n",
      "1321:\tlearn: 0.0114230\ttotal: 741ms\tremaining: 4.87s\n",
      "1322:\tlearn: 0.0114101\ttotal: 742ms\tremaining: 4.87s\n",
      "1323:\tlearn: 0.0113783\ttotal: 742ms\tremaining: 4.86s\n",
      "1324:\tlearn: 0.0113312\ttotal: 743ms\tremaining: 4.86s\n",
      "1325:\tlearn: 0.0112864\ttotal: 743ms\tremaining: 4.86s\n",
      "1326:\tlearn: 0.0112670\ttotal: 744ms\tremaining: 4.86s\n",
      "1327:\tlearn: 0.0111958\ttotal: 745ms\tremaining: 4.86s\n",
      "1328:\tlearn: 0.0111677\ttotal: 745ms\tremaining: 4.86s\n",
      "1329:\tlearn: 0.0111525\ttotal: 746ms\tremaining: 4.86s\n",
      "1330:\tlearn: 0.0110909\ttotal: 747ms\tremaining: 4.86s\n",
      "1331:\tlearn: 0.0110397\ttotal: 747ms\tremaining: 4.86s\n",
      "1332:\tlearn: 0.0110249\ttotal: 748ms\tremaining: 4.86s\n",
      "1333:\tlearn: 0.0109361\ttotal: 749ms\tremaining: 4.86s\n",
      "1334:\tlearn: 0.0109226\ttotal: 750ms\tremaining: 4.87s\n",
      "1335:\tlearn: 0.0109045\ttotal: 751ms\tremaining: 4.87s\n",
      "1336:\tlearn: 0.0108875\ttotal: 753ms\tremaining: 4.88s\n",
      "1337:\tlearn: 0.0108162\ttotal: 753ms\tremaining: 4.88s\n",
      "1338:\tlearn: 0.0107564\ttotal: 754ms\tremaining: 4.88s\n",
      "1339:\tlearn: 0.0107012\ttotal: 754ms\tremaining: 4.88s\n",
      "1340:\tlearn: 0.0106529\ttotal: 755ms\tremaining: 4.87s\n",
      "1341:\tlearn: 0.0106227\ttotal: 756ms\tremaining: 4.87s\n",
      "1342:\tlearn: 0.0105605\ttotal: 756ms\tremaining: 4.87s\n",
      "1343:\tlearn: 0.0105309\ttotal: 757ms\tremaining: 4.87s\n",
      "1344:\tlearn: 0.0105141\ttotal: 758ms\tremaining: 4.88s\n",
      "1345:\tlearn: 0.0104298\ttotal: 759ms\tremaining: 4.88s\n",
      "1346:\tlearn: 0.0103502\ttotal: 760ms\tremaining: 4.88s\n",
      "1347:\tlearn: 0.0103328\ttotal: 760ms\tremaining: 4.88s\n",
      "1348:\tlearn: 0.0102432\ttotal: 761ms\tremaining: 4.88s\n",
      "1349:\tlearn: 0.0102177\ttotal: 763ms\tremaining: 4.89s\n",
      "1350:\tlearn: 0.0101617\ttotal: 764ms\tremaining: 4.89s\n",
      "1351:\tlearn: 0.0101148\ttotal: 766ms\tremaining: 4.9s\n",
      "1352:\tlearn: 0.0100262\ttotal: 767ms\tremaining: 4.9s\n",
      "1353:\tlearn: 0.0099488\ttotal: 768ms\tremaining: 4.9s\n",
      "1354:\tlearn: 0.0098952\ttotal: 769ms\tremaining: 4.91s\n",
      "1355:\tlearn: 0.0098476\ttotal: 770ms\tremaining: 4.91s\n",
      "1356:\tlearn: 0.0097942\ttotal: 771ms\tremaining: 4.91s\n",
      "1357:\tlearn: 0.0097343\ttotal: 771ms\tremaining: 4.91s\n",
      "1358:\tlearn: 0.0096463\ttotal: 772ms\tremaining: 4.91s\n",
      "1359:\tlearn: 0.0096337\ttotal: 773ms\tremaining: 4.91s\n",
      "1360:\tlearn: 0.0096142\ttotal: 773ms\tremaining: 4.91s\n",
      "1361:\tlearn: 0.0095622\ttotal: 774ms\tremaining: 4.91s\n",
      "1362:\tlearn: 0.0095480\ttotal: 774ms\tremaining: 4.91s\n",
      "1363:\tlearn: 0.0095038\ttotal: 776ms\tremaining: 4.91s\n",
      "1364:\tlearn: 0.0094688\ttotal: 777ms\tremaining: 4.91s\n",
      "1365:\tlearn: 0.0094575\ttotal: 778ms\tremaining: 4.92s\n",
      "1366:\tlearn: 0.0094108\ttotal: 778ms\tremaining: 4.92s\n",
      "1367:\tlearn: 0.0093558\ttotal: 779ms\tremaining: 4.92s\n",
      "1368:\tlearn: 0.0092884\ttotal: 780ms\tremaining: 4.92s\n",
      "1369:\tlearn: 0.0092786\ttotal: 780ms\tremaining: 4.91s\n",
      "1370:\tlearn: 0.0092704\ttotal: 781ms\tremaining: 4.91s\n",
      "1371:\tlearn: 0.0092476\ttotal: 781ms\tremaining: 4.91s\n",
      "1372:\tlearn: 0.0092351\ttotal: 782ms\tremaining: 4.91s\n",
      "1373:\tlearn: 0.0091630\ttotal: 782ms\tremaining: 4.91s\n",
      "1374:\tlearn: 0.0091037\ttotal: 783ms\tremaining: 4.91s\n",
      "1375:\tlearn: 0.0090631\ttotal: 784ms\tremaining: 4.91s\n",
      "1376:\tlearn: 0.0090357\ttotal: 784ms\tremaining: 4.91s\n",
      "1377:\tlearn: 0.0089802\ttotal: 785ms\tremaining: 4.91s\n",
      "1378:\tlearn: 0.0089638\ttotal: 785ms\tremaining: 4.91s\n",
      "1379:\tlearn: 0.0089570\ttotal: 786ms\tremaining: 4.91s\n",
      "1380:\tlearn: 0.0089455\ttotal: 786ms\tremaining: 4.91s\n",
      "1381:\tlearn: 0.0088901\ttotal: 787ms\tremaining: 4.91s\n",
      "1382:\tlearn: 0.0088198\ttotal: 788ms\tremaining: 4.91s\n",
      "1383:\tlearn: 0.0087908\ttotal: 788ms\tremaining: 4.91s\n",
      "1384:\tlearn: 0.0087783\ttotal: 789ms\tremaining: 4.91s\n",
      "1385:\tlearn: 0.0087707\ttotal: 789ms\tremaining: 4.91s\n",
      "1386:\tlearn: 0.0087594\ttotal: 790ms\tremaining: 4.91s\n",
      "1387:\tlearn: 0.0087498\ttotal: 791ms\tremaining: 4.91s\n",
      "1388:\tlearn: 0.0087096\ttotal: 791ms\tremaining: 4.9s\n",
      "1389:\tlearn: 0.0086848\ttotal: 792ms\tremaining: 4.9s\n",
      "1390:\tlearn: 0.0086700\ttotal: 792ms\tremaining: 4.9s\n",
      "1391:\tlearn: 0.0086139\ttotal: 793ms\tremaining: 4.9s\n",
      "1392:\tlearn: 0.0085584\ttotal: 793ms\tremaining: 4.9s\n",
      "1393:\tlearn: 0.0084856\ttotal: 794ms\tremaining: 4.9s\n",
      "1394:\tlearn: 0.0084665\ttotal: 794ms\tremaining: 4.9s\n",
      "1395:\tlearn: 0.0084582\ttotal: 795ms\tremaining: 4.9s\n",
      "1396:\tlearn: 0.0084457\ttotal: 796ms\tremaining: 4.9s\n",
      "1397:\tlearn: 0.0084014\ttotal: 796ms\tremaining: 4.9s\n",
      "1398:\tlearn: 0.0083838\ttotal: 797ms\tremaining: 4.9s\n",
      "1399:\tlearn: 0.0083727\ttotal: 797ms\tremaining: 4.9s\n",
      "1400:\tlearn: 0.0083287\ttotal: 798ms\tremaining: 4.9s\n",
      "1401:\tlearn: 0.0083170\ttotal: 799ms\tremaining: 4.9s\n",
      "1402:\tlearn: 0.0083037\ttotal: 799ms\tremaining: 4.9s\n",
      "1403:\tlearn: 0.0082931\ttotal: 800ms\tremaining: 4.9s\n",
      "1404:\tlearn: 0.0082413\ttotal: 800ms\tremaining: 4.89s\n",
      "1405:\tlearn: 0.0081936\ttotal: 801ms\tremaining: 4.89s\n",
      "1406:\tlearn: 0.0081785\ttotal: 801ms\tremaining: 4.89s\n",
      "1407:\tlearn: 0.0081109\ttotal: 802ms\tremaining: 4.89s\n",
      "1408:\tlearn: 0.0080912\ttotal: 803ms\tremaining: 4.89s\n",
      "1409:\tlearn: 0.0080444\ttotal: 805ms\tremaining: 4.9s\n",
      "1410:\tlearn: 0.0080379\ttotal: 806ms\tremaining: 4.91s\n",
      "1411:\tlearn: 0.0080281\ttotal: 807ms\tremaining: 4.91s\n",
      "1412:\tlearn: 0.0079872\ttotal: 808ms\tremaining: 4.91s\n",
      "1413:\tlearn: 0.0079608\ttotal: 809ms\tremaining: 4.91s\n",
      "1414:\tlearn: 0.0079464\ttotal: 809ms\tremaining: 4.91s\n",
      "1415:\tlearn: 0.0079360\ttotal: 810ms\tremaining: 4.91s\n",
      "1416:\tlearn: 0.0078835\ttotal: 810ms\tremaining: 4.91s\n",
      "1417:\tlearn: 0.0078653\ttotal: 811ms\tremaining: 4.91s\n",
      "1418:\tlearn: 0.0078130\ttotal: 811ms\tremaining: 4.91s\n",
      "1419:\tlearn: 0.0077485\ttotal: 812ms\tremaining: 4.91s\n",
      "1420:\tlearn: 0.0077003\ttotal: 812ms\tremaining: 4.91s\n",
      "1421:\tlearn: 0.0076609\ttotal: 813ms\tremaining: 4.9s\n",
      "1422:\tlearn: 0.0076081\ttotal: 814ms\tremaining: 4.91s\n",
      "1423:\tlearn: 0.0075924\ttotal: 814ms\tremaining: 4.91s\n",
      "1424:\tlearn: 0.0075353\ttotal: 815ms\tremaining: 4.9s\n",
      "1425:\tlearn: 0.0075148\ttotal: 818ms\tremaining: 4.92s\n",
      "1426:\tlearn: 0.0074832\ttotal: 820ms\tremaining: 4.92s\n",
      "1427:\tlearn: 0.0074791\ttotal: 821ms\tremaining: 4.93s\n",
      "1428:\tlearn: 0.0074327\ttotal: 821ms\tremaining: 4.93s\n",
      "1429:\tlearn: 0.0074016\ttotal: 822ms\tremaining: 4.93s\n",
      "1430:\tlearn: 0.0073594\ttotal: 823ms\tremaining: 4.92s\n",
      "1431:\tlearn: 0.0072705\ttotal: 823ms\tremaining: 4.92s\n",
      "1432:\tlearn: 0.0071983\ttotal: 824ms\tremaining: 4.92s\n",
      "1433:\tlearn: 0.0071885\ttotal: 824ms\tremaining: 4.92s\n",
      "1434:\tlearn: 0.0071322\ttotal: 825ms\tremaining: 4.92s\n",
      "1435:\tlearn: 0.0071006\ttotal: 826ms\tremaining: 4.92s\n",
      "1436:\tlearn: 0.0070911\ttotal: 826ms\tremaining: 4.92s\n",
      "1437:\tlearn: 0.0070292\ttotal: 827ms\tremaining: 4.92s\n",
      "1438:\tlearn: 0.0070148\ttotal: 828ms\tremaining: 4.92s\n",
      "1439:\tlearn: 0.0069616\ttotal: 828ms\tremaining: 4.92s\n",
      "1440:\tlearn: 0.0069081\ttotal: 829ms\tremaining: 4.92s\n",
      "1441:\tlearn: 0.0068961\ttotal: 829ms\tremaining: 4.92s\n",
      "1442:\tlearn: 0.0068658\ttotal: 831ms\tremaining: 4.93s\n",
      "1443:\tlearn: 0.0068445\ttotal: 833ms\tremaining: 4.93s\n",
      "1444:\tlearn: 0.0068376\ttotal: 834ms\tremaining: 4.94s\n",
      "1445:\tlearn: 0.0068282\ttotal: 835ms\tremaining: 4.94s\n",
      "1446:\tlearn: 0.0068191\ttotal: 836ms\tremaining: 4.94s\n",
      "1447:\tlearn: 0.0067672\ttotal: 837ms\tremaining: 4.94s\n",
      "1448:\tlearn: 0.0067522\ttotal: 838ms\tremaining: 4.94s\n",
      "1449:\tlearn: 0.0067416\ttotal: 838ms\tremaining: 4.94s\n",
      "1450:\tlearn: 0.0067010\ttotal: 839ms\tremaining: 4.94s\n",
      "1451:\tlearn: 0.0066456\ttotal: 839ms\tremaining: 4.94s\n",
      "1452:\tlearn: 0.0066083\ttotal: 840ms\tremaining: 4.94s\n",
      "1453:\tlearn: 0.0065570\ttotal: 841ms\tremaining: 4.94s\n",
      "1454:\tlearn: 0.0065472\ttotal: 842ms\tremaining: 4.94s\n",
      "1455:\tlearn: 0.0065397\ttotal: 842ms\tremaining: 4.94s\n",
      "1456:\tlearn: 0.0065282\ttotal: 845ms\tremaining: 4.95s\n",
      "1457:\tlearn: 0.0065149\ttotal: 846ms\tremaining: 4.96s\n",
      "1458:\tlearn: 0.0065086\ttotal: 847ms\tremaining: 4.96s\n",
      "1459:\tlearn: 0.0064721\ttotal: 848ms\tremaining: 4.96s\n",
      "1460:\tlearn: 0.0064477\ttotal: 849ms\tremaining: 4.96s\n",
      "1461:\tlearn: 0.0064401\ttotal: 849ms\tremaining: 4.96s\n",
      "1462:\tlearn: 0.0064082\ttotal: 850ms\tremaining: 4.96s\n",
      "1463:\tlearn: 0.0064010\ttotal: 850ms\tremaining: 4.96s\n",
      "1464:\tlearn: 0.0063595\ttotal: 851ms\tremaining: 4.96s\n",
      "1465:\tlearn: 0.0063106\ttotal: 852ms\tremaining: 4.96s\n",
      "1466:\tlearn: 0.0062770\ttotal: 852ms\tremaining: 4.96s\n",
      "1467:\tlearn: 0.0062712\ttotal: 853ms\tremaining: 4.96s\n",
      "1468:\tlearn: 0.0062530\ttotal: 854ms\tremaining: 4.96s\n",
      "1469:\tlearn: 0.0062183\ttotal: 854ms\tremaining: 4.96s\n",
      "1470:\tlearn: 0.0061783\ttotal: 855ms\tremaining: 4.96s\n",
      "1471:\tlearn: 0.0061354\ttotal: 856ms\tremaining: 4.96s\n",
      "1472:\tlearn: 0.0061077\ttotal: 857ms\tremaining: 4.96s\n",
      "1473:\tlearn: 0.0061040\ttotal: 859ms\tremaining: 4.97s\n",
      "1474:\tlearn: 0.0060824\ttotal: 861ms\tremaining: 4.98s\n",
      "1475:\tlearn: 0.0060372\ttotal: 862ms\tremaining: 4.98s\n",
      "1476:\tlearn: 0.0060276\ttotal: 862ms\tremaining: 4.98s\n",
      "1477:\tlearn: 0.0060193\ttotal: 863ms\tremaining: 4.97s\n",
      "1478:\tlearn: 0.0059657\ttotal: 863ms\tremaining: 4.97s\n",
      "1479:\tlearn: 0.0059295\ttotal: 864ms\tremaining: 4.97s\n",
      "1480:\tlearn: 0.0058869\ttotal: 865ms\tremaining: 4.97s\n",
      "1481:\tlearn: 0.0058566\ttotal: 865ms\tremaining: 4.97s\n",
      "1482:\tlearn: 0.0058493\ttotal: 866ms\tremaining: 4.97s\n",
      "1483:\tlearn: 0.0057847\ttotal: 866ms\tremaining: 4.97s\n",
      "1484:\tlearn: 0.0057537\ttotal: 867ms\tremaining: 4.97s\n",
      "1485:\tlearn: 0.0057239\ttotal: 867ms\tremaining: 4.97s\n",
      "1486:\tlearn: 0.0056959\ttotal: 868ms\tremaining: 4.97s\n",
      "1487:\tlearn: 0.0056609\ttotal: 868ms\tremaining: 4.96s\n",
      "1488:\tlearn: 0.0056240\ttotal: 869ms\tremaining: 4.96s\n",
      "1489:\tlearn: 0.0056182\ttotal: 869ms\tremaining: 4.96s\n",
      "1490:\tlearn: 0.0055893\ttotal: 870ms\tremaining: 4.96s\n",
      "1491:\tlearn: 0.0055599\ttotal: 872ms\tremaining: 4.97s\n",
      "1492:\tlearn: 0.0055517\ttotal: 875ms\tremaining: 4.99s\n",
      "1493:\tlearn: 0.0055415\ttotal: 876ms\tremaining: 4.98s\n",
      "1494:\tlearn: 0.0055138\ttotal: 876ms\tremaining: 4.98s\n",
      "1495:\tlearn: 0.0054820\ttotal: 877ms\tremaining: 4.98s\n",
      "1496:\tlearn: 0.0054559\ttotal: 877ms\tremaining: 4.98s\n",
      "1497:\tlearn: 0.0054205\ttotal: 878ms\tremaining: 4.98s\n",
      "1498:\tlearn: 0.0054152\ttotal: 878ms\tremaining: 4.98s\n",
      "1499:\tlearn: 0.0053703\ttotal: 879ms\tremaining: 4.98s\n",
      "1500:\tlearn: 0.0053611\ttotal: 879ms\tremaining: 4.98s\n",
      "1501:\tlearn: 0.0053531\ttotal: 880ms\tremaining: 4.98s\n",
      "1502:\tlearn: 0.0053337\ttotal: 880ms\tremaining: 4.97s\n",
      "1503:\tlearn: 0.0053053\ttotal: 881ms\tremaining: 4.97s\n",
      "1504:\tlearn: 0.0052990\ttotal: 881ms\tremaining: 4.97s\n",
      "1505:\tlearn: 0.0052751\ttotal: 882ms\tremaining: 4.97s\n",
      "1506:\tlearn: 0.0052686\ttotal: 882ms\tremaining: 4.97s\n",
      "1507:\tlearn: 0.0052166\ttotal: 883ms\tremaining: 4.97s\n",
      "1508:\tlearn: 0.0052086\ttotal: 883ms\tremaining: 4.97s\n",
      "1509:\tlearn: 0.0051956\ttotal: 884ms\tremaining: 4.97s\n",
      "1510:\tlearn: 0.0051530\ttotal: 886ms\tremaining: 4.98s\n",
      "1511:\tlearn: 0.0051402\ttotal: 887ms\tremaining: 4.98s\n",
      "1512:\tlearn: 0.0051119\ttotal: 888ms\tremaining: 4.98s\n",
      "1513:\tlearn: 0.0050821\ttotal: 889ms\tremaining: 4.98s\n",
      "1514:\tlearn: 0.0050648\ttotal: 889ms\tremaining: 4.98s\n",
      "1515:\tlearn: 0.0050591\ttotal: 890ms\tremaining: 4.98s\n",
      "1516:\tlearn: 0.0050365\ttotal: 890ms\tremaining: 4.98s\n",
      "1517:\tlearn: 0.0050083\ttotal: 891ms\tremaining: 4.98s\n",
      "1518:\tlearn: 0.0049639\ttotal: 891ms\tremaining: 4.97s\n",
      "1519:\tlearn: 0.0049456\ttotal: 892ms\tremaining: 4.97s\n",
      "1520:\tlearn: 0.0049413\ttotal: 892ms\tremaining: 4.97s\n",
      "1521:\tlearn: 0.0049068\ttotal: 893ms\tremaining: 4.97s\n",
      "1522:\tlearn: 0.0048846\ttotal: 893ms\tremaining: 4.97s\n",
      "1523:\tlearn: 0.0048340\ttotal: 894ms\tremaining: 4.97s\n",
      "1524:\tlearn: 0.0048140\ttotal: 895ms\tremaining: 4.97s\n",
      "1525:\tlearn: 0.0047859\ttotal: 895ms\tremaining: 4.97s\n",
      "1526:\tlearn: 0.0047635\ttotal: 896ms\tremaining: 4.97s\n",
      "1527:\tlearn: 0.0047456\ttotal: 896ms\tremaining: 4.97s\n",
      "1528:\tlearn: 0.0047232\ttotal: 897ms\tremaining: 4.97s\n",
      "1529:\tlearn: 0.0047018\ttotal: 897ms\tremaining: 4.96s\n",
      "1530:\tlearn: 0.0046689\ttotal: 898ms\tremaining: 4.97s\n",
      "1531:\tlearn: 0.0046242\ttotal: 899ms\tremaining: 4.97s\n",
      "1532:\tlearn: 0.0045920\ttotal: 900ms\tremaining: 4.97s\n",
      "1533:\tlearn: 0.0045840\ttotal: 902ms\tremaining: 4.98s\n",
      "1534:\tlearn: 0.0045720\ttotal: 903ms\tremaining: 4.98s\n",
      "1535:\tlearn: 0.0045665\ttotal: 903ms\tremaining: 4.98s\n",
      "1536:\tlearn: 0.0045598\ttotal: 904ms\tremaining: 4.98s\n",
      "1537:\tlearn: 0.0045407\ttotal: 904ms\tremaining: 4.97s\n",
      "1538:\tlearn: 0.0045294\ttotal: 905ms\tremaining: 4.97s\n",
      "1539:\tlearn: 0.0045254\ttotal: 905ms\tremaining: 4.97s\n",
      "1540:\tlearn: 0.0044925\ttotal: 906ms\tremaining: 4.97s\n",
      "1541:\tlearn: 0.0044814\ttotal: 907ms\tremaining: 4.97s\n",
      "1542:\tlearn: 0.0044644\ttotal: 907ms\tremaining: 4.97s\n",
      "1543:\tlearn: 0.0044436\ttotal: 907ms\tremaining: 4.97s\n",
      "1544:\tlearn: 0.0044178\ttotal: 908ms\tremaining: 4.97s\n",
      "1545:\tlearn: 0.0043940\ttotal: 908ms\tremaining: 4.96s\n",
      "1546:\tlearn: 0.0043847\ttotal: 909ms\tremaining: 4.96s\n",
      "1547:\tlearn: 0.0043457\ttotal: 909ms\tremaining: 4.96s\n",
      "1548:\tlearn: 0.0043090\ttotal: 909ms\tremaining: 4.96s\n",
      "1549:\tlearn: 0.0042828\ttotal: 910ms\tremaining: 4.96s\n",
      "1550:\tlearn: 0.0042532\ttotal: 910ms\tremaining: 4.96s\n",
      "1551:\tlearn: 0.0042381\ttotal: 911ms\tremaining: 4.96s\n",
      "1552:\tlearn: 0.0042199\ttotal: 912ms\tremaining: 4.96s\n",
      "1553:\tlearn: 0.0041925\ttotal: 913ms\tremaining: 4.96s\n",
      "1554:\tlearn: 0.0041484\ttotal: 915ms\tremaining: 4.97s\n",
      "1555:\tlearn: 0.0041280\ttotal: 915ms\tremaining: 4.97s\n",
      "1556:\tlearn: 0.0041238\ttotal: 916ms\tremaining: 4.97s\n",
      "1557:\tlearn: 0.0041049\ttotal: 916ms\tremaining: 4.96s\n",
      "1558:\tlearn: 0.0040875\ttotal: 917ms\tremaining: 4.96s\n",
      "1559:\tlearn: 0.0040673\ttotal: 917ms\tremaining: 4.96s\n",
      "1560:\tlearn: 0.0040482\ttotal: 918ms\tremaining: 4.96s\n",
      "1561:\tlearn: 0.0040425\ttotal: 919ms\tremaining: 4.96s\n",
      "1562:\tlearn: 0.0040378\ttotal: 919ms\tremaining: 4.96s\n",
      "1563:\tlearn: 0.0040134\ttotal: 920ms\tremaining: 4.96s\n",
      "1564:\tlearn: 0.0040039\ttotal: 920ms\tremaining: 4.96s\n",
      "1565:\tlearn: 0.0039894\ttotal: 921ms\tremaining: 4.96s\n",
      "1566:\tlearn: 0.0039602\ttotal: 921ms\tremaining: 4.96s\n",
      "1567:\tlearn: 0.0039553\ttotal: 921ms\tremaining: 4.96s\n",
      "1568:\tlearn: 0.0039501\ttotal: 922ms\tremaining: 4.95s\n",
      "1569:\tlearn: 0.0039414\ttotal: 922ms\tremaining: 4.95s\n",
      "1570:\tlearn: 0.0039318\ttotal: 923ms\tremaining: 4.95s\n",
      "1571:\tlearn: 0.0039088\ttotal: 923ms\tremaining: 4.95s\n",
      "1572:\tlearn: 0.0039048\ttotal: 924ms\tremaining: 4.95s\n",
      "1573:\tlearn: 0.0038877\ttotal: 925ms\tremaining: 4.95s\n",
      "1574:\tlearn: 0.0038594\ttotal: 927ms\tremaining: 4.96s\n",
      "1575:\tlearn: 0.0038326\ttotal: 928ms\tremaining: 4.96s\n",
      "1576:\tlearn: 0.0038244\ttotal: 929ms\tremaining: 4.96s\n",
      "1577:\tlearn: 0.0038199\ttotal: 930ms\tremaining: 4.96s\n",
      "1578:\tlearn: 0.0037944\ttotal: 930ms\tremaining: 4.96s\n",
      "1579:\tlearn: 0.0037902\ttotal: 931ms\tremaining: 4.96s\n",
      "1580:\tlearn: 0.0037709\ttotal: 931ms\tremaining: 4.96s\n",
      "1581:\tlearn: 0.0037668\ttotal: 931ms\tremaining: 4.96s\n",
      "1582:\tlearn: 0.0037533\ttotal: 932ms\tremaining: 4.96s\n",
      "1583:\tlearn: 0.0037427\ttotal: 932ms\tremaining: 4.95s\n",
      "1584:\tlearn: 0.0037326\ttotal: 933ms\tremaining: 4.95s\n",
      "1585:\tlearn: 0.0037276\ttotal: 933ms\tremaining: 4.95s\n",
      "1586:\tlearn: 0.0037240\ttotal: 934ms\tremaining: 4.95s\n",
      "1587:\tlearn: 0.0036827\ttotal: 935ms\tremaining: 4.95s\n",
      "1588:\tlearn: 0.0036648\ttotal: 935ms\tremaining: 4.95s\n",
      "1589:\tlearn: 0.0036425\ttotal: 935ms\tremaining: 4.95s\n",
      "1590:\tlearn: 0.0036118\ttotal: 936ms\tremaining: 4.95s\n",
      "1591:\tlearn: 0.0035941\ttotal: 936ms\tremaining: 4.95s\n",
      "1592:\tlearn: 0.0035817\ttotal: 937ms\tremaining: 4.94s\n",
      "1593:\tlearn: 0.0035780\ttotal: 937ms\tremaining: 4.94s\n",
      "1594:\tlearn: 0.0035729\ttotal: 938ms\tremaining: 4.94s\n",
      "1595:\tlearn: 0.0035485\ttotal: 939ms\tremaining: 4.94s\n",
      "1596:\tlearn: 0.0035450\ttotal: 942ms\tremaining: 4.96s\n",
      "1597:\tlearn: 0.0035079\ttotal: 943ms\tremaining: 4.96s\n",
      "1598:\tlearn: 0.0034999\ttotal: 943ms\tremaining: 4.96s\n",
      "1599:\tlearn: 0.0034925\ttotal: 944ms\tremaining: 4.96s\n",
      "1600:\tlearn: 0.0034679\ttotal: 944ms\tremaining: 4.95s\n",
      "1601:\tlearn: 0.0034626\ttotal: 945ms\tremaining: 4.95s\n",
      "1602:\tlearn: 0.0034391\ttotal: 945ms\tremaining: 4.95s\n",
      "1603:\tlearn: 0.0034364\ttotal: 946ms\tremaining: 4.95s\n",
      "1604:\tlearn: 0.0034080\ttotal: 946ms\tremaining: 4.95s\n",
      "1605:\tlearn: 0.0033831\ttotal: 947ms\tremaining: 4.95s\n",
      "1606:\tlearn: 0.0033773\ttotal: 947ms\tremaining: 4.95s\n",
      "1607:\tlearn: 0.0033738\ttotal: 948ms\tremaining: 4.95s\n",
      "1608:\tlearn: 0.0033711\ttotal: 948ms\tremaining: 4.95s\n",
      "1609:\tlearn: 0.0033477\ttotal: 949ms\tremaining: 4.94s\n",
      "1610:\tlearn: 0.0033405\ttotal: 949ms\tremaining: 4.94s\n",
      "1611:\tlearn: 0.0033242\ttotal: 950ms\tremaining: 4.94s\n",
      "1612:\tlearn: 0.0032968\ttotal: 950ms\tremaining: 4.94s\n",
      "1613:\tlearn: 0.0032931\ttotal: 951ms\tremaining: 4.94s\n",
      "1614:\tlearn: 0.0032898\ttotal: 951ms\tremaining: 4.94s\n",
      "1615:\tlearn: 0.0032651\ttotal: 952ms\tremaining: 4.94s\n",
      "1616:\tlearn: 0.0032605\ttotal: 952ms\tremaining: 4.93s\n",
      "1617:\tlearn: 0.0032544\ttotal: 953ms\tremaining: 4.94s\n",
      "1618:\tlearn: 0.0032506\ttotal: 954ms\tremaining: 4.94s\n",
      "1619:\tlearn: 0.0032477\ttotal: 956ms\tremaining: 4.94s\n",
      "1620:\tlearn: 0.0032371\ttotal: 956ms\tremaining: 4.94s\n",
      "1621:\tlearn: 0.0032328\ttotal: 957ms\tremaining: 4.94s\n",
      "1622:\tlearn: 0.0032284\ttotal: 957ms\tremaining: 4.94s\n",
      "1623:\tlearn: 0.0032100\ttotal: 958ms\tremaining: 4.94s\n",
      "1624:\tlearn: 0.0031879\ttotal: 958ms\tremaining: 4.94s\n",
      "1625:\tlearn: 0.0031731\ttotal: 959ms\tremaining: 4.94s\n",
      "1626:\tlearn: 0.0031558\ttotal: 959ms\tremaining: 4.94s\n",
      "1627:\tlearn: 0.0031528\ttotal: 960ms\tremaining: 4.94s\n",
      "1628:\tlearn: 0.0031376\ttotal: 961ms\tremaining: 4.93s\n",
      "1629:\tlearn: 0.0031219\ttotal: 961ms\tremaining: 4.93s\n",
      "1630:\tlearn: 0.0031081\ttotal: 962ms\tremaining: 4.93s\n",
      "1631:\tlearn: 0.0030882\ttotal: 962ms\tremaining: 4.93s\n",
      "1632:\tlearn: 0.0030743\ttotal: 962ms\tremaining: 4.93s\n",
      "1633:\tlearn: 0.0030472\ttotal: 963ms\tremaining: 4.93s\n",
      "1634:\tlearn: 0.0030325\ttotal: 963ms\tremaining: 4.93s\n",
      "1635:\tlearn: 0.0030069\ttotal: 964ms\tremaining: 4.93s\n",
      "1636:\tlearn: 0.0029769\ttotal: 964ms\tremaining: 4.93s\n",
      "1637:\tlearn: 0.0029741\ttotal: 965ms\tremaining: 4.92s\n",
      "1638:\tlearn: 0.0029708\ttotal: 965ms\tremaining: 4.92s\n",
      "1639:\tlearn: 0.0029683\ttotal: 966ms\tremaining: 4.92s\n",
      "1640:\tlearn: 0.0029661\ttotal: 971ms\tremaining: 4.94s\n",
      "1641:\tlearn: 0.0029621\ttotal: 971ms\tremaining: 4.94s\n",
      "1642:\tlearn: 0.0029337\ttotal: 972ms\tremaining: 4.94s\n",
      "1643:\tlearn: 0.0029313\ttotal: 973ms\tremaining: 4.94s\n",
      "1644:\tlearn: 0.0029023\ttotal: 973ms\tremaining: 4.94s\n",
      "1645:\tlearn: 0.0028754\ttotal: 974ms\tremaining: 4.94s\n",
      "1646:\tlearn: 0.0028732\ttotal: 975ms\tremaining: 4.94s\n",
      "1647:\tlearn: 0.0028712\ttotal: 975ms\tremaining: 4.94s\n",
      "1648:\tlearn: 0.0028507\ttotal: 976ms\tremaining: 4.94s\n",
      "1649:\tlearn: 0.0028396\ttotal: 976ms\tremaining: 4.94s\n",
      "1650:\tlearn: 0.0028229\ttotal: 977ms\tremaining: 4.94s\n",
      "1651:\tlearn: 0.0028201\ttotal: 977ms\tremaining: 4.94s\n",
      "1652:\tlearn: 0.0028174\ttotal: 978ms\tremaining: 4.94s\n",
      "1653:\tlearn: 0.0028055\ttotal: 978ms\tremaining: 4.94s\n",
      "1654:\tlearn: 0.0028033\ttotal: 979ms\tremaining: 4.93s\n",
      "1655:\tlearn: 0.0027971\ttotal: 979ms\tremaining: 4.93s\n",
      "1656:\tlearn: 0.0027908\ttotal: 980ms\tremaining: 4.93s\n",
      "1657:\tlearn: 0.0027807\ttotal: 981ms\tremaining: 4.93s\n",
      "1658:\tlearn: 0.0027611\ttotal: 983ms\tremaining: 4.94s\n",
      "1659:\tlearn: 0.0027584\ttotal: 984ms\tremaining: 4.95s\n",
      "1660:\tlearn: 0.0027547\ttotal: 985ms\tremaining: 4.94s\n",
      "1661:\tlearn: 0.0027343\ttotal: 985ms\tremaining: 4.94s\n",
      "1662:\tlearn: 0.0027259\ttotal: 986ms\tremaining: 4.94s\n",
      "1663:\tlearn: 0.0027082\ttotal: 987ms\tremaining: 4.94s\n",
      "1664:\tlearn: 0.0026971\ttotal: 987ms\tremaining: 4.94s\n",
      "1665:\tlearn: 0.0026942\ttotal: 988ms\tremaining: 4.94s\n",
      "1666:\tlearn: 0.0026865\ttotal: 988ms\tremaining: 4.94s\n",
      "1667:\tlearn: 0.0026751\ttotal: 989ms\tremaining: 4.94s\n",
      "1668:\tlearn: 0.0026705\ttotal: 989ms\tremaining: 4.94s\n",
      "1669:\tlearn: 0.0026604\ttotal: 990ms\tremaining: 4.94s\n",
      "1670:\tlearn: 0.0026549\ttotal: 990ms\tremaining: 4.93s\n",
      "1671:\tlearn: 0.0026288\ttotal: 991ms\tremaining: 4.93s\n",
      "1672:\tlearn: 0.0026050\ttotal: 991ms\tremaining: 4.93s\n",
      "1673:\tlearn: 0.0025774\ttotal: 992ms\tremaining: 4.93s\n",
      "1674:\tlearn: 0.0025679\ttotal: 992ms\tremaining: 4.93s\n",
      "1675:\tlearn: 0.0025654\ttotal: 993ms\tremaining: 4.93s\n",
      "1676:\tlearn: 0.0025542\ttotal: 993ms\tremaining: 4.93s\n",
      "1677:\tlearn: 0.0025397\ttotal: 994ms\tremaining: 4.93s\n",
      "1678:\tlearn: 0.0025383\ttotal: 995ms\tremaining: 4.93s\n",
      "1679:\tlearn: 0.0025078\ttotal: 996ms\tremaining: 4.93s\n",
      "1680:\tlearn: 0.0025022\ttotal: 998ms\tremaining: 4.94s\n",
      "1681:\tlearn: 0.0024919\ttotal: 999ms\tremaining: 4.94s\n",
      "1682:\tlearn: 0.0024816\ttotal: 1000ms\tremaining: 4.94s\n",
      "1683:\tlearn: 0.0024773\ttotal: 1s\tremaining: 4.94s\n",
      "1684:\tlearn: 0.0024749\ttotal: 1s\tremaining: 4.94s\n",
      "1685:\tlearn: 0.0024629\ttotal: 1s\tremaining: 4.94s\n",
      "1686:\tlearn: 0.0024499\ttotal: 1s\tremaining: 4.94s\n",
      "1687:\tlearn: 0.0024273\ttotal: 1s\tremaining: 4.93s\n",
      "1688:\tlearn: 0.0024252\ttotal: 1s\tremaining: 4.93s\n",
      "1689:\tlearn: 0.0024189\ttotal: 1s\tremaining: 4.93s\n",
      "1690:\tlearn: 0.0024148\ttotal: 1s\tremaining: 4.93s\n",
      "1691:\tlearn: 0.0024100\ttotal: 1s\tremaining: 4.93s\n",
      "1692:\tlearn: 0.0024079\ttotal: 1s\tremaining: 4.93s\n",
      "1693:\tlearn: 0.0024052\ttotal: 1s\tremaining: 4.93s\n",
      "1694:\tlearn: 0.0024036\ttotal: 1s\tremaining: 4.93s\n",
      "1695:\tlearn: 0.0023993\ttotal: 1.01s\tremaining: 4.93s\n",
      "1696:\tlearn: 0.0023729\ttotal: 1.01s\tremaining: 4.92s\n",
      "1697:\tlearn: 0.0023664\ttotal: 1.01s\tremaining: 4.92s\n",
      "1698:\tlearn: 0.0023482\ttotal: 1.01s\tremaining: 4.92s\n",
      "1699:\tlearn: 0.0023228\ttotal: 1.01s\tremaining: 4.92s\n",
      "1700:\tlearn: 0.0023021\ttotal: 1.01s\tremaining: 4.92s\n",
      "1701:\tlearn: 0.0022819\ttotal: 1.01s\tremaining: 4.92s\n",
      "1702:\tlearn: 0.0022778\ttotal: 1.01s\tremaining: 4.93s\n",
      "1703:\tlearn: 0.0022579\ttotal: 1.01s\tremaining: 4.93s\n",
      "1704:\tlearn: 0.0022568\ttotal: 1.01s\tremaining: 4.93s\n",
      "1705:\tlearn: 0.0022374\ttotal: 1.01s\tremaining: 4.93s\n",
      "1706:\tlearn: 0.0022226\ttotal: 1.01s\tremaining: 4.93s\n",
      "1707:\tlearn: 0.0022092\ttotal: 1.01s\tremaining: 4.92s\n",
      "1708:\tlearn: 0.0022017\ttotal: 1.01s\tremaining: 4.92s\n",
      "1709:\tlearn: 0.0021871\ttotal: 1.01s\tremaining: 4.92s\n",
      "1710:\tlearn: 0.0021754\ttotal: 1.01s\tremaining: 4.92s\n",
      "1711:\tlearn: 0.0021614\ttotal: 1.02s\tremaining: 4.92s\n",
      "1712:\tlearn: 0.0021484\ttotal: 1.02s\tremaining: 4.92s\n",
      "1713:\tlearn: 0.0021252\ttotal: 1.02s\tremaining: 4.92s\n",
      "1714:\tlearn: 0.0021190\ttotal: 1.02s\tremaining: 4.92s\n",
      "1715:\tlearn: 0.0021007\ttotal: 1.02s\tremaining: 4.92s\n",
      "1716:\tlearn: 0.0020910\ttotal: 1.02s\tremaining: 4.91s\n",
      "1717:\tlearn: 0.0020876\ttotal: 1.02s\tremaining: 4.91s\n",
      "1718:\tlearn: 0.0020809\ttotal: 1.02s\tremaining: 4.91s\n",
      "1719:\tlearn: 0.0020737\ttotal: 1.02s\tremaining: 4.91s\n",
      "1720:\tlearn: 0.0020649\ttotal: 1.02s\tremaining: 4.91s\n",
      "1721:\tlearn: 0.0020479\ttotal: 1.02s\tremaining: 4.91s\n",
      "1722:\tlearn: 0.0020346\ttotal: 1.02s\tremaining: 4.91s\n",
      "1723:\tlearn: 0.0020221\ttotal: 1.02s\tremaining: 4.91s\n",
      "1724:\tlearn: 0.0020161\ttotal: 1.02s\tremaining: 4.92s\n",
      "1725:\tlearn: 0.0020058\ttotal: 1.03s\tremaining: 4.92s\n",
      "1726:\tlearn: 0.0020037\ttotal: 1.03s\tremaining: 4.92s\n",
      "1727:\tlearn: 0.0019962\ttotal: 1.03s\tremaining: 4.92s\n",
      "1728:\tlearn: 0.0019942\ttotal: 1.03s\tremaining: 4.92s\n",
      "1729:\tlearn: 0.0019880\ttotal: 1.03s\tremaining: 4.92s\n",
      "1730:\tlearn: 0.0019862\ttotal: 1.03s\tremaining: 4.92s\n",
      "1731:\tlearn: 0.0019758\ttotal: 1.03s\tremaining: 4.91s\n",
      "1732:\tlearn: 0.0019675\ttotal: 1.03s\tremaining: 4.91s\n",
      "1733:\tlearn: 0.0019537\ttotal: 1.03s\tremaining: 4.91s\n",
      "1734:\tlearn: 0.0019413\ttotal: 1.03s\tremaining: 4.91s\n",
      "1735:\tlearn: 0.0019275\ttotal: 1.03s\tremaining: 4.91s\n",
      "1736:\tlearn: 0.0019137\ttotal: 1.03s\tremaining: 4.91s\n",
      "1737:\tlearn: 0.0019039\ttotal: 1.03s\tremaining: 4.91s\n",
      "1738:\tlearn: 0.0018902\ttotal: 1.03s\tremaining: 4.91s\n",
      "1739:\tlearn: 0.0018876\ttotal: 1.03s\tremaining: 4.91s\n",
      "1740:\tlearn: 0.0018760\ttotal: 1.03s\tremaining: 4.9s\n",
      "1741:\tlearn: 0.0018641\ttotal: 1.03s\tremaining: 4.9s\n",
      "1742:\tlearn: 0.0018621\ttotal: 1.03s\tremaining: 4.9s\n",
      "1743:\tlearn: 0.0018483\ttotal: 1.03s\tremaining: 4.9s\n",
      "1744:\tlearn: 0.0018469\ttotal: 1.04s\tremaining: 4.91s\n",
      "1745:\tlearn: 0.0018450\ttotal: 1.04s\tremaining: 4.91s\n",
      "1746:\tlearn: 0.0018318\ttotal: 1.04s\tremaining: 4.91s\n",
      "1747:\tlearn: 0.0018297\ttotal: 1.04s\tremaining: 4.91s\n",
      "1748:\tlearn: 0.0018221\ttotal: 1.04s\tremaining: 4.91s\n",
      "1749:\tlearn: 0.0018094\ttotal: 1.04s\tremaining: 4.91s\n",
      "1750:\tlearn: 0.0018046\ttotal: 1.04s\tremaining: 4.91s\n",
      "1751:\tlearn: 0.0017935\ttotal: 1.04s\tremaining: 4.91s\n",
      "1752:\tlearn: 0.0017816\ttotal: 1.04s\tremaining: 4.91s\n",
      "1753:\tlearn: 0.0017721\ttotal: 1.04s\tremaining: 4.91s\n",
      "1754:\tlearn: 0.0017602\ttotal: 1.04s\tremaining: 4.91s\n",
      "1755:\tlearn: 0.0017484\ttotal: 1.04s\tremaining: 4.9s\n",
      "1756:\tlearn: 0.0017355\ttotal: 1.04s\tremaining: 4.9s\n",
      "1757:\tlearn: 0.0017339\ttotal: 1.04s\tremaining: 4.9s\n",
      "1758:\tlearn: 0.0017233\ttotal: 1.04s\tremaining: 4.9s\n",
      "1759:\tlearn: 0.0017071\ttotal: 1.05s\tremaining: 4.9s\n",
      "1760:\tlearn: 0.0017019\ttotal: 1.05s\tremaining: 4.9s\n",
      "1761:\tlearn: 0.0016984\ttotal: 1.05s\tremaining: 4.9s\n",
      "1762:\tlearn: 0.0016818\ttotal: 1.05s\tremaining: 4.89s\n",
      "1763:\tlearn: 0.0016793\ttotal: 1.05s\tremaining: 4.89s\n",
      "1764:\tlearn: 0.0016671\ttotal: 1.05s\tremaining: 4.89s\n",
      "1765:\tlearn: 0.0016575\ttotal: 1.05s\tremaining: 4.89s\n",
      "1766:\tlearn: 0.0016481\ttotal: 1.05s\tremaining: 4.89s\n",
      "1767:\tlearn: 0.0016465\ttotal: 1.05s\tremaining: 4.9s\n",
      "1768:\tlearn: 0.0016362\ttotal: 1.05s\tremaining: 4.91s\n",
      "1769:\tlearn: 0.0016339\ttotal: 1.05s\tremaining: 4.91s\n",
      "1770:\tlearn: 0.0016257\ttotal: 1.05s\tremaining: 4.9s\n",
      "1771:\tlearn: 0.0016237\ttotal: 1.05s\tremaining: 4.9s\n",
      "1772:\tlearn: 0.0016172\ttotal: 1.06s\tremaining: 4.9s\n",
      "1773:\tlearn: 0.0016142\ttotal: 1.06s\tremaining: 4.9s\n",
      "1774:\tlearn: 0.0016118\ttotal: 1.06s\tremaining: 4.9s\n",
      "1775:\tlearn: 0.0016099\ttotal: 1.06s\tremaining: 4.9s\n",
      "1776:\tlearn: 0.0016016\ttotal: 1.06s\tremaining: 4.9s\n",
      "1777:\tlearn: 0.0015972\ttotal: 1.06s\tremaining: 4.9s\n",
      "1778:\tlearn: 0.0015867\ttotal: 1.06s\tremaining: 4.9s\n",
      "1779:\tlearn: 0.0015801\ttotal: 1.06s\tremaining: 4.89s\n",
      "1780:\tlearn: 0.0015779\ttotal: 1.06s\tremaining: 4.89s\n",
      "1781:\tlearn: 0.0015627\ttotal: 1.06s\tremaining: 4.89s\n",
      "1782:\tlearn: 0.0015489\ttotal: 1.06s\tremaining: 4.89s\n",
      "1783:\tlearn: 0.0015465\ttotal: 1.06s\tremaining: 4.89s\n",
      "1784:\tlearn: 0.0015328\ttotal: 1.06s\tremaining: 4.89s\n",
      "1785:\tlearn: 0.0015256\ttotal: 1.06s\tremaining: 4.89s\n",
      "1786:\tlearn: 0.0015167\ttotal: 1.06s\tremaining: 4.89s\n",
      "1787:\tlearn: 0.0015149\ttotal: 1.06s\tremaining: 4.89s\n",
      "1788:\tlearn: 0.0015117\ttotal: 1.07s\tremaining: 4.89s\n",
      "1789:\tlearn: 0.0015064\ttotal: 1.07s\tremaining: 4.89s\n",
      "1790:\tlearn: 0.0015035\ttotal: 1.07s\tremaining: 4.89s\n",
      "1791:\tlearn: 0.0014895\ttotal: 1.07s\tremaining: 4.89s\n",
      "1792:\tlearn: 0.0014773\ttotal: 1.07s\tremaining: 4.89s\n",
      "1793:\tlearn: 0.0014756\ttotal: 1.07s\tremaining: 4.89s\n",
      "1794:\tlearn: 0.0014737\ttotal: 1.07s\tremaining: 4.89s\n",
      "1795:\tlearn: 0.0014606\ttotal: 1.07s\tremaining: 4.89s\n",
      "1796:\tlearn: 0.0014590\ttotal: 1.07s\tremaining: 4.89s\n",
      "1797:\tlearn: 0.0014567\ttotal: 1.07s\tremaining: 4.89s\n",
      "1798:\tlearn: 0.0014550\ttotal: 1.07s\tremaining: 4.89s\n",
      "1799:\tlearn: 0.0014421\ttotal: 1.07s\tremaining: 4.89s\n",
      "1800:\tlearn: 0.0014406\ttotal: 1.07s\tremaining: 4.88s\n",
      "1801:\tlearn: 0.0014391\ttotal: 1.07s\tremaining: 4.88s\n",
      "1802:\tlearn: 0.0014377\ttotal: 1.07s\tremaining: 4.88s\n",
      "1803:\tlearn: 0.0014338\ttotal: 1.07s\tremaining: 4.88s\n",
      "1804:\tlearn: 0.0014300\ttotal: 1.07s\tremaining: 4.88s\n",
      "1805:\tlearn: 0.0014190\ttotal: 1.07s\tremaining: 4.88s\n",
      "1806:\tlearn: 0.0014170\ttotal: 1.07s\tremaining: 4.88s\n",
      "1807:\tlearn: 0.0014057\ttotal: 1.08s\tremaining: 4.88s\n",
      "1808:\tlearn: 0.0014038\ttotal: 1.08s\tremaining: 4.88s\n",
      "1809:\tlearn: 0.0014024\ttotal: 1.08s\tremaining: 4.87s\n",
      "1810:\tlearn: 0.0013959\ttotal: 1.08s\tremaining: 4.87s\n",
      "1811:\tlearn: 0.0013899\ttotal: 1.08s\tremaining: 4.88s\n",
      "1812:\tlearn: 0.0013810\ttotal: 1.08s\tremaining: 4.88s\n",
      "1813:\tlearn: 0.0013699\ttotal: 1.08s\tremaining: 4.88s\n",
      "1814:\tlearn: 0.0013650\ttotal: 1.08s\tremaining: 4.88s\n",
      "1815:\tlearn: 0.0013582\ttotal: 1.08s\tremaining: 4.88s\n",
      "1816:\tlearn: 0.0013523\ttotal: 1.08s\tremaining: 4.88s\n",
      "1817:\tlearn: 0.0013477\ttotal: 1.08s\tremaining: 4.88s\n",
      "1818:\tlearn: 0.0013405\ttotal: 1.08s\tremaining: 4.88s\n",
      "1819:\tlearn: 0.0013294\ttotal: 1.08s\tremaining: 4.88s\n",
      "1820:\tlearn: 0.0013215\ttotal: 1.08s\tremaining: 4.87s\n",
      "1821:\tlearn: 0.0013200\ttotal: 1.08s\tremaining: 4.87s\n",
      "1822:\tlearn: 0.0013152\ttotal: 1.09s\tremaining: 4.87s\n",
      "1823:\tlearn: 0.0013142\ttotal: 1.09s\tremaining: 4.87s\n",
      "1824:\tlearn: 0.0013127\ttotal: 1.09s\tremaining: 4.87s\n",
      "1825:\tlearn: 0.0013110\ttotal: 1.09s\tremaining: 4.87s\n",
      "1826:\tlearn: 0.0013100\ttotal: 1.09s\tremaining: 4.87s\n",
      "1827:\tlearn: 0.0013076\ttotal: 1.09s\tremaining: 4.87s\n",
      "1828:\tlearn: 0.0012948\ttotal: 1.09s\tremaining: 4.87s\n",
      "1829:\tlearn: 0.0012853\ttotal: 1.09s\tremaining: 4.87s\n",
      "1830:\tlearn: 0.0012799\ttotal: 1.09s\tremaining: 4.86s\n",
      "1831:\tlearn: 0.0012778\ttotal: 1.09s\tremaining: 4.86s\n",
      "1832:\tlearn: 0.0012700\ttotal: 1.09s\tremaining: 4.86s\n",
      "1833:\tlearn: 0.0012611\ttotal: 1.09s\tremaining: 4.86s\n",
      "1834:\tlearn: 0.0012580\ttotal: 1.09s\tremaining: 4.87s\n",
      "1835:\tlearn: 0.0012567\ttotal: 1.09s\tremaining: 4.87s\n",
      "1836:\tlearn: 0.0012550\ttotal: 1.1s\tremaining: 4.87s\n",
      "1837:\tlearn: 0.0012434\ttotal: 1.1s\tremaining: 4.87s\n",
      "1838:\tlearn: 0.0012349\ttotal: 1.1s\tremaining: 4.87s\n",
      "1839:\tlearn: 0.0012320\ttotal: 1.1s\tremaining: 4.87s\n",
      "1840:\tlearn: 0.0012259\ttotal: 1.1s\tremaining: 4.87s\n",
      "1841:\tlearn: 0.0012168\ttotal: 1.1s\tremaining: 4.87s\n",
      "1842:\tlearn: 0.0012090\ttotal: 1.1s\tremaining: 4.87s\n",
      "1843:\tlearn: 0.0012018\ttotal: 1.1s\tremaining: 4.86s\n",
      "1844:\tlearn: 0.0011955\ttotal: 1.1s\tremaining: 4.86s\n",
      "1845:\tlearn: 0.0011942\ttotal: 1.1s\tremaining: 4.86s\n",
      "1846:\tlearn: 0.0011932\ttotal: 1.1s\tremaining: 4.86s\n",
      "1847:\tlearn: 0.0011856\ttotal: 1.1s\tremaining: 4.86s\n",
      "1848:\tlearn: 0.0011746\ttotal: 1.1s\tremaining: 4.86s\n",
      "1849:\tlearn: 0.0011696\ttotal: 1.1s\tremaining: 4.86s\n",
      "1850:\tlearn: 0.0011615\ttotal: 1.1s\tremaining: 4.86s\n",
      "1851:\tlearn: 0.0011567\ttotal: 1.1s\tremaining: 4.85s\n",
      "1852:\tlearn: 0.0011548\ttotal: 1.1s\tremaining: 4.85s\n",
      "1853:\tlearn: 0.0011511\ttotal: 1.1s\tremaining: 4.85s\n",
      "1854:\tlearn: 0.0011498\ttotal: 1.1s\tremaining: 4.85s\n",
      "1855:\tlearn: 0.0011389\ttotal: 1.1s\tremaining: 4.85s\n",
      "1856:\tlearn: 0.0011342\ttotal: 1.1s\tremaining: 4.85s\n",
      "1857:\tlearn: 0.0011274\ttotal: 1.11s\tremaining: 4.85s\n",
      "1858:\tlearn: 0.0011197\ttotal: 1.11s\tremaining: 4.85s\n",
      "1859:\tlearn: 0.0011174\ttotal: 1.11s\tremaining: 4.85s\n",
      "1860:\tlearn: 0.0011108\ttotal: 1.11s\tremaining: 4.86s\n",
      "1861:\tlearn: 0.0011087\ttotal: 1.11s\tremaining: 4.85s\n",
      "1862:\tlearn: 0.0011017\ttotal: 1.11s\tremaining: 4.85s\n",
      "1863:\tlearn: 0.0010994\ttotal: 1.11s\tremaining: 4.85s\n",
      "1864:\tlearn: 0.0010954\ttotal: 1.11s\tremaining: 4.85s\n",
      "1865:\tlearn: 0.0010888\ttotal: 1.11s\tremaining: 4.85s\n",
      "1866:\tlearn: 0.0010878\ttotal: 1.11s\tremaining: 4.85s\n",
      "1867:\tlearn: 0.0010842\ttotal: 1.11s\tremaining: 4.85s\n",
      "1868:\tlearn: 0.0010808\ttotal: 1.11s\tremaining: 4.85s\n",
      "1869:\tlearn: 0.0010700\ttotal: 1.11s\tremaining: 4.85s\n",
      "1870:\tlearn: 0.0010685\ttotal: 1.11s\tremaining: 4.84s\n",
      "1871:\tlearn: 0.0010586\ttotal: 1.11s\tremaining: 4.84s\n",
      "1872:\tlearn: 0.0010513\ttotal: 1.12s\tremaining: 4.84s\n",
      "1873:\tlearn: 0.0010506\ttotal: 1.12s\tremaining: 4.84s\n",
      "1874:\tlearn: 0.0010494\ttotal: 1.12s\tremaining: 4.84s\n",
      "1875:\tlearn: 0.0010485\ttotal: 1.12s\tremaining: 4.84s\n",
      "1876:\tlearn: 0.0010398\ttotal: 1.12s\tremaining: 4.84s\n",
      "1877:\tlearn: 0.0010385\ttotal: 1.12s\tremaining: 4.84s\n",
      "1878:\tlearn: 0.0010326\ttotal: 1.12s\tremaining: 4.84s\n",
      "1879:\tlearn: 0.0010274\ttotal: 1.12s\tremaining: 4.83s\n",
      "1880:\tlearn: 0.0010225\ttotal: 1.12s\tremaining: 4.84s\n",
      "1881:\tlearn: 0.0010162\ttotal: 1.12s\tremaining: 4.84s\n",
      "1882:\tlearn: 0.0010129\ttotal: 1.12s\tremaining: 4.84s\n",
      "1883:\tlearn: 0.0010066\ttotal: 1.12s\tremaining: 4.84s\n",
      "1884:\tlearn: 0.0010025\ttotal: 1.12s\tremaining: 4.84s\n",
      "1885:\tlearn: 0.0009997\ttotal: 1.13s\tremaining: 4.84s\n",
      "1886:\tlearn: 0.0009923\ttotal: 1.13s\tremaining: 4.84s\n",
      "1887:\tlearn: 0.0009878\ttotal: 1.13s\tremaining: 4.84s\n",
      "1888:\tlearn: 0.0009845\ttotal: 1.13s\tremaining: 4.84s\n",
      "1889:\tlearn: 0.0009834\ttotal: 1.13s\tremaining: 4.84s\n",
      "1890:\tlearn: 0.0009739\ttotal: 1.13s\tremaining: 4.83s\n",
      "1891:\tlearn: 0.0009719\ttotal: 1.13s\tremaining: 4.83s\n",
      "1892:\tlearn: 0.0009662\ttotal: 1.13s\tremaining: 4.83s\n",
      "1893:\tlearn: 0.0009644\ttotal: 1.13s\tremaining: 4.83s\n",
      "1894:\tlearn: 0.0009599\ttotal: 1.13s\tremaining: 4.83s\n",
      "1895:\tlearn: 0.0009589\ttotal: 1.13s\tremaining: 4.83s\n",
      "1896:\tlearn: 0.0009521\ttotal: 1.13s\tremaining: 4.83s\n",
      "1897:\tlearn: 0.0009484\ttotal: 1.13s\tremaining: 4.83s\n",
      "1898:\tlearn: 0.0009459\ttotal: 1.13s\tremaining: 4.83s\n",
      "1899:\tlearn: 0.0009400\ttotal: 1.13s\tremaining: 4.83s\n",
      "1900:\tlearn: 0.0009336\ttotal: 1.13s\tremaining: 4.82s\n",
      "1901:\tlearn: 0.0009322\ttotal: 1.13s\tremaining: 4.82s\n",
      "1902:\tlearn: 0.0009236\ttotal: 1.13s\tremaining: 4.82s\n",
      "1903:\tlearn: 0.0009187\ttotal: 1.13s\tremaining: 4.82s\n",
      "1904:\tlearn: 0.0009137\ttotal: 1.13s\tremaining: 4.82s\n",
      "1905:\tlearn: 0.0009126\ttotal: 1.14s\tremaining: 4.82s\n",
      "1906:\tlearn: 0.0009120\ttotal: 1.14s\tremaining: 4.82s\n",
      "1907:\tlearn: 0.0009059\ttotal: 1.14s\tremaining: 4.83s\n",
      "1908:\tlearn: 0.0009044\ttotal: 1.14s\tremaining: 4.82s\n",
      "1909:\tlearn: 0.0009007\ttotal: 1.14s\tremaining: 4.82s\n",
      "1910:\tlearn: 0.0008988\ttotal: 1.14s\tremaining: 4.82s\n",
      "1911:\tlearn: 0.0008983\ttotal: 1.14s\tremaining: 4.82s\n",
      "1912:\tlearn: 0.0008868\ttotal: 1.14s\tremaining: 4.82s\n",
      "1913:\tlearn: 0.0008863\ttotal: 1.14s\tremaining: 4.82s\n",
      "1914:\tlearn: 0.0008804\ttotal: 1.14s\tremaining: 4.82s\n",
      "1915:\tlearn: 0.0008748\ttotal: 1.14s\tremaining: 4.82s\n",
      "1916:\tlearn: 0.0008703\ttotal: 1.14s\tremaining: 4.81s\n",
      "1917:\tlearn: 0.0008649\ttotal: 1.14s\tremaining: 4.81s\n",
      "1918:\tlearn: 0.0008559\ttotal: 1.14s\tremaining: 4.81s\n",
      "1919:\tlearn: 0.0008551\ttotal: 1.14s\tremaining: 4.81s\n",
      "1920:\tlearn: 0.0008478\ttotal: 1.14s\tremaining: 4.81s\n",
      "1921:\tlearn: 0.0008450\ttotal: 1.14s\tremaining: 4.81s\n",
      "1922:\tlearn: 0.0008434\ttotal: 1.14s\tremaining: 4.81s\n",
      "1923:\tlearn: 0.0008384\ttotal: 1.15s\tremaining: 4.81s\n",
      "1924:\tlearn: 0.0008373\ttotal: 1.15s\tremaining: 4.8s\n",
      "1925:\tlearn: 0.0008363\ttotal: 1.15s\tremaining: 4.8s\n",
      "1926:\tlearn: 0.0008354\ttotal: 1.15s\tremaining: 4.8s\n",
      "1927:\tlearn: 0.0008304\ttotal: 1.15s\tremaining: 4.8s\n",
      "1928:\tlearn: 0.0008282\ttotal: 1.15s\tremaining: 4.8s\n",
      "1929:\tlearn: 0.0008277\ttotal: 1.15s\tremaining: 4.8s\n",
      "1930:\tlearn: 0.0008268\ttotal: 1.15s\tremaining: 4.8s\n",
      "1931:\tlearn: 0.0008234\ttotal: 1.15s\tremaining: 4.8s\n",
      "1932:\tlearn: 0.0008169\ttotal: 1.15s\tremaining: 4.8s\n",
      "1933:\tlearn: 0.0008162\ttotal: 1.15s\tremaining: 4.8s\n",
      "1934:\tlearn: 0.0008093\ttotal: 1.15s\tremaining: 4.8s\n",
      "1935:\tlearn: 0.0008064\ttotal: 1.15s\tremaining: 4.8s\n",
      "1936:\tlearn: 0.0008020\ttotal: 1.15s\tremaining: 4.8s\n",
      "1937:\tlearn: 0.0007984\ttotal: 1.15s\tremaining: 4.8s\n",
      "1938:\tlearn: 0.0007968\ttotal: 1.15s\tremaining: 4.8s\n",
      "1939:\tlearn: 0.0007959\ttotal: 1.16s\tremaining: 4.8s\n",
      "1940:\tlearn: 0.0007899\ttotal: 1.16s\tremaining: 4.8s\n",
      "1941:\tlearn: 0.0007885\ttotal: 1.16s\tremaining: 4.8s\n",
      "1942:\tlearn: 0.0007869\ttotal: 1.16s\tremaining: 4.79s\n",
      "1943:\tlearn: 0.0007818\ttotal: 1.16s\tremaining: 4.79s\n",
      "1944:\tlearn: 0.0007811\ttotal: 1.16s\tremaining: 4.79s\n",
      "1945:\tlearn: 0.0007793\ttotal: 1.16s\tremaining: 4.79s\n",
      "1946:\tlearn: 0.0007747\ttotal: 1.16s\tremaining: 4.79s\n",
      "1947:\tlearn: 0.0007734\ttotal: 1.16s\tremaining: 4.79s\n",
      "1948:\tlearn: 0.0007677\ttotal: 1.16s\tremaining: 4.79s\n",
      "1949:\tlearn: 0.0007666\ttotal: 1.16s\tremaining: 4.79s\n",
      "1950:\tlearn: 0.0007596\ttotal: 1.16s\tremaining: 4.79s\n",
      "1951:\tlearn: 0.0007587\ttotal: 1.16s\tremaining: 4.78s\n",
      "1952:\tlearn: 0.0007560\ttotal: 1.16s\tremaining: 4.78s\n",
      "1953:\tlearn: 0.0007506\ttotal: 1.16s\tremaining: 4.78s\n",
      "1954:\tlearn: 0.0007446\ttotal: 1.16s\tremaining: 4.78s\n",
      "1955:\tlearn: 0.0007398\ttotal: 1.16s\tremaining: 4.78s\n",
      "1956:\tlearn: 0.0007307\ttotal: 1.16s\tremaining: 4.79s\n",
      "1957:\tlearn: 0.0007236\ttotal: 1.17s\tremaining: 4.79s\n",
      "1958:\tlearn: 0.0007225\ttotal: 1.17s\tremaining: 4.79s\n",
      "1959:\tlearn: 0.0007180\ttotal: 1.17s\tremaining: 4.79s\n",
      "1960:\tlearn: 0.0007171\ttotal: 1.17s\tremaining: 4.79s\n",
      "1961:\tlearn: 0.0007126\ttotal: 1.17s\tremaining: 4.79s\n",
      "1962:\tlearn: 0.0007088\ttotal: 1.17s\tremaining: 4.78s\n",
      "1963:\tlearn: 0.0007035\ttotal: 1.17s\tremaining: 4.78s\n",
      "1964:\tlearn: 0.0006994\ttotal: 1.17s\tremaining: 4.78s\n",
      "1965:\tlearn: 0.0006973\ttotal: 1.17s\tremaining: 4.78s\n",
      "1966:\tlearn: 0.0006967\ttotal: 1.17s\tremaining: 4.78s\n",
      "1967:\tlearn: 0.0006944\ttotal: 1.17s\tremaining: 4.78s\n",
      "1968:\tlearn: 0.0006896\ttotal: 1.17s\tremaining: 4.78s\n",
      "1969:\tlearn: 0.0006864\ttotal: 1.17s\tremaining: 4.78s\n",
      "1970:\tlearn: 0.0006824\ttotal: 1.17s\tremaining: 4.78s\n",
      "1971:\tlearn: 0.0006815\ttotal: 1.17s\tremaining: 4.78s\n",
      "1972:\tlearn: 0.0006778\ttotal: 1.17s\tremaining: 4.77s\n",
      "1973:\tlearn: 0.0006753\ttotal: 1.17s\tremaining: 4.77s\n",
      "1974:\tlearn: 0.0006719\ttotal: 1.17s\tremaining: 4.77s\n",
      "1975:\tlearn: 0.0006679\ttotal: 1.17s\tremaining: 4.77s\n",
      "1976:\tlearn: 0.0006613\ttotal: 1.18s\tremaining: 4.77s\n",
      "1977:\tlearn: 0.0006578\ttotal: 1.18s\tremaining: 4.77s\n",
      "1978:\tlearn: 0.0006533\ttotal: 1.18s\tremaining: 4.77s\n",
      "1979:\tlearn: 0.0006522\ttotal: 1.18s\tremaining: 4.77s\n",
      "1980:\tlearn: 0.0006515\ttotal: 1.18s\tremaining: 4.77s\n",
      "1981:\tlearn: 0.0006483\ttotal: 1.18s\tremaining: 4.77s\n",
      "1982:\tlearn: 0.0006454\ttotal: 1.18s\tremaining: 4.77s\n",
      "1983:\tlearn: 0.0006425\ttotal: 1.18s\tremaining: 4.77s\n",
      "1984:\tlearn: 0.0006385\ttotal: 1.18s\tremaining: 4.76s\n",
      "1985:\tlearn: 0.0006337\ttotal: 1.18s\tremaining: 4.76s\n",
      "1986:\tlearn: 0.0006323\ttotal: 1.18s\tremaining: 4.76s\n",
      "1987:\tlearn: 0.0006285\ttotal: 1.18s\tremaining: 4.76s\n",
      "1988:\tlearn: 0.0006270\ttotal: 1.18s\tremaining: 4.76s\n",
      "1989:\tlearn: 0.0006264\ttotal: 1.18s\tremaining: 4.76s\n",
      "1990:\tlearn: 0.0006239\ttotal: 1.18s\tremaining: 4.76s\n",
      "1991:\tlearn: 0.0006202\ttotal: 1.18s\tremaining: 4.76s\n",
      "1992:\tlearn: 0.0006189\ttotal: 1.18s\tremaining: 4.76s\n",
      "1993:\tlearn: 0.0006158\ttotal: 1.18s\tremaining: 4.75s\n",
      "1994:\tlearn: 0.0006123\ttotal: 1.18s\tremaining: 4.75s\n",
      "1995:\tlearn: 0.0006088\ttotal: 1.19s\tremaining: 4.75s\n",
      "1996:\tlearn: 0.0006051\ttotal: 1.19s\tremaining: 4.75s\n",
      "1997:\tlearn: 0.0006041\ttotal: 1.19s\tremaining: 4.75s\n",
      "1998:\tlearn: 0.0006015\ttotal: 1.19s\tremaining: 4.75s\n",
      "1999:\tlearn: 0.0005987\ttotal: 1.19s\tremaining: 4.75s\n",
      "2000:\tlearn: 0.0005974\ttotal: 1.19s\tremaining: 4.75s\n",
      "2001:\tlearn: 0.0005969\ttotal: 1.19s\tremaining: 4.75s\n",
      "2002:\tlearn: 0.0005962\ttotal: 1.19s\tremaining: 4.75s\n",
      "2003:\tlearn: 0.0005930\ttotal: 1.19s\tremaining: 4.75s\n",
      "2004:\tlearn: 0.0005924\ttotal: 1.19s\tremaining: 4.74s\n",
      "2005:\tlearn: 0.0005884\ttotal: 1.19s\tremaining: 4.74s\n",
      "2006:\tlearn: 0.0005825\ttotal: 1.19s\tremaining: 4.74s\n",
      "2007:\tlearn: 0.0005792\ttotal: 1.19s\tremaining: 4.74s\n",
      "2008:\tlearn: 0.0005776\ttotal: 1.19s\tremaining: 4.74s\n",
      "2009:\tlearn: 0.0005745\ttotal: 1.19s\tremaining: 4.74s\n",
      "2010:\tlearn: 0.0005737\ttotal: 1.19s\tremaining: 4.74s\n",
      "2011:\tlearn: 0.0005695\ttotal: 1.19s\tremaining: 4.74s\n",
      "2012:\tlearn: 0.0005665\ttotal: 1.19s\tremaining: 4.74s\n",
      "2013:\tlearn: 0.0005633\ttotal: 1.19s\tremaining: 4.74s\n",
      "2014:\tlearn: 0.0005598\ttotal: 1.2s\tremaining: 4.74s\n",
      "2015:\tlearn: 0.0005593\ttotal: 1.2s\tremaining: 4.73s\n",
      "2016:\tlearn: 0.0005587\ttotal: 1.2s\tremaining: 4.73s\n",
      "2017:\tlearn: 0.0005551\ttotal: 1.2s\tremaining: 4.73s\n",
      "2018:\tlearn: 0.0005528\ttotal: 1.2s\tremaining: 4.73s\n",
      "2019:\tlearn: 0.0005493\ttotal: 1.2s\tremaining: 4.73s\n",
      "2020:\tlearn: 0.0005465\ttotal: 1.2s\tremaining: 4.73s\n",
      "2021:\tlearn: 0.0005433\ttotal: 1.2s\tremaining: 4.73s\n",
      "2022:\tlearn: 0.0005421\ttotal: 1.2s\tremaining: 4.73s\n",
      "2023:\tlearn: 0.0005416\ttotal: 1.2s\tremaining: 4.72s\n",
      "2024:\tlearn: 0.0005411\ttotal: 1.2s\tremaining: 4.72s\n",
      "2025:\tlearn: 0.0005344\ttotal: 1.2s\tremaining: 4.72s\n",
      "2026:\tlearn: 0.0005321\ttotal: 1.2s\tremaining: 4.72s\n",
      "2027:\tlearn: 0.0005315\ttotal: 1.2s\tremaining: 4.72s\n",
      "2028:\tlearn: 0.0005283\ttotal: 1.2s\tremaining: 4.72s\n",
      "2029:\tlearn: 0.0005275\ttotal: 1.2s\tremaining: 4.72s\n",
      "2030:\tlearn: 0.0005273\ttotal: 1.2s\tremaining: 4.72s\n",
      "2031:\tlearn: 0.0005259\ttotal: 1.2s\tremaining: 4.71s\n",
      "2032:\tlearn: 0.0005248\ttotal: 1.2s\tremaining: 4.71s\n",
      "2033:\tlearn: 0.0005239\ttotal: 1.2s\tremaining: 4.71s\n",
      "2034:\tlearn: 0.0005231\ttotal: 1.2s\tremaining: 4.71s\n",
      "2035:\tlearn: 0.0005219\ttotal: 1.2s\tremaining: 4.71s\n",
      "2036:\tlearn: 0.0005180\ttotal: 1.2s\tremaining: 4.71s\n",
      "2037:\tlearn: 0.0005147\ttotal: 1.21s\tremaining: 4.71s\n",
      "2038:\tlearn: 0.0005122\ttotal: 1.21s\tremaining: 4.71s\n",
      "2039:\tlearn: 0.0005098\ttotal: 1.21s\tremaining: 4.71s\n",
      "2040:\tlearn: 0.0005076\ttotal: 1.21s\tremaining: 4.71s\n",
      "2041:\tlearn: 0.0005072\ttotal: 1.21s\tremaining: 4.71s\n",
      "2042:\tlearn: 0.0005067\ttotal: 1.21s\tremaining: 4.71s\n",
      "2043:\tlearn: 0.0005050\ttotal: 1.21s\tremaining: 4.71s\n",
      "2044:\tlearn: 0.0005045\ttotal: 1.21s\tremaining: 4.71s\n",
      "2045:\tlearn: 0.0005014\ttotal: 1.21s\tremaining: 4.71s\n",
      "2046:\tlearn: 0.0004967\ttotal: 1.21s\tremaining: 4.7s\n",
      "2047:\tlearn: 0.0004961\ttotal: 1.21s\tremaining: 4.7s\n",
      "2048:\tlearn: 0.0004949\ttotal: 1.21s\tremaining: 4.7s\n",
      "2049:\tlearn: 0.0004941\ttotal: 1.21s\tremaining: 4.7s\n",
      "2050:\tlearn: 0.0004934\ttotal: 1.21s\tremaining: 4.7s\n",
      "2051:\tlearn: 0.0004928\ttotal: 1.21s\tremaining: 4.7s\n",
      "2052:\tlearn: 0.0004868\ttotal: 1.21s\tremaining: 4.7s\n",
      "2053:\tlearn: 0.0004836\ttotal: 1.21s\tremaining: 4.7s\n",
      "2054:\tlearn: 0.0004827\ttotal: 1.21s\tremaining: 4.7s\n",
      "2055:\tlearn: 0.0004803\ttotal: 1.21s\tremaining: 4.69s\n",
      "2056:\tlearn: 0.0004783\ttotal: 1.22s\tremaining: 4.69s\n",
      "2057:\tlearn: 0.0004772\ttotal: 1.22s\tremaining: 4.69s\n",
      "2058:\tlearn: 0.0004729\ttotal: 1.22s\tremaining: 4.69s\n",
      "2059:\tlearn: 0.0004689\ttotal: 1.22s\tremaining: 4.69s\n",
      "2060:\tlearn: 0.0004668\ttotal: 1.22s\tremaining: 4.69s\n",
      "2061:\tlearn: 0.0004654\ttotal: 1.22s\tremaining: 4.69s\n",
      "2062:\tlearn: 0.0004624\ttotal: 1.22s\tremaining: 4.68s\n",
      "2063:\tlearn: 0.0004590\ttotal: 1.22s\tremaining: 4.68s\n",
      "2064:\tlearn: 0.0004552\ttotal: 1.22s\tremaining: 4.68s\n",
      "2065:\tlearn: 0.0004524\ttotal: 1.22s\tremaining: 4.68s\n",
      "2066:\tlearn: 0.0004491\ttotal: 1.22s\tremaining: 4.68s\n",
      "2067:\tlearn: 0.0004462\ttotal: 1.22s\tremaining: 4.68s\n",
      "2068:\tlearn: 0.0004441\ttotal: 1.22s\tremaining: 4.68s\n",
      "2069:\tlearn: 0.0004408\ttotal: 1.22s\tremaining: 4.68s\n",
      "2070:\tlearn: 0.0004405\ttotal: 1.22s\tremaining: 4.68s\n",
      "2071:\tlearn: 0.0004378\ttotal: 1.22s\tremaining: 4.68s\n",
      "2072:\tlearn: 0.0004374\ttotal: 1.22s\tremaining: 4.68s\n",
      "2073:\tlearn: 0.0004354\ttotal: 1.22s\tremaining: 4.68s\n",
      "2074:\tlearn: 0.0004347\ttotal: 1.22s\tremaining: 4.68s\n",
      "2075:\tlearn: 0.0004338\ttotal: 1.23s\tremaining: 4.68s\n",
      "2076:\tlearn: 0.0004326\ttotal: 1.23s\tremaining: 4.67s\n",
      "2077:\tlearn: 0.0004300\ttotal: 1.23s\tremaining: 4.67s\n",
      "2078:\tlearn: 0.0004295\ttotal: 1.23s\tremaining: 4.67s\n",
      "2079:\tlearn: 0.0004291\ttotal: 1.23s\tremaining: 4.67s\n",
      "2080:\tlearn: 0.0004283\ttotal: 1.23s\tremaining: 4.67s\n",
      "2081:\tlearn: 0.0004261\ttotal: 1.23s\tremaining: 4.67s\n",
      "2082:\tlearn: 0.0004255\ttotal: 1.23s\tremaining: 4.67s\n",
      "2083:\tlearn: 0.0004246\ttotal: 1.23s\tremaining: 4.67s\n",
      "2084:\tlearn: 0.0004240\ttotal: 1.23s\tremaining: 4.67s\n",
      "2085:\tlearn: 0.0004237\ttotal: 1.23s\tremaining: 4.67s\n",
      "2086:\tlearn: 0.0004232\ttotal: 1.23s\tremaining: 4.66s\n",
      "2087:\tlearn: 0.0004225\ttotal: 1.23s\tremaining: 4.66s\n",
      "2088:\tlearn: 0.0004204\ttotal: 1.23s\tremaining: 4.66s\n",
      "2089:\tlearn: 0.0004188\ttotal: 1.23s\tremaining: 4.66s\n",
      "2090:\tlearn: 0.0004182\ttotal: 1.23s\tremaining: 4.66s\n",
      "2091:\tlearn: 0.0004159\ttotal: 1.23s\tremaining: 4.66s\n",
      "2092:\tlearn: 0.0004128\ttotal: 1.23s\tremaining: 4.66s\n",
      "2093:\tlearn: 0.0004101\ttotal: 1.23s\tremaining: 4.66s\n",
      "2094:\tlearn: 0.0004076\ttotal: 1.24s\tremaining: 4.66s\n",
      "2095:\tlearn: 0.0004046\ttotal: 1.24s\tremaining: 4.66s\n",
      "2096:\tlearn: 0.0004042\ttotal: 1.24s\tremaining: 4.66s\n",
      "2097:\tlearn: 0.0004025\ttotal: 1.24s\tremaining: 4.66s\n",
      "2098:\tlearn: 0.0004022\ttotal: 1.24s\tremaining: 4.66s\n",
      "2099:\tlearn: 0.0003997\ttotal: 1.24s\tremaining: 4.66s\n",
      "2100:\tlearn: 0.0003975\ttotal: 1.24s\tremaining: 4.66s\n",
      "2101:\tlearn: 0.0003943\ttotal: 1.24s\tremaining: 4.65s\n",
      "2102:\tlearn: 0.0003923\ttotal: 1.24s\tremaining: 4.65s\n",
      "2103:\tlearn: 0.0003918\ttotal: 1.24s\tremaining: 4.65s\n",
      "2104:\tlearn: 0.0003904\ttotal: 1.24s\tremaining: 4.65s\n",
      "2105:\tlearn: 0.0003901\ttotal: 1.24s\tremaining: 4.65s\n",
      "2106:\tlearn: 0.0003890\ttotal: 1.24s\tremaining: 4.65s\n",
      "2107:\tlearn: 0.0003864\ttotal: 1.24s\tremaining: 4.65s\n",
      "2108:\tlearn: 0.0003860\ttotal: 1.24s\tremaining: 4.65s\n",
      "2109:\tlearn: 0.0003838\ttotal: 1.24s\tremaining: 4.64s\n",
      "2110:\tlearn: 0.0003836\ttotal: 1.24s\tremaining: 4.64s\n",
      "2111:\tlearn: 0.0003817\ttotal: 1.24s\tremaining: 4.64s\n",
      "2112:\tlearn: 0.0003812\ttotal: 1.24s\tremaining: 4.64s\n",
      "2113:\tlearn: 0.0003807\ttotal: 1.24s\tremaining: 4.64s\n",
      "2114:\tlearn: 0.0003786\ttotal: 1.24s\tremaining: 4.64s\n",
      "2115:\tlearn: 0.0003770\ttotal: 1.25s\tremaining: 4.64s\n",
      "2116:\tlearn: 0.0003760\ttotal: 1.25s\tremaining: 4.64s\n",
      "2117:\tlearn: 0.0003747\ttotal: 1.25s\tremaining: 4.64s\n",
      "2118:\tlearn: 0.0003745\ttotal: 1.25s\tremaining: 4.64s\n",
      "2119:\tlearn: 0.0003720\ttotal: 1.25s\tremaining: 4.63s\n",
      "2120:\tlearn: 0.0003698\ttotal: 1.25s\tremaining: 4.64s\n",
      "2121:\tlearn: 0.0003694\ttotal: 1.25s\tremaining: 4.64s\n",
      "2122:\tlearn: 0.0003672\ttotal: 1.25s\tremaining: 4.64s\n",
      "2123:\tlearn: 0.0003654\ttotal: 1.25s\tremaining: 4.64s\n",
      "2124:\tlearn: 0.0003646\ttotal: 1.25s\tremaining: 4.64s\n",
      "2125:\tlearn: 0.0003612\ttotal: 1.25s\tremaining: 4.64s\n",
      "2126:\tlearn: 0.0003590\ttotal: 1.25s\tremaining: 4.64s\n",
      "2127:\tlearn: 0.0003549\ttotal: 1.25s\tremaining: 4.63s\n",
      "2128:\tlearn: 0.0003539\ttotal: 1.25s\tremaining: 4.63s\n",
      "2129:\tlearn: 0.0003507\ttotal: 1.25s\tremaining: 4.63s\n",
      "2130:\tlearn: 0.0003480\ttotal: 1.25s\tremaining: 4.63s\n",
      "2131:\tlearn: 0.0003459\ttotal: 1.25s\tremaining: 4.63s\n",
      "2132:\tlearn: 0.0003438\ttotal: 1.26s\tremaining: 4.63s\n",
      "2133:\tlearn: 0.0003434\ttotal: 1.26s\tremaining: 4.63s\n",
      "2134:\tlearn: 0.0003399\ttotal: 1.26s\tremaining: 4.63s\n",
      "2135:\tlearn: 0.0003378\ttotal: 1.26s\tremaining: 4.63s\n",
      "2136:\tlearn: 0.0003343\ttotal: 1.26s\tremaining: 4.63s\n",
      "2137:\tlearn: 0.0003317\ttotal: 1.26s\tremaining: 4.63s\n",
      "2138:\tlearn: 0.0003300\ttotal: 1.26s\tremaining: 4.63s\n",
      "2139:\tlearn: 0.0003294\ttotal: 1.26s\tremaining: 4.63s\n",
      "2140:\tlearn: 0.0003290\ttotal: 1.26s\tremaining: 4.63s\n",
      "2141:\tlearn: 0.0003283\ttotal: 1.26s\tremaining: 4.63s\n",
      "2142:\tlearn: 0.0003266\ttotal: 1.26s\tremaining: 4.63s\n",
      "2143:\tlearn: 0.0003235\ttotal: 1.26s\tremaining: 4.64s\n",
      "2144:\tlearn: 0.0003216\ttotal: 1.26s\tremaining: 4.63s\n",
      "2145:\tlearn: 0.0003196\ttotal: 1.27s\tremaining: 4.63s\n",
      "2146:\tlearn: 0.0003182\ttotal: 1.27s\tremaining: 4.63s\n",
      "2147:\tlearn: 0.0003168\ttotal: 1.27s\tremaining: 4.63s\n",
      "2148:\tlearn: 0.0003165\ttotal: 1.27s\tremaining: 4.63s\n",
      "2149:\tlearn: 0.0003162\ttotal: 1.27s\tremaining: 4.63s\n",
      "2150:\tlearn: 0.0003150\ttotal: 1.27s\tremaining: 4.63s\n",
      "2151:\tlearn: 0.0003133\ttotal: 1.27s\tremaining: 4.63s\n",
      "2152:\tlearn: 0.0003107\ttotal: 1.27s\tremaining: 4.63s\n",
      "2153:\tlearn: 0.0003072\ttotal: 1.27s\tremaining: 4.63s\n",
      "2154:\tlearn: 0.0003066\ttotal: 1.27s\tremaining: 4.63s\n",
      "2155:\tlearn: 0.0003039\ttotal: 1.27s\tremaining: 4.63s\n",
      "2156:\tlearn: 0.0003032\ttotal: 1.27s\tremaining: 4.62s\n",
      "2157:\tlearn: 0.0003021\ttotal: 1.27s\tremaining: 4.62s\n",
      "2158:\tlearn: 0.0003001\ttotal: 1.27s\tremaining: 4.62s\n",
      "2159:\tlearn: 0.0002995\ttotal: 1.27s\tremaining: 4.62s\n",
      "2160:\tlearn: 0.0002986\ttotal: 1.27s\tremaining: 4.62s\n",
      "2161:\tlearn: 0.0002983\ttotal: 1.27s\tremaining: 4.62s\n",
      "2162:\tlearn: 0.0002981\ttotal: 1.27s\tremaining: 4.62s\n",
      "2163:\tlearn: 0.0002977\ttotal: 1.27s\tremaining: 4.62s\n",
      "2164:\tlearn: 0.0002974\ttotal: 1.28s\tremaining: 4.62s\n",
      "2165:\tlearn: 0.0002956\ttotal: 1.28s\tremaining: 4.62s\n",
      "2166:\tlearn: 0.0002946\ttotal: 1.28s\tremaining: 4.62s\n",
      "2167:\tlearn: 0.0002942\ttotal: 1.28s\tremaining: 4.62s\n",
      "2168:\tlearn: 0.0002926\ttotal: 1.28s\tremaining: 4.62s\n",
      "2169:\tlearn: 0.0002906\ttotal: 1.28s\tremaining: 4.62s\n",
      "2170:\tlearn: 0.0002894\ttotal: 1.28s\tremaining: 4.62s\n",
      "2171:\tlearn: 0.0002874\ttotal: 1.28s\tremaining: 4.62s\n",
      "2172:\tlearn: 0.0002855\ttotal: 1.28s\tremaining: 4.62s\n",
      "2173:\tlearn: 0.0002829\ttotal: 1.28s\tremaining: 4.62s\n",
      "2174:\tlearn: 0.0002811\ttotal: 1.28s\tremaining: 4.61s\n",
      "2175:\tlearn: 0.0002791\ttotal: 1.28s\tremaining: 4.61s\n",
      "2176:\tlearn: 0.0002785\ttotal: 1.28s\tremaining: 4.61s\n",
      "2177:\tlearn: 0.0002780\ttotal: 1.28s\tremaining: 4.61s\n",
      "2178:\tlearn: 0.0002769\ttotal: 1.28s\tremaining: 4.61s\n",
      "2179:\tlearn: 0.0002757\ttotal: 1.28s\tremaining: 4.61s\n",
      "2180:\tlearn: 0.0002738\ttotal: 1.28s\tremaining: 4.61s\n",
      "2181:\tlearn: 0.0002717\ttotal: 1.29s\tremaining: 4.61s\n",
      "2182:\tlearn: 0.0002712\ttotal: 1.29s\tremaining: 4.61s\n",
      "2183:\tlearn: 0.0002708\ttotal: 1.29s\tremaining: 4.61s\n",
      "2184:\tlearn: 0.0002702\ttotal: 1.29s\tremaining: 4.6s\n",
      "2185:\tlearn: 0.0002698\ttotal: 1.29s\tremaining: 4.6s\n",
      "2186:\tlearn: 0.0002681\ttotal: 1.29s\tremaining: 4.6s\n",
      "2187:\tlearn: 0.0002667\ttotal: 1.29s\tremaining: 4.6s\n",
      "2188:\tlearn: 0.0002664\ttotal: 1.29s\tremaining: 4.6s\n",
      "2189:\tlearn: 0.0002654\ttotal: 1.29s\tremaining: 4.6s\n",
      "2190:\tlearn: 0.0002638\ttotal: 1.29s\tremaining: 4.6s\n",
      "2191:\tlearn: 0.0002622\ttotal: 1.29s\tremaining: 4.6s\n",
      "2192:\tlearn: 0.0002613\ttotal: 1.29s\tremaining: 4.6s\n",
      "2193:\tlearn: 0.0002597\ttotal: 1.29s\tremaining: 4.6s\n",
      "2194:\tlearn: 0.0002592\ttotal: 1.29s\tremaining: 4.6s\n",
      "2195:\tlearn: 0.0002583\ttotal: 1.29s\tremaining: 4.6s\n",
      "2196:\tlearn: 0.0002570\ttotal: 1.29s\tremaining: 4.6s\n",
      "2197:\tlearn: 0.0002556\ttotal: 1.29s\tremaining: 4.6s\n",
      "2198:\tlearn: 0.0002543\ttotal: 1.29s\tremaining: 4.59s\n",
      "2199:\tlearn: 0.0002533\ttotal: 1.29s\tremaining: 4.59s\n",
      "2200:\tlearn: 0.0002516\ttotal: 1.3s\tremaining: 4.59s\n",
      "2201:\tlearn: 0.0002503\ttotal: 1.3s\tremaining: 4.59s\n",
      "2202:\tlearn: 0.0002500\ttotal: 1.3s\tremaining: 4.59s\n",
      "2203:\tlearn: 0.0002493\ttotal: 1.3s\tremaining: 4.59s\n",
      "2204:\tlearn: 0.0002477\ttotal: 1.3s\tremaining: 4.59s\n",
      "2205:\tlearn: 0.0002462\ttotal: 1.3s\tremaining: 4.59s\n",
      "2206:\tlearn: 0.0002449\ttotal: 1.3s\tremaining: 4.59s\n",
      "2207:\tlearn: 0.0002433\ttotal: 1.3s\tremaining: 4.59s\n",
      "2208:\tlearn: 0.0002425\ttotal: 1.3s\tremaining: 4.58s\n",
      "2209:\tlearn: 0.0002423\ttotal: 1.3s\tremaining: 4.58s\n",
      "2210:\tlearn: 0.0002413\ttotal: 1.3s\tremaining: 4.58s\n",
      "2211:\tlearn: 0.0002410\ttotal: 1.3s\tremaining: 4.58s\n",
      "2212:\tlearn: 0.0002401\ttotal: 1.3s\tremaining: 4.58s\n",
      "2213:\tlearn: 0.0002388\ttotal: 1.3s\tremaining: 4.58s\n",
      "2214:\tlearn: 0.0002374\ttotal: 1.3s\tremaining: 4.58s\n",
      "2215:\tlearn: 0.0002360\ttotal: 1.3s\tremaining: 4.58s\n",
      "2216:\tlearn: 0.0002357\ttotal: 1.3s\tremaining: 4.58s\n",
      "2217:\tlearn: 0.0002352\ttotal: 1.3s\tremaining: 4.58s\n",
      "2218:\tlearn: 0.0002338\ttotal: 1.3s\tremaining: 4.58s\n",
      "2219:\tlearn: 0.0002321\ttotal: 1.31s\tremaining: 4.58s\n",
      "2220:\tlearn: 0.0002316\ttotal: 1.31s\tremaining: 4.58s\n",
      "2221:\tlearn: 0.0002313\ttotal: 1.31s\tremaining: 4.58s\n",
      "2222:\tlearn: 0.0002304\ttotal: 1.31s\tremaining: 4.57s\n",
      "2223:\tlearn: 0.0002301\ttotal: 1.31s\tremaining: 4.57s\n",
      "2224:\tlearn: 0.0002299\ttotal: 1.31s\tremaining: 4.57s\n",
      "2225:\tlearn: 0.0002285\ttotal: 1.31s\tremaining: 4.57s\n",
      "2226:\tlearn: 0.0002270\ttotal: 1.31s\tremaining: 4.57s\n",
      "2227:\tlearn: 0.0002257\ttotal: 1.31s\tremaining: 4.57s\n",
      "2228:\tlearn: 0.0002245\ttotal: 1.31s\tremaining: 4.57s\n",
      "2229:\tlearn: 0.0002232\ttotal: 1.31s\tremaining: 4.57s\n",
      "2230:\tlearn: 0.0002222\ttotal: 1.31s\tremaining: 4.57s\n",
      "2231:\tlearn: 0.0002212\ttotal: 1.31s\tremaining: 4.56s\n",
      "2232:\tlearn: 0.0002208\ttotal: 1.31s\tremaining: 4.56s\n",
      "2233:\tlearn: 0.0002197\ttotal: 1.31s\tremaining: 4.56s\n",
      "2234:\tlearn: 0.0002195\ttotal: 1.31s\tremaining: 4.56s\n",
      "2235:\tlearn: 0.0002178\ttotal: 1.31s\tremaining: 4.56s\n",
      "2236:\tlearn: 0.0002176\ttotal: 1.31s\tremaining: 4.56s\n",
      "2237:\tlearn: 0.0002161\ttotal: 1.31s\tremaining: 4.56s\n",
      "2238:\tlearn: 0.0002158\ttotal: 1.31s\tremaining: 4.56s\n",
      "2239:\tlearn: 0.0002156\ttotal: 1.31s\tremaining: 4.55s\n",
      "2240:\tlearn: 0.0002144\ttotal: 1.31s\tremaining: 4.55s\n",
      "2241:\tlearn: 0.0002132\ttotal: 1.31s\tremaining: 4.55s\n",
      "2242:\tlearn: 0.0002129\ttotal: 1.32s\tremaining: 4.55s\n",
      "2243:\tlearn: 0.0002125\ttotal: 1.32s\tremaining: 4.55s\n",
      "2244:\tlearn: 0.0002111\ttotal: 1.32s\tremaining: 4.55s\n",
      "2245:\tlearn: 0.0002110\ttotal: 1.32s\tremaining: 4.55s\n",
      "2246:\tlearn: 0.0002097\ttotal: 1.32s\tremaining: 4.55s\n",
      "2247:\tlearn: 0.0002084\ttotal: 1.32s\tremaining: 4.55s\n",
      "2248:\tlearn: 0.0002070\ttotal: 1.32s\tremaining: 4.55s\n",
      "2249:\tlearn: 0.0002062\ttotal: 1.32s\tremaining: 4.55s\n",
      "2250:\tlearn: 0.0002050\ttotal: 1.32s\tremaining: 4.55s\n",
      "2251:\tlearn: 0.0002041\ttotal: 1.32s\tremaining: 4.55s\n",
      "2252:\tlearn: 0.0002030\ttotal: 1.32s\tremaining: 4.55s\n",
      "2253:\tlearn: 0.0002028\ttotal: 1.32s\tremaining: 4.55s\n",
      "2254:\tlearn: 0.0002015\ttotal: 1.32s\tremaining: 4.55s\n",
      "2255:\tlearn: 0.0002007\ttotal: 1.32s\tremaining: 4.55s\n",
      "2256:\tlearn: 0.0001997\ttotal: 1.32s\tremaining: 4.54s\n",
      "2257:\tlearn: 0.0001996\ttotal: 1.32s\tremaining: 4.54s\n",
      "2258:\tlearn: 0.0001985\ttotal: 1.32s\tremaining: 4.54s\n",
      "2259:\tlearn: 0.0001975\ttotal: 1.33s\tremaining: 4.54s\n",
      "2260:\tlearn: 0.0001964\ttotal: 1.33s\tremaining: 4.54s\n",
      "2261:\tlearn: 0.0001951\ttotal: 1.33s\tremaining: 4.54s\n",
      "2262:\tlearn: 0.0001943\ttotal: 1.33s\tremaining: 4.54s\n",
      "2263:\tlearn: 0.0001930\ttotal: 1.33s\tremaining: 4.54s\n",
      "2264:\tlearn: 0.0001922\ttotal: 1.33s\tremaining: 4.54s\n",
      "2265:\tlearn: 0.0001919\ttotal: 1.33s\tremaining: 4.54s\n",
      "2266:\tlearn: 0.0001910\ttotal: 1.33s\tremaining: 4.54s\n",
      "2267:\tlearn: 0.0001906\ttotal: 1.33s\tremaining: 4.53s\n",
      "2268:\tlearn: 0.0001897\ttotal: 1.33s\tremaining: 4.53s\n",
      "2269:\tlearn: 0.0001895\ttotal: 1.33s\tremaining: 4.53s\n",
      "2270:\tlearn: 0.0001888\ttotal: 1.33s\tremaining: 4.53s\n",
      "2271:\tlearn: 0.0001881\ttotal: 1.33s\tremaining: 4.53s\n",
      "2272:\tlearn: 0.0001873\ttotal: 1.33s\tremaining: 4.53s\n",
      "2273:\tlearn: 0.0001863\ttotal: 1.33s\tremaining: 4.53s\n",
      "2274:\tlearn: 0.0001862\ttotal: 1.33s\tremaining: 4.53s\n",
      "2275:\tlearn: 0.0001852\ttotal: 1.33s\tremaining: 4.53s\n",
      "2276:\tlearn: 0.0001842\ttotal: 1.33s\tremaining: 4.53s\n",
      "2277:\tlearn: 0.0001839\ttotal: 1.33s\tremaining: 4.53s\n",
      "2278:\tlearn: 0.0001834\ttotal: 1.33s\tremaining: 4.53s\n",
      "2279:\tlearn: 0.0001831\ttotal: 1.34s\tremaining: 4.52s\n",
      "2280:\tlearn: 0.0001819\ttotal: 1.34s\tremaining: 4.52s\n",
      "2281:\tlearn: 0.0001805\ttotal: 1.34s\tremaining: 4.52s\n",
      "2282:\tlearn: 0.0001795\ttotal: 1.34s\tremaining: 4.52s\n",
      "2283:\tlearn: 0.0001787\ttotal: 1.34s\tremaining: 4.52s\n",
      "2284:\tlearn: 0.0001771\ttotal: 1.34s\tremaining: 4.52s\n",
      "2285:\tlearn: 0.0001760\ttotal: 1.34s\tremaining: 4.52s\n",
      "2286:\tlearn: 0.0001756\ttotal: 1.34s\tremaining: 4.52s\n",
      "2287:\tlearn: 0.0001754\ttotal: 1.34s\tremaining: 4.52s\n",
      "2288:\tlearn: 0.0001742\ttotal: 1.34s\tremaining: 4.52s\n",
      "2289:\tlearn: 0.0001738\ttotal: 1.34s\tremaining: 4.51s\n",
      "2290:\tlearn: 0.0001734\ttotal: 1.34s\tremaining: 4.51s\n",
      "2291:\tlearn: 0.0001724\ttotal: 1.34s\tremaining: 4.51s\n",
      "2292:\tlearn: 0.0001722\ttotal: 1.34s\tremaining: 4.51s\n",
      "2293:\tlearn: 0.0001719\ttotal: 1.34s\tremaining: 4.51s\n",
      "2294:\tlearn: 0.0001718\ttotal: 1.34s\tremaining: 4.51s\n",
      "2295:\tlearn: 0.0001707\ttotal: 1.34s\tremaining: 4.51s\n",
      "2296:\tlearn: 0.0001694\ttotal: 1.34s\tremaining: 4.51s\n",
      "2297:\tlearn: 0.0001685\ttotal: 1.34s\tremaining: 4.51s\n",
      "2298:\tlearn: 0.0001683\ttotal: 1.34s\tremaining: 4.5s\n",
      "2299:\tlearn: 0.0001670\ttotal: 1.34s\tremaining: 4.5s\n",
      "2300:\tlearn: 0.0001663\ttotal: 1.35s\tremaining: 4.5s\n",
      "2301:\tlearn: 0.0001653\ttotal: 1.35s\tremaining: 4.5s\n",
      "2302:\tlearn: 0.0001644\ttotal: 1.35s\tremaining: 4.5s\n",
      "2303:\tlearn: 0.0001643\ttotal: 1.35s\tremaining: 4.5s\n",
      "2304:\tlearn: 0.0001641\ttotal: 1.35s\tremaining: 4.5s\n",
      "2305:\tlearn: 0.0001636\ttotal: 1.35s\tremaining: 4.5s\n",
      "2306:\tlearn: 0.0001626\ttotal: 1.35s\tremaining: 4.5s\n",
      "2307:\tlearn: 0.0001618\ttotal: 1.35s\tremaining: 4.5s\n",
      "2308:\tlearn: 0.0001617\ttotal: 1.35s\tremaining: 4.5s\n",
      "2309:\tlearn: 0.0001606\ttotal: 1.35s\tremaining: 4.5s\n",
      "2310:\tlearn: 0.0001598\ttotal: 1.35s\tremaining: 4.5s\n",
      "2311:\tlearn: 0.0001591\ttotal: 1.35s\tremaining: 4.5s\n",
      "2312:\tlearn: 0.0001583\ttotal: 1.35s\tremaining: 4.5s\n",
      "2313:\tlearn: 0.0001581\ttotal: 1.35s\tremaining: 4.49s\n",
      "2314:\tlearn: 0.0001578\ttotal: 1.35s\tremaining: 4.49s\n",
      "2315:\tlearn: 0.0001566\ttotal: 1.35s\tremaining: 4.49s\n",
      "2316:\tlearn: 0.0001560\ttotal: 1.35s\tremaining: 4.49s\n",
      "2317:\tlearn: 0.0001554\ttotal: 1.35s\tremaining: 4.49s\n",
      "2318:\tlearn: 0.0001553\ttotal: 1.35s\tremaining: 4.49s\n",
      "2319:\tlearn: 0.0001546\ttotal: 1.35s\tremaining: 4.49s\n",
      "2320:\tlearn: 0.0001538\ttotal: 1.36s\tremaining: 4.49s\n",
      "2321:\tlearn: 0.0001532\ttotal: 1.36s\tremaining: 4.49s\n",
      "2322:\tlearn: 0.0001531\ttotal: 1.36s\tremaining: 4.49s\n",
      "2323:\tlearn: 0.0001526\ttotal: 1.36s\tremaining: 4.48s\n",
      "2324:\tlearn: 0.0001513\ttotal: 1.36s\tremaining: 4.48s\n",
      "2325:\tlearn: 0.0001511\ttotal: 1.36s\tremaining: 4.48s\n",
      "2326:\tlearn: 0.0001509\ttotal: 1.36s\tremaining: 4.48s\n",
      "2327:\tlearn: 0.0001502\ttotal: 1.36s\tremaining: 4.48s\n",
      "2328:\tlearn: 0.0001491\ttotal: 1.36s\tremaining: 4.48s\n",
      "2329:\tlearn: 0.0001482\ttotal: 1.36s\tremaining: 4.48s\n",
      "2330:\tlearn: 0.0001478\ttotal: 1.36s\tremaining: 4.48s\n",
      "2331:\tlearn: 0.0001470\ttotal: 1.36s\tremaining: 4.48s\n",
      "2332:\tlearn: 0.0001458\ttotal: 1.36s\tremaining: 4.48s\n",
      "2333:\tlearn: 0.0001451\ttotal: 1.36s\tremaining: 4.48s\n",
      "2334:\tlearn: 0.0001445\ttotal: 1.36s\tremaining: 4.47s\n",
      "2335:\tlearn: 0.0001435\ttotal: 1.36s\tremaining: 4.47s\n",
      "2336:\tlearn: 0.0001431\ttotal: 1.36s\tremaining: 4.47s\n",
      "2337:\tlearn: 0.0001429\ttotal: 1.36s\tremaining: 4.47s\n",
      "2338:\tlearn: 0.0001416\ttotal: 1.36s\tremaining: 4.47s\n",
      "2339:\tlearn: 0.0001414\ttotal: 1.36s\tremaining: 4.47s\n",
      "2340:\tlearn: 0.0001413\ttotal: 1.37s\tremaining: 4.47s\n",
      "2341:\tlearn: 0.0001405\ttotal: 1.37s\tremaining: 4.47s\n",
      "2342:\tlearn: 0.0001399\ttotal: 1.37s\tremaining: 4.47s\n",
      "2343:\tlearn: 0.0001385\ttotal: 1.37s\tremaining: 4.47s\n",
      "2344:\tlearn: 0.0001381\ttotal: 1.37s\tremaining: 4.46s\n",
      "2345:\tlearn: 0.0001377\ttotal: 1.37s\tremaining: 4.46s\n",
      "2346:\tlearn: 0.0001369\ttotal: 1.37s\tremaining: 4.46s\n",
      "2347:\tlearn: 0.0001359\ttotal: 1.37s\tremaining: 4.46s\n",
      "2348:\tlearn: 0.0001358\ttotal: 1.37s\tremaining: 4.46s\n",
      "2349:\tlearn: 0.0001345\ttotal: 1.37s\tremaining: 4.46s\n",
      "2350:\tlearn: 0.0001337\ttotal: 1.37s\tremaining: 4.46s\n",
      "2351:\tlearn: 0.0001329\ttotal: 1.37s\tremaining: 4.46s\n",
      "2352:\tlearn: 0.0001324\ttotal: 1.37s\tremaining: 4.46s\n",
      "2353:\tlearn: 0.0001317\ttotal: 1.37s\tremaining: 4.46s\n",
      "2354:\tlearn: 0.0001311\ttotal: 1.37s\tremaining: 4.46s\n",
      "2355:\tlearn: 0.0001306\ttotal: 1.37s\tremaining: 4.45s\n",
      "2356:\tlearn: 0.0001301\ttotal: 1.37s\tremaining: 4.45s\n",
      "2357:\tlearn: 0.0001296\ttotal: 1.37s\tremaining: 4.45s\n",
      "2358:\tlearn: 0.0001294\ttotal: 1.37s\tremaining: 4.45s\n",
      "2359:\tlearn: 0.0001293\ttotal: 1.38s\tremaining: 4.45s\n",
      "2360:\tlearn: 0.0001284\ttotal: 1.38s\tremaining: 4.45s\n",
      "2361:\tlearn: 0.0001282\ttotal: 1.38s\tremaining: 4.45s\n",
      "2362:\tlearn: 0.0001271\ttotal: 1.38s\tremaining: 4.45s\n",
      "2363:\tlearn: 0.0001266\ttotal: 1.38s\tremaining: 4.45s\n",
      "2364:\tlearn: 0.0001258\ttotal: 1.38s\tremaining: 4.45s\n",
      "2365:\tlearn: 0.0001257\ttotal: 1.38s\tremaining: 4.45s\n",
      "2366:\tlearn: 0.0001248\ttotal: 1.38s\tremaining: 4.45s\n",
      "2367:\tlearn: 0.0001244\ttotal: 1.38s\tremaining: 4.45s\n",
      "2368:\tlearn: 0.0001237\ttotal: 1.38s\tremaining: 4.44s\n",
      "2369:\tlearn: 0.0001229\ttotal: 1.38s\tremaining: 4.44s\n",
      "2370:\tlearn: 0.0001218\ttotal: 1.38s\tremaining: 4.44s\n",
      "2371:\tlearn: 0.0001210\ttotal: 1.38s\tremaining: 4.44s\n",
      "2372:\tlearn: 0.0001209\ttotal: 1.38s\tremaining: 4.44s\n",
      "2373:\tlearn: 0.0001207\ttotal: 1.38s\tremaining: 4.44s\n",
      "2374:\tlearn: 0.0001198\ttotal: 1.38s\tremaining: 4.44s\n",
      "2375:\tlearn: 0.0001197\ttotal: 1.38s\tremaining: 4.44s\n",
      "2376:\tlearn: 0.0001195\ttotal: 1.38s\tremaining: 4.44s\n",
      "2377:\tlearn: 0.0001193\ttotal: 1.38s\tremaining: 4.43s\n",
      "2378:\tlearn: 0.0001189\ttotal: 1.38s\tremaining: 4.43s\n",
      "2379:\tlearn: 0.0001182\ttotal: 1.38s\tremaining: 4.43s\n",
      "2380:\tlearn: 0.0001175\ttotal: 1.39s\tremaining: 4.43s\n",
      "2381:\tlearn: 0.0001173\ttotal: 1.39s\tremaining: 4.43s\n",
      "2382:\tlearn: 0.0001167\ttotal: 1.39s\tremaining: 4.43s\n",
      "2383:\tlearn: 0.0001165\ttotal: 1.39s\tremaining: 4.43s\n",
      "2384:\tlearn: 0.0001158\ttotal: 1.39s\tremaining: 4.43s\n",
      "2385:\tlearn: 0.0001151\ttotal: 1.39s\tremaining: 4.43s\n",
      "2386:\tlearn: 0.0001141\ttotal: 1.39s\tremaining: 4.43s\n",
      "2387:\tlearn: 0.0001139\ttotal: 1.39s\tremaining: 4.43s\n",
      "2388:\tlearn: 0.0001137\ttotal: 1.39s\tremaining: 4.43s\n",
      "2389:\tlearn: 0.0001128\ttotal: 1.39s\tremaining: 4.43s\n",
      "2390:\tlearn: 0.0001127\ttotal: 1.39s\tremaining: 4.42s\n",
      "2391:\tlearn: 0.0001116\ttotal: 1.39s\tremaining: 4.42s\n",
      "2392:\tlearn: 0.0001111\ttotal: 1.39s\tremaining: 4.42s\n",
      "2393:\tlearn: 0.0001110\ttotal: 1.39s\tremaining: 4.42s\n",
      "2394:\tlearn: 0.0001103\ttotal: 1.39s\tremaining: 4.42s\n",
      "2395:\tlearn: 0.0001102\ttotal: 1.39s\tremaining: 4.42s\n",
      "2396:\tlearn: 0.0001091\ttotal: 1.39s\tremaining: 4.42s\n",
      "2397:\tlearn: 0.0001083\ttotal: 1.39s\tremaining: 4.42s\n",
      "2398:\tlearn: 0.0001079\ttotal: 1.39s\tremaining: 4.42s\n",
      "2399:\tlearn: 0.0001077\ttotal: 1.39s\tremaining: 4.42s\n",
      "2400:\tlearn: 0.0001071\ttotal: 1.4s\tremaining: 4.42s\n",
      "2401:\tlearn: 0.0001069\ttotal: 1.4s\tremaining: 4.41s\n",
      "2402:\tlearn: 0.0001061\ttotal: 1.4s\tremaining: 4.41s\n",
      "2403:\tlearn: 0.0001059\ttotal: 1.4s\tremaining: 4.41s\n",
      "2404:\tlearn: 0.0001052\ttotal: 1.4s\tremaining: 4.41s\n",
      "2405:\tlearn: 0.0001048\ttotal: 1.4s\tremaining: 4.41s\n",
      "2406:\tlearn: 0.0001043\ttotal: 1.4s\tremaining: 4.41s\n",
      "2407:\tlearn: 0.0001042\ttotal: 1.4s\tremaining: 4.41s\n",
      "2408:\tlearn: 0.0001040\ttotal: 1.4s\tremaining: 4.41s\n",
      "2409:\tlearn: 0.0001036\ttotal: 1.4s\tremaining: 4.41s\n",
      "2410:\tlearn: 0.0001031\ttotal: 1.4s\tremaining: 4.41s\n",
      "2411:\tlearn: 0.0001025\ttotal: 1.4s\tremaining: 4.4s\n",
      "2412:\tlearn: 0.0001020\ttotal: 1.4s\tremaining: 4.4s\n",
      "2413:\tlearn: 0.0001018\ttotal: 1.4s\tremaining: 4.4s\n",
      "2414:\tlearn: 0.0001016\ttotal: 1.4s\tremaining: 4.4s\n",
      "2415:\tlearn: 0.0001011\ttotal: 1.4s\tremaining: 4.4s\n",
      "2416:\tlearn: 0.0001003\ttotal: 1.4s\tremaining: 4.4s\n",
      "2417:\tlearn: 0.0000996\ttotal: 1.4s\tremaining: 4.4s\n",
      "2418:\tlearn: 0.0000995\ttotal: 1.4s\tremaining: 4.4s\n",
      "2419:\tlearn: 0.0000994\ttotal: 1.4s\tremaining: 4.4s\n",
      "2420:\tlearn: 0.0000993\ttotal: 1.4s\tremaining: 4.4s\n",
      "2421:\tlearn: 0.0000987\ttotal: 1.41s\tremaining: 4.4s\n",
      "2422:\tlearn: 0.0000986\ttotal: 1.41s\tremaining: 4.4s\n",
      "2423:\tlearn: 0.0000980\ttotal: 1.41s\tremaining: 4.39s\n",
      "2424:\tlearn: 0.0000979\ttotal: 1.41s\tremaining: 4.39s\n",
      "2425:\tlearn: 0.0000974\ttotal: 1.41s\tremaining: 4.39s\n",
      "2426:\tlearn: 0.0000970\ttotal: 1.41s\tremaining: 4.39s\n",
      "2427:\tlearn: 0.0000963\ttotal: 1.41s\tremaining: 4.39s\n",
      "2428:\tlearn: 0.0000959\ttotal: 1.41s\tremaining: 4.39s\n",
      "2429:\tlearn: 0.0000954\ttotal: 1.41s\tremaining: 4.39s\n",
      "2430:\tlearn: 0.0000948\ttotal: 1.41s\tremaining: 4.39s\n",
      "2431:\tlearn: 0.0000947\ttotal: 1.41s\tremaining: 4.39s\n",
      "2432:\tlearn: 0.0000940\ttotal: 1.41s\tremaining: 4.39s\n",
      "2433:\tlearn: 0.0000937\ttotal: 1.41s\tremaining: 4.38s\n",
      "2434:\tlearn: 0.0000930\ttotal: 1.41s\tremaining: 4.38s\n",
      "2435:\tlearn: 0.0000927\ttotal: 1.41s\tremaining: 4.38s\n",
      "2436:\tlearn: 0.0000922\ttotal: 1.41s\tremaining: 4.38s\n",
      "2437:\tlearn: 0.0000915\ttotal: 1.41s\tremaining: 4.38s\n",
      "2438:\tlearn: 0.0000914\ttotal: 1.41s\tremaining: 4.38s\n",
      "2439:\tlearn: 0.0000909\ttotal: 1.41s\tremaining: 4.38s\n",
      "2440:\tlearn: 0.0000905\ttotal: 1.41s\tremaining: 4.38s\n",
      "2441:\tlearn: 0.0000903\ttotal: 1.42s\tremaining: 4.38s\n",
      "2442:\tlearn: 0.0000902\ttotal: 1.42s\tremaining: 4.38s\n",
      "2443:\tlearn: 0.0000899\ttotal: 1.42s\tremaining: 4.38s\n",
      "2444:\tlearn: 0.0000892\ttotal: 1.42s\tremaining: 4.38s\n",
      "2445:\tlearn: 0.0000887\ttotal: 1.42s\tremaining: 4.38s\n",
      "2446:\tlearn: 0.0000878\ttotal: 1.42s\tremaining: 4.38s\n",
      "2447:\tlearn: 0.0000878\ttotal: 1.42s\tremaining: 4.38s\n",
      "2448:\tlearn: 0.0000877\ttotal: 1.42s\tremaining: 4.38s\n",
      "2449:\tlearn: 0.0000872\ttotal: 1.42s\tremaining: 4.37s\n",
      "2450:\tlearn: 0.0000866\ttotal: 1.42s\tremaining: 4.37s\n",
      "2451:\tlearn: 0.0000865\ttotal: 1.42s\tremaining: 4.37s\n",
      "2452:\tlearn: 0.0000859\ttotal: 1.42s\tremaining: 4.37s\n",
      "2453:\tlearn: 0.0000852\ttotal: 1.42s\tremaining: 4.37s\n",
      "2454:\tlearn: 0.0000851\ttotal: 1.42s\tremaining: 4.37s\n",
      "2455:\tlearn: 0.0000848\ttotal: 1.42s\tremaining: 4.37s\n",
      "2456:\tlearn: 0.0000844\ttotal: 1.42s\tremaining: 4.37s\n",
      "2457:\tlearn: 0.0000843\ttotal: 1.42s\tremaining: 4.37s\n",
      "2458:\tlearn: 0.0000843\ttotal: 1.42s\tremaining: 4.37s\n",
      "2459:\tlearn: 0.0000837\ttotal: 1.42s\tremaining: 4.37s\n",
      "2460:\tlearn: 0.0000831\ttotal: 1.43s\tremaining: 4.37s\n",
      "2461:\tlearn: 0.0000827\ttotal: 1.43s\tremaining: 4.36s\n",
      "2462:\tlearn: 0.0000820\ttotal: 1.43s\tremaining: 4.36s\n",
      "2463:\tlearn: 0.0000815\ttotal: 1.43s\tremaining: 4.36s\n",
      "2464:\tlearn: 0.0000812\ttotal: 1.43s\tremaining: 4.36s\n",
      "2465:\tlearn: 0.0000804\ttotal: 1.43s\tremaining: 4.36s\n",
      "2466:\tlearn: 0.0000801\ttotal: 1.43s\tremaining: 4.36s\n",
      "2467:\tlearn: 0.0000799\ttotal: 1.43s\tremaining: 4.36s\n",
      "2468:\tlearn: 0.0000798\ttotal: 1.43s\tremaining: 4.36s\n",
      "2469:\tlearn: 0.0000795\ttotal: 1.43s\tremaining: 4.36s\n",
      "2470:\tlearn: 0.0000792\ttotal: 1.43s\tremaining: 4.36s\n",
      "2471:\tlearn: 0.0000787\ttotal: 1.43s\tremaining: 4.36s\n",
      "2472:\tlearn: 0.0000783\ttotal: 1.43s\tremaining: 4.35s\n",
      "2473:\tlearn: 0.0000781\ttotal: 1.43s\tremaining: 4.35s\n",
      "2474:\tlearn: 0.0000781\ttotal: 1.43s\tremaining: 4.35s\n",
      "2475:\tlearn: 0.0000776\ttotal: 1.43s\tremaining: 4.35s\n",
      "2476:\tlearn: 0.0000775\ttotal: 1.43s\tremaining: 4.35s\n",
      "2477:\tlearn: 0.0000775\ttotal: 1.43s\tremaining: 4.35s\n",
      "2478:\tlearn: 0.0000771\ttotal: 1.43s\tremaining: 4.35s\n",
      "2479:\tlearn: 0.0000765\ttotal: 1.43s\tremaining: 4.35s\n",
      "2480:\tlearn: 0.0000763\ttotal: 1.43s\tremaining: 4.35s\n",
      "2481:\tlearn: 0.0000759\ttotal: 1.44s\tremaining: 4.35s\n",
      "2482:\tlearn: 0.0000755\ttotal: 1.44s\tremaining: 4.35s\n",
      "2483:\tlearn: 0.0000754\ttotal: 1.44s\tremaining: 4.35s\n",
      "2484:\tlearn: 0.0000752\ttotal: 1.44s\tremaining: 4.35s\n",
      "2485:\tlearn: 0.0000746\ttotal: 1.44s\tremaining: 4.34s\n",
      "2486:\tlearn: 0.0000741\ttotal: 1.44s\tremaining: 4.34s\n",
      "2487:\tlearn: 0.0000735\ttotal: 1.44s\tremaining: 4.34s\n",
      "2488:\tlearn: 0.0000733\ttotal: 1.44s\tremaining: 4.34s\n",
      "2489:\tlearn: 0.0000729\ttotal: 1.44s\tremaining: 4.34s\n",
      "2490:\tlearn: 0.0000726\ttotal: 1.44s\tremaining: 4.34s\n",
      "2491:\tlearn: 0.0000724\ttotal: 1.44s\tremaining: 4.34s\n",
      "2492:\tlearn: 0.0000723\ttotal: 1.44s\tremaining: 4.34s\n",
      "2493:\tlearn: 0.0000721\ttotal: 1.44s\tremaining: 4.34s\n",
      "2494:\tlearn: 0.0000720\ttotal: 1.44s\tremaining: 4.34s\n",
      "2495:\tlearn: 0.0000715\ttotal: 1.44s\tremaining: 4.34s\n",
      "2496:\tlearn: 0.0000712\ttotal: 1.44s\tremaining: 4.34s\n",
      "2497:\tlearn: 0.0000711\ttotal: 1.44s\tremaining: 4.34s\n",
      "2498:\tlearn: 0.0000707\ttotal: 1.44s\tremaining: 4.33s\n",
      "2499:\tlearn: 0.0000707\ttotal: 1.44s\tremaining: 4.33s\n",
      "2500:\tlearn: 0.0000705\ttotal: 1.45s\tremaining: 4.33s\n",
      "2501:\tlearn: 0.0000700\ttotal: 1.45s\tremaining: 4.33s\n",
      "2502:\tlearn: 0.0000695\ttotal: 1.45s\tremaining: 4.33s\n",
      "2503:\tlearn: 0.0000691\ttotal: 1.45s\tremaining: 4.33s\n",
      "2504:\tlearn: 0.0000687\ttotal: 1.45s\tremaining: 4.33s\n",
      "2505:\tlearn: 0.0000685\ttotal: 1.45s\tremaining: 4.33s\n",
      "2506:\tlearn: 0.0000685\ttotal: 1.45s\tremaining: 4.33s\n",
      "2507:\tlearn: 0.0000680\ttotal: 1.45s\tremaining: 4.33s\n",
      "2508:\tlearn: 0.0000674\ttotal: 1.45s\tremaining: 4.33s\n",
      "2509:\tlearn: 0.0000669\ttotal: 1.45s\tremaining: 4.33s\n",
      "2510:\tlearn: 0.0000669\ttotal: 1.45s\tremaining: 4.33s\n",
      "2511:\tlearn: 0.0000665\ttotal: 1.45s\tremaining: 4.33s\n",
      "2512:\tlearn: 0.0000662\ttotal: 1.45s\tremaining: 4.32s\n",
      "2513:\tlearn: 0.0000661\ttotal: 1.45s\tremaining: 4.32s\n",
      "2514:\tlearn: 0.0000657\ttotal: 1.45s\tremaining: 4.32s\n",
      "2515:\tlearn: 0.0000657\ttotal: 1.45s\tremaining: 4.32s\n",
      "2516:\tlearn: 0.0000652\ttotal: 1.45s\tremaining: 4.32s\n",
      "2517:\tlearn: 0.0000647\ttotal: 1.45s\tremaining: 4.32s\n",
      "2518:\tlearn: 0.0000646\ttotal: 1.45s\tremaining: 4.32s\n",
      "2519:\tlearn: 0.0000646\ttotal: 1.45s\tremaining: 4.32s\n",
      "2520:\tlearn: 0.0000642\ttotal: 1.46s\tremaining: 4.32s\n",
      "2521:\tlearn: 0.0000638\ttotal: 1.46s\tremaining: 4.32s\n",
      "2522:\tlearn: 0.0000634\ttotal: 1.46s\tremaining: 4.32s\n",
      "2523:\tlearn: 0.0000630\ttotal: 1.46s\tremaining: 4.31s\n",
      "2524:\tlearn: 0.0000627\ttotal: 1.46s\tremaining: 4.31s\n",
      "2525:\tlearn: 0.0000623\ttotal: 1.46s\tremaining: 4.31s\n",
      "2526:\tlearn: 0.0000620\ttotal: 1.46s\tremaining: 4.31s\n",
      "2527:\tlearn: 0.0000616\ttotal: 1.46s\tremaining: 4.31s\n",
      "2528:\tlearn: 0.0000612\ttotal: 1.46s\tremaining: 4.31s\n",
      "2529:\tlearn: 0.0000608\ttotal: 1.46s\tremaining: 4.31s\n",
      "2530:\tlearn: 0.0000607\ttotal: 1.46s\tremaining: 4.31s\n",
      "2531:\tlearn: 0.0000604\ttotal: 1.46s\tremaining: 4.31s\n",
      "2532:\tlearn: 0.0000601\ttotal: 1.46s\tremaining: 4.31s\n",
      "2533:\tlearn: 0.0000599\ttotal: 1.46s\tremaining: 4.31s\n",
      "2534:\tlearn: 0.0000596\ttotal: 1.46s\tremaining: 4.31s\n",
      "2535:\tlearn: 0.0000596\ttotal: 1.46s\tremaining: 4.31s\n",
      "2536:\tlearn: 0.0000596\ttotal: 1.46s\tremaining: 4.31s\n",
      "2537:\tlearn: 0.0000595\ttotal: 1.46s\tremaining: 4.3s\n",
      "2538:\tlearn: 0.0000594\ttotal: 1.46s\tremaining: 4.3s\n",
      "2539:\tlearn: 0.0000591\ttotal: 1.47s\tremaining: 4.3s\n",
      "2540:\tlearn: 0.0000587\ttotal: 1.47s\tremaining: 4.3s\n",
      "2541:\tlearn: 0.0000587\ttotal: 1.47s\tremaining: 4.3s\n",
      "2542:\tlearn: 0.0000586\ttotal: 1.47s\tremaining: 4.3s\n",
      "2543:\tlearn: 0.0000583\ttotal: 1.47s\tremaining: 4.3s\n",
      "2544:\tlearn: 0.0000580\ttotal: 1.47s\tremaining: 4.3s\n",
      "2545:\tlearn: 0.0000579\ttotal: 1.47s\tremaining: 4.3s\n",
      "2546:\tlearn: 0.0000577\ttotal: 1.47s\tremaining: 4.3s\n",
      "2547:\tlearn: 0.0000576\ttotal: 1.47s\tremaining: 4.3s\n",
      "2548:\tlearn: 0.0000572\ttotal: 1.47s\tremaining: 4.29s\n",
      "2549:\tlearn: 0.0000568\ttotal: 1.47s\tremaining: 4.29s\n",
      "2550:\tlearn: 0.0000567\ttotal: 1.47s\tremaining: 4.29s\n",
      "2551:\tlearn: 0.0000567\ttotal: 1.47s\tremaining: 4.29s\n",
      "2552:\tlearn: 0.0000566\ttotal: 1.47s\tremaining: 4.29s\n",
      "2553:\tlearn: 0.0000565\ttotal: 1.47s\tremaining: 4.29s\n",
      "2554:\tlearn: 0.0000562\ttotal: 1.47s\tremaining: 4.29s\n",
      "2555:\tlearn: 0.0000561\ttotal: 1.47s\tremaining: 4.29s\n",
      "2556:\tlearn: 0.0000559\ttotal: 1.47s\tremaining: 4.29s\n",
      "2557:\tlearn: 0.0000556\ttotal: 1.47s\tremaining: 4.29s\n",
      "2558:\tlearn: 0.0000554\ttotal: 1.48s\tremaining: 4.29s\n",
      "2559:\tlearn: 0.0000552\ttotal: 1.48s\tremaining: 4.29s\n",
      "2560:\tlearn: 0.0000547\ttotal: 1.48s\tremaining: 4.29s\n",
      "2561:\tlearn: 0.0000545\ttotal: 1.48s\tremaining: 4.29s\n",
      "2562:\tlearn: 0.0000542\ttotal: 1.48s\tremaining: 4.29s\n",
      "2563:\tlearn: 0.0000539\ttotal: 1.48s\tremaining: 4.29s\n",
      "2564:\tlearn: 0.0000537\ttotal: 1.48s\tremaining: 4.28s\n",
      "2565:\tlearn: 0.0000534\ttotal: 1.48s\tremaining: 4.28s\n",
      "2566:\tlearn: 0.0000531\ttotal: 1.48s\tremaining: 4.28s\n",
      "2567:\tlearn: 0.0000528\ttotal: 1.48s\tremaining: 4.28s\n",
      "2568:\tlearn: 0.0000528\ttotal: 1.48s\tremaining: 4.28s\n",
      "2569:\tlearn: 0.0000527\ttotal: 1.48s\tremaining: 4.28s\n",
      "2570:\tlearn: 0.0000524\ttotal: 1.48s\tremaining: 4.28s\n",
      "2571:\tlearn: 0.0000520\ttotal: 1.48s\tremaining: 4.28s\n",
      "2572:\tlearn: 0.0000517\ttotal: 1.48s\tremaining: 4.28s\n",
      "2573:\tlearn: 0.0000517\ttotal: 1.48s\tremaining: 4.28s\n",
      "2574:\tlearn: 0.0000511\ttotal: 1.48s\tremaining: 4.28s\n",
      "2575:\tlearn: 0.0000508\ttotal: 1.48s\tremaining: 4.28s\n",
      "2576:\tlearn: 0.0000508\ttotal: 1.48s\tremaining: 4.27s\n",
      "2577:\tlearn: 0.0000504\ttotal: 1.48s\tremaining: 4.27s\n",
      "2578:\tlearn: 0.0000502\ttotal: 1.48s\tremaining: 4.27s\n",
      "2579:\tlearn: 0.0000499\ttotal: 1.48s\tremaining: 4.27s\n",
      "2580:\tlearn: 0.0000497\ttotal: 1.49s\tremaining: 4.27s\n",
      "2581:\tlearn: 0.0000495\ttotal: 1.49s\tremaining: 4.27s\n",
      "2582:\tlearn: 0.0000494\ttotal: 1.49s\tremaining: 4.27s\n",
      "2583:\tlearn: 0.0000490\ttotal: 1.49s\tremaining: 4.27s\n",
      "2584:\tlearn: 0.0000488\ttotal: 1.49s\tremaining: 4.27s\n",
      "2585:\tlearn: 0.0000485\ttotal: 1.49s\tremaining: 4.26s\n",
      "2586:\tlearn: 0.0000482\ttotal: 1.49s\tremaining: 4.26s\n",
      "2587:\tlearn: 0.0000479\ttotal: 1.49s\tremaining: 4.26s\n",
      "2588:\tlearn: 0.0000479\ttotal: 1.49s\tremaining: 4.26s\n",
      "2589:\tlearn: 0.0000476\ttotal: 1.49s\tremaining: 4.26s\n",
      "2590:\tlearn: 0.0000473\ttotal: 1.49s\tremaining: 4.26s\n",
      "2591:\tlearn: 0.0000471\ttotal: 1.49s\tremaining: 4.26s\n",
      "2592:\tlearn: 0.0000468\ttotal: 1.49s\tremaining: 4.26s\n",
      "2593:\tlearn: 0.0000465\ttotal: 1.49s\tremaining: 4.26s\n",
      "2594:\tlearn: 0.0000461\ttotal: 1.49s\tremaining: 4.26s\n",
      "2595:\tlearn: 0.0000459\ttotal: 1.49s\tremaining: 4.26s\n",
      "2596:\tlearn: 0.0000459\ttotal: 1.49s\tremaining: 4.26s\n",
      "2597:\tlearn: 0.0000457\ttotal: 1.49s\tremaining: 4.26s\n",
      "2598:\tlearn: 0.0000455\ttotal: 1.5s\tremaining: 4.26s\n",
      "2599:\tlearn: 0.0000453\ttotal: 1.5s\tremaining: 4.26s\n",
      "2600:\tlearn: 0.0000451\ttotal: 1.5s\tremaining: 4.25s\n",
      "2601:\tlearn: 0.0000448\ttotal: 1.5s\tremaining: 4.25s\n",
      "2602:\tlearn: 0.0000445\ttotal: 1.5s\tremaining: 4.25s\n",
      "2603:\tlearn: 0.0000443\ttotal: 1.5s\tremaining: 4.25s\n",
      "2604:\tlearn: 0.0000440\ttotal: 1.5s\tremaining: 4.25s\n",
      "2605:\tlearn: 0.0000438\ttotal: 1.5s\tremaining: 4.25s\n",
      "2606:\tlearn: 0.0000435\ttotal: 1.5s\tremaining: 4.25s\n",
      "2607:\tlearn: 0.0000434\ttotal: 1.5s\tremaining: 4.25s\n",
      "2608:\tlearn: 0.0000432\ttotal: 1.5s\tremaining: 4.25s\n",
      "2609:\tlearn: 0.0000429\ttotal: 1.5s\tremaining: 4.25s\n",
      "2610:\tlearn: 0.0000427\ttotal: 1.5s\tremaining: 4.25s\n",
      "2611:\tlearn: 0.0000425\ttotal: 1.5s\tremaining: 4.25s\n",
      "2612:\tlearn: 0.0000422\ttotal: 1.5s\tremaining: 4.25s\n",
      "2613:\tlearn: 0.0000422\ttotal: 1.5s\tremaining: 4.24s\n",
      "2614:\tlearn: 0.0000420\ttotal: 1.5s\tremaining: 4.24s\n",
      "2615:\tlearn: 0.0000418\ttotal: 1.5s\tremaining: 4.24s\n",
      "2616:\tlearn: 0.0000417\ttotal: 1.5s\tremaining: 4.24s\n",
      "2617:\tlearn: 0.0000415\ttotal: 1.5s\tremaining: 4.24s\n",
      "2618:\tlearn: 0.0000412\ttotal: 1.5s\tremaining: 4.24s\n",
      "2619:\tlearn: 0.0000411\ttotal: 1.51s\tremaining: 4.24s\n",
      "2620:\tlearn: 0.0000409\ttotal: 1.51s\tremaining: 4.24s\n",
      "2621:\tlearn: 0.0000405\ttotal: 1.51s\tremaining: 4.24s\n",
      "2622:\tlearn: 0.0000404\ttotal: 1.51s\tremaining: 4.24s\n",
      "2623:\tlearn: 0.0000404\ttotal: 1.51s\tremaining: 4.24s\n",
      "2624:\tlearn: 0.0000403\ttotal: 1.51s\tremaining: 4.24s\n",
      "2625:\tlearn: 0.0000401\ttotal: 1.51s\tremaining: 4.24s\n",
      "2626:\tlearn: 0.0000399\ttotal: 1.51s\tremaining: 4.24s\n",
      "2627:\tlearn: 0.0000398\ttotal: 1.51s\tremaining: 4.24s\n",
      "2628:\tlearn: 0.0000396\ttotal: 1.51s\tremaining: 4.24s\n",
      "2629:\tlearn: 0.0000394\ttotal: 1.51s\tremaining: 4.23s\n",
      "2630:\tlearn: 0.0000392\ttotal: 1.51s\tremaining: 4.23s\n",
      "2631:\tlearn: 0.0000389\ttotal: 1.51s\tremaining: 4.23s\n",
      "2632:\tlearn: 0.0000387\ttotal: 1.51s\tremaining: 4.23s\n",
      "2633:\tlearn: 0.0000385\ttotal: 1.51s\tremaining: 4.23s\n",
      "2634:\tlearn: 0.0000383\ttotal: 1.51s\tremaining: 4.23s\n",
      "2635:\tlearn: 0.0000381\ttotal: 1.51s\tremaining: 4.23s\n",
      "2636:\tlearn: 0.0000379\ttotal: 1.51s\tremaining: 4.23s\n",
      "2637:\tlearn: 0.0000377\ttotal: 1.51s\tremaining: 4.23s\n",
      "2638:\tlearn: 0.0000377\ttotal: 1.51s\tremaining: 4.23s\n",
      "2639:\tlearn: 0.0000375\ttotal: 1.51s\tremaining: 4.23s\n",
      "2640:\tlearn: 0.0000372\ttotal: 1.52s\tremaining: 4.22s\n",
      "2641:\tlearn: 0.0000372\ttotal: 1.52s\tremaining: 4.22s\n",
      "2642:\tlearn: 0.0000370\ttotal: 1.52s\tremaining: 4.22s\n",
      "2643:\tlearn: 0.0000369\ttotal: 1.52s\tremaining: 4.22s\n",
      "2644:\tlearn: 0.0000366\ttotal: 1.52s\tremaining: 4.22s\n",
      "2645:\tlearn: 0.0000365\ttotal: 1.52s\tremaining: 4.22s\n",
      "2646:\tlearn: 0.0000363\ttotal: 1.52s\tremaining: 4.22s\n",
      "2647:\tlearn: 0.0000361\ttotal: 1.52s\tremaining: 4.22s\n",
      "2648:\tlearn: 0.0000361\ttotal: 1.52s\tremaining: 4.22s\n",
      "2649:\tlearn: 0.0000361\ttotal: 1.52s\tremaining: 4.22s\n",
      "2650:\tlearn: 0.0000359\ttotal: 1.52s\tremaining: 4.22s\n",
      "2651:\tlearn: 0.0000356\ttotal: 1.52s\tremaining: 4.22s\n",
      "2652:\tlearn: 0.0000356\ttotal: 1.52s\tremaining: 4.21s\n",
      "2653:\tlearn: 0.0000355\ttotal: 1.52s\tremaining: 4.21s\n",
      "2654:\tlearn: 0.0000354\ttotal: 1.52s\tremaining: 4.21s\n",
      "2655:\tlearn: 0.0000352\ttotal: 1.52s\tremaining: 4.21s\n",
      "2656:\tlearn: 0.0000351\ttotal: 1.52s\tremaining: 4.21s\n",
      "2657:\tlearn: 0.0000348\ttotal: 1.52s\tremaining: 4.21s\n",
      "2658:\tlearn: 0.0000347\ttotal: 1.52s\tremaining: 4.21s\n",
      "2659:\tlearn: 0.0000345\ttotal: 1.52s\tremaining: 4.21s\n",
      "2660:\tlearn: 0.0000344\ttotal: 1.52s\tremaining: 4.21s\n",
      "2661:\tlearn: 0.0000343\ttotal: 1.53s\tremaining: 4.21s\n",
      "2662:\tlearn: 0.0000343\ttotal: 1.53s\tremaining: 4.21s\n",
      "2663:\tlearn: 0.0000341\ttotal: 1.53s\tremaining: 4.21s\n",
      "2664:\tlearn: 0.0000341\ttotal: 1.53s\tremaining: 4.2s\n",
      "2665:\tlearn: 0.0000340\ttotal: 1.53s\tremaining: 4.2s\n",
      "2666:\tlearn: 0.0000339\ttotal: 1.53s\tremaining: 4.2s\n",
      "2667:\tlearn: 0.0000338\ttotal: 1.53s\tremaining: 4.2s\n",
      "2668:\tlearn: 0.0000337\ttotal: 1.53s\tremaining: 4.2s\n",
      "2669:\tlearn: 0.0000336\ttotal: 1.53s\tremaining: 4.2s\n",
      "2670:\tlearn: 0.0000333\ttotal: 1.53s\tremaining: 4.2s\n",
      "2671:\tlearn: 0.0000333\ttotal: 1.53s\tremaining: 4.2s\n",
      "2672:\tlearn: 0.0000333\ttotal: 1.53s\tremaining: 4.2s\n",
      "2673:\tlearn: 0.0000331\ttotal: 1.53s\tremaining: 4.2s\n",
      "2674:\tlearn: 0.0000328\ttotal: 1.53s\tremaining: 4.2s\n",
      "2675:\tlearn: 0.0000327\ttotal: 1.53s\tremaining: 4.2s\n",
      "2676:\tlearn: 0.0000325\ttotal: 1.53s\tremaining: 4.2s\n",
      "2677:\tlearn: 0.0000325\ttotal: 1.53s\tremaining: 4.2s\n",
      "2678:\tlearn: 0.0000323\ttotal: 1.53s\tremaining: 4.19s\n",
      "2679:\tlearn: 0.0000322\ttotal: 1.53s\tremaining: 4.19s\n",
      "2680:\tlearn: 0.0000321\ttotal: 1.53s\tremaining: 4.19s\n",
      "2681:\tlearn: 0.0000319\ttotal: 1.54s\tremaining: 4.19s\n",
      "2682:\tlearn: 0.0000318\ttotal: 1.54s\tremaining: 4.19s\n",
      "2683:\tlearn: 0.0000315\ttotal: 1.54s\tremaining: 4.19s\n",
      "2684:\tlearn: 0.0000312\ttotal: 1.54s\tremaining: 4.19s\n",
      "2685:\tlearn: 0.0000311\ttotal: 1.54s\tremaining: 4.19s\n",
      "2686:\tlearn: 0.0000310\ttotal: 1.54s\tremaining: 4.19s\n",
      "2687:\tlearn: 0.0000308\ttotal: 1.54s\tremaining: 4.19s\n",
      "2688:\tlearn: 0.0000307\ttotal: 1.54s\tremaining: 4.18s\n",
      "2689:\tlearn: 0.0000306\ttotal: 1.54s\tremaining: 4.18s\n",
      "2690:\tlearn: 0.0000305\ttotal: 1.54s\tremaining: 4.18s\n",
      "2691:\tlearn: 0.0000305\ttotal: 1.54s\tremaining: 4.18s\n",
      "2692:\tlearn: 0.0000304\ttotal: 1.54s\tremaining: 4.18s\n",
      "2693:\tlearn: 0.0000302\ttotal: 1.54s\tremaining: 4.18s\n",
      "2694:\tlearn: 0.0000301\ttotal: 1.54s\tremaining: 4.18s\n",
      "2695:\tlearn: 0.0000300\ttotal: 1.54s\tremaining: 4.18s\n",
      "2696:\tlearn: 0.0000299\ttotal: 1.54s\tremaining: 4.18s\n",
      "2697:\tlearn: 0.0000297\ttotal: 1.54s\tremaining: 4.18s\n",
      "2698:\tlearn: 0.0000296\ttotal: 1.54s\tremaining: 4.18s\n",
      "2699:\tlearn: 0.0000294\ttotal: 1.54s\tremaining: 4.18s\n",
      "2700:\tlearn: 0.0000292\ttotal: 1.54s\tremaining: 4.17s\n",
      "2701:\tlearn: 0.0000290\ttotal: 1.54s\tremaining: 4.17s\n",
      "2702:\tlearn: 0.0000288\ttotal: 1.55s\tremaining: 4.17s\n",
      "2703:\tlearn: 0.0000286\ttotal: 1.55s\tremaining: 4.17s\n",
      "2704:\tlearn: 0.0000286\ttotal: 1.55s\tremaining: 4.17s\n",
      "2705:\tlearn: 0.0000284\ttotal: 1.55s\tremaining: 4.17s\n",
      "2706:\tlearn: 0.0000282\ttotal: 1.55s\tremaining: 4.17s\n",
      "2707:\tlearn: 0.0000282\ttotal: 1.55s\tremaining: 4.17s\n",
      "2708:\tlearn: 0.0000280\ttotal: 1.55s\tremaining: 4.17s\n",
      "2709:\tlearn: 0.0000279\ttotal: 1.55s\tremaining: 4.17s\n",
      "2710:\tlearn: 0.0000278\ttotal: 1.55s\tremaining: 4.17s\n",
      "2711:\tlearn: 0.0000277\ttotal: 1.55s\tremaining: 4.17s\n",
      "2712:\tlearn: 0.0000276\ttotal: 1.55s\tremaining: 4.17s\n",
      "2713:\tlearn: 0.0000275\ttotal: 1.55s\tremaining: 4.17s\n",
      "2714:\tlearn: 0.0000273\ttotal: 1.55s\tremaining: 4.16s\n",
      "2715:\tlearn: 0.0000272\ttotal: 1.55s\tremaining: 4.16s\n",
      "2716:\tlearn: 0.0000272\ttotal: 1.55s\tremaining: 4.16s\n",
      "2717:\tlearn: 0.0000270\ttotal: 1.55s\tremaining: 4.16s\n",
      "2718:\tlearn: 0.0000267\ttotal: 1.55s\tremaining: 4.16s\n",
      "2719:\tlearn: 0.0000267\ttotal: 1.55s\tremaining: 4.16s\n",
      "2720:\tlearn: 0.0000267\ttotal: 1.55s\tremaining: 4.16s\n",
      "2721:\tlearn: 0.0000266\ttotal: 1.55s\tremaining: 4.16s\n",
      "2722:\tlearn: 0.0000265\ttotal: 1.55s\tremaining: 4.16s\n",
      "2723:\tlearn: 0.0000264\ttotal: 1.56s\tremaining: 4.16s\n",
      "2724:\tlearn: 0.0000264\ttotal: 1.56s\tremaining: 4.16s\n",
      "2725:\tlearn: 0.0000262\ttotal: 1.56s\tremaining: 4.15s\n",
      "2726:\tlearn: 0.0000261\ttotal: 1.56s\tremaining: 4.15s\n",
      "2727:\tlearn: 0.0000260\ttotal: 1.56s\tremaining: 4.15s\n",
      "2728:\tlearn: 0.0000258\ttotal: 1.56s\tremaining: 4.15s\n",
      "2729:\tlearn: 0.0000258\ttotal: 1.56s\tremaining: 4.15s\n",
      "2730:\tlearn: 0.0000257\ttotal: 1.56s\tremaining: 4.15s\n",
      "2731:\tlearn: 0.0000256\ttotal: 1.56s\tremaining: 4.15s\n",
      "2732:\tlearn: 0.0000254\ttotal: 1.56s\tremaining: 4.15s\n",
      "2733:\tlearn: 0.0000254\ttotal: 1.56s\tremaining: 4.15s\n",
      "2734:\tlearn: 0.0000252\ttotal: 1.56s\tremaining: 4.15s\n",
      "2735:\tlearn: 0.0000252\ttotal: 1.56s\tremaining: 4.15s\n",
      "2736:\tlearn: 0.0000252\ttotal: 1.56s\tremaining: 4.15s\n",
      "2737:\tlearn: 0.0000251\ttotal: 1.56s\tremaining: 4.15s\n",
      "2738:\tlearn: 0.0000250\ttotal: 1.56s\tremaining: 4.14s\n",
      "2739:\tlearn: 0.0000249\ttotal: 1.56s\tremaining: 4.14s\n",
      "2740:\tlearn: 0.0000248\ttotal: 1.56s\tremaining: 4.14s\n",
      "2741:\tlearn: 0.0000246\ttotal: 1.56s\tremaining: 4.14s\n",
      "2742:\tlearn: 0.0000245\ttotal: 1.56s\tremaining: 4.14s\n",
      "2743:\tlearn: 0.0000244\ttotal: 1.56s\tremaining: 4.14s\n",
      "2744:\tlearn: 0.0000243\ttotal: 1.57s\tremaining: 4.14s\n",
      "2745:\tlearn: 0.0000242\ttotal: 1.57s\tremaining: 4.14s\n",
      "2746:\tlearn: 0.0000241\ttotal: 1.57s\tremaining: 4.14s\n",
      "2747:\tlearn: 0.0000240\ttotal: 1.57s\tremaining: 4.14s\n",
      "2748:\tlearn: 0.0000239\ttotal: 1.57s\tremaining: 4.14s\n",
      "2749:\tlearn: 0.0000239\ttotal: 1.57s\tremaining: 4.13s\n",
      "2750:\tlearn: 0.0000239\ttotal: 1.57s\tremaining: 4.13s\n",
      "2751:\tlearn: 0.0000238\ttotal: 1.57s\tremaining: 4.13s\n",
      "2752:\tlearn: 0.0000237\ttotal: 1.57s\tremaining: 4.13s\n",
      "2753:\tlearn: 0.0000236\ttotal: 1.57s\tremaining: 4.13s\n",
      "2754:\tlearn: 0.0000234\ttotal: 1.57s\tremaining: 4.13s\n",
      "2755:\tlearn: 0.0000234\ttotal: 1.57s\tremaining: 4.13s\n",
      "2756:\tlearn: 0.0000233\ttotal: 1.57s\tremaining: 4.13s\n",
      "2757:\tlearn: 0.0000232\ttotal: 1.57s\tremaining: 4.13s\n",
      "2758:\tlearn: 0.0000232\ttotal: 1.57s\tremaining: 4.13s\n",
      "2759:\tlearn: 0.0000230\ttotal: 1.57s\tremaining: 4.13s\n",
      "2760:\tlearn: 0.0000230\ttotal: 1.57s\tremaining: 4.13s\n",
      "2761:\tlearn: 0.0000230\ttotal: 1.57s\tremaining: 4.13s\n",
      "2762:\tlearn: 0.0000228\ttotal: 1.57s\tremaining: 4.13s\n",
      "2763:\tlearn: 0.0000228\ttotal: 1.58s\tremaining: 4.13s\n",
      "2764:\tlearn: 0.0000228\ttotal: 1.58s\tremaining: 4.13s\n",
      "2765:\tlearn: 0.0000226\ttotal: 1.58s\tremaining: 4.12s\n",
      "2766:\tlearn: 0.0000226\ttotal: 1.58s\tremaining: 4.12s\n",
      "2767:\tlearn: 0.0000225\ttotal: 1.58s\tremaining: 4.12s\n",
      "2768:\tlearn: 0.0000224\ttotal: 1.58s\tremaining: 4.12s\n",
      "2769:\tlearn: 0.0000223\ttotal: 1.58s\tremaining: 4.12s\n",
      "2770:\tlearn: 0.0000222\ttotal: 1.58s\tremaining: 4.12s\n",
      "2771:\tlearn: 0.0000221\ttotal: 1.58s\tremaining: 4.12s\n",
      "2772:\tlearn: 0.0000220\ttotal: 1.58s\tremaining: 4.12s\n",
      "2773:\tlearn: 0.0000219\ttotal: 1.58s\tremaining: 4.12s\n",
      "2774:\tlearn: 0.0000218\ttotal: 1.58s\tremaining: 4.12s\n",
      "2775:\tlearn: 0.0000216\ttotal: 1.58s\tremaining: 4.12s\n",
      "2776:\tlearn: 0.0000215\ttotal: 1.58s\tremaining: 4.11s\n",
      "2777:\tlearn: 0.0000215\ttotal: 1.58s\tremaining: 4.11s\n",
      "2778:\tlearn: 0.0000214\ttotal: 1.58s\tremaining: 4.11s\n",
      "2779:\tlearn: 0.0000213\ttotal: 1.58s\tremaining: 4.11s\n",
      "2780:\tlearn: 0.0000213\ttotal: 1.58s\tremaining: 4.11s\n",
      "2781:\tlearn: 0.0000211\ttotal: 1.58s\tremaining: 4.11s\n",
      "2782:\tlearn: 0.0000209\ttotal: 1.58s\tremaining: 4.11s\n",
      "2783:\tlearn: 0.0000209\ttotal: 1.58s\tremaining: 4.11s\n",
      "2784:\tlearn: 0.0000207\ttotal: 1.58s\tremaining: 4.11s\n",
      "2785:\tlearn: 0.0000206\ttotal: 1.59s\tremaining: 4.11s\n",
      "2786:\tlearn: 0.0000206\ttotal: 1.59s\tremaining: 4.11s\n",
      "2787:\tlearn: 0.0000205\ttotal: 1.59s\tremaining: 4.11s\n",
      "2788:\tlearn: 0.0000204\ttotal: 1.59s\tremaining: 4.11s\n",
      "2789:\tlearn: 0.0000202\ttotal: 1.59s\tremaining: 4.11s\n",
      "2790:\tlearn: 0.0000202\ttotal: 1.59s\tremaining: 4.11s\n",
      "2791:\tlearn: 0.0000201\ttotal: 1.59s\tremaining: 4.11s\n",
      "2792:\tlearn: 0.0000201\ttotal: 1.59s\tremaining: 4.11s\n",
      "2793:\tlearn: 0.0000200\ttotal: 1.59s\tremaining: 4.11s\n",
      "2794:\tlearn: 0.0000200\ttotal: 1.59s\tremaining: 4.1s\n",
      "2795:\tlearn: 0.0000198\ttotal: 1.59s\tremaining: 4.1s\n",
      "2796:\tlearn: 0.0000197\ttotal: 1.59s\tremaining: 4.1s\n",
      "2797:\tlearn: 0.0000197\ttotal: 1.59s\tremaining: 4.1s\n",
      "2798:\tlearn: 0.0000195\ttotal: 1.59s\tremaining: 4.1s\n",
      "2799:\tlearn: 0.0000195\ttotal: 1.59s\tremaining: 4.1s\n",
      "2800:\tlearn: 0.0000194\ttotal: 1.59s\tremaining: 4.1s\n",
      "2801:\tlearn: 0.0000193\ttotal: 1.59s\tremaining: 4.1s\n",
      "2802:\tlearn: 0.0000193\ttotal: 1.6s\tremaining: 4.1s\n",
      "2803:\tlearn: 0.0000192\ttotal: 1.6s\tremaining: 4.1s\n",
      "2804:\tlearn: 0.0000191\ttotal: 1.6s\tremaining: 4.09s\n",
      "2805:\tlearn: 0.0000189\ttotal: 1.6s\tremaining: 4.09s\n",
      "2806:\tlearn: 0.0000187\ttotal: 1.6s\tremaining: 4.09s\n",
      "2807:\tlearn: 0.0000187\ttotal: 1.6s\tremaining: 4.09s\n",
      "2808:\tlearn: 0.0000186\ttotal: 1.6s\tremaining: 4.09s\n",
      "2809:\tlearn: 0.0000185\ttotal: 1.6s\tremaining: 4.09s\n",
      "2810:\tlearn: 0.0000184\ttotal: 1.6s\tremaining: 4.09s\n",
      "2811:\tlearn: 0.0000184\ttotal: 1.6s\tremaining: 4.09s\n",
      "2812:\tlearn: 0.0000183\ttotal: 1.6s\tremaining: 4.09s\n",
      "2813:\tlearn: 0.0000182\ttotal: 1.6s\tremaining: 4.09s\n",
      "2814:\tlearn: 0.0000181\ttotal: 1.6s\tremaining: 4.09s\n",
      "2815:\tlearn: 0.0000179\ttotal: 1.6s\tremaining: 4.09s\n",
      "2816:\tlearn: 0.0000178\ttotal: 1.6s\tremaining: 4.08s\n",
      "2817:\tlearn: 0.0000177\ttotal: 1.6s\tremaining: 4.08s\n",
      "2818:\tlearn: 0.0000176\ttotal: 1.6s\tremaining: 4.08s\n",
      "2819:\tlearn: 0.0000176\ttotal: 1.6s\tremaining: 4.08s\n",
      "2820:\tlearn: 0.0000175\ttotal: 1.6s\tremaining: 4.08s\n",
      "2821:\tlearn: 0.0000174\ttotal: 1.6s\tremaining: 4.08s\n",
      "2822:\tlearn: 0.0000173\ttotal: 1.6s\tremaining: 4.08s\n",
      "2823:\tlearn: 0.0000172\ttotal: 1.6s\tremaining: 4.08s\n",
      "2824:\tlearn: 0.0000171\ttotal: 1.61s\tremaining: 4.08s\n",
      "2825:\tlearn: 0.0000170\ttotal: 1.61s\tremaining: 4.08s\n",
      "2826:\tlearn: 0.0000170\ttotal: 1.61s\tremaining: 4.08s\n",
      "2827:\tlearn: 0.0000169\ttotal: 1.61s\tremaining: 4.08s\n",
      "2828:\tlearn: 0.0000169\ttotal: 1.61s\tremaining: 4.08s\n",
      "2829:\tlearn: 0.0000168\ttotal: 1.61s\tremaining: 4.08s\n",
      "2830:\tlearn: 0.0000167\ttotal: 1.61s\tremaining: 4.08s\n",
      "2831:\tlearn: 0.0000167\ttotal: 1.61s\tremaining: 4.08s\n",
      "2832:\tlearn: 0.0000166\ttotal: 1.61s\tremaining: 4.07s\n",
      "2833:\tlearn: 0.0000166\ttotal: 1.61s\tremaining: 4.07s\n",
      "2834:\tlearn: 0.0000166\ttotal: 1.61s\tremaining: 4.07s\n",
      "2835:\tlearn: 0.0000164\ttotal: 1.61s\tremaining: 4.07s\n",
      "2836:\tlearn: 0.0000164\ttotal: 1.61s\tremaining: 4.07s\n",
      "2837:\tlearn: 0.0000163\ttotal: 1.61s\tremaining: 4.07s\n",
      "2838:\tlearn: 0.0000162\ttotal: 1.61s\tremaining: 4.07s\n",
      "2839:\tlearn: 0.0000162\ttotal: 1.61s\tremaining: 4.07s\n",
      "2840:\tlearn: 0.0000161\ttotal: 1.61s\tremaining: 4.07s\n",
      "2841:\tlearn: 0.0000161\ttotal: 1.61s\tremaining: 4.07s\n",
      "2842:\tlearn: 0.0000159\ttotal: 1.61s\tremaining: 4.07s\n",
      "2843:\tlearn: 0.0000159\ttotal: 1.62s\tremaining: 4.07s\n",
      "2844:\tlearn: 0.0000159\ttotal: 1.62s\tremaining: 4.07s\n",
      "2845:\tlearn: 0.0000158\ttotal: 1.62s\tremaining: 4.07s\n",
      "2846:\tlearn: 0.0000157\ttotal: 1.62s\tremaining: 4.07s\n",
      "2847:\tlearn: 0.0000156\ttotal: 1.62s\tremaining: 4.07s\n",
      "2848:\tlearn: 0.0000155\ttotal: 1.62s\tremaining: 4.07s\n",
      "2849:\tlearn: 0.0000154\ttotal: 1.62s\tremaining: 4.07s\n",
      "2850:\tlearn: 0.0000153\ttotal: 1.62s\tremaining: 4.07s\n",
      "2851:\tlearn: 0.0000153\ttotal: 1.62s\tremaining: 4.06s\n",
      "2852:\tlearn: 0.0000152\ttotal: 1.62s\tremaining: 4.06s\n",
      "2853:\tlearn: 0.0000151\ttotal: 1.62s\tremaining: 4.06s\n",
      "2854:\tlearn: 0.0000150\ttotal: 1.62s\tremaining: 4.06s\n",
      "2855:\tlearn: 0.0000149\ttotal: 1.62s\tremaining: 4.06s\n",
      "2856:\tlearn: 0.0000148\ttotal: 1.62s\tremaining: 4.06s\n",
      "2857:\tlearn: 0.0000148\ttotal: 1.62s\tremaining: 4.06s\n",
      "2858:\tlearn: 0.0000147\ttotal: 1.63s\tremaining: 4.06s\n",
      "2859:\tlearn: 0.0000146\ttotal: 1.63s\tremaining: 4.06s\n",
      "2860:\tlearn: 0.0000146\ttotal: 1.63s\tremaining: 4.06s\n",
      "2861:\tlearn: 0.0000146\ttotal: 1.63s\tremaining: 4.06s\n",
      "2862:\tlearn: 0.0000146\ttotal: 1.63s\tremaining: 4.06s\n",
      "2863:\tlearn: 0.0000146\ttotal: 1.63s\tremaining: 4.06s\n",
      "2864:\tlearn: 0.0000144\ttotal: 1.63s\tremaining: 4.06s\n",
      "2865:\tlearn: 0.0000144\ttotal: 1.63s\tremaining: 4.05s\n",
      "2866:\tlearn: 0.0000143\ttotal: 1.63s\tremaining: 4.05s\n",
      "2867:\tlearn: 0.0000143\ttotal: 1.63s\tremaining: 4.05s\n",
      "2868:\tlearn: 0.0000142\ttotal: 1.63s\tremaining: 4.05s\n",
      "2869:\tlearn: 0.0000141\ttotal: 1.63s\tremaining: 4.05s\n",
      "2870:\tlearn: 0.0000140\ttotal: 1.63s\tremaining: 4.05s\n",
      "2871:\tlearn: 0.0000139\ttotal: 1.63s\tremaining: 4.05s\n",
      "2872:\tlearn: 0.0000139\ttotal: 1.63s\tremaining: 4.05s\n",
      "2873:\tlearn: 0.0000139\ttotal: 1.63s\tremaining: 4.05s\n",
      "2874:\tlearn: 0.0000139\ttotal: 1.63s\tremaining: 4.05s\n",
      "2875:\tlearn: 0.0000138\ttotal: 1.64s\tremaining: 4.05s\n",
      "2876:\tlearn: 0.0000138\ttotal: 1.64s\tremaining: 4.05s\n",
      "2877:\tlearn: 0.0000137\ttotal: 1.64s\tremaining: 4.05s\n",
      "2878:\tlearn: 0.0000136\ttotal: 1.64s\tremaining: 4.05s\n",
      "2879:\tlearn: 0.0000136\ttotal: 1.64s\tremaining: 4.05s\n",
      "2880:\tlearn: 0.0000135\ttotal: 1.64s\tremaining: 4.05s\n",
      "2881:\tlearn: 0.0000135\ttotal: 1.64s\tremaining: 4.05s\n",
      "2882:\tlearn: 0.0000134\ttotal: 1.64s\tremaining: 4.05s\n",
      "2883:\tlearn: 0.0000134\ttotal: 1.64s\tremaining: 4.04s\n",
      "2884:\tlearn: 0.0000133\ttotal: 1.64s\tremaining: 4.04s\n",
      "2885:\tlearn: 0.0000133\ttotal: 1.64s\tremaining: 4.04s\n",
      "2886:\tlearn: 0.0000133\ttotal: 1.64s\tremaining: 4.04s\n",
      "2887:\tlearn: 0.0000132\ttotal: 1.64s\tremaining: 4.04s\n",
      "2888:\tlearn: 0.0000132\ttotal: 1.64s\tremaining: 4.04s\n",
      "2889:\tlearn: 0.0000131\ttotal: 1.64s\tremaining: 4.04s\n",
      "2890:\tlearn: 0.0000131\ttotal: 1.64s\tremaining: 4.04s\n",
      "2891:\tlearn: 0.0000130\ttotal: 1.64s\tremaining: 4.04s\n",
      "2892:\tlearn: 0.0000130\ttotal: 1.64s\tremaining: 4.04s\n",
      "2893:\tlearn: 0.0000130\ttotal: 1.64s\tremaining: 4.04s\n",
      "2894:\tlearn: 0.0000129\ttotal: 1.65s\tremaining: 4.04s\n",
      "2895:\tlearn: 0.0000128\ttotal: 1.65s\tremaining: 4.04s\n",
      "2896:\tlearn: 0.0000127\ttotal: 1.65s\tremaining: 4.04s\n",
      "2897:\tlearn: 0.0000127\ttotal: 1.65s\tremaining: 4.04s\n",
      "2898:\tlearn: 0.0000127\ttotal: 1.65s\tremaining: 4.04s\n",
      "2899:\tlearn: 0.0000126\ttotal: 1.65s\tremaining: 4.04s\n",
      "2900:\tlearn: 0.0000125\ttotal: 1.65s\tremaining: 4.04s\n",
      "2901:\tlearn: 0.0000124\ttotal: 1.65s\tremaining: 4.04s\n",
      "2902:\tlearn: 0.0000123\ttotal: 1.65s\tremaining: 4.04s\n",
      "2903:\tlearn: 0.0000123\ttotal: 1.65s\tremaining: 4.03s\n",
      "2904:\tlearn: 0.0000123\ttotal: 1.65s\tremaining: 4.03s\n",
      "2905:\tlearn: 0.0000123\ttotal: 1.65s\tremaining: 4.03s\n",
      "2906:\tlearn: 0.0000122\ttotal: 1.65s\tremaining: 4.03s\n",
      "2907:\tlearn: 0.0000122\ttotal: 1.65s\tremaining: 4.03s\n",
      "2908:\tlearn: 0.0000121\ttotal: 1.65s\tremaining: 4.03s\n",
      "2909:\tlearn: 0.0000121\ttotal: 1.65s\tremaining: 4.03s\n",
      "2910:\tlearn: 0.0000120\ttotal: 1.65s\tremaining: 4.03s\n",
      "2911:\tlearn: 0.0000119\ttotal: 1.65s\tremaining: 4.03s\n",
      "2912:\tlearn: 0.0000118\ttotal: 1.66s\tremaining: 4.03s\n",
      "2913:\tlearn: 0.0000117\ttotal: 1.66s\tremaining: 4.03s\n",
      "2914:\tlearn: 0.0000117\ttotal: 1.66s\tremaining: 4.03s\n",
      "2915:\tlearn: 0.0000117\ttotal: 1.66s\tremaining: 4.02s\n",
      "2916:\tlearn: 0.0000117\ttotal: 1.66s\tremaining: 4.02s\n",
      "2917:\tlearn: 0.0000116\ttotal: 1.66s\tremaining: 4.02s\n",
      "2918:\tlearn: 0.0000116\ttotal: 1.66s\tremaining: 4.02s\n",
      "2919:\tlearn: 0.0000115\ttotal: 1.66s\tremaining: 4.02s\n",
      "2920:\tlearn: 0.0000115\ttotal: 1.66s\tremaining: 4.02s\n",
      "2921:\tlearn: 0.0000115\ttotal: 1.66s\tremaining: 4.02s\n",
      "2922:\tlearn: 0.0000115\ttotal: 1.66s\tremaining: 4.02s\n",
      "2923:\tlearn: 0.0000114\ttotal: 1.66s\tremaining: 4.02s\n",
      "2924:\tlearn: 0.0000114\ttotal: 1.66s\tremaining: 4.02s\n",
      "2925:\tlearn: 0.0000113\ttotal: 1.66s\tremaining: 4.02s\n",
      "2926:\tlearn: 0.0000112\ttotal: 1.66s\tremaining: 4.02s\n",
      "2927:\tlearn: 0.0000112\ttotal: 1.66s\tremaining: 4.02s\n",
      "2928:\tlearn: 0.0000112\ttotal: 1.67s\tremaining: 4.02s\n",
      "2929:\tlearn: 0.0000111\ttotal: 1.67s\tremaining: 4.02s\n",
      "2930:\tlearn: 0.0000111\ttotal: 1.67s\tremaining: 4.02s\n",
      "2931:\tlearn: 0.0000110\ttotal: 1.67s\tremaining: 4.02s\n",
      "2932:\tlearn: 0.0000109\ttotal: 1.67s\tremaining: 4.02s\n",
      "2933:\tlearn: 0.0000109\ttotal: 1.67s\tremaining: 4.02s\n",
      "2934:\tlearn: 0.0000108\ttotal: 1.67s\tremaining: 4.01s\n",
      "2935:\tlearn: 0.0000107\ttotal: 1.67s\tremaining: 4.01s\n",
      "2936:\tlearn: 0.0000107\ttotal: 1.67s\tremaining: 4.01s\n",
      "2937:\tlearn: 0.0000107\ttotal: 1.67s\tremaining: 4.01s\n",
      "2938:\tlearn: 0.0000106\ttotal: 1.67s\tremaining: 4.01s\n",
      "2939:\tlearn: 0.0000106\ttotal: 1.67s\tremaining: 4.01s\n",
      "2940:\tlearn: 0.0000105\ttotal: 1.67s\tremaining: 4.01s\n",
      "2941:\tlearn: 0.0000105\ttotal: 1.67s\tremaining: 4.01s\n",
      "2942:\tlearn: 0.0000105\ttotal: 1.67s\tremaining: 4.01s\n",
      "2943:\tlearn: 0.0000104\ttotal: 1.67s\tremaining: 4.01s\n",
      "2944:\tlearn: 0.0000104\ttotal: 1.67s\tremaining: 4.01s\n",
      "2945:\tlearn: 0.0000104\ttotal: 1.68s\tremaining: 4.01s\n",
      "2946:\tlearn: 0.0000103\ttotal: 1.68s\tremaining: 4.01s\n",
      "2947:\tlearn: 0.0000103\ttotal: 1.68s\tremaining: 4.02s\n",
      "2948:\tlearn: 0.0000102\ttotal: 1.68s\tremaining: 4.02s\n",
      "2949:\tlearn: 0.0000101\ttotal: 1.68s\tremaining: 4.02s\n",
      "2950:\tlearn: 0.0000101\ttotal: 1.68s\tremaining: 4.02s\n",
      "2951:\tlearn: 0.0000101\ttotal: 1.69s\tremaining: 4.03s\n",
      "2952:\tlearn: 0.0000101\ttotal: 1.69s\tremaining: 4.03s\n",
      "2953:\tlearn: 0.0000100\ttotal: 1.69s\tremaining: 4.03s\n",
      "2954:\tlearn: 0.0000100\ttotal: 1.69s\tremaining: 4.03s\n",
      "2955:\tlearn: 0.0000100\ttotal: 1.69s\tremaining: 4.03s\n",
      "2956:\tlearn: 0.0000099\ttotal: 1.69s\tremaining: 4.03s\n",
      "2957:\tlearn: 0.0000098\ttotal: 1.69s\tremaining: 4.03s\n",
      "2958:\tlearn: 0.0000098\ttotal: 1.69s\tremaining: 4.03s\n",
      "2959:\tlearn: 0.0000098\ttotal: 1.69s\tremaining: 4.03s\n",
      "2960:\tlearn: 0.0000097\ttotal: 1.7s\tremaining: 4.03s\n",
      "2961:\tlearn: 0.0000097\ttotal: 1.7s\tremaining: 4.03s\n",
      "2962:\tlearn: 0.0000097\ttotal: 1.7s\tremaining: 4.03s\n",
      "2963:\tlearn: 0.0000097\ttotal: 1.7s\tremaining: 4.03s\n",
      "2964:\tlearn: 0.0000096\ttotal: 1.7s\tremaining: 4.03s\n",
      "2965:\tlearn: 0.0000096\ttotal: 1.7s\tremaining: 4.03s\n",
      "2966:\tlearn: 0.0000095\ttotal: 1.7s\tremaining: 4.03s\n",
      "2967:\tlearn: 0.0000095\ttotal: 1.7s\tremaining: 4.02s\n",
      "2968:\tlearn: 0.0000094\ttotal: 1.7s\tremaining: 4.02s\n",
      "2969:\tlearn: 0.0000094\ttotal: 1.7s\tremaining: 4.02s\n",
      "2970:\tlearn: 0.0000093\ttotal: 1.7s\tremaining: 4.02s\n",
      "2971:\tlearn: 0.0000092\ttotal: 1.7s\tremaining: 4.02s\n",
      "2972:\tlearn: 0.0000092\ttotal: 1.7s\tremaining: 4.02s\n",
      "2973:\tlearn: 0.0000092\ttotal: 1.7s\tremaining: 4.02s\n",
      "2974:\tlearn: 0.0000091\ttotal: 1.7s\tremaining: 4.02s\n",
      "2975:\tlearn: 0.0000091\ttotal: 1.7s\tremaining: 4.02s\n",
      "2976:\tlearn: 0.0000091\ttotal: 1.7s\tremaining: 4.02s\n",
      "2977:\tlearn: 0.0000091\ttotal: 1.7s\tremaining: 4.01s\n",
      "2978:\tlearn: 0.0000090\ttotal: 1.7s\tremaining: 4.01s\n",
      "2979:\tlearn: 0.0000090\ttotal: 1.7s\tremaining: 4.01s\n",
      "2980:\tlearn: 0.0000090\ttotal: 1.7s\tremaining: 4.01s\n",
      "2981:\tlearn: 0.0000089\ttotal: 1.71s\tremaining: 4.01s\n",
      "2982:\tlearn: 0.0000089\ttotal: 1.71s\tremaining: 4.01s\n",
      "2983:\tlearn: 0.0000088\ttotal: 1.71s\tremaining: 4.01s\n",
      "2984:\tlearn: 0.0000088\ttotal: 1.71s\tremaining: 4.01s\n",
      "2985:\tlearn: 0.0000088\ttotal: 1.71s\tremaining: 4.01s\n",
      "2986:\tlearn: 0.0000087\ttotal: 1.71s\tremaining: 4.01s\n",
      "2987:\tlearn: 0.0000087\ttotal: 1.71s\tremaining: 4.01s\n",
      "2988:\tlearn: 0.0000087\ttotal: 1.71s\tremaining: 4.01s\n",
      "2989:\tlearn: 0.0000086\ttotal: 1.71s\tremaining: 4.01s\n",
      "2990:\tlearn: 0.0000086\ttotal: 1.71s\tremaining: 4.01s\n",
      "2991:\tlearn: 0.0000085\ttotal: 1.71s\tremaining: 4.01s\n",
      "2992:\tlearn: 0.0000084\ttotal: 1.71s\tremaining: 4.01s\n",
      "2993:\tlearn: 0.0000084\ttotal: 1.71s\tremaining: 4.01s\n",
      "2994:\tlearn: 0.0000084\ttotal: 1.71s\tremaining: 4s\n",
      "2995:\tlearn: 0.0000084\ttotal: 1.71s\tremaining: 4s\n",
      "2996:\tlearn: 0.0000084\ttotal: 1.71s\tremaining: 4s\n",
      "2997:\tlearn: 0.0000083\ttotal: 1.71s\tremaining: 4s\n",
      "2998:\tlearn: 0.0000083\ttotal: 1.71s\tremaining: 4s\n",
      "2999:\tlearn: 0.0000083\ttotal: 1.72s\tremaining: 4s\n",
      "3000:\tlearn: 0.0000083\ttotal: 1.72s\tremaining: 4s\n",
      "3001:\tlearn: 0.0000083\ttotal: 1.72s\tremaining: 4s\n",
      "3002:\tlearn: 0.0000083\ttotal: 1.72s\tremaining: 4s\n",
      "3003:\tlearn: 0.0000082\ttotal: 1.72s\tremaining: 4s\n",
      "3004:\tlearn: 0.0000082\ttotal: 1.72s\tremaining: 4s\n",
      "3005:\tlearn: 0.0000082\ttotal: 1.72s\tremaining: 4s\n",
      "3006:\tlearn: 0.0000082\ttotal: 1.72s\tremaining: 4s\n",
      "3007:\tlearn: 0.0000082\ttotal: 1.72s\tremaining: 4s\n",
      "3008:\tlearn: 0.0000081\ttotal: 1.72s\tremaining: 4s\n",
      "3009:\tlearn: 0.0000081\ttotal: 1.72s\tremaining: 4s\n",
      "3010:\tlearn: 0.0000080\ttotal: 1.72s\tremaining: 3.99s\n",
      "3011:\tlearn: 0.0000080\ttotal: 1.72s\tremaining: 3.99s\n",
      "3012:\tlearn: 0.0000080\ttotal: 1.72s\tremaining: 3.99s\n",
      "3013:\tlearn: 0.0000079\ttotal: 1.72s\tremaining: 3.99s\n",
      "3014:\tlearn: 0.0000079\ttotal: 1.72s\tremaining: 3.99s\n",
      "3015:\tlearn: 0.0000079\ttotal: 1.72s\tremaining: 3.99s\n",
      "3016:\tlearn: 0.0000078\ttotal: 1.72s\tremaining: 3.99s\n",
      "3017:\tlearn: 0.0000078\ttotal: 1.73s\tremaining: 3.99s\n",
      "3018:\tlearn: 0.0000078\ttotal: 1.73s\tremaining: 3.99s\n",
      "3019:\tlearn: 0.0000078\ttotal: 1.73s\tremaining: 3.99s\n",
      "3020:\tlearn: 0.0000078\ttotal: 1.73s\tremaining: 3.99s\n",
      "3021:\tlearn: 0.0000077\ttotal: 1.73s\tremaining: 3.99s\n",
      "3022:\tlearn: 0.0000077\ttotal: 1.73s\tremaining: 3.99s\n",
      "3023:\tlearn: 0.0000076\ttotal: 1.73s\tremaining: 3.99s\n",
      "3024:\tlearn: 0.0000076\ttotal: 1.73s\tremaining: 3.98s\n",
      "3025:\tlearn: 0.0000076\ttotal: 1.73s\tremaining: 3.98s\n",
      "3026:\tlearn: 0.0000076\ttotal: 1.73s\tremaining: 3.98s\n",
      "3027:\tlearn: 0.0000075\ttotal: 1.73s\tremaining: 3.98s\n",
      "3028:\tlearn: 0.0000075\ttotal: 1.73s\tremaining: 3.98s\n",
      "3029:\tlearn: 0.0000074\ttotal: 1.73s\tremaining: 3.98s\n",
      "3030:\tlearn: 0.0000074\ttotal: 1.73s\tremaining: 3.98s\n",
      "3031:\tlearn: 0.0000073\ttotal: 1.73s\tremaining: 3.98s\n",
      "3032:\tlearn: 0.0000073\ttotal: 1.73s\tremaining: 3.98s\n",
      "3033:\tlearn: 0.0000073\ttotal: 1.73s\tremaining: 3.98s\n",
      "3034:\tlearn: 0.0000072\ttotal: 1.73s\tremaining: 3.98s\n",
      "3035:\tlearn: 0.0000072\ttotal: 1.73s\tremaining: 3.98s\n",
      "3036:\tlearn: 0.0000072\ttotal: 1.73s\tremaining: 3.98s\n",
      "3037:\tlearn: 0.0000071\ttotal: 1.73s\tremaining: 3.98s\n",
      "3038:\tlearn: 0.0000071\ttotal: 1.74s\tremaining: 3.97s\n",
      "3039:\tlearn: 0.0000071\ttotal: 1.74s\tremaining: 3.97s\n",
      "3040:\tlearn: 0.0000070\ttotal: 1.74s\tremaining: 3.97s\n",
      "3041:\tlearn: 0.0000069\ttotal: 1.74s\tremaining: 3.97s\n",
      "3042:\tlearn: 0.0000069\ttotal: 1.74s\tremaining: 3.97s\n",
      "3043:\tlearn: 0.0000069\ttotal: 1.74s\tremaining: 3.97s\n",
      "3044:\tlearn: 0.0000068\ttotal: 1.74s\tremaining: 3.97s\n",
      "3045:\tlearn: 0.0000068\ttotal: 1.74s\tremaining: 3.97s\n",
      "3046:\tlearn: 0.0000067\ttotal: 1.74s\tremaining: 3.97s\n",
      "3047:\tlearn: 0.0000067\ttotal: 1.74s\tremaining: 3.97s\n",
      "3048:\tlearn: 0.0000067\ttotal: 1.74s\tremaining: 3.97s\n",
      "3049:\tlearn: 0.0000066\ttotal: 1.74s\tremaining: 3.97s\n",
      "3050:\tlearn: 0.0000066\ttotal: 1.74s\tremaining: 3.97s\n",
      "3051:\tlearn: 0.0000066\ttotal: 1.74s\tremaining: 3.97s\n",
      "3052:\tlearn: 0.0000065\ttotal: 1.74s\tremaining: 3.96s\n",
      "3053:\tlearn: 0.0000065\ttotal: 1.74s\tremaining: 3.96s\n",
      "3054:\tlearn: 0.0000065\ttotal: 1.74s\tremaining: 3.96s\n",
      "3055:\tlearn: 0.0000065\ttotal: 1.74s\tremaining: 3.96s\n",
      "3056:\tlearn: 0.0000064\ttotal: 1.74s\tremaining: 3.96s\n",
      "3057:\tlearn: 0.0000064\ttotal: 1.75s\tremaining: 3.96s\n",
      "3058:\tlearn: 0.0000064\ttotal: 1.75s\tremaining: 3.96s\n",
      "3059:\tlearn: 0.0000064\ttotal: 1.75s\tremaining: 3.96s\n",
      "3060:\tlearn: 0.0000064\ttotal: 1.75s\tremaining: 3.96s\n",
      "3061:\tlearn: 0.0000063\ttotal: 1.75s\tremaining: 3.96s\n",
      "3062:\tlearn: 0.0000063\ttotal: 1.75s\tremaining: 3.96s\n",
      "3063:\tlearn: 0.0000062\ttotal: 1.75s\tremaining: 3.96s\n",
      "3064:\tlearn: 0.0000062\ttotal: 1.75s\tremaining: 3.96s\n",
      "3065:\tlearn: 0.0000062\ttotal: 1.75s\tremaining: 3.96s\n",
      "3066:\tlearn: 0.0000062\ttotal: 1.75s\tremaining: 3.96s\n",
      "3067:\tlearn: 0.0000061\ttotal: 1.75s\tremaining: 3.95s\n",
      "3068:\tlearn: 0.0000061\ttotal: 1.75s\tremaining: 3.95s\n",
      "3069:\tlearn: 0.0000061\ttotal: 1.75s\tremaining: 3.95s\n",
      "3070:\tlearn: 0.0000060\ttotal: 1.75s\tremaining: 3.95s\n",
      "3071:\tlearn: 0.0000060\ttotal: 1.75s\tremaining: 3.95s\n",
      "3072:\tlearn: 0.0000060\ttotal: 1.75s\tremaining: 3.95s\n",
      "3073:\tlearn: 0.0000059\ttotal: 1.75s\tremaining: 3.95s\n",
      "3074:\tlearn: 0.0000059\ttotal: 1.75s\tremaining: 3.95s\n",
      "3075:\tlearn: 0.0000059\ttotal: 1.75s\tremaining: 3.95s\n",
      "3076:\tlearn: 0.0000059\ttotal: 1.75s\tremaining: 3.95s\n",
      "3077:\tlearn: 0.0000058\ttotal: 1.75s\tremaining: 3.95s\n",
      "3078:\tlearn: 0.0000058\ttotal: 1.76s\tremaining: 3.95s\n",
      "3079:\tlearn: 0.0000058\ttotal: 1.76s\tremaining: 3.95s\n",
      "3080:\tlearn: 0.0000058\ttotal: 1.76s\tremaining: 3.94s\n",
      "3081:\tlearn: 0.0000058\ttotal: 1.76s\tremaining: 3.94s\n",
      "3082:\tlearn: 0.0000058\ttotal: 1.76s\tremaining: 3.94s\n",
      "3083:\tlearn: 0.0000058\ttotal: 1.76s\tremaining: 3.94s\n",
      "3084:\tlearn: 0.0000057\ttotal: 1.76s\tremaining: 3.94s\n",
      "3085:\tlearn: 0.0000057\ttotal: 1.76s\tremaining: 3.94s\n",
      "3086:\tlearn: 0.0000057\ttotal: 1.76s\tremaining: 3.94s\n",
      "3087:\tlearn: 0.0000057\ttotal: 1.76s\tremaining: 3.94s\n",
      "3088:\tlearn: 0.0000057\ttotal: 1.76s\tremaining: 3.94s\n",
      "3089:\tlearn: 0.0000056\ttotal: 1.76s\tremaining: 3.94s\n",
      "3090:\tlearn: 0.0000056\ttotal: 1.76s\tremaining: 3.94s\n",
      "3091:\tlearn: 0.0000056\ttotal: 1.76s\tremaining: 3.94s\n",
      "3092:\tlearn: 0.0000056\ttotal: 1.76s\tremaining: 3.94s\n",
      "3093:\tlearn: 0.0000056\ttotal: 1.76s\tremaining: 3.94s\n",
      "3094:\tlearn: 0.0000055\ttotal: 1.76s\tremaining: 3.94s\n",
      "3095:\tlearn: 0.0000055\ttotal: 1.76s\tremaining: 3.94s\n",
      "3096:\tlearn: 0.0000054\ttotal: 1.76s\tremaining: 3.93s\n",
      "3097:\tlearn: 0.0000054\ttotal: 1.76s\tremaining: 3.93s\n",
      "3098:\tlearn: 0.0000054\ttotal: 1.77s\tremaining: 3.93s\n",
      "3099:\tlearn: 0.0000054\ttotal: 1.77s\tremaining: 3.93s\n",
      "3100:\tlearn: 0.0000053\ttotal: 1.77s\tremaining: 3.93s\n",
      "3101:\tlearn: 0.0000053\ttotal: 1.77s\tremaining: 3.93s\n",
      "3102:\tlearn: 0.0000053\ttotal: 1.77s\tremaining: 3.93s\n",
      "3103:\tlearn: 0.0000052\ttotal: 1.77s\tremaining: 3.93s\n",
      "3104:\tlearn: 0.0000052\ttotal: 1.77s\tremaining: 3.93s\n",
      "3105:\tlearn: 0.0000052\ttotal: 1.77s\tremaining: 3.93s\n",
      "3106:\tlearn: 0.0000052\ttotal: 1.77s\tremaining: 3.93s\n",
      "3107:\tlearn: 0.0000052\ttotal: 1.77s\tremaining: 3.93s\n",
      "3108:\tlearn: 0.0000052\ttotal: 1.77s\tremaining: 3.93s\n",
      "3109:\tlearn: 0.0000051\ttotal: 1.77s\tremaining: 3.93s\n",
      "3110:\tlearn: 0.0000051\ttotal: 1.77s\tremaining: 3.93s\n",
      "3111:\tlearn: 0.0000051\ttotal: 1.77s\tremaining: 3.93s\n",
      "3112:\tlearn: 0.0000050\ttotal: 1.77s\tremaining: 3.93s\n",
      "3113:\tlearn: 0.0000050\ttotal: 1.77s\tremaining: 3.93s\n",
      "3114:\tlearn: 0.0000050\ttotal: 1.78s\tremaining: 3.92s\n",
      "3115:\tlearn: 0.0000050\ttotal: 1.78s\tremaining: 3.92s\n",
      "3116:\tlearn: 0.0000049\ttotal: 1.78s\tremaining: 3.92s\n",
      "3117:\tlearn: 0.0000049\ttotal: 1.78s\tremaining: 3.92s\n",
      "3118:\tlearn: 0.0000049\ttotal: 1.78s\tremaining: 3.92s\n",
      "3119:\tlearn: 0.0000049\ttotal: 1.78s\tremaining: 3.92s\n",
      "3120:\tlearn: 0.0000049\ttotal: 1.78s\tremaining: 3.92s\n",
      "3121:\tlearn: 0.0000048\ttotal: 1.78s\tremaining: 3.92s\n",
      "3122:\tlearn: 0.0000048\ttotal: 1.78s\tremaining: 3.92s\n",
      "3123:\tlearn: 0.0000048\ttotal: 1.78s\tremaining: 3.92s\n",
      "3124:\tlearn: 0.0000048\ttotal: 1.78s\tremaining: 3.92s\n",
      "3125:\tlearn: 0.0000048\ttotal: 1.78s\tremaining: 3.92s\n",
      "3126:\tlearn: 0.0000048\ttotal: 1.78s\tremaining: 3.92s\n",
      "3127:\tlearn: 0.0000048\ttotal: 1.78s\tremaining: 3.92s\n",
      "3128:\tlearn: 0.0000048\ttotal: 1.78s\tremaining: 3.92s\n",
      "3129:\tlearn: 0.0000047\ttotal: 1.78s\tremaining: 3.92s\n",
      "3130:\tlearn: 0.0000047\ttotal: 1.78s\tremaining: 3.92s\n",
      "3131:\tlearn: 0.0000047\ttotal: 1.78s\tremaining: 3.92s\n",
      "3132:\tlearn: 0.0000047\ttotal: 1.79s\tremaining: 3.92s\n",
      "3133:\tlearn: 0.0000047\ttotal: 1.79s\tremaining: 3.91s\n",
      "3134:\tlearn: 0.0000047\ttotal: 1.79s\tremaining: 3.91s\n",
      "3135:\tlearn: 0.0000046\ttotal: 1.79s\tremaining: 3.91s\n",
      "3136:\tlearn: 0.0000046\ttotal: 1.79s\tremaining: 3.91s\n",
      "3137:\tlearn: 0.0000046\ttotal: 1.79s\tremaining: 3.91s\n",
      "3138:\tlearn: 0.0000046\ttotal: 1.79s\tremaining: 3.91s\n",
      "3139:\tlearn: 0.0000046\ttotal: 1.79s\tremaining: 3.91s\n",
      "3140:\tlearn: 0.0000046\ttotal: 1.79s\tremaining: 3.91s\n",
      "3141:\tlearn: 0.0000045\ttotal: 1.79s\tremaining: 3.91s\n",
      "3142:\tlearn: 0.0000045\ttotal: 1.79s\tremaining: 3.91s\n",
      "3143:\tlearn: 0.0000045\ttotal: 1.79s\tremaining: 3.91s\n",
      "3144:\tlearn: 0.0000044\ttotal: 1.79s\tremaining: 3.91s\n",
      "3145:\tlearn: 0.0000044\ttotal: 1.79s\tremaining: 3.91s\n",
      "3146:\tlearn: 0.0000044\ttotal: 1.79s\tremaining: 3.91s\n",
      "3147:\tlearn: 0.0000044\ttotal: 1.8s\tremaining: 3.91s\n",
      "3148:\tlearn: 0.0000044\ttotal: 1.8s\tremaining: 3.91s\n",
      "3149:\tlearn: 0.0000044\ttotal: 1.8s\tremaining: 3.91s\n",
      "3150:\tlearn: 0.0000043\ttotal: 1.8s\tremaining: 3.91s\n",
      "3151:\tlearn: 0.0000043\ttotal: 1.8s\tremaining: 3.91s\n",
      "3152:\tlearn: 0.0000043\ttotal: 1.8s\tremaining: 3.91s\n",
      "3153:\tlearn: 0.0000042\ttotal: 1.8s\tremaining: 3.9s\n",
      "3154:\tlearn: 0.0000042\ttotal: 1.8s\tremaining: 3.9s\n",
      "3155:\tlearn: 0.0000042\ttotal: 1.8s\tremaining: 3.9s\n",
      "3156:\tlearn: 0.0000042\ttotal: 1.8s\tremaining: 3.9s\n",
      "3157:\tlearn: 0.0000042\ttotal: 1.8s\tremaining: 3.9s\n",
      "3158:\tlearn: 0.0000041\ttotal: 1.8s\tremaining: 3.9s\n",
      "3159:\tlearn: 0.0000041\ttotal: 1.8s\tremaining: 3.9s\n",
      "3160:\tlearn: 0.0000041\ttotal: 1.8s\tremaining: 3.9s\n",
      "3161:\tlearn: 0.0000041\ttotal: 1.8s\tremaining: 3.9s\n",
      "3162:\tlearn: 0.0000040\ttotal: 1.8s\tremaining: 3.9s\n",
      "3163:\tlearn: 0.0000040\ttotal: 1.8s\tremaining: 3.9s\n",
      "3164:\tlearn: 0.0000040\ttotal: 1.8s\tremaining: 3.9s\n",
      "3165:\tlearn: 0.0000040\ttotal: 1.81s\tremaining: 3.9s\n",
      "3166:\tlearn: 0.0000040\ttotal: 1.81s\tremaining: 3.9s\n",
      "3167:\tlearn: 0.0000039\ttotal: 1.81s\tremaining: 3.9s\n",
      "3168:\tlearn: 0.0000039\ttotal: 1.81s\tremaining: 3.9s\n",
      "3169:\tlearn: 0.0000039\ttotal: 1.81s\tremaining: 3.9s\n",
      "3170:\tlearn: 0.0000039\ttotal: 1.81s\tremaining: 3.9s\n",
      "3171:\tlearn: 0.0000039\ttotal: 1.81s\tremaining: 3.9s\n",
      "3172:\tlearn: 0.0000039\ttotal: 1.81s\tremaining: 3.9s\n",
      "3173:\tlearn: 0.0000038\ttotal: 1.81s\tremaining: 3.9s\n",
      "3174:\tlearn: 0.0000038\ttotal: 1.81s\tremaining: 3.89s\n",
      "3175:\tlearn: 0.0000038\ttotal: 1.81s\tremaining: 3.89s\n",
      "3176:\tlearn: 0.0000038\ttotal: 1.81s\tremaining: 3.89s\n",
      "3177:\tlearn: 0.0000038\ttotal: 1.81s\tremaining: 3.89s\n",
      "3178:\tlearn: 0.0000038\ttotal: 1.81s\tremaining: 3.89s\n",
      "3179:\tlearn: 0.0000038\ttotal: 1.81s\tremaining: 3.89s\n",
      "3180:\tlearn: 0.0000037\ttotal: 1.81s\tremaining: 3.89s\n",
      "3181:\tlearn: 0.0000037\ttotal: 1.81s\tremaining: 3.89s\n",
      "3182:\tlearn: 0.0000037\ttotal: 1.81s\tremaining: 3.89s\n",
      "3183:\tlearn: 0.0000037\ttotal: 1.82s\tremaining: 3.89s\n",
      "3184:\tlearn: 0.0000037\ttotal: 1.82s\tremaining: 3.89s\n",
      "3185:\tlearn: 0.0000036\ttotal: 1.82s\tremaining: 3.88s\n",
      "3186:\tlearn: 0.0000036\ttotal: 1.82s\tremaining: 3.88s\n",
      "3187:\tlearn: 0.0000036\ttotal: 1.82s\tremaining: 3.88s\n",
      "3188:\tlearn: 0.0000036\ttotal: 1.82s\tremaining: 3.88s\n",
      "3189:\tlearn: 0.0000036\ttotal: 1.82s\tremaining: 3.88s\n",
      "3190:\tlearn: 0.0000036\ttotal: 1.82s\tremaining: 3.88s\n",
      "3191:\tlearn: 0.0000036\ttotal: 1.82s\tremaining: 3.88s\n",
      "3192:\tlearn: 0.0000036\ttotal: 1.82s\tremaining: 3.88s\n",
      "3193:\tlearn: 0.0000035\ttotal: 1.82s\tremaining: 3.88s\n",
      "3194:\tlearn: 0.0000035\ttotal: 1.82s\tremaining: 3.88s\n",
      "3195:\tlearn: 0.0000035\ttotal: 1.82s\tremaining: 3.88s\n",
      "3196:\tlearn: 0.0000035\ttotal: 1.82s\tremaining: 3.88s\n",
      "3197:\tlearn: 0.0000035\ttotal: 1.82s\tremaining: 3.88s\n",
      "3198:\tlearn: 0.0000035\ttotal: 1.82s\tremaining: 3.88s\n",
      "3199:\tlearn: 0.0000035\ttotal: 1.82s\tremaining: 3.88s\n",
      "3200:\tlearn: 0.0000035\ttotal: 1.82s\tremaining: 3.88s\n",
      "3201:\tlearn: 0.0000034\ttotal: 1.82s\tremaining: 3.88s\n",
      "3202:\tlearn: 0.0000034\ttotal: 1.82s\tremaining: 3.87s\n",
      "3203:\tlearn: 0.0000034\ttotal: 1.83s\tremaining: 3.87s\n",
      "3204:\tlearn: 0.0000034\ttotal: 1.83s\tremaining: 3.87s\n",
      "3205:\tlearn: 0.0000034\ttotal: 1.83s\tremaining: 3.87s\n",
      "3206:\tlearn: 0.0000034\ttotal: 1.83s\tremaining: 3.87s\n",
      "3207:\tlearn: 0.0000034\ttotal: 1.83s\tremaining: 3.87s\n",
      "3208:\tlearn: 0.0000033\ttotal: 1.83s\tremaining: 3.87s\n",
      "3209:\tlearn: 0.0000033\ttotal: 1.83s\tremaining: 3.87s\n",
      "3210:\tlearn: 0.0000033\ttotal: 1.83s\tremaining: 3.87s\n",
      "3211:\tlearn: 0.0000033\ttotal: 1.83s\tremaining: 3.87s\n",
      "3212:\tlearn: 0.0000033\ttotal: 1.83s\tremaining: 3.87s\n",
      "3213:\tlearn: 0.0000033\ttotal: 1.83s\tremaining: 3.87s\n",
      "3214:\tlearn: 0.0000033\ttotal: 1.83s\tremaining: 3.86s\n",
      "3215:\tlearn: 0.0000033\ttotal: 1.83s\tremaining: 3.86s\n",
      "3216:\tlearn: 0.0000032\ttotal: 1.83s\tremaining: 3.86s\n",
      "3217:\tlearn: 0.0000032\ttotal: 1.83s\tremaining: 3.86s\n",
      "3218:\tlearn: 0.0000032\ttotal: 1.83s\tremaining: 3.86s\n",
      "3219:\tlearn: 0.0000032\ttotal: 1.83s\tremaining: 3.86s\n",
      "3220:\tlearn: 0.0000032\ttotal: 1.83s\tremaining: 3.86s\n",
      "3221:\tlearn: 0.0000032\ttotal: 1.83s\tremaining: 3.86s\n",
      "3222:\tlearn: 0.0000031\ttotal: 1.83s\tremaining: 3.86s\n",
      "3223:\tlearn: 0.0000031\ttotal: 1.83s\tremaining: 3.86s\n",
      "3224:\tlearn: 0.0000031\ttotal: 1.84s\tremaining: 3.86s\n",
      "3225:\tlearn: 0.0000031\ttotal: 1.84s\tremaining: 3.86s\n",
      "3226:\tlearn: 0.0000031\ttotal: 1.84s\tremaining: 3.86s\n",
      "3227:\tlearn: 0.0000031\ttotal: 1.84s\tremaining: 3.86s\n",
      "3228:\tlearn: 0.0000031\ttotal: 1.84s\tremaining: 3.85s\n",
      "3229:\tlearn: 0.0000030\ttotal: 1.84s\tremaining: 3.85s\n",
      "3230:\tlearn: 0.0000030\ttotal: 1.84s\tremaining: 3.85s\n",
      "3231:\tlearn: 0.0000030\ttotal: 1.84s\tremaining: 3.85s\n",
      "3232:\tlearn: 0.0000030\ttotal: 1.84s\tremaining: 3.85s\n",
      "3233:\tlearn: 0.0000030\ttotal: 1.84s\tremaining: 3.85s\n",
      "3234:\tlearn: 0.0000030\ttotal: 1.84s\tremaining: 3.85s\n",
      "3235:\tlearn: 0.0000030\ttotal: 1.84s\tremaining: 3.85s\n",
      "3236:\tlearn: 0.0000029\ttotal: 1.84s\tremaining: 3.85s\n",
      "3237:\tlearn: 0.0000029\ttotal: 1.84s\tremaining: 3.85s\n",
      "3238:\tlearn: 0.0000029\ttotal: 1.84s\tremaining: 3.85s\n",
      "3239:\tlearn: 0.0000029\ttotal: 1.84s\tremaining: 3.85s\n",
      "3240:\tlearn: 0.0000029\ttotal: 1.84s\tremaining: 3.85s\n",
      "3241:\tlearn: 0.0000029\ttotal: 1.84s\tremaining: 3.85s\n",
      "3242:\tlearn: 0.0000029\ttotal: 1.84s\tremaining: 3.84s\n",
      "3243:\tlearn: 0.0000028\ttotal: 1.84s\tremaining: 3.84s\n",
      "3244:\tlearn: 0.0000028\ttotal: 1.85s\tremaining: 3.84s\n",
      "3245:\tlearn: 0.0000028\ttotal: 1.85s\tremaining: 3.84s\n",
      "3246:\tlearn: 0.0000028\ttotal: 1.85s\tremaining: 3.84s\n",
      "3247:\tlearn: 0.0000028\ttotal: 1.85s\tremaining: 3.84s\n",
      "3248:\tlearn: 0.0000028\ttotal: 1.85s\tremaining: 3.84s\n",
      "3249:\tlearn: 0.0000028\ttotal: 1.85s\tremaining: 3.84s\n",
      "3250:\tlearn: 0.0000028\ttotal: 1.85s\tremaining: 3.84s\n",
      "3251:\tlearn: 0.0000028\ttotal: 1.85s\tremaining: 3.84s\n",
      "3252:\tlearn: 0.0000028\ttotal: 1.85s\tremaining: 3.84s\n",
      "3253:\tlearn: 0.0000028\ttotal: 1.85s\tremaining: 3.83s\n",
      "3254:\tlearn: 0.0000027\ttotal: 1.85s\tremaining: 3.83s\n",
      "3255:\tlearn: 0.0000027\ttotal: 1.85s\tremaining: 3.83s\n",
      "3256:\tlearn: 0.0000027\ttotal: 1.85s\tremaining: 3.83s\n",
      "3257:\tlearn: 0.0000027\ttotal: 1.85s\tremaining: 3.83s\n",
      "3258:\tlearn: 0.0000027\ttotal: 1.85s\tremaining: 3.83s\n",
      "3259:\tlearn: 0.0000027\ttotal: 1.85s\tremaining: 3.83s\n",
      "3260:\tlearn: 0.0000026\ttotal: 1.85s\tremaining: 3.83s\n",
      "3261:\tlearn: 0.0000026\ttotal: 1.85s\tremaining: 3.83s\n",
      "3262:\tlearn: 0.0000026\ttotal: 1.85s\tremaining: 3.83s\n",
      "3263:\tlearn: 0.0000026\ttotal: 1.85s\tremaining: 3.83s\n",
      "3264:\tlearn: 0.0000026\ttotal: 1.86s\tremaining: 3.83s\n",
      "3265:\tlearn: 0.0000026\ttotal: 1.86s\tremaining: 3.83s\n",
      "3266:\tlearn: 0.0000026\ttotal: 1.86s\tremaining: 3.83s\n",
      "3267:\tlearn: 0.0000026\ttotal: 1.86s\tremaining: 3.83s\n",
      "3268:\tlearn: 0.0000025\ttotal: 1.86s\tremaining: 3.83s\n",
      "3269:\tlearn: 0.0000025\ttotal: 1.86s\tremaining: 3.82s\n",
      "3270:\tlearn: 0.0000025\ttotal: 1.86s\tremaining: 3.82s\n",
      "3271:\tlearn: 0.0000025\ttotal: 1.86s\tremaining: 3.82s\n",
      "3272:\tlearn: 0.0000025\ttotal: 1.86s\tremaining: 3.82s\n",
      "3273:\tlearn: 0.0000025\ttotal: 1.86s\tremaining: 3.82s\n",
      "3274:\tlearn: 0.0000025\ttotal: 1.86s\tremaining: 3.82s\n",
      "3275:\tlearn: 0.0000025\ttotal: 1.86s\tremaining: 3.82s\n",
      "3276:\tlearn: 0.0000024\ttotal: 1.86s\tremaining: 3.82s\n",
      "3277:\tlearn: 0.0000024\ttotal: 1.86s\tremaining: 3.82s\n",
      "3278:\tlearn: 0.0000024\ttotal: 1.86s\tremaining: 3.82s\n",
      "3279:\tlearn: 0.0000024\ttotal: 1.86s\tremaining: 3.82s\n",
      "3280:\tlearn: 0.0000024\ttotal: 1.86s\tremaining: 3.82s\n",
      "3281:\tlearn: 0.0000024\ttotal: 1.86s\tremaining: 3.81s\n",
      "3282:\tlearn: 0.0000024\ttotal: 1.86s\tremaining: 3.81s\n",
      "3283:\tlearn: 0.0000024\ttotal: 1.86s\tremaining: 3.81s\n",
      "3284:\tlearn: 0.0000024\ttotal: 1.86s\tremaining: 3.81s\n",
      "3285:\tlearn: 0.0000024\ttotal: 1.87s\tremaining: 3.81s\n",
      "3286:\tlearn: 0.0000024\ttotal: 1.87s\tremaining: 3.81s\n",
      "3287:\tlearn: 0.0000023\ttotal: 1.87s\tremaining: 3.81s\n",
      "3288:\tlearn: 0.0000023\ttotal: 1.87s\tremaining: 3.81s\n",
      "3289:\tlearn: 0.0000023\ttotal: 1.87s\tremaining: 3.81s\n",
      "3290:\tlearn: 0.0000023\ttotal: 1.87s\tremaining: 3.81s\n",
      "3291:\tlearn: 0.0000023\ttotal: 1.87s\tremaining: 3.81s\n",
      "3292:\tlearn: 0.0000023\ttotal: 1.87s\tremaining: 3.81s\n",
      "3293:\tlearn: 0.0000023\ttotal: 1.87s\tremaining: 3.81s\n",
      "3294:\tlearn: 0.0000023\ttotal: 1.87s\tremaining: 3.81s\n",
      "3295:\tlearn: 0.0000023\ttotal: 1.87s\tremaining: 3.81s\n",
      "3296:\tlearn: 0.0000023\ttotal: 1.87s\tremaining: 3.81s\n",
      "3297:\tlearn: 0.0000023\ttotal: 1.87s\tremaining: 3.81s\n",
      "3298:\tlearn: 0.0000022\ttotal: 1.87s\tremaining: 3.81s\n",
      "3299:\tlearn: 0.0000022\ttotal: 1.87s\tremaining: 3.81s\n",
      "3300:\tlearn: 0.0000022\ttotal: 1.87s\tremaining: 3.8s\n",
      "3301:\tlearn: 0.0000022\ttotal: 1.88s\tremaining: 3.8s\n",
      "3302:\tlearn: 0.0000022\ttotal: 1.88s\tremaining: 3.8s\n",
      "3303:\tlearn: 0.0000022\ttotal: 1.88s\tremaining: 3.8s\n",
      "3304:\tlearn: 0.0000022\ttotal: 1.88s\tremaining: 3.8s\n",
      "3305:\tlearn: 0.0000022\ttotal: 1.88s\tremaining: 3.8s\n",
      "3306:\tlearn: 0.0000022\ttotal: 1.88s\tremaining: 3.8s\n",
      "3307:\tlearn: 0.0000022\ttotal: 1.88s\tremaining: 3.8s\n",
      "3308:\tlearn: 0.0000022\ttotal: 1.88s\tremaining: 3.8s\n",
      "3309:\tlearn: 0.0000022\ttotal: 1.88s\tremaining: 3.8s\n",
      "3310:\tlearn: 0.0000021\ttotal: 1.88s\tremaining: 3.8s\n",
      "3311:\tlearn: 0.0000021\ttotal: 1.88s\tremaining: 3.8s\n",
      "3312:\tlearn: 0.0000021\ttotal: 1.88s\tremaining: 3.79s\n",
      "3313:\tlearn: 0.0000021\ttotal: 1.88s\tremaining: 3.79s\n",
      "3314:\tlearn: 0.0000021\ttotal: 1.88s\tremaining: 3.79s\n",
      "3315:\tlearn: 0.0000021\ttotal: 1.88s\tremaining: 3.79s\n",
      "3316:\tlearn: 0.0000021\ttotal: 1.88s\tremaining: 3.79s\n",
      "3317:\tlearn: 0.0000021\ttotal: 1.88s\tremaining: 3.79s\n",
      "3318:\tlearn: 0.0000021\ttotal: 1.88s\tremaining: 3.79s\n",
      "3319:\tlearn: 0.0000021\ttotal: 1.88s\tremaining: 3.79s\n",
      "3320:\tlearn: 0.0000021\ttotal: 1.88s\tremaining: 3.79s\n",
      "3321:\tlearn: 0.0000021\ttotal: 1.89s\tremaining: 3.79s\n",
      "3322:\tlearn: 0.0000021\ttotal: 1.89s\tremaining: 3.79s\n",
      "3323:\tlearn: 0.0000021\ttotal: 1.89s\tremaining: 3.79s\n",
      "3324:\tlearn: 0.0000021\ttotal: 1.89s\tremaining: 3.79s\n",
      "3325:\tlearn: 0.0000020\ttotal: 1.89s\tremaining: 3.79s\n",
      "3326:\tlearn: 0.0000020\ttotal: 1.89s\tremaining: 3.79s\n",
      "3327:\tlearn: 0.0000020\ttotal: 1.89s\tremaining: 3.78s\n",
      "3328:\tlearn: 0.0000020\ttotal: 1.89s\tremaining: 3.78s\n",
      "3329:\tlearn: 0.0000020\ttotal: 1.89s\tremaining: 3.78s\n",
      "3330:\tlearn: 0.0000020\ttotal: 1.89s\tremaining: 3.78s\n",
      "3331:\tlearn: 0.0000020\ttotal: 1.89s\tremaining: 3.78s\n",
      "3332:\tlearn: 0.0000020\ttotal: 1.89s\tremaining: 3.78s\n",
      "3333:\tlearn: 0.0000020\ttotal: 1.89s\tremaining: 3.78s\n",
      "3334:\tlearn: 0.0000019\ttotal: 1.89s\tremaining: 3.78s\n",
      "3335:\tlearn: 0.0000019\ttotal: 1.89s\tremaining: 3.78s\n",
      "3336:\tlearn: 0.0000019\ttotal: 1.89s\tremaining: 3.78s\n",
      "3337:\tlearn: 0.0000019\ttotal: 1.89s\tremaining: 3.78s\n",
      "3338:\tlearn: 0.0000019\ttotal: 1.89s\tremaining: 3.78s\n",
      "3339:\tlearn: 0.0000019\ttotal: 1.89s\tremaining: 3.77s\n",
      "3340:\tlearn: 0.0000019\ttotal: 1.89s\tremaining: 3.77s\n",
      "3341:\tlearn: 0.0000019\ttotal: 1.89s\tremaining: 3.77s\n",
      "3342:\tlearn: 0.0000019\ttotal: 1.9s\tremaining: 3.77s\n",
      "3343:\tlearn: 0.0000019\ttotal: 1.9s\tremaining: 3.77s\n",
      "3344:\tlearn: 0.0000019\ttotal: 1.9s\tremaining: 3.77s\n",
      "3345:\tlearn: 0.0000019\ttotal: 1.9s\tremaining: 3.77s\n",
      "3346:\tlearn: 0.0000019\ttotal: 1.9s\tremaining: 3.77s\n",
      "3347:\tlearn: 0.0000018\ttotal: 1.9s\tremaining: 3.77s\n",
      "3348:\tlearn: 0.0000018\ttotal: 1.9s\tremaining: 3.77s\n",
      "3349:\tlearn: 0.0000018\ttotal: 1.9s\tremaining: 3.77s\n",
      "3350:\tlearn: 0.0000018\ttotal: 1.9s\tremaining: 3.77s\n",
      "3351:\tlearn: 0.0000018\ttotal: 1.9s\tremaining: 3.77s\n",
      "3352:\tlearn: 0.0000018\ttotal: 1.9s\tremaining: 3.77s\n",
      "3353:\tlearn: 0.0000018\ttotal: 1.9s\tremaining: 3.77s\n",
      "3354:\tlearn: 0.0000018\ttotal: 1.9s\tremaining: 3.77s\n",
      "3355:\tlearn: 0.0000018\ttotal: 1.9s\tremaining: 3.77s\n",
      "3356:\tlearn: 0.0000018\ttotal: 1.9s\tremaining: 3.76s\n",
      "3357:\tlearn: 0.0000018\ttotal: 1.9s\tremaining: 3.76s\n",
      "3358:\tlearn: 0.0000018\ttotal: 1.9s\tremaining: 3.76s\n",
      "3359:\tlearn: 0.0000017\ttotal: 1.9s\tremaining: 3.76s\n",
      "3360:\tlearn: 0.0000017\ttotal: 1.9s\tremaining: 3.76s\n",
      "3361:\tlearn: 0.0000017\ttotal: 1.9s\tremaining: 3.76s\n",
      "3362:\tlearn: 0.0000017\ttotal: 1.91s\tremaining: 3.76s\n",
      "3363:\tlearn: 0.0000017\ttotal: 1.91s\tremaining: 3.76s\n",
      "3364:\tlearn: 0.0000017\ttotal: 1.91s\tremaining: 3.76s\n",
      "3365:\tlearn: 0.0000017\ttotal: 1.91s\tremaining: 3.76s\n",
      "3366:\tlearn: 0.0000017\ttotal: 1.91s\tremaining: 3.76s\n",
      "3367:\tlearn: 0.0000017\ttotal: 1.91s\tremaining: 3.75s\n",
      "3368:\tlearn: 0.0000017\ttotal: 1.91s\tremaining: 3.75s\n",
      "3369:\tlearn: 0.0000017\ttotal: 1.91s\tremaining: 3.75s\n",
      "3370:\tlearn: 0.0000017\ttotal: 1.91s\tremaining: 3.75s\n",
      "3371:\tlearn: 0.0000017\ttotal: 1.91s\tremaining: 3.75s\n",
      "3372:\tlearn: 0.0000017\ttotal: 1.91s\tremaining: 3.75s\n",
      "3373:\tlearn: 0.0000016\ttotal: 1.91s\tremaining: 3.75s\n",
      "3374:\tlearn: 0.0000016\ttotal: 1.91s\tremaining: 3.75s\n",
      "3375:\tlearn: 0.0000016\ttotal: 1.91s\tremaining: 3.75s\n",
      "3376:\tlearn: 0.0000016\ttotal: 1.91s\tremaining: 3.75s\n",
      "3377:\tlearn: 0.0000016\ttotal: 1.91s\tremaining: 3.75s\n",
      "3378:\tlearn: 0.0000016\ttotal: 1.91s\tremaining: 3.75s\n",
      "3379:\tlearn: 0.0000016\ttotal: 1.91s\tremaining: 3.75s\n",
      "3380:\tlearn: 0.0000016\ttotal: 1.91s\tremaining: 3.75s\n",
      "3381:\tlearn: 0.0000016\ttotal: 1.91s\tremaining: 3.75s\n",
      "3382:\tlearn: 0.0000016\ttotal: 1.91s\tremaining: 3.75s\n",
      "3383:\tlearn: 0.0000016\ttotal: 1.92s\tremaining: 3.74s\n",
      "3384:\tlearn: 0.0000016\ttotal: 1.92s\tremaining: 3.74s\n",
      "3385:\tlearn: 0.0000016\ttotal: 1.92s\tremaining: 3.74s\n",
      "3386:\tlearn: 0.0000016\ttotal: 1.92s\tremaining: 3.74s\n",
      "3387:\tlearn: 0.0000016\ttotal: 1.92s\tremaining: 3.74s\n",
      "3388:\tlearn: 0.0000016\ttotal: 1.92s\tremaining: 3.74s\n",
      "3389:\tlearn: 0.0000016\ttotal: 1.92s\tremaining: 3.74s\n",
      "3390:\tlearn: 0.0000015\ttotal: 1.92s\tremaining: 3.74s\n",
      "3391:\tlearn: 0.0000015\ttotal: 1.92s\tremaining: 3.74s\n",
      "3392:\tlearn: 0.0000015\ttotal: 1.92s\tremaining: 3.74s\n",
      "3393:\tlearn: 0.0000015\ttotal: 1.92s\tremaining: 3.74s\n",
      "3394:\tlearn: 0.0000015\ttotal: 1.92s\tremaining: 3.73s\n",
      "3395:\tlearn: 0.0000015\ttotal: 1.92s\tremaining: 3.73s\n",
      "3396:\tlearn: 0.0000015\ttotal: 1.92s\tremaining: 3.73s\n",
      "3397:\tlearn: 0.0000015\ttotal: 1.92s\tremaining: 3.73s\n",
      "3398:\tlearn: 0.0000015\ttotal: 1.92s\tremaining: 3.73s\n",
      "3399:\tlearn: 0.0000015\ttotal: 1.92s\tremaining: 3.73s\n",
      "3400:\tlearn: 0.0000015\ttotal: 1.92s\tremaining: 3.73s\n",
      "3401:\tlearn: 0.0000015\ttotal: 1.92s\tremaining: 3.73s\n",
      "3402:\tlearn: 0.0000015\ttotal: 1.92s\tremaining: 3.73s\n",
      "3403:\tlearn: 0.0000015\ttotal: 1.93s\tremaining: 3.73s\n",
      "3404:\tlearn: 0.0000015\ttotal: 1.93s\tremaining: 3.73s\n",
      "3405:\tlearn: 0.0000015\ttotal: 1.93s\tremaining: 3.73s\n",
      "3406:\tlearn: 0.0000015\ttotal: 1.93s\tremaining: 3.73s\n",
      "3407:\tlearn: 0.0000015\ttotal: 1.93s\tremaining: 3.73s\n",
      "3408:\tlearn: 0.0000014\ttotal: 1.93s\tremaining: 3.73s\n",
      "3409:\tlearn: 0.0000014\ttotal: 1.93s\tremaining: 3.73s\n",
      "3410:\tlearn: 0.0000014\ttotal: 1.93s\tremaining: 3.72s\n",
      "3411:\tlearn: 0.0000014\ttotal: 1.93s\tremaining: 3.72s\n",
      "3412:\tlearn: 0.0000014\ttotal: 1.93s\tremaining: 3.72s\n",
      "3413:\tlearn: 0.0000014\ttotal: 1.93s\tremaining: 3.72s\n",
      "3414:\tlearn: 0.0000014\ttotal: 1.93s\tremaining: 3.72s\n",
      "3415:\tlearn: 0.0000014\ttotal: 1.93s\tremaining: 3.72s\n",
      "3416:\tlearn: 0.0000014\ttotal: 1.93s\tremaining: 3.72s\n",
      "3417:\tlearn: 0.0000014\ttotal: 1.93s\tremaining: 3.72s\n",
      "3418:\tlearn: 0.0000014\ttotal: 1.93s\tremaining: 3.72s\n",
      "3419:\tlearn: 0.0000014\ttotal: 1.93s\tremaining: 3.72s\n",
      "3420:\tlearn: 0.0000014\ttotal: 1.93s\tremaining: 3.72s\n",
      "3421:\tlearn: 0.0000014\ttotal: 1.93s\tremaining: 3.72s\n",
      "3422:\tlearn: 0.0000014\ttotal: 1.93s\tremaining: 3.71s\n",
      "3423:\tlearn: 0.0000014\ttotal: 1.93s\tremaining: 3.71s\n",
      "3424:\tlearn: 0.0000013\ttotal: 1.93s\tremaining: 3.71s\n",
      "3425:\tlearn: 0.0000013\ttotal: 1.94s\tremaining: 3.71s\n",
      "3426:\tlearn: 0.0000013\ttotal: 1.94s\tremaining: 3.71s\n",
      "3427:\tlearn: 0.0000013\ttotal: 1.94s\tremaining: 3.71s\n",
      "3428:\tlearn: 0.0000013\ttotal: 1.94s\tremaining: 3.71s\n",
      "3429:\tlearn: 0.0000013\ttotal: 1.94s\tremaining: 3.71s\n",
      "3430:\tlearn: 0.0000013\ttotal: 1.94s\tremaining: 3.71s\n",
      "3431:\tlearn: 0.0000013\ttotal: 1.94s\tremaining: 3.71s\n",
      "3432:\tlearn: 0.0000013\ttotal: 1.94s\tremaining: 3.71s\n",
      "3433:\tlearn: 0.0000013\ttotal: 1.94s\tremaining: 3.71s\n",
      "3434:\tlearn: 0.0000013\ttotal: 1.94s\tremaining: 3.71s\n",
      "3435:\tlearn: 0.0000013\ttotal: 1.94s\tremaining: 3.71s\n",
      "3436:\tlearn: 0.0000013\ttotal: 1.94s\tremaining: 3.71s\n",
      "3437:\tlearn: 0.0000013\ttotal: 1.94s\tremaining: 3.71s\n",
      "3438:\tlearn: 0.0000013\ttotal: 1.94s\tremaining: 3.71s\n",
      "3439:\tlearn: 0.0000013\ttotal: 1.94s\tremaining: 3.71s\n",
      "3440:\tlearn: 0.0000013\ttotal: 1.94s\tremaining: 3.7s\n",
      "3441:\tlearn: 0.0000013\ttotal: 1.94s\tremaining: 3.7s\n",
      "3442:\tlearn: 0.0000013\ttotal: 1.94s\tremaining: 3.7s\n",
      "3443:\tlearn: 0.0000013\ttotal: 1.94s\tremaining: 3.7s\n",
      "3444:\tlearn: 0.0000012\ttotal: 1.95s\tremaining: 3.7s\n",
      "3445:\tlearn: 0.0000012\ttotal: 1.95s\tremaining: 3.7s\n",
      "3446:\tlearn: 0.0000012\ttotal: 1.95s\tremaining: 3.7s\n",
      "3447:\tlearn: 0.0000012\ttotal: 1.95s\tremaining: 3.7s\n",
      "3448:\tlearn: 0.0000012\ttotal: 1.95s\tremaining: 3.7s\n",
      "3449:\tlearn: 0.0000012\ttotal: 1.95s\tremaining: 3.7s\n",
      "3450:\tlearn: 0.0000012\ttotal: 1.95s\tremaining: 3.7s\n",
      "3451:\tlearn: 0.0000012\ttotal: 1.95s\tremaining: 3.69s\n",
      "3452:\tlearn: 0.0000012\ttotal: 1.95s\tremaining: 3.69s\n",
      "3453:\tlearn: 0.0000012\ttotal: 1.95s\tremaining: 3.69s\n",
      "3454:\tlearn: 0.0000012\ttotal: 1.95s\tremaining: 3.69s\n",
      "3455:\tlearn: 0.0000012\ttotal: 1.95s\tremaining: 3.69s\n",
      "3456:\tlearn: 0.0000012\ttotal: 1.95s\tremaining: 3.69s\n",
      "3457:\tlearn: 0.0000012\ttotal: 1.95s\tremaining: 3.69s\n",
      "3458:\tlearn: 0.0000012\ttotal: 1.95s\tremaining: 3.69s\n",
      "3459:\tlearn: 0.0000012\ttotal: 1.95s\tremaining: 3.69s\n",
      "3460:\tlearn: 0.0000012\ttotal: 1.95s\tremaining: 3.69s\n",
      "3461:\tlearn: 0.0000012\ttotal: 1.95s\tremaining: 3.69s\n",
      "3462:\tlearn: 0.0000012\ttotal: 1.95s\tremaining: 3.69s\n",
      "3463:\tlearn: 0.0000012\ttotal: 1.95s\tremaining: 3.69s\n",
      "3464:\tlearn: 0.0000012\ttotal: 1.96s\tremaining: 3.69s\n",
      "3465:\tlearn: 0.0000012\ttotal: 1.96s\tremaining: 3.69s\n",
      "3466:\tlearn: 0.0000011\ttotal: 1.96s\tremaining: 3.69s\n",
      "3467:\tlearn: 0.0000011\ttotal: 1.96s\tremaining: 3.69s\n",
      "3468:\tlearn: 0.0000011\ttotal: 1.96s\tremaining: 3.68s\n",
      "3469:\tlearn: 0.0000011\ttotal: 1.96s\tremaining: 3.68s\n",
      "3470:\tlearn: 0.0000011\ttotal: 1.96s\tremaining: 3.68s\n",
      "3471:\tlearn: 0.0000011\ttotal: 1.96s\tremaining: 3.68s\n",
      "3472:\tlearn: 0.0000011\ttotal: 1.96s\tremaining: 3.68s\n",
      "3473:\tlearn: 0.0000011\ttotal: 1.96s\tremaining: 3.68s\n",
      "3474:\tlearn: 0.0000011\ttotal: 1.96s\tremaining: 3.68s\n",
      "3475:\tlearn: 0.0000011\ttotal: 1.96s\tremaining: 3.68s\n",
      "3476:\tlearn: 0.0000011\ttotal: 1.96s\tremaining: 3.68s\n",
      "3477:\tlearn: 0.0000011\ttotal: 1.96s\tremaining: 3.68s\n",
      "3478:\tlearn: 0.0000011\ttotal: 1.96s\tremaining: 3.68s\n",
      "3479:\tlearn: 0.0000011\ttotal: 1.96s\tremaining: 3.68s\n",
      "3480:\tlearn: 0.0000011\ttotal: 1.96s\tremaining: 3.68s\n",
      "3481:\tlearn: 0.0000011\ttotal: 1.96s\tremaining: 3.67s\n",
      "3482:\tlearn: 0.0000011\ttotal: 1.96s\tremaining: 3.67s\n",
      "3483:\tlearn: 0.0000011\ttotal: 1.96s\tremaining: 3.67s\n",
      "3484:\tlearn: 0.0000011\ttotal: 1.97s\tremaining: 3.67s\n",
      "3485:\tlearn: 0.0000011\ttotal: 1.97s\tremaining: 3.67s\n",
      "3486:\tlearn: 0.0000011\ttotal: 1.97s\tremaining: 3.67s\n",
      "3487:\tlearn: 0.0000011\ttotal: 1.97s\tremaining: 3.67s\n",
      "3488:\tlearn: 0.0000011\ttotal: 1.97s\tremaining: 3.67s\n",
      "3489:\tlearn: 0.0000011\ttotal: 1.97s\tremaining: 3.67s\n",
      "3490:\tlearn: 0.0000010\ttotal: 1.97s\tremaining: 3.67s\n",
      "3491:\tlearn: 0.0000010\ttotal: 1.97s\tremaining: 3.67s\n",
      "3492:\tlearn: 0.0000010\ttotal: 1.97s\tremaining: 3.67s\n",
      "3493:\tlearn: 0.0000010\ttotal: 1.97s\tremaining: 3.67s\n",
      "3494:\tlearn: 0.0000010\ttotal: 1.97s\tremaining: 3.67s\n",
      "3495:\tlearn: 0.0000010\ttotal: 1.97s\tremaining: 3.67s\n",
      "3496:\tlearn: 0.0000010\ttotal: 1.97s\tremaining: 3.67s\n",
      "3497:\tlearn: 0.0000010\ttotal: 1.97s\tremaining: 3.66s\n",
      "3498:\tlearn: 0.0000010\ttotal: 1.97s\tremaining: 3.66s\n",
      "3499:\tlearn: 0.0000010\ttotal: 1.97s\tremaining: 3.66s\n",
      "3500:\tlearn: 0.0000010\ttotal: 1.97s\tremaining: 3.66s\n",
      "3501:\tlearn: 0.0000010\ttotal: 1.97s\tremaining: 3.66s\n",
      "3502:\tlearn: 0.0000010\ttotal: 1.97s\tremaining: 3.66s\n",
      "3503:\tlearn: 0.0000010\ttotal: 1.97s\tremaining: 3.66s\n",
      "3504:\tlearn: 0.0000010\ttotal: 1.97s\tremaining: 3.66s\n",
      "3505:\tlearn: 0.0000010\ttotal: 1.98s\tremaining: 3.66s\n",
      "3506:\tlearn: 0.0000010\ttotal: 1.98s\tremaining: 3.66s\n",
      "3507:\tlearn: 0.0000010\ttotal: 1.98s\tremaining: 3.66s\n",
      "3508:\tlearn: 0.0000010\ttotal: 1.98s\tremaining: 3.66s\n",
      "3509:\tlearn: 0.0000010\ttotal: 1.98s\tremaining: 3.65s\n",
      "3510:\tlearn: 0.0000010\ttotal: 1.98s\tremaining: 3.65s\n",
      "3511:\tlearn: 0.0000010\ttotal: 1.98s\tremaining: 3.65s\n",
      "3512:\tlearn: 0.0000010\ttotal: 1.98s\tremaining: 3.65s\n",
      "3513:\tlearn: 0.0000009\ttotal: 1.98s\tremaining: 3.65s\n",
      "3514:\tlearn: 0.0000009\ttotal: 1.98s\tremaining: 3.65s\n",
      "3515:\tlearn: 0.0000009\ttotal: 1.98s\tremaining: 3.65s\n",
      "3516:\tlearn: 0.0000009\ttotal: 1.98s\tremaining: 3.65s\n",
      "3517:\tlearn: 0.0000009\ttotal: 1.98s\tremaining: 3.65s\n",
      "3518:\tlearn: 0.0000009\ttotal: 1.98s\tremaining: 3.65s\n",
      "3519:\tlearn: 0.0000009\ttotal: 1.98s\tremaining: 3.65s\n",
      "3520:\tlearn: 0.0000009\ttotal: 1.98s\tremaining: 3.65s\n",
      "3521:\tlearn: 0.0000009\ttotal: 1.98s\tremaining: 3.65s\n",
      "3522:\tlearn: 0.0000009\ttotal: 1.98s\tremaining: 3.65s\n",
      "3523:\tlearn: 0.0000009\ttotal: 1.98s\tremaining: 3.65s\n",
      "3524:\tlearn: 0.0000009\ttotal: 1.99s\tremaining: 3.65s\n",
      "3525:\tlearn: 0.0000009\ttotal: 1.99s\tremaining: 3.65s\n",
      "3526:\tlearn: 0.0000009\ttotal: 1.99s\tremaining: 3.65s\n",
      "3527:\tlearn: 0.0000009\ttotal: 1.99s\tremaining: 3.64s\n",
      "3528:\tlearn: 0.0000009\ttotal: 1.99s\tremaining: 3.64s\n",
      "3529:\tlearn: 0.0000009\ttotal: 1.99s\tremaining: 3.64s\n",
      "3530:\tlearn: 0.0000009\ttotal: 1.99s\tremaining: 3.64s\n",
      "3531:\tlearn: 0.0000009\ttotal: 1.99s\tremaining: 3.64s\n",
      "3532:\tlearn: 0.0000009\ttotal: 1.99s\tremaining: 3.64s\n",
      "3533:\tlearn: 0.0000009\ttotal: 1.99s\tremaining: 3.64s\n",
      "3534:\tlearn: 0.0000009\ttotal: 1.99s\tremaining: 3.64s\n",
      "3535:\tlearn: 0.0000009\ttotal: 1.99s\tremaining: 3.64s\n",
      "3536:\tlearn: 0.0000009\ttotal: 1.99s\tremaining: 3.64s\n",
      "3537:\tlearn: 0.0000009\ttotal: 1.99s\tremaining: 3.64s\n",
      "3538:\tlearn: 0.0000009\ttotal: 1.99s\tremaining: 3.64s\n",
      "3539:\tlearn: 0.0000008\ttotal: 1.99s\tremaining: 3.63s\n",
      "3540:\tlearn: 0.0000008\ttotal: 1.99s\tremaining: 3.63s\n",
      "3541:\tlearn: 0.0000008\ttotal: 1.99s\tremaining: 3.63s\n",
      "3542:\tlearn: 0.0000008\ttotal: 1.99s\tremaining: 3.63s\n",
      "3543:\tlearn: 0.0000008\ttotal: 2s\tremaining: 3.63s\n",
      "3544:\tlearn: 0.0000008\ttotal: 2s\tremaining: 3.63s\n",
      "3545:\tlearn: 0.0000008\ttotal: 2s\tremaining: 3.63s\n",
      "3546:\tlearn: 0.0000008\ttotal: 2s\tremaining: 3.63s\n",
      "3547:\tlearn: 0.0000008\ttotal: 2s\tremaining: 3.63s\n",
      "3548:\tlearn: 0.0000008\ttotal: 2s\tremaining: 3.63s\n",
      "3549:\tlearn: 0.0000008\ttotal: 2s\tremaining: 3.63s\n",
      "3550:\tlearn: 0.0000008\ttotal: 2s\tremaining: 3.63s\n",
      "3551:\tlearn: 0.0000008\ttotal: 2s\tremaining: 3.63s\n",
      "3552:\tlearn: 0.0000008\ttotal: 2s\tremaining: 3.63s\n",
      "3553:\tlearn: 0.0000008\ttotal: 2s\tremaining: 3.63s\n",
      "3554:\tlearn: 0.0000008\ttotal: 2s\tremaining: 3.63s\n",
      "3555:\tlearn: 0.0000008\ttotal: 2s\tremaining: 3.63s\n",
      "3556:\tlearn: 0.0000008\ttotal: 2s\tremaining: 3.63s\n",
      "3557:\tlearn: 0.0000008\ttotal: 2s\tremaining: 3.63s\n",
      "3558:\tlearn: 0.0000008\ttotal: 2s\tremaining: 3.63s\n",
      "3559:\tlearn: 0.0000008\ttotal: 2s\tremaining: 3.62s\n",
      "3560:\tlearn: 0.0000008\ttotal: 2s\tremaining: 3.62s\n",
      "3561:\tlearn: 0.0000008\ttotal: 2s\tremaining: 3.62s\n",
      "3562:\tlearn: 0.0000008\ttotal: 2s\tremaining: 3.62s\n",
      "3563:\tlearn: 0.0000008\ttotal: 2s\tremaining: 3.62s\n",
      "3564:\tlearn: 0.0000008\ttotal: 2.01s\tremaining: 3.62s\n",
      "3565:\tlearn: 0.0000008\ttotal: 2.01s\tremaining: 3.62s\n",
      "3566:\tlearn: 0.0000008\ttotal: 2.01s\tremaining: 3.62s\n",
      "3567:\tlearn: 0.0000007\ttotal: 2.01s\tremaining: 3.62s\n",
      "3568:\tlearn: 0.0000007\ttotal: 2.01s\tremaining: 3.62s\n",
      "3569:\tlearn: 0.0000007\ttotal: 2.01s\tremaining: 3.62s\n",
      "3570:\tlearn: 0.0000007\ttotal: 2.01s\tremaining: 3.62s\n",
      "3571:\tlearn: 0.0000007\ttotal: 2.01s\tremaining: 3.62s\n",
      "3572:\tlearn: 0.0000007\ttotal: 2.01s\tremaining: 3.62s\n",
      "3573:\tlearn: 0.0000007\ttotal: 2.01s\tremaining: 3.62s\n",
      "3574:\tlearn: 0.0000007\ttotal: 2.01s\tremaining: 3.62s\n",
      "3575:\tlearn: 0.0000007\ttotal: 2.01s\tremaining: 3.61s\n",
      "3576:\tlearn: 0.0000007\ttotal: 2.01s\tremaining: 3.61s\n",
      "3577:\tlearn: 0.0000007\ttotal: 2.01s\tremaining: 3.61s\n",
      "3578:\tlearn: 0.0000007\ttotal: 2.01s\tremaining: 3.61s\n",
      "3579:\tlearn: 0.0000007\ttotal: 2.01s\tremaining: 3.61s\n",
      "3580:\tlearn: 0.0000007\ttotal: 2.01s\tremaining: 3.61s\n",
      "3581:\tlearn: 0.0000007\ttotal: 2.01s\tremaining: 3.61s\n",
      "3582:\tlearn: 0.0000007\ttotal: 2.02s\tremaining: 3.61s\n",
      "3583:\tlearn: 0.0000007\ttotal: 2.02s\tremaining: 3.61s\n",
      "3584:\tlearn: 0.0000007\ttotal: 2.02s\tremaining: 3.61s\n",
      "3585:\tlearn: 0.0000007\ttotal: 2.02s\tremaining: 3.61s\n",
      "3586:\tlearn: 0.0000007\ttotal: 2.02s\tremaining: 3.61s\n",
      "3587:\tlearn: 0.0000007\ttotal: 2.02s\tremaining: 3.6s\n",
      "3588:\tlearn: 0.0000007\ttotal: 2.02s\tremaining: 3.6s\n",
      "3589:\tlearn: 0.0000007\ttotal: 2.02s\tremaining: 3.6s\n",
      "3590:\tlearn: 0.0000007\ttotal: 2.02s\tremaining: 3.6s\n",
      "3591:\tlearn: 0.0000007\ttotal: 2.02s\tremaining: 3.6s\n",
      "3592:\tlearn: 0.0000007\ttotal: 2.02s\tremaining: 3.6s\n",
      "3593:\tlearn: 0.0000007\ttotal: 2.02s\tremaining: 3.6s\n",
      "3594:\tlearn: 0.0000007\ttotal: 2.02s\tremaining: 3.6s\n",
      "3595:\tlearn: 0.0000007\ttotal: 2.02s\tremaining: 3.6s\n",
      "3596:\tlearn: 0.0000007\ttotal: 2.02s\tremaining: 3.6s\n",
      "3597:\tlearn: 0.0000007\ttotal: 2.02s\tremaining: 3.6s\n",
      "3598:\tlearn: 0.0000007\ttotal: 2.02s\tremaining: 3.6s\n",
      "3599:\tlearn: 0.0000007\ttotal: 2.02s\tremaining: 3.6s\n",
      "3600:\tlearn: 0.0000007\ttotal: 2.02s\tremaining: 3.6s\n",
      "3601:\tlearn: 0.0000007\ttotal: 2.02s\tremaining: 3.6s\n",
      "3602:\tlearn: 0.0000007\ttotal: 2.02s\tremaining: 3.6s\n",
      "3603:\tlearn: 0.0000007\ttotal: 2.02s\tremaining: 3.6s\n",
      "3604:\tlearn: 0.0000007\ttotal: 2.03s\tremaining: 3.59s\n",
      "3605:\tlearn: 0.0000006\ttotal: 2.03s\tremaining: 3.59s\n",
      "3606:\tlearn: 0.0000006\ttotal: 2.03s\tremaining: 3.59s\n",
      "3607:\tlearn: 0.0000006\ttotal: 2.03s\tremaining: 3.59s\n",
      "3608:\tlearn: 0.0000006\ttotal: 2.03s\tremaining: 3.59s\n",
      "3609:\tlearn: 0.0000006\ttotal: 2.03s\tremaining: 3.59s\n",
      "3610:\tlearn: 0.0000006\ttotal: 2.03s\tremaining: 3.59s\n",
      "3611:\tlearn: 0.0000006\ttotal: 2.03s\tremaining: 3.59s\n",
      "3612:\tlearn: 0.0000006\ttotal: 2.03s\tremaining: 3.59s\n",
      "3613:\tlearn: 0.0000006\ttotal: 2.03s\tremaining: 3.59s\n",
      "3614:\tlearn: 0.0000006\ttotal: 2.03s\tremaining: 3.59s\n",
      "3615:\tlearn: 0.0000006\ttotal: 2.03s\tremaining: 3.58s\n",
      "3616:\tlearn: 0.0000006\ttotal: 2.03s\tremaining: 3.58s\n",
      "3617:\tlearn: 0.0000006\ttotal: 2.03s\tremaining: 3.58s\n",
      "3618:\tlearn: 0.0000006\ttotal: 2.03s\tremaining: 3.58s\n",
      "3619:\tlearn: 0.0000006\ttotal: 2.03s\tremaining: 3.58s\n",
      "3620:\tlearn: 0.0000006\ttotal: 2.03s\tremaining: 3.58s\n",
      "3621:\tlearn: 0.0000006\ttotal: 2.03s\tremaining: 3.58s\n",
      "3622:\tlearn: 0.0000006\ttotal: 2.03s\tremaining: 3.58s\n",
      "3623:\tlearn: 0.0000006\ttotal: 2.03s\tremaining: 3.58s\n",
      "3624:\tlearn: 0.0000006\ttotal: 2.04s\tremaining: 3.58s\n",
      "3625:\tlearn: 0.0000006\ttotal: 2.04s\tremaining: 3.58s\n",
      "3626:\tlearn: 0.0000006\ttotal: 2.04s\tremaining: 3.58s\n",
      "3627:\tlearn: 0.0000006\ttotal: 2.04s\tremaining: 3.58s\n",
      "3628:\tlearn: 0.0000006\ttotal: 2.04s\tremaining: 3.58s\n",
      "3629:\tlearn: 0.0000006\ttotal: 2.04s\tremaining: 3.58s\n",
      "3630:\tlearn: 0.0000006\ttotal: 2.04s\tremaining: 3.58s\n",
      "3631:\tlearn: 0.0000006\ttotal: 2.04s\tremaining: 3.58s\n",
      "3632:\tlearn: 0.0000006\ttotal: 2.04s\tremaining: 3.58s\n",
      "3633:\tlearn: 0.0000006\ttotal: 2.04s\tremaining: 3.57s\n",
      "3634:\tlearn: 0.0000006\ttotal: 2.04s\tremaining: 3.57s\n",
      "3635:\tlearn: 0.0000006\ttotal: 2.04s\tremaining: 3.57s\n",
      "3636:\tlearn: 0.0000006\ttotal: 2.04s\tremaining: 3.57s\n",
      "3637:\tlearn: 0.0000006\ttotal: 2.04s\tremaining: 3.57s\n",
      "3638:\tlearn: 0.0000006\ttotal: 2.04s\tremaining: 3.57s\n",
      "3639:\tlearn: 0.0000006\ttotal: 2.04s\tremaining: 3.57s\n",
      "3640:\tlearn: 0.0000006\ttotal: 2.04s\tremaining: 3.57s\n",
      "3641:\tlearn: 0.0000006\ttotal: 2.04s\tremaining: 3.57s\n",
      "3642:\tlearn: 0.0000006\ttotal: 2.04s\tremaining: 3.57s\n",
      "3643:\tlearn: 0.0000006\ttotal: 2.04s\tremaining: 3.57s\n",
      "3644:\tlearn: 0.0000006\ttotal: 2.04s\tremaining: 3.57s\n",
      "3645:\tlearn: 0.0000006\ttotal: 2.05s\tremaining: 3.56s\n",
      "3646:\tlearn: 0.0000006\ttotal: 2.05s\tremaining: 3.56s\n",
      "3647:\tlearn: 0.0000006\ttotal: 2.05s\tremaining: 3.56s\n",
      "3648:\tlearn: 0.0000006\ttotal: 2.05s\tremaining: 3.56s\n",
      "3649:\tlearn: 0.0000006\ttotal: 2.05s\tremaining: 3.56s\n",
      "3650:\tlearn: 0.0000006\ttotal: 2.05s\tremaining: 3.56s\n",
      "3651:\tlearn: 0.0000005\ttotal: 2.05s\tremaining: 3.56s\n",
      "3652:\tlearn: 0.0000005\ttotal: 2.05s\tremaining: 3.56s\n",
      "3653:\tlearn: 0.0000005\ttotal: 2.05s\tremaining: 3.56s\n",
      "3654:\tlearn: 0.0000005\ttotal: 2.05s\tremaining: 3.56s\n",
      "3655:\tlearn: 0.0000005\ttotal: 2.05s\tremaining: 3.56s\n",
      "3656:\tlearn: 0.0000005\ttotal: 2.05s\tremaining: 3.56s\n",
      "3657:\tlearn: 0.0000005\ttotal: 2.05s\tremaining: 3.56s\n",
      "3658:\tlearn: 0.0000005\ttotal: 2.05s\tremaining: 3.56s\n",
      "3659:\tlearn: 0.0000005\ttotal: 2.05s\tremaining: 3.56s\n",
      "3660:\tlearn: 0.0000005\ttotal: 2.05s\tremaining: 3.56s\n",
      "3661:\tlearn: 0.0000005\ttotal: 2.05s\tremaining: 3.56s\n",
      "3662:\tlearn: 0.0000005\ttotal: 2.06s\tremaining: 3.56s\n",
      "3663:\tlearn: 0.0000005\ttotal: 2.06s\tremaining: 3.55s\n",
      "3664:\tlearn: 0.0000005\ttotal: 2.06s\tremaining: 3.55s\n",
      "3665:\tlearn: 0.0000005\ttotal: 2.06s\tremaining: 3.55s\n",
      "3666:\tlearn: 0.0000005\ttotal: 2.06s\tremaining: 3.55s\n",
      "3667:\tlearn: 0.0000005\ttotal: 2.06s\tremaining: 3.55s\n",
      "3668:\tlearn: 0.0000005\ttotal: 2.06s\tremaining: 3.55s\n",
      "3669:\tlearn: 0.0000005\ttotal: 2.06s\tremaining: 3.55s\n",
      "3670:\tlearn: 0.0000005\ttotal: 2.06s\tremaining: 3.55s\n",
      "3671:\tlearn: 0.0000005\ttotal: 2.06s\tremaining: 3.55s\n",
      "3672:\tlearn: 0.0000005\ttotal: 2.06s\tremaining: 3.55s\n",
      "3673:\tlearn: 0.0000005\ttotal: 2.06s\tremaining: 3.55s\n",
      "3674:\tlearn: 0.0000005\ttotal: 2.06s\tremaining: 3.55s\n",
      "3675:\tlearn: 0.0000005\ttotal: 2.06s\tremaining: 3.54s\n",
      "3676:\tlearn: 0.0000005\ttotal: 2.06s\tremaining: 3.54s\n",
      "3677:\tlearn: 0.0000005\ttotal: 2.06s\tremaining: 3.54s\n",
      "3678:\tlearn: 0.0000005\ttotal: 2.06s\tremaining: 3.54s\n",
      "3679:\tlearn: 0.0000005\ttotal: 2.06s\tremaining: 3.54s\n",
      "3680:\tlearn: 0.0000005\ttotal: 2.06s\tremaining: 3.54s\n",
      "3681:\tlearn: 0.0000005\ttotal: 2.06s\tremaining: 3.54s\n",
      "3682:\tlearn: 0.0000005\ttotal: 2.06s\tremaining: 3.54s\n",
      "3683:\tlearn: 0.0000005\ttotal: 2.06s\tremaining: 3.54s\n",
      "3684:\tlearn: 0.0000005\ttotal: 2.06s\tremaining: 3.54s\n",
      "3685:\tlearn: 0.0000005\ttotal: 2.07s\tremaining: 3.54s\n",
      "3686:\tlearn: 0.0000005\ttotal: 2.07s\tremaining: 3.54s\n",
      "3687:\tlearn: 0.0000005\ttotal: 2.07s\tremaining: 3.54s\n",
      "3688:\tlearn: 0.0000005\ttotal: 2.07s\tremaining: 3.54s\n",
      "3689:\tlearn: 0.0000005\ttotal: 2.07s\tremaining: 3.54s\n",
      "3690:\tlearn: 0.0000005\ttotal: 2.07s\tremaining: 3.54s\n",
      "3691:\tlearn: 0.0000004\ttotal: 2.07s\tremaining: 3.54s\n",
      "3692:\tlearn: 0.0000004\ttotal: 2.07s\tremaining: 3.53s\n",
      "3693:\tlearn: 0.0000004\ttotal: 2.07s\tremaining: 3.53s\n",
      "3694:\tlearn: 0.0000004\ttotal: 2.07s\tremaining: 3.53s\n",
      "3695:\tlearn: 0.0000004\ttotal: 2.07s\tremaining: 3.53s\n",
      "3696:\tlearn: 0.0000004\ttotal: 2.07s\tremaining: 3.53s\n",
      "3697:\tlearn: 0.0000004\ttotal: 2.07s\tremaining: 3.53s\n",
      "3698:\tlearn: 0.0000004\ttotal: 2.07s\tremaining: 3.53s\n",
      "3699:\tlearn: 0.0000004\ttotal: 2.07s\tremaining: 3.53s\n",
      "3700:\tlearn: 0.0000004\ttotal: 2.07s\tremaining: 3.53s\n",
      "3701:\tlearn: 0.0000004\ttotal: 2.07s\tremaining: 3.53s\n",
      "3702:\tlearn: 0.0000004\ttotal: 2.07s\tremaining: 3.53s\n",
      "3703:\tlearn: 0.0000004\ttotal: 2.07s\tremaining: 3.53s\n",
      "3704:\tlearn: 0.0000004\ttotal: 2.08s\tremaining: 3.53s\n",
      "3705:\tlearn: 0.0000004\ttotal: 2.08s\tremaining: 3.52s\n",
      "3706:\tlearn: 0.0000004\ttotal: 2.08s\tremaining: 3.52s\n",
      "3707:\tlearn: 0.0000004\ttotal: 2.08s\tremaining: 3.52s\n",
      "3708:\tlearn: 0.0000004\ttotal: 2.08s\tremaining: 3.52s\n",
      "3709:\tlearn: 0.0000004\ttotal: 2.08s\tremaining: 3.52s\n",
      "3710:\tlearn: 0.0000004\ttotal: 2.08s\tremaining: 3.52s\n",
      "3711:\tlearn: 0.0000004\ttotal: 2.08s\tremaining: 3.52s\n",
      "3712:\tlearn: 0.0000004\ttotal: 2.08s\tremaining: 3.52s\n",
      "3713:\tlearn: 0.0000004\ttotal: 2.08s\tremaining: 3.52s\n",
      "3714:\tlearn: 0.0000004\ttotal: 2.08s\tremaining: 3.52s\n",
      "3715:\tlearn: 0.0000004\ttotal: 2.08s\tremaining: 3.52s\n",
      "3716:\tlearn: 0.0000004\ttotal: 2.08s\tremaining: 3.52s\n",
      "3717:\tlearn: 0.0000004\ttotal: 2.08s\tremaining: 3.52s\n",
      "3718:\tlearn: 0.0000004\ttotal: 2.08s\tremaining: 3.52s\n",
      "3719:\tlearn: 0.0000004\ttotal: 2.08s\tremaining: 3.52s\n",
      "3720:\tlearn: 0.0000004\ttotal: 2.08s\tremaining: 3.52s\n",
      "3721:\tlearn: 0.0000004\ttotal: 2.08s\tremaining: 3.52s\n",
      "3722:\tlearn: 0.0000004\ttotal: 2.08s\tremaining: 3.52s\n",
      "3723:\tlearn: 0.0000004\ttotal: 2.08s\tremaining: 3.51s\n",
      "3724:\tlearn: 0.0000004\ttotal: 2.08s\tremaining: 3.51s\n",
      "3725:\tlearn: 0.0000004\ttotal: 2.09s\tremaining: 3.51s\n",
      "3726:\tlearn: 0.0000004\ttotal: 2.09s\tremaining: 3.51s\n",
      "3727:\tlearn: 0.0000004\ttotal: 2.09s\tremaining: 3.51s\n",
      "3728:\tlearn: 0.0000004\ttotal: 2.09s\tremaining: 3.51s\n",
      "3729:\tlearn: 0.0000004\ttotal: 2.09s\tremaining: 3.51s\n",
      "3730:\tlearn: 0.0000004\ttotal: 2.09s\tremaining: 3.51s\n",
      "3731:\tlearn: 0.0000004\ttotal: 2.09s\tremaining: 3.51s\n",
      "3732:\tlearn: 0.0000004\ttotal: 2.09s\tremaining: 3.51s\n",
      "3733:\tlearn: 0.0000004\ttotal: 2.09s\tremaining: 3.51s\n",
      "3734:\tlearn: 0.0000004\ttotal: 2.09s\tremaining: 3.5s\n",
      "3735:\tlearn: 0.0000004\ttotal: 2.09s\tremaining: 3.5s\n",
      "3736:\tlearn: 0.0000004\ttotal: 2.09s\tremaining: 3.5s\n",
      "3737:\tlearn: 0.0000004\ttotal: 2.09s\tremaining: 3.5s\n",
      "3738:\tlearn: 0.0000004\ttotal: 2.09s\tremaining: 3.5s\n",
      "3739:\tlearn: 0.0000004\ttotal: 2.09s\tremaining: 3.5s\n",
      "3740:\tlearn: 0.0000004\ttotal: 2.09s\tremaining: 3.5s\n",
      "3741:\tlearn: 0.0000004\ttotal: 2.09s\tremaining: 3.5s\n",
      "3742:\tlearn: 0.0000004\ttotal: 2.09s\tremaining: 3.5s\n",
      "3743:\tlearn: 0.0000004\ttotal: 2.1s\tremaining: 3.5s\n",
      "3744:\tlearn: 0.0000004\ttotal: 2.1s\tremaining: 3.5s\n",
      "3745:\tlearn: 0.0000004\ttotal: 2.1s\tremaining: 3.5s\n",
      "3746:\tlearn: 0.0000004\ttotal: 2.1s\tremaining: 3.5s\n",
      "3747:\tlearn: 0.0000003\ttotal: 2.1s\tremaining: 3.5s\n",
      "3748:\tlearn: 0.0000003\ttotal: 2.1s\tremaining: 3.5s\n",
      "3749:\tlearn: 0.0000003\ttotal: 2.1s\tremaining: 3.5s\n",
      "3750:\tlearn: 0.0000003\ttotal: 2.1s\tremaining: 3.5s\n",
      "3751:\tlearn: 0.0000003\ttotal: 2.1s\tremaining: 3.5s\n",
      "3752:\tlearn: 0.0000003\ttotal: 2.1s\tremaining: 3.49s\n",
      "3753:\tlearn: 0.0000003\ttotal: 2.1s\tremaining: 3.49s\n",
      "3754:\tlearn: 0.0000003\ttotal: 2.1s\tremaining: 3.49s\n",
      "3755:\tlearn: 0.0000003\ttotal: 2.1s\tremaining: 3.49s\n",
      "3756:\tlearn: 0.0000003\ttotal: 2.1s\tremaining: 3.49s\n",
      "3757:\tlearn: 0.0000003\ttotal: 2.1s\tremaining: 3.49s\n",
      "3758:\tlearn: 0.0000003\ttotal: 2.1s\tremaining: 3.49s\n",
      "3759:\tlearn: 0.0000003\ttotal: 2.1s\tremaining: 3.49s\n",
      "3760:\tlearn: 0.0000003\ttotal: 2.1s\tremaining: 3.49s\n",
      "3761:\tlearn: 0.0000003\ttotal: 2.1s\tremaining: 3.49s\n",
      "3762:\tlearn: 0.0000003\ttotal: 2.1s\tremaining: 3.49s\n",
      "3763:\tlearn: 0.0000003\ttotal: 2.1s\tremaining: 3.49s\n",
      "3764:\tlearn: 0.0000003\ttotal: 2.1s\tremaining: 3.49s\n",
      "3765:\tlearn: 0.0000003\ttotal: 2.1s\tremaining: 3.48s\n",
      "3766:\tlearn: 0.0000003\ttotal: 2.11s\tremaining: 3.48s\n",
      "3767:\tlearn: 0.0000003\ttotal: 2.11s\tremaining: 3.48s\n",
      "3768:\tlearn: 0.0000003\ttotal: 2.11s\tremaining: 3.48s\n",
      "3769:\tlearn: 0.0000003\ttotal: 2.11s\tremaining: 3.48s\n",
      "3770:\tlearn: 0.0000003\ttotal: 2.11s\tremaining: 3.48s\n",
      "3771:\tlearn: 0.0000003\ttotal: 2.11s\tremaining: 3.48s\n",
      "3772:\tlearn: 0.0000003\ttotal: 2.11s\tremaining: 3.48s\n",
      "3773:\tlearn: 0.0000003\ttotal: 2.11s\tremaining: 3.48s\n",
      "3774:\tlearn: 0.0000003\ttotal: 2.11s\tremaining: 3.48s\n",
      "3775:\tlearn: 0.0000003\ttotal: 2.11s\tremaining: 3.48s\n",
      "3776:\tlearn: 0.0000003\ttotal: 2.11s\tremaining: 3.48s\n",
      "3777:\tlearn: 0.0000003\ttotal: 2.11s\tremaining: 3.48s\n",
      "3778:\tlearn: 0.0000003\ttotal: 2.11s\tremaining: 3.48s\n",
      "3779:\tlearn: 0.0000003\ttotal: 2.11s\tremaining: 3.48s\n",
      "3780:\tlearn: 0.0000003\ttotal: 2.11s\tremaining: 3.48s\n",
      "3781:\tlearn: 0.0000003\ttotal: 2.11s\tremaining: 3.48s\n",
      "3782:\tlearn: 0.0000003\ttotal: 2.11s\tremaining: 3.47s\n",
      "3783:\tlearn: 0.0000003\ttotal: 2.11s\tremaining: 3.47s\n",
      "3784:\tlearn: 0.0000003\ttotal: 2.12s\tremaining: 3.47s\n",
      "3785:\tlearn: 0.0000003\ttotal: 2.12s\tremaining: 3.47s\n",
      "3786:\tlearn: 0.0000003\ttotal: 2.12s\tremaining: 3.47s\n",
      "3787:\tlearn: 0.0000003\ttotal: 2.12s\tremaining: 3.47s\n",
      "3788:\tlearn: 0.0000003\ttotal: 2.12s\tremaining: 3.47s\n",
      "3789:\tlearn: 0.0000003\ttotal: 2.12s\tremaining: 3.47s\n",
      "3790:\tlearn: 0.0000003\ttotal: 2.12s\tremaining: 3.47s\n",
      "3791:\tlearn: 0.0000003\ttotal: 2.12s\tremaining: 3.47s\n",
      "3792:\tlearn: 0.0000003\ttotal: 2.12s\tremaining: 3.47s\n",
      "3793:\tlearn: 0.0000003\ttotal: 2.12s\tremaining: 3.47s\n",
      "3794:\tlearn: 0.0000003\ttotal: 2.12s\tremaining: 3.47s\n",
      "3795:\tlearn: 0.0000003\ttotal: 2.12s\tremaining: 3.47s\n",
      "3796:\tlearn: 0.0000003\ttotal: 2.12s\tremaining: 3.46s\n",
      "3797:\tlearn: 0.0000003\ttotal: 2.12s\tremaining: 3.46s\n",
      "3798:\tlearn: 0.0000003\ttotal: 2.12s\tremaining: 3.47s\n",
      "3799:\tlearn: 0.0000003\ttotal: 2.12s\tremaining: 3.47s\n",
      "3800:\tlearn: 0.0000003\ttotal: 2.13s\tremaining: 3.46s\n",
      "3801:\tlearn: 0.0000003\ttotal: 2.13s\tremaining: 3.46s\n",
      "3802:\tlearn: 0.0000003\ttotal: 2.13s\tremaining: 3.46s\n",
      "3803:\tlearn: 0.0000003\ttotal: 2.13s\tremaining: 3.46s\n",
      "3804:\tlearn: 0.0000003\ttotal: 2.13s\tremaining: 3.46s\n",
      "3805:\tlearn: 0.0000003\ttotal: 2.13s\tremaining: 3.46s\n",
      "3806:\tlearn: 0.0000003\ttotal: 2.13s\tremaining: 3.46s\n",
      "3807:\tlearn: 0.0000003\ttotal: 2.13s\tremaining: 3.46s\n",
      "3808:\tlearn: 0.0000003\ttotal: 2.13s\tremaining: 3.46s\n",
      "3809:\tlearn: 0.0000003\ttotal: 2.13s\tremaining: 3.46s\n",
      "3810:\tlearn: 0.0000003\ttotal: 2.13s\tremaining: 3.46s\n",
      "3811:\tlearn: 0.0000003\ttotal: 2.13s\tremaining: 3.46s\n",
      "3812:\tlearn: 0.0000003\ttotal: 2.13s\tremaining: 3.46s\n",
      "3813:\tlearn: 0.0000003\ttotal: 2.13s\tremaining: 3.46s\n",
      "3814:\tlearn: 0.0000003\ttotal: 2.13s\tremaining: 3.46s\n",
      "3815:\tlearn: 0.0000003\ttotal: 2.13s\tremaining: 3.45s\n",
      "3816:\tlearn: 0.0000003\ttotal: 2.13s\tremaining: 3.45s\n",
      "3817:\tlearn: 0.0000003\ttotal: 2.13s\tremaining: 3.45s\n",
      "3818:\tlearn: 0.0000003\ttotal: 2.13s\tremaining: 3.45s\n",
      "3819:\tlearn: 0.0000003\ttotal: 2.13s\tremaining: 3.45s\n",
      "3820:\tlearn: 0.0000003\ttotal: 2.13s\tremaining: 3.45s\n",
      "3821:\tlearn: 0.0000003\ttotal: 2.13s\tremaining: 3.45s\n",
      "3822:\tlearn: 0.0000003\ttotal: 2.13s\tremaining: 3.45s\n",
      "3823:\tlearn: 0.0000003\ttotal: 2.13s\tremaining: 3.45s\n",
      "3824:\tlearn: 0.0000003\ttotal: 2.14s\tremaining: 3.45s\n",
      "3825:\tlearn: 0.0000003\ttotal: 2.14s\tremaining: 3.45s\n",
      "3826:\tlearn: 0.0000003\ttotal: 2.14s\tremaining: 3.45s\n",
      "3827:\tlearn: 0.0000003\ttotal: 2.14s\tremaining: 3.45s\n",
      "3828:\tlearn: 0.0000003\ttotal: 2.14s\tremaining: 3.45s\n",
      "3829:\tlearn: 0.0000003\ttotal: 2.14s\tremaining: 3.45s\n",
      "3830:\tlearn: 0.0000003\ttotal: 2.14s\tremaining: 3.44s\n",
      "3831:\tlearn: 0.0000003\ttotal: 2.14s\tremaining: 3.44s\n",
      "3832:\tlearn: 0.0000003\ttotal: 2.14s\tremaining: 3.44s\n",
      "3833:\tlearn: 0.0000003\ttotal: 2.14s\tremaining: 3.44s\n",
      "3834:\tlearn: 0.0000003\ttotal: 2.14s\tremaining: 3.44s\n",
      "3835:\tlearn: 0.0000003\ttotal: 2.14s\tremaining: 3.44s\n",
      "3836:\tlearn: 0.0000002\ttotal: 2.14s\tremaining: 3.44s\n",
      "3837:\tlearn: 0.0000002\ttotal: 2.14s\tremaining: 3.44s\n",
      "3838:\tlearn: 0.0000002\ttotal: 2.14s\tremaining: 3.44s\n",
      "3839:\tlearn: 0.0000002\ttotal: 2.14s\tremaining: 3.44s\n",
      "3840:\tlearn: 0.0000002\ttotal: 2.15s\tremaining: 3.44s\n",
      "3841:\tlearn: 0.0000002\ttotal: 2.15s\tremaining: 3.44s\n",
      "3842:\tlearn: 0.0000002\ttotal: 2.15s\tremaining: 3.44s\n",
      "3843:\tlearn: 0.0000002\ttotal: 2.15s\tremaining: 3.44s\n",
      "3844:\tlearn: 0.0000002\ttotal: 2.15s\tremaining: 3.44s\n",
      "3845:\tlearn: 0.0000002\ttotal: 2.15s\tremaining: 3.44s\n",
      "3846:\tlearn: 0.0000002\ttotal: 2.15s\tremaining: 3.44s\n",
      "3847:\tlearn: 0.0000002\ttotal: 2.15s\tremaining: 3.44s\n",
      "3848:\tlearn: 0.0000002\ttotal: 2.15s\tremaining: 3.43s\n",
      "3849:\tlearn: 0.0000002\ttotal: 2.15s\tremaining: 3.43s\n",
      "3850:\tlearn: 0.0000002\ttotal: 2.15s\tremaining: 3.43s\n",
      "3851:\tlearn: 0.0000002\ttotal: 2.15s\tremaining: 3.43s\n",
      "3852:\tlearn: 0.0000002\ttotal: 2.15s\tremaining: 3.43s\n",
      "3853:\tlearn: 0.0000002\ttotal: 2.15s\tremaining: 3.43s\n",
      "3854:\tlearn: 0.0000002\ttotal: 2.15s\tremaining: 3.43s\n",
      "3855:\tlearn: 0.0000002\ttotal: 2.15s\tremaining: 3.43s\n",
      "3856:\tlearn: 0.0000002\ttotal: 2.15s\tremaining: 3.43s\n",
      "3857:\tlearn: 0.0000002\ttotal: 2.15s\tremaining: 3.43s\n",
      "3858:\tlearn: 0.0000002\ttotal: 2.15s\tremaining: 3.43s\n",
      "3859:\tlearn: 0.0000002\ttotal: 2.15s\tremaining: 3.43s\n",
      "3860:\tlearn: 0.0000002\ttotal: 2.15s\tremaining: 3.43s\n",
      "3861:\tlearn: 0.0000002\ttotal: 2.15s\tremaining: 3.43s\n",
      "3862:\tlearn: 0.0000002\ttotal: 2.16s\tremaining: 3.42s\n",
      "3863:\tlearn: 0.0000002\ttotal: 2.16s\tremaining: 3.42s\n",
      "3864:\tlearn: 0.0000002\ttotal: 2.16s\tremaining: 3.42s\n",
      "3865:\tlearn: 0.0000002\ttotal: 2.16s\tremaining: 3.42s\n",
      "3866:\tlearn: 0.0000002\ttotal: 2.16s\tremaining: 3.42s\n",
      "3867:\tlearn: 0.0000002\ttotal: 2.16s\tremaining: 3.42s\n",
      "3868:\tlearn: 0.0000002\ttotal: 2.16s\tremaining: 3.42s\n",
      "3869:\tlearn: 0.0000002\ttotal: 2.16s\tremaining: 3.42s\n",
      "3870:\tlearn: 0.0000002\ttotal: 2.16s\tremaining: 3.42s\n",
      "3871:\tlearn: 0.0000002\ttotal: 2.16s\tremaining: 3.42s\n",
      "3872:\tlearn: 0.0000002\ttotal: 2.16s\tremaining: 3.42s\n",
      "3873:\tlearn: 0.0000002\ttotal: 2.16s\tremaining: 3.42s\n",
      "3874:\tlearn: 0.0000002\ttotal: 2.16s\tremaining: 3.42s\n",
      "3875:\tlearn: 0.0000002\ttotal: 2.16s\tremaining: 3.42s\n",
      "3876:\tlearn: 0.0000002\ttotal: 2.16s\tremaining: 3.42s\n",
      "3877:\tlearn: 0.0000002\ttotal: 2.16s\tremaining: 3.41s\n",
      "3878:\tlearn: 0.0000002\ttotal: 2.16s\tremaining: 3.41s\n",
      "3879:\tlearn: 0.0000002\ttotal: 2.16s\tremaining: 3.41s\n",
      "3880:\tlearn: 0.0000002\ttotal: 2.16s\tremaining: 3.41s\n",
      "3881:\tlearn: 0.0000002\ttotal: 2.17s\tremaining: 3.41s\n",
      "3882:\tlearn: 0.0000002\ttotal: 2.17s\tremaining: 3.41s\n",
      "3883:\tlearn: 0.0000002\ttotal: 2.17s\tremaining: 3.41s\n",
      "3884:\tlearn: 0.0000002\ttotal: 2.17s\tremaining: 3.41s\n",
      "3885:\tlearn: 0.0000002\ttotal: 2.17s\tremaining: 3.41s\n",
      "3886:\tlearn: 0.0000002\ttotal: 2.17s\tremaining: 3.41s\n",
      "3887:\tlearn: 0.0000002\ttotal: 2.17s\tremaining: 3.41s\n",
      "3888:\tlearn: 0.0000002\ttotal: 2.17s\tremaining: 3.41s\n",
      "3889:\tlearn: 0.0000002\ttotal: 2.17s\tremaining: 3.41s\n",
      "3890:\tlearn: 0.0000002\ttotal: 2.17s\tremaining: 3.41s\n",
      "3891:\tlearn: 0.0000002\ttotal: 2.17s\tremaining: 3.41s\n",
      "3892:\tlearn: 0.0000002\ttotal: 2.17s\tremaining: 3.4s\n",
      "3893:\tlearn: 0.0000002\ttotal: 2.17s\tremaining: 3.4s\n",
      "3894:\tlearn: 0.0000002\ttotal: 2.17s\tremaining: 3.4s\n",
      "3895:\tlearn: 0.0000002\ttotal: 2.17s\tremaining: 3.4s\n",
      "3896:\tlearn: 0.0000002\ttotal: 2.17s\tremaining: 3.4s\n",
      "3897:\tlearn: 0.0000002\ttotal: 2.17s\tremaining: 3.4s\n",
      "3898:\tlearn: 0.0000002\ttotal: 2.17s\tremaining: 3.4s\n",
      "3899:\tlearn: 0.0000002\ttotal: 2.17s\tremaining: 3.4s\n",
      "3900:\tlearn: 0.0000002\ttotal: 2.17s\tremaining: 3.4s\n",
      "3901:\tlearn: 0.0000002\ttotal: 2.17s\tremaining: 3.4s\n",
      "3902:\tlearn: 0.0000002\ttotal: 2.17s\tremaining: 3.4s\n",
      "3903:\tlearn: 0.0000002\ttotal: 2.18s\tremaining: 3.4s\n",
      "3904:\tlearn: 0.0000002\ttotal: 2.18s\tremaining: 3.4s\n",
      "3905:\tlearn: 0.0000002\ttotal: 2.18s\tremaining: 3.4s\n",
      "3906:\tlearn: 0.0000002\ttotal: 2.18s\tremaining: 3.4s\n",
      "3907:\tlearn: 0.0000002\ttotal: 2.18s\tremaining: 3.4s\n",
      "3908:\tlearn: 0.0000002\ttotal: 2.18s\tremaining: 3.4s\n",
      "3909:\tlearn: 0.0000002\ttotal: 2.18s\tremaining: 3.4s\n",
      "3910:\tlearn: 0.0000002\ttotal: 2.18s\tremaining: 3.4s\n",
      "3911:\tlearn: 0.0000002\ttotal: 2.18s\tremaining: 3.4s\n",
      "3912:\tlearn: 0.0000002\ttotal: 2.18s\tremaining: 3.4s\n",
      "3913:\tlearn: 0.0000002\ttotal: 2.18s\tremaining: 3.39s\n",
      "3914:\tlearn: 0.0000002\ttotal: 2.18s\tremaining: 3.39s\n",
      "3915:\tlearn: 0.0000002\ttotal: 2.18s\tremaining: 3.39s\n",
      "3916:\tlearn: 0.0000002\ttotal: 2.18s\tremaining: 3.39s\n",
      "3917:\tlearn: 0.0000002\ttotal: 2.18s\tremaining: 3.39s\n",
      "3918:\tlearn: 0.0000002\ttotal: 2.19s\tremaining: 3.39s\n",
      "3919:\tlearn: 0.0000002\ttotal: 2.19s\tremaining: 3.39s\n",
      "3920:\tlearn: 0.0000002\ttotal: 2.19s\tremaining: 3.39s\n",
      "3921:\tlearn: 0.0000002\ttotal: 2.19s\tremaining: 3.39s\n",
      "3922:\tlearn: 0.0000002\ttotal: 2.19s\tremaining: 3.39s\n",
      "3923:\tlearn: 0.0000002\ttotal: 2.19s\tremaining: 3.39s\n",
      "3924:\tlearn: 0.0000002\ttotal: 2.19s\tremaining: 3.39s\n",
      "3925:\tlearn: 0.0000002\ttotal: 2.19s\tremaining: 3.39s\n",
      "3926:\tlearn: 0.0000002\ttotal: 2.19s\tremaining: 3.38s\n",
      "3927:\tlearn: 0.0000002\ttotal: 2.19s\tremaining: 3.38s\n",
      "3928:\tlearn: 0.0000002\ttotal: 2.19s\tremaining: 3.38s\n",
      "3929:\tlearn: 0.0000002\ttotal: 2.19s\tremaining: 3.38s\n",
      "3930:\tlearn: 0.0000002\ttotal: 2.19s\tremaining: 3.38s\n",
      "3931:\tlearn: 0.0000002\ttotal: 2.19s\tremaining: 3.38s\n",
      "3932:\tlearn: 0.0000002\ttotal: 2.19s\tremaining: 3.38s\n",
      "3933:\tlearn: 0.0000002\ttotal: 2.19s\tremaining: 3.38s\n",
      "3934:\tlearn: 0.0000002\ttotal: 2.19s\tremaining: 3.38s\n",
      "3935:\tlearn: 0.0000002\ttotal: 2.19s\tremaining: 3.38s\n",
      "3936:\tlearn: 0.0000002\ttotal: 2.19s\tremaining: 3.38s\n",
      "3937:\tlearn: 0.0000002\ttotal: 2.19s\tremaining: 3.38s\n",
      "3938:\tlearn: 0.0000002\ttotal: 2.19s\tremaining: 3.38s\n",
      "3939:\tlearn: 0.0000002\ttotal: 2.2s\tremaining: 3.38s\n",
      "3940:\tlearn: 0.0000002\ttotal: 2.2s\tremaining: 3.38s\n",
      "3941:\tlearn: 0.0000002\ttotal: 2.2s\tremaining: 3.38s\n",
      "3942:\tlearn: 0.0000002\ttotal: 2.2s\tremaining: 3.38s\n",
      "3943:\tlearn: 0.0000002\ttotal: 2.2s\tremaining: 3.38s\n",
      "3944:\tlearn: 0.0000002\ttotal: 2.2s\tremaining: 3.37s\n",
      "3945:\tlearn: 0.0000002\ttotal: 2.2s\tremaining: 3.37s\n",
      "3946:\tlearn: 0.0000002\ttotal: 2.2s\tremaining: 3.37s\n",
      "3947:\tlearn: 0.0000002\ttotal: 2.2s\tremaining: 3.37s\n",
      "3948:\tlearn: 0.0000002\ttotal: 2.2s\tremaining: 3.37s\n",
      "3949:\tlearn: 0.0000002\ttotal: 2.2s\tremaining: 3.37s\n",
      "3950:\tlearn: 0.0000002\ttotal: 2.2s\tremaining: 3.37s\n",
      "3951:\tlearn: 0.0000002\ttotal: 2.2s\tremaining: 3.37s\n",
      "3952:\tlearn: 0.0000002\ttotal: 2.2s\tremaining: 3.37s\n",
      "3953:\tlearn: 0.0000002\ttotal: 2.2s\tremaining: 3.37s\n",
      "3954:\tlearn: 0.0000002\ttotal: 2.2s\tremaining: 3.37s\n",
      "3955:\tlearn: 0.0000001\ttotal: 2.2s\tremaining: 3.37s\n",
      "3956:\tlearn: 0.0000001\ttotal: 2.2s\tremaining: 3.37s\n",
      "3957:\tlearn: 0.0000001\ttotal: 2.2s\tremaining: 3.37s\n",
      "3958:\tlearn: 0.0000001\ttotal: 2.2s\tremaining: 3.36s\n",
      "3959:\tlearn: 0.0000001\ttotal: 2.21s\tremaining: 3.36s\n",
      "3960:\tlearn: 0.0000001\ttotal: 2.21s\tremaining: 3.36s\n",
      "3961:\tlearn: 0.0000001\ttotal: 2.21s\tremaining: 3.36s\n",
      "3962:\tlearn: 0.0000001\ttotal: 2.21s\tremaining: 3.36s\n",
      "3963:\tlearn: 0.0000001\ttotal: 2.21s\tremaining: 3.36s\n",
      "3964:\tlearn: 0.0000001\ttotal: 2.21s\tremaining: 3.36s\n",
      "3965:\tlearn: 0.0000001\ttotal: 2.21s\tremaining: 3.36s\n",
      "3966:\tlearn: 0.0000001\ttotal: 2.21s\tremaining: 3.36s\n",
      "3967:\tlearn: 0.0000001\ttotal: 2.21s\tremaining: 3.36s\n",
      "3968:\tlearn: 0.0000001\ttotal: 2.21s\tremaining: 3.36s\n",
      "3969:\tlearn: 0.0000001\ttotal: 2.21s\tremaining: 3.36s\n",
      "3970:\tlearn: 0.0000001\ttotal: 2.21s\tremaining: 3.36s\n",
      "3971:\tlearn: 0.0000001\ttotal: 2.21s\tremaining: 3.36s\n",
      "3972:\tlearn: 0.0000001\ttotal: 2.21s\tremaining: 3.35s\n",
      "3973:\tlearn: 0.0000001\ttotal: 2.21s\tremaining: 3.35s\n",
      "3974:\tlearn: 0.0000001\ttotal: 2.21s\tremaining: 3.35s\n",
      "3975:\tlearn: 0.0000001\ttotal: 2.21s\tremaining: 3.35s\n",
      "3976:\tlearn: 0.0000001\ttotal: 2.21s\tremaining: 3.35s\n",
      "3977:\tlearn: 0.0000001\ttotal: 2.21s\tremaining: 3.35s\n",
      "3978:\tlearn: 0.0000001\ttotal: 2.21s\tremaining: 3.35s\n",
      "3979:\tlearn: 0.0000001\ttotal: 2.21s\tremaining: 3.35s\n",
      "3980:\tlearn: 0.0000001\ttotal: 2.21s\tremaining: 3.35s\n",
      "3981:\tlearn: 0.0000001\ttotal: 2.22s\tremaining: 3.35s\n",
      "3982:\tlearn: 0.0000001\ttotal: 2.22s\tremaining: 3.35s\n",
      "3983:\tlearn: 0.0000001\ttotal: 2.22s\tremaining: 3.35s\n",
      "3984:\tlearn: 0.0000001\ttotal: 2.22s\tremaining: 3.35s\n",
      "3985:\tlearn: 0.0000001\ttotal: 2.22s\tremaining: 3.35s\n",
      "3986:\tlearn: 0.0000001\ttotal: 2.22s\tremaining: 3.35s\n",
      "3987:\tlearn: 0.0000001\ttotal: 2.22s\tremaining: 3.35s\n",
      "3988:\tlearn: 0.0000001\ttotal: 2.22s\tremaining: 3.34s\n",
      "3989:\tlearn: 0.0000001\ttotal: 2.22s\tremaining: 3.34s\n",
      "3990:\tlearn: 0.0000001\ttotal: 2.22s\tremaining: 3.34s\n",
      "3991:\tlearn: 0.0000001\ttotal: 2.22s\tremaining: 3.34s\n",
      "3992:\tlearn: 0.0000001\ttotal: 2.22s\tremaining: 3.34s\n",
      "3993:\tlearn: 0.0000001\ttotal: 2.22s\tremaining: 3.34s\n",
      "3994:\tlearn: 0.0000001\ttotal: 2.22s\tremaining: 3.34s\n",
      "3995:\tlearn: 0.0000001\ttotal: 2.22s\tremaining: 3.34s\n",
      "3996:\tlearn: 0.0000001\ttotal: 2.22s\tremaining: 3.34s\n",
      "3997:\tlearn: 0.0000001\ttotal: 2.22s\tremaining: 3.34s\n",
      "3998:\tlearn: 0.0000001\ttotal: 2.23s\tremaining: 3.34s\n",
      "3999:\tlearn: 0.0000001\ttotal: 2.23s\tremaining: 3.34s\n",
      "4000:\tlearn: 0.0000001\ttotal: 2.23s\tremaining: 3.34s\n",
      "4001:\tlearn: 0.0000001\ttotal: 2.23s\tremaining: 3.34s\n",
      "4002:\tlearn: 0.0000001\ttotal: 2.23s\tremaining: 3.34s\n",
      "4003:\tlearn: 0.0000001\ttotal: 2.23s\tremaining: 3.34s\n",
      "4004:\tlearn: 0.0000001\ttotal: 2.23s\tremaining: 3.33s\n",
      "4005:\tlearn: 0.0000001\ttotal: 2.23s\tremaining: 3.33s\n",
      "4006:\tlearn: 0.0000001\ttotal: 2.23s\tremaining: 3.33s\n",
      "4007:\tlearn: 0.0000001\ttotal: 2.23s\tremaining: 3.33s\n",
      "4008:\tlearn: 0.0000001\ttotal: 2.23s\tremaining: 3.33s\n",
      "4009:\tlearn: 0.0000001\ttotal: 2.23s\tremaining: 3.33s\n",
      "4010:\tlearn: 0.0000001\ttotal: 2.23s\tremaining: 3.33s\n",
      "4011:\tlearn: 0.0000001\ttotal: 2.23s\tremaining: 3.33s\n",
      "4012:\tlearn: 0.0000001\ttotal: 2.23s\tremaining: 3.33s\n",
      "4013:\tlearn: 0.0000001\ttotal: 2.23s\tremaining: 3.33s\n",
      "4014:\tlearn: 0.0000001\ttotal: 2.23s\tremaining: 3.33s\n",
      "4015:\tlearn: 0.0000001\ttotal: 2.23s\tremaining: 3.33s\n",
      "4016:\tlearn: 0.0000001\ttotal: 2.23s\tremaining: 3.33s\n",
      "4017:\tlearn: 0.0000001\ttotal: 2.23s\tremaining: 3.33s\n",
      "4018:\tlearn: 0.0000001\ttotal: 2.23s\tremaining: 3.33s\n",
      "4019:\tlearn: 0.0000001\ttotal: 2.23s\tremaining: 3.32s\n",
      "4020:\tlearn: 0.0000001\ttotal: 2.23s\tremaining: 3.32s\n",
      "4021:\tlearn: 0.0000001\ttotal: 2.24s\tremaining: 3.32s\n",
      "4022:\tlearn: 0.0000001\ttotal: 2.24s\tremaining: 3.32s\n",
      "4023:\tlearn: 0.0000001\ttotal: 2.24s\tremaining: 3.32s\n",
      "4024:\tlearn: 0.0000001\ttotal: 2.24s\tremaining: 3.32s\n",
      "4025:\tlearn: 0.0000001\ttotal: 2.24s\tremaining: 3.32s\n",
      "4026:\tlearn: 0.0000001\ttotal: 2.24s\tremaining: 3.32s\n",
      "4027:\tlearn: 0.0000001\ttotal: 2.24s\tremaining: 3.32s\n",
      "4028:\tlearn: 0.0000001\ttotal: 2.24s\tremaining: 3.32s\n",
      "4029:\tlearn: 0.0000001\ttotal: 2.24s\tremaining: 3.32s\n",
      "4030:\tlearn: 0.0000001\ttotal: 2.24s\tremaining: 3.32s\n",
      "4031:\tlearn: 0.0000001\ttotal: 2.24s\tremaining: 3.32s\n",
      "4032:\tlearn: 0.0000001\ttotal: 2.24s\tremaining: 3.32s\n",
      "4033:\tlearn: 0.0000001\ttotal: 2.24s\tremaining: 3.31s\n",
      "4034:\tlearn: 0.0000001\ttotal: 2.24s\tremaining: 3.31s\n",
      "4035:\tlearn: 0.0000001\ttotal: 2.24s\tremaining: 3.31s\n",
      "4036:\tlearn: 0.0000001\ttotal: 2.24s\tremaining: 3.31s\n",
      "4037:\tlearn: 0.0000001\ttotal: 2.24s\tremaining: 3.31s\n",
      "4038:\tlearn: 0.0000001\ttotal: 2.24s\tremaining: 3.31s\n",
      "4039:\tlearn: 0.0000001\ttotal: 2.24s\tremaining: 3.31s\n",
      "4040:\tlearn: 0.0000001\ttotal: 2.25s\tremaining: 3.31s\n",
      "4041:\tlearn: 0.0000001\ttotal: 2.25s\tremaining: 3.31s\n",
      "4042:\tlearn: 0.0000001\ttotal: 2.25s\tremaining: 3.31s\n",
      "4043:\tlearn: 0.0000001\ttotal: 2.25s\tremaining: 3.31s\n",
      "4044:\tlearn: 0.0000001\ttotal: 2.25s\tremaining: 3.31s\n",
      "4045:\tlearn: 0.0000001\ttotal: 2.25s\tremaining: 3.31s\n",
      "4046:\tlearn: 0.0000001\ttotal: 2.25s\tremaining: 3.31s\n",
      "4047:\tlearn: 0.0000001\ttotal: 2.25s\tremaining: 3.31s\n",
      "4048:\tlearn: 0.0000001\ttotal: 2.25s\tremaining: 3.31s\n",
      "4049:\tlearn: 0.0000001\ttotal: 2.25s\tremaining: 3.3s\n",
      "4050:\tlearn: 0.0000001\ttotal: 2.25s\tremaining: 3.3s\n",
      "4051:\tlearn: 0.0000001\ttotal: 2.25s\tremaining: 3.3s\n",
      "4052:\tlearn: 0.0000001\ttotal: 2.25s\tremaining: 3.3s\n",
      "4053:\tlearn: 0.0000001\ttotal: 2.25s\tremaining: 3.3s\n",
      "4054:\tlearn: 0.0000001\ttotal: 2.25s\tremaining: 3.3s\n",
      "4055:\tlearn: 0.0000001\ttotal: 2.25s\tremaining: 3.3s\n",
      "4056:\tlearn: 0.0000001\ttotal: 2.25s\tremaining: 3.3s\n",
      "4057:\tlearn: 0.0000001\ttotal: 2.25s\tremaining: 3.3s\n",
      "4058:\tlearn: 0.0000001\ttotal: 2.25s\tremaining: 3.3s\n",
      "4059:\tlearn: 0.0000001\ttotal: 2.25s\tremaining: 3.3s\n",
      "4060:\tlearn: 0.0000001\ttotal: 2.25s\tremaining: 3.3s\n",
      "4061:\tlearn: 0.0000001\ttotal: 2.25s\tremaining: 3.3s\n",
      "4062:\tlearn: 0.0000001\ttotal: 2.26s\tremaining: 3.3s\n",
      "4063:\tlearn: 0.0000001\ttotal: 2.26s\tremaining: 3.3s\n",
      "4064:\tlearn: 0.0000001\ttotal: 2.26s\tremaining: 3.29s\n",
      "4065:\tlearn: 0.0000001\ttotal: 2.26s\tremaining: 3.29s\n",
      "4066:\tlearn: 0.0000001\ttotal: 2.26s\tremaining: 3.29s\n",
      "4067:\tlearn: 0.0000001\ttotal: 2.26s\tremaining: 3.29s\n",
      "4068:\tlearn: 0.0000001\ttotal: 2.26s\tremaining: 3.29s\n",
      "4069:\tlearn: 0.0000001\ttotal: 2.26s\tremaining: 3.29s\n",
      "4070:\tlearn: 0.0000001\ttotal: 2.26s\tremaining: 3.29s\n",
      "4071:\tlearn: 0.0000001\ttotal: 2.26s\tremaining: 3.29s\n",
      "4072:\tlearn: 0.0000001\ttotal: 2.26s\tremaining: 3.29s\n",
      "4073:\tlearn: 0.0000001\ttotal: 2.26s\tremaining: 3.29s\n",
      "4074:\tlearn: 0.0000001\ttotal: 2.26s\tremaining: 3.29s\n",
      "4075:\tlearn: 0.0000001\ttotal: 2.26s\tremaining: 3.29s\n",
      "4076:\tlearn: 0.0000001\ttotal: 2.26s\tremaining: 3.29s\n",
      "4077:\tlearn: 0.0000001\ttotal: 2.26s\tremaining: 3.29s\n",
      "4078:\tlearn: 0.0000001\ttotal: 2.26s\tremaining: 3.29s\n",
      "4079:\tlearn: 0.0000001\ttotal: 2.26s\tremaining: 3.28s\n",
      "4080:\tlearn: 0.0000001\ttotal: 2.26s\tremaining: 3.28s\n",
      "4081:\tlearn: 0.0000001\ttotal: 2.27s\tremaining: 3.28s\n",
      "4082:\tlearn: 0.0000001\ttotal: 2.27s\tremaining: 3.28s\n",
      "4083:\tlearn: 0.0000001\ttotal: 2.27s\tremaining: 3.28s\n",
      "4084:\tlearn: 0.0000001\ttotal: 2.27s\tremaining: 3.28s\n",
      "4085:\tlearn: 0.0000001\ttotal: 2.27s\tremaining: 3.28s\n",
      "4086:\tlearn: 0.0000001\ttotal: 2.27s\tremaining: 3.28s\n",
      "4087:\tlearn: 0.0000001\ttotal: 2.27s\tremaining: 3.28s\n",
      "4088:\tlearn: 0.0000001\ttotal: 2.27s\tremaining: 3.28s\n",
      "4089:\tlearn: 0.0000001\ttotal: 2.27s\tremaining: 3.28s\n",
      "4090:\tlearn: 0.0000001\ttotal: 2.27s\tremaining: 3.28s\n",
      "4091:\tlearn: 0.0000001\ttotal: 2.27s\tremaining: 3.28s\n",
      "4092:\tlearn: 0.0000001\ttotal: 2.27s\tremaining: 3.28s\n",
      "4093:\tlearn: 0.0000001\ttotal: 2.27s\tremaining: 3.28s\n",
      "4094:\tlearn: 0.0000001\ttotal: 2.27s\tremaining: 3.28s\n",
      "4095:\tlearn: 0.0000001\ttotal: 2.27s\tremaining: 3.27s\n",
      "4096:\tlearn: 0.0000001\ttotal: 2.27s\tremaining: 3.27s\n",
      "4097:\tlearn: 0.0000001\ttotal: 2.27s\tremaining: 3.27s\n",
      "4098:\tlearn: 0.0000001\ttotal: 2.27s\tremaining: 3.27s\n",
      "4099:\tlearn: 0.0000001\ttotal: 2.27s\tremaining: 3.27s\n",
      "4100:\tlearn: 0.0000001\ttotal: 2.27s\tremaining: 3.27s\n",
      "4101:\tlearn: 0.0000001\ttotal: 2.27s\tremaining: 3.27s\n",
      "4102:\tlearn: 0.0000001\ttotal: 2.28s\tremaining: 3.27s\n",
      "4103:\tlearn: 0.0000001\ttotal: 2.28s\tremaining: 3.27s\n",
      "4104:\tlearn: 0.0000001\ttotal: 2.28s\tremaining: 3.27s\n",
      "4105:\tlearn: 0.0000001\ttotal: 2.28s\tremaining: 3.27s\n",
      "4106:\tlearn: 0.0000001\ttotal: 2.28s\tremaining: 3.27s\n",
      "4107:\tlearn: 0.0000001\ttotal: 2.28s\tremaining: 3.27s\n",
      "4108:\tlearn: 0.0000001\ttotal: 2.28s\tremaining: 3.27s\n",
      "4109:\tlearn: 0.0000001\ttotal: 2.28s\tremaining: 3.27s\n",
      "4110:\tlearn: 0.0000001\ttotal: 2.28s\tremaining: 3.27s\n",
      "4111:\tlearn: 0.0000001\ttotal: 2.28s\tremaining: 3.27s\n",
      "4112:\tlearn: 0.0000001\ttotal: 2.28s\tremaining: 3.27s\n",
      "4113:\tlearn: 0.0000001\ttotal: 2.28s\tremaining: 3.27s\n",
      "4114:\tlearn: 0.0000001\ttotal: 2.28s\tremaining: 3.26s\n",
      "4115:\tlearn: 0.0000001\ttotal: 2.28s\tremaining: 3.26s\n",
      "4116:\tlearn: 0.0000001\ttotal: 2.28s\tremaining: 3.26s\n",
      "4117:\tlearn: 0.0000001\ttotal: 2.28s\tremaining: 3.26s\n",
      "4118:\tlearn: 0.0000001\ttotal: 2.28s\tremaining: 3.26s\n",
      "4119:\tlearn: 0.0000001\ttotal: 2.29s\tremaining: 3.26s\n",
      "4120:\tlearn: 0.0000001\ttotal: 2.29s\tremaining: 3.26s\n",
      "4121:\tlearn: 0.0000001\ttotal: 2.29s\tremaining: 3.26s\n",
      "4122:\tlearn: 0.0000001\ttotal: 2.29s\tremaining: 3.26s\n",
      "4123:\tlearn: 0.0000001\ttotal: 2.29s\tremaining: 3.26s\n",
      "4124:\tlearn: 0.0000001\ttotal: 2.29s\tremaining: 3.26s\n",
      "4125:\tlearn: 0.0000001\ttotal: 2.29s\tremaining: 3.26s\n",
      "4126:\tlearn: 0.0000001\ttotal: 2.29s\tremaining: 3.26s\n",
      "4127:\tlearn: 0.0000001\ttotal: 2.29s\tremaining: 3.26s\n",
      "4128:\tlearn: 0.0000001\ttotal: 2.29s\tremaining: 3.25s\n",
      "4129:\tlearn: 0.0000001\ttotal: 2.29s\tremaining: 3.25s\n",
      "4130:\tlearn: 0.0000001\ttotal: 2.29s\tremaining: 3.25s\n",
      "4131:\tlearn: 0.0000001\ttotal: 2.29s\tremaining: 3.25s\n",
      "4132:\tlearn: 0.0000001\ttotal: 2.29s\tremaining: 3.25s\n",
      "4133:\tlearn: 0.0000001\ttotal: 2.29s\tremaining: 3.25s\n",
      "4134:\tlearn: 0.0000001\ttotal: 2.29s\tremaining: 3.25s\n",
      "4135:\tlearn: 0.0000001\ttotal: 2.29s\tremaining: 3.25s\n",
      "4136:\tlearn: 0.0000001\ttotal: 2.29s\tremaining: 3.25s\n",
      "4137:\tlearn: 0.0000001\ttotal: 2.29s\tremaining: 3.25s\n",
      "4138:\tlearn: 0.0000001\ttotal: 2.29s\tremaining: 3.25s\n",
      "4139:\tlearn: 0.0000001\ttotal: 2.3s\tremaining: 3.25s\n",
      "4140:\tlearn: 0.0000001\ttotal: 2.3s\tremaining: 3.25s\n",
      "4141:\tlearn: 0.0000001\ttotal: 2.3s\tremaining: 3.25s\n",
      "4142:\tlearn: 0.0000001\ttotal: 2.3s\tremaining: 3.25s\n",
      "4143:\tlearn: 0.0000001\ttotal: 2.3s\tremaining: 3.25s\n",
      "4144:\tlearn: 0.0000001\ttotal: 2.3s\tremaining: 3.25s\n",
      "4145:\tlearn: 0.0000001\ttotal: 2.3s\tremaining: 3.25s\n",
      "4146:\tlearn: 0.0000001\ttotal: 2.3s\tremaining: 3.25s\n",
      "4147:\tlearn: 0.0000001\ttotal: 2.3s\tremaining: 3.25s\n",
      "4148:\tlearn: 0.0000001\ttotal: 2.3s\tremaining: 3.24s\n",
      "4149:\tlearn: 0.0000001\ttotal: 2.3s\tremaining: 3.24s\n",
      "4150:\tlearn: 0.0000001\ttotal: 2.3s\tremaining: 3.24s\n",
      "4151:\tlearn: 0.0000001\ttotal: 2.3s\tremaining: 3.24s\n",
      "4152:\tlearn: 0.0000001\ttotal: 2.3s\tremaining: 3.24s\n",
      "4153:\tlearn: 0.0000001\ttotal: 2.3s\tremaining: 3.24s\n",
      "4154:\tlearn: 0.0000001\ttotal: 2.3s\tremaining: 3.24s\n",
      "4155:\tlearn: 0.0000001\ttotal: 2.3s\tremaining: 3.24s\n",
      "4156:\tlearn: 0.0000001\ttotal: 2.3s\tremaining: 3.24s\n",
      "4157:\tlearn: 0.0000001\ttotal: 2.3s\tremaining: 3.24s\n",
      "4158:\tlearn: 0.0000001\ttotal: 2.31s\tremaining: 3.24s\n",
      "4159:\tlearn: 0.0000001\ttotal: 2.31s\tremaining: 3.24s\n",
      "4160:\tlearn: 0.0000001\ttotal: 2.31s\tremaining: 3.24s\n",
      "4161:\tlearn: 0.0000001\ttotal: 2.31s\tremaining: 3.24s\n",
      "4162:\tlearn: 0.0000001\ttotal: 2.31s\tremaining: 3.24s\n",
      "4163:\tlearn: 0.0000001\ttotal: 2.31s\tremaining: 3.24s\n",
      "4164:\tlearn: 0.0000001\ttotal: 2.31s\tremaining: 3.23s\n",
      "4165:\tlearn: 0.0000001\ttotal: 2.31s\tremaining: 3.23s\n",
      "4166:\tlearn: 0.0000001\ttotal: 2.31s\tremaining: 3.23s\n",
      "4167:\tlearn: 0.0000001\ttotal: 2.31s\tremaining: 3.23s\n",
      "4168:\tlearn: 0.0000001\ttotal: 2.31s\tremaining: 3.23s\n",
      "4169:\tlearn: 0.0000001\ttotal: 2.31s\tremaining: 3.23s\n",
      "4170:\tlearn: 0.0000001\ttotal: 2.31s\tremaining: 3.23s\n",
      "4171:\tlearn: 0.0000001\ttotal: 2.31s\tremaining: 3.23s\n",
      "4172:\tlearn: 0.0000001\ttotal: 2.31s\tremaining: 3.23s\n",
      "4173:\tlearn: 0.0000001\ttotal: 2.32s\tremaining: 3.24s\n",
      "4174:\tlearn: 0.0000001\ttotal: 2.32s\tremaining: 3.24s\n",
      "4175:\tlearn: 0.0000001\ttotal: 2.33s\tremaining: 3.24s\n",
      "4176:\tlearn: 0.0000001\ttotal: 2.33s\tremaining: 3.24s\n",
      "4177:\tlearn: 0.0000001\ttotal: 2.33s\tremaining: 3.24s\n",
      "4178:\tlearn: 0.0000001\ttotal: 2.33s\tremaining: 3.24s\n",
      "4179:\tlearn: 0.0000001\ttotal: 2.33s\tremaining: 3.24s\n",
      "4180:\tlearn: 0.0000001\ttotal: 2.33s\tremaining: 3.24s\n",
      "4181:\tlearn: 0.0000001\ttotal: 2.33s\tremaining: 3.24s\n",
      "4182:\tlearn: 0.0000001\ttotal: 2.33s\tremaining: 3.24s\n",
      "4183:\tlearn: 0.0000001\ttotal: 2.33s\tremaining: 3.24s\n",
      "4184:\tlearn: 0.0000001\ttotal: 2.33s\tremaining: 3.24s\n",
      "4185:\tlearn: 0.0000001\ttotal: 2.33s\tremaining: 3.24s\n",
      "4186:\tlearn: 0.0000001\ttotal: 2.33s\tremaining: 3.24s\n",
      "4187:\tlearn: 0.0000001\ttotal: 2.33s\tremaining: 3.23s\n",
      "4188:\tlearn: 0.0000001\ttotal: 2.33s\tremaining: 3.23s\n",
      "4189:\tlearn: 0.0000001\ttotal: 2.33s\tremaining: 3.23s\n",
      "4190:\tlearn: 0.0000001\ttotal: 2.33s\tremaining: 3.23s\n",
      "4191:\tlearn: 0.0000001\ttotal: 2.33s\tremaining: 3.23s\n",
      "4192:\tlearn: 0.0000001\ttotal: 2.33s\tremaining: 3.23s\n",
      "4193:\tlearn: 0.0000001\ttotal: 2.33s\tremaining: 3.23s\n",
      "4194:\tlearn: 0.0000001\ttotal: 2.33s\tremaining: 3.23s\n",
      "4195:\tlearn: 0.0000001\ttotal: 2.33s\tremaining: 3.23s\n",
      "4196:\tlearn: 0.0000001\ttotal: 2.33s\tremaining: 3.23s\n",
      "4197:\tlearn: 0.0000001\ttotal: 2.34s\tremaining: 3.23s\n",
      "4198:\tlearn: 0.0000001\ttotal: 2.34s\tremaining: 3.23s\n",
      "4199:\tlearn: 0.0000001\ttotal: 2.34s\tremaining: 3.23s\n",
      "4200:\tlearn: 0.0000001\ttotal: 2.34s\tremaining: 3.23s\n",
      "4201:\tlearn: 0.0000001\ttotal: 2.34s\tremaining: 3.23s\n",
      "4202:\tlearn: 0.0000001\ttotal: 2.34s\tremaining: 3.23s\n",
      "4203:\tlearn: 0.0000001\ttotal: 2.34s\tremaining: 3.23s\n",
      "4204:\tlearn: 0.0000001\ttotal: 2.34s\tremaining: 3.23s\n",
      "4205:\tlearn: 0.0000001\ttotal: 2.34s\tremaining: 3.22s\n",
      "4206:\tlearn: 0.0000001\ttotal: 2.34s\tremaining: 3.22s\n",
      "4207:\tlearn: 0.0000001\ttotal: 2.34s\tremaining: 3.22s\n",
      "4208:\tlearn: 0.0000001\ttotal: 2.34s\tremaining: 3.22s\n",
      "4209:\tlearn: 0.0000001\ttotal: 2.34s\tremaining: 3.22s\n",
      "4210:\tlearn: 0.0000001\ttotal: 2.34s\tremaining: 3.22s\n",
      "4211:\tlearn: 0.0000001\ttotal: 2.34s\tremaining: 3.22s\n",
      "4212:\tlearn: 0.0000001\ttotal: 2.34s\tremaining: 3.22s\n",
      "4213:\tlearn: 0.0000001\ttotal: 2.34s\tremaining: 3.22s\n",
      "4214:\tlearn: 0.0000001\ttotal: 2.35s\tremaining: 3.22s\n",
      "4215:\tlearn: 0.0000001\ttotal: 2.35s\tremaining: 3.22s\n",
      "4216:\tlearn: 0.0000001\ttotal: 2.35s\tremaining: 3.22s\n",
      "4217:\tlearn: 0.0000001\ttotal: 2.35s\tremaining: 3.22s\n",
      "4218:\tlearn: 0.0000001\ttotal: 2.35s\tremaining: 3.22s\n",
      "4219:\tlearn: 0.0000001\ttotal: 2.35s\tremaining: 3.21s\n",
      "4220:\tlearn: 0.0000001\ttotal: 2.35s\tremaining: 3.21s\n",
      "4221:\tlearn: 0.0000001\ttotal: 2.35s\tremaining: 3.21s\n",
      "4222:\tlearn: 0.0000001\ttotal: 2.35s\tremaining: 3.21s\n",
      "4223:\tlearn: 0.0000001\ttotal: 2.35s\tremaining: 3.21s\n",
      "4224:\tlearn: 0.0000001\ttotal: 2.35s\tremaining: 3.21s\n",
      "4225:\tlearn: 0.0000001\ttotal: 2.35s\tremaining: 3.21s\n",
      "4226:\tlearn: 0.0000001\ttotal: 2.35s\tremaining: 3.21s\n",
      "4227:\tlearn: 0.0000001\ttotal: 2.35s\tremaining: 3.21s\n",
      "4228:\tlearn: 0.0000001\ttotal: 2.35s\tremaining: 3.21s\n",
      "4229:\tlearn: 0.0000000\ttotal: 2.35s\tremaining: 3.21s\n",
      "4230:\tlearn: 0.0000000\ttotal: 2.35s\tremaining: 3.21s\n",
      "4231:\tlearn: 0.0000000\ttotal: 2.36s\tremaining: 3.21s\n",
      "4232:\tlearn: 0.0000000\ttotal: 2.36s\tremaining: 3.21s\n",
      "4233:\tlearn: 0.0000000\ttotal: 2.36s\tremaining: 3.21s\n",
      "4234:\tlearn: 0.0000000\ttotal: 2.36s\tremaining: 3.21s\n",
      "4235:\tlearn: 0.0000000\ttotal: 2.36s\tremaining: 3.21s\n",
      "4236:\tlearn: 0.0000000\ttotal: 2.36s\tremaining: 3.21s\n",
      "4237:\tlearn: 0.0000000\ttotal: 2.36s\tremaining: 3.21s\n",
      "4238:\tlearn: 0.0000000\ttotal: 2.36s\tremaining: 3.21s\n",
      "4239:\tlearn: 0.0000000\ttotal: 2.36s\tremaining: 3.21s\n",
      "4240:\tlearn: 0.0000000\ttotal: 2.36s\tremaining: 3.21s\n",
      "4241:\tlearn: 0.0000000\ttotal: 2.36s\tremaining: 3.2s\n",
      "4242:\tlearn: 0.0000000\ttotal: 2.36s\tremaining: 3.2s\n",
      "4243:\tlearn: 0.0000000\ttotal: 2.36s\tremaining: 3.2s\n",
      "4244:\tlearn: 0.0000000\ttotal: 2.36s\tremaining: 3.2s\n",
      "4245:\tlearn: 0.0000000\ttotal: 2.36s\tremaining: 3.2s\n",
      "4246:\tlearn: 0.0000000\ttotal: 2.36s\tremaining: 3.2s\n",
      "4247:\tlearn: 0.0000000\ttotal: 2.36s\tremaining: 3.2s\n",
      "4248:\tlearn: 0.0000000\ttotal: 2.36s\tremaining: 3.2s\n",
      "4249:\tlearn: 0.0000000\ttotal: 2.36s\tremaining: 3.2s\n",
      "4250:\tlearn: 0.0000000\ttotal: 2.37s\tremaining: 3.2s\n",
      "4251:\tlearn: 0.0000000\ttotal: 2.37s\tremaining: 3.2s\n",
      "4252:\tlearn: 0.0000000\ttotal: 2.37s\tremaining: 3.2s\n",
      "4253:\tlearn: 0.0000000\ttotal: 2.37s\tremaining: 3.2s\n",
      "4254:\tlearn: 0.0000000\ttotal: 2.37s\tremaining: 3.2s\n",
      "4255:\tlearn: 0.0000000\ttotal: 2.37s\tremaining: 3.2s\n",
      "4256:\tlearn: 0.0000000\ttotal: 2.37s\tremaining: 3.19s\n",
      "4257:\tlearn: 0.0000000\ttotal: 2.37s\tremaining: 3.19s\n",
      "4258:\tlearn: 0.0000000\ttotal: 2.37s\tremaining: 3.19s\n",
      "4259:\tlearn: 0.0000000\ttotal: 2.37s\tremaining: 3.19s\n",
      "4260:\tlearn: 0.0000000\ttotal: 2.37s\tremaining: 3.19s\n",
      "4261:\tlearn: 0.0000000\ttotal: 2.37s\tremaining: 3.19s\n",
      "4262:\tlearn: 0.0000000\ttotal: 2.37s\tremaining: 3.19s\n",
      "4263:\tlearn: 0.0000000\ttotal: 2.37s\tremaining: 3.19s\n",
      "4264:\tlearn: 0.0000000\ttotal: 2.37s\tremaining: 3.19s\n",
      "4265:\tlearn: 0.0000000\ttotal: 2.37s\tremaining: 3.19s\n",
      "4266:\tlearn: 0.0000000\ttotal: 2.37s\tremaining: 3.19s\n",
      "4267:\tlearn: 0.0000000\ttotal: 2.37s\tremaining: 3.19s\n",
      "4268:\tlearn: 0.0000000\ttotal: 2.37s\tremaining: 3.19s\n",
      "4269:\tlearn: 0.0000000\ttotal: 2.37s\tremaining: 3.19s\n",
      "4270:\tlearn: 0.0000000\ttotal: 2.38s\tremaining: 3.19s\n",
      "4271:\tlearn: 0.0000000\ttotal: 2.38s\tremaining: 3.19s\n",
      "4272:\tlearn: 0.0000000\ttotal: 2.38s\tremaining: 3.18s\n",
      "4273:\tlearn: 0.0000000\ttotal: 2.38s\tremaining: 3.18s\n",
      "4274:\tlearn: 0.0000000\ttotal: 2.38s\tremaining: 3.18s\n",
      "4275:\tlearn: 0.0000000\ttotal: 2.38s\tremaining: 3.18s\n",
      "4276:\tlearn: 0.0000000\ttotal: 2.38s\tremaining: 3.18s\n",
      "4277:\tlearn: 0.0000000\ttotal: 2.38s\tremaining: 3.18s\n",
      "4278:\tlearn: 0.0000000\ttotal: 2.38s\tremaining: 3.18s\n",
      "4279:\tlearn: 0.0000000\ttotal: 2.38s\tremaining: 3.18s\n",
      "4280:\tlearn: 0.0000000\ttotal: 2.38s\tremaining: 3.18s\n",
      "4281:\tlearn: 0.0000000\ttotal: 2.38s\tremaining: 3.18s\n",
      "4282:\tlearn: 0.0000000\ttotal: 2.38s\tremaining: 3.18s\n",
      "4283:\tlearn: 0.0000000\ttotal: 2.38s\tremaining: 3.18s\n",
      "4284:\tlearn: 0.0000000\ttotal: 2.38s\tremaining: 3.18s\n",
      "4285:\tlearn: 0.0000000\ttotal: 2.38s\tremaining: 3.18s\n",
      "4286:\tlearn: 0.0000000\ttotal: 2.38s\tremaining: 3.18s\n",
      "4287:\tlearn: 0.0000000\ttotal: 2.38s\tremaining: 3.17s\n",
      "4288:\tlearn: 0.0000000\ttotal: 2.38s\tremaining: 3.17s\n",
      "4289:\tlearn: 0.0000000\ttotal: 2.38s\tremaining: 3.17s\n",
      "4290:\tlearn: 0.0000000\ttotal: 2.38s\tremaining: 3.17s\n",
      "4291:\tlearn: 0.0000000\ttotal: 2.38s\tremaining: 3.17s\n",
      "4292:\tlearn: 0.0000000\ttotal: 2.39s\tremaining: 3.17s\n",
      "4293:\tlearn: 0.0000000\ttotal: 2.39s\tremaining: 3.17s\n",
      "4294:\tlearn: 0.0000000\ttotal: 2.39s\tremaining: 3.17s\n",
      "4295:\tlearn: 0.0000000\ttotal: 2.39s\tremaining: 3.17s\n",
      "4296:\tlearn: 0.0000000\ttotal: 2.39s\tremaining: 3.17s\n",
      "4297:\tlearn: 0.0000000\ttotal: 2.39s\tremaining: 3.17s\n",
      "4298:\tlearn: 0.0000000\ttotal: 2.39s\tremaining: 3.17s\n",
      "4299:\tlearn: 0.0000000\ttotal: 2.39s\tremaining: 3.17s\n",
      "4300:\tlearn: 0.0000000\ttotal: 2.39s\tremaining: 3.17s\n",
      "4301:\tlearn: 0.0000000\ttotal: 2.39s\tremaining: 3.17s\n",
      "4302:\tlearn: 0.0000000\ttotal: 2.39s\tremaining: 3.16s\n",
      "4303:\tlearn: 0.0000000\ttotal: 2.39s\tremaining: 3.16s\n",
      "4304:\tlearn: 0.0000000\ttotal: 2.39s\tremaining: 3.16s\n",
      "4305:\tlearn: 0.0000000\ttotal: 2.39s\tremaining: 3.16s\n",
      "4306:\tlearn: 0.0000000\ttotal: 2.39s\tremaining: 3.16s\n",
      "4307:\tlearn: 0.0000000\ttotal: 2.39s\tremaining: 3.16s\n",
      "4308:\tlearn: 0.0000000\ttotal: 2.39s\tremaining: 3.16s\n",
      "4309:\tlearn: 0.0000000\ttotal: 2.39s\tremaining: 3.16s\n",
      "4310:\tlearn: 0.0000000\ttotal: 2.39s\tremaining: 3.16s\n",
      "4311:\tlearn: 0.0000000\ttotal: 2.4s\tremaining: 3.16s\n",
      "4312:\tlearn: 0.0000000\ttotal: 2.4s\tremaining: 3.16s\n",
      "4313:\tlearn: 0.0000000\ttotal: 2.4s\tremaining: 3.16s\n",
      "4314:\tlearn: 0.0000000\ttotal: 2.4s\tremaining: 3.16s\n",
      "4315:\tlearn: 0.0000000\ttotal: 2.4s\tremaining: 3.16s\n",
      "4316:\tlearn: 0.0000000\ttotal: 2.4s\tremaining: 3.16s\n",
      "4317:\tlearn: 0.0000000\ttotal: 2.4s\tremaining: 3.15s\n",
      "4318:\tlearn: 0.0000000\ttotal: 2.4s\tremaining: 3.15s\n",
      "4319:\tlearn: 0.0000000\ttotal: 2.4s\tremaining: 3.15s\n",
      "4320:\tlearn: 0.0000000\ttotal: 2.4s\tremaining: 3.15s\n",
      "4321:\tlearn: 0.0000000\ttotal: 2.4s\tremaining: 3.15s\n",
      "4322:\tlearn: 0.0000000\ttotal: 2.4s\tremaining: 3.15s\n",
      "4323:\tlearn: 0.0000000\ttotal: 2.4s\tremaining: 3.15s\n",
      "4324:\tlearn: 0.0000000\ttotal: 2.4s\tremaining: 3.15s\n",
      "4325:\tlearn: 0.0000000\ttotal: 2.4s\tremaining: 3.15s\n",
      "4326:\tlearn: 0.0000000\ttotal: 2.4s\tremaining: 3.15s\n",
      "4327:\tlearn: 0.0000000\ttotal: 2.4s\tremaining: 3.15s\n",
      "4328:\tlearn: 0.0000000\ttotal: 2.4s\tremaining: 3.15s\n",
      "4329:\tlearn: 0.0000000\ttotal: 2.4s\tremaining: 3.15s\n",
      "4330:\tlearn: 0.0000000\ttotal: 2.4s\tremaining: 3.15s\n",
      "4331:\tlearn: 0.0000000\ttotal: 2.4s\tremaining: 3.15s\n",
      "4332:\tlearn: 0.0000000\ttotal: 2.4s\tremaining: 3.15s\n",
      "4333:\tlearn: 0.0000000\ttotal: 2.4s\tremaining: 3.15s\n",
      "4334:\tlearn: 0.0000000\ttotal: 2.41s\tremaining: 3.14s\n",
      "4335:\tlearn: 0.0000000\ttotal: 2.41s\tremaining: 3.14s\n",
      "4336:\tlearn: 0.0000000\ttotal: 2.41s\tremaining: 3.14s\n",
      "4337:\tlearn: 0.0000000\ttotal: 2.41s\tremaining: 3.14s\n",
      "4338:\tlearn: 0.0000000\ttotal: 2.41s\tremaining: 3.14s\n",
      "4339:\tlearn: 0.0000000\ttotal: 2.41s\tremaining: 3.14s\n",
      "4340:\tlearn: 0.0000000\ttotal: 2.41s\tremaining: 3.14s\n",
      "4341:\tlearn: 0.0000000\ttotal: 2.41s\tremaining: 3.14s\n",
      "4342:\tlearn: 0.0000000\ttotal: 2.41s\tremaining: 3.14s\n",
      "4343:\tlearn: 0.0000000\ttotal: 2.41s\tremaining: 3.14s\n",
      "4344:\tlearn: 0.0000000\ttotal: 2.41s\tremaining: 3.14s\n",
      "4345:\tlearn: 0.0000000\ttotal: 2.41s\tremaining: 3.14s\n",
      "4346:\tlearn: 0.0000000\ttotal: 2.41s\tremaining: 3.14s\n",
      "4347:\tlearn: 0.0000000\ttotal: 2.41s\tremaining: 3.14s\n",
      "4348:\tlearn: 0.0000000\ttotal: 2.41s\tremaining: 3.14s\n",
      "4349:\tlearn: 0.0000000\ttotal: 2.41s\tremaining: 3.13s\n",
      "4350:\tlearn: 0.0000000\ttotal: 2.41s\tremaining: 3.13s\n",
      "4351:\tlearn: 0.0000000\ttotal: 2.42s\tremaining: 3.13s\n",
      "4352:\tlearn: 0.0000000\ttotal: 2.42s\tremaining: 3.13s\n",
      "4353:\tlearn: 0.0000000\ttotal: 2.42s\tremaining: 3.13s\n",
      "4354:\tlearn: 0.0000000\ttotal: 2.42s\tremaining: 3.13s\n",
      "4355:\tlearn: 0.0000000\ttotal: 2.42s\tremaining: 3.13s\n",
      "4356:\tlearn: 0.0000000\ttotal: 2.42s\tremaining: 3.13s\n",
      "4357:\tlearn: 0.0000000\ttotal: 2.42s\tremaining: 3.13s\n",
      "4358:\tlearn: 0.0000000\ttotal: 2.42s\tremaining: 3.13s\n",
      "4359:\tlearn: 0.0000000\ttotal: 2.42s\tremaining: 3.13s\n",
      "4360:\tlearn: 0.0000000\ttotal: 2.42s\tremaining: 3.13s\n",
      "4361:\tlearn: 0.0000000\ttotal: 2.42s\tremaining: 3.13s\n",
      "4362:\tlearn: 0.0000000\ttotal: 2.42s\tremaining: 3.13s\n",
      "4363:\tlearn: 0.0000000\ttotal: 2.42s\tremaining: 3.13s\n",
      "4364:\tlearn: 0.0000000\ttotal: 2.42s\tremaining: 3.13s\n",
      "4365:\tlearn: 0.0000000\ttotal: 2.42s\tremaining: 3.12s\n",
      "4366:\tlearn: 0.0000000\ttotal: 2.42s\tremaining: 3.12s\n",
      "4367:\tlearn: 0.0000000\ttotal: 2.42s\tremaining: 3.12s\n",
      "4368:\tlearn: 0.0000000\ttotal: 2.42s\tremaining: 3.12s\n",
      "4369:\tlearn: 0.0000000\ttotal: 2.42s\tremaining: 3.12s\n",
      "4370:\tlearn: 0.0000000\ttotal: 2.42s\tremaining: 3.12s\n",
      "4371:\tlearn: 0.0000000\ttotal: 2.42s\tremaining: 3.12s\n",
      "4372:\tlearn: 0.0000000\ttotal: 2.42s\tremaining: 3.12s\n",
      "4373:\tlearn: 0.0000000\ttotal: 2.42s\tremaining: 3.12s\n",
      "4374:\tlearn: 0.0000000\ttotal: 2.43s\tremaining: 3.12s\n",
      "4375:\tlearn: 0.0000000\ttotal: 2.43s\tremaining: 3.12s\n",
      "4376:\tlearn: 0.0000000\ttotal: 2.43s\tremaining: 3.12s\n",
      "4377:\tlearn: 0.0000000\ttotal: 2.43s\tremaining: 3.12s\n",
      "4378:\tlearn: 0.0000000\ttotal: 2.43s\tremaining: 3.12s\n",
      "4379:\tlearn: 0.0000000\ttotal: 2.43s\tremaining: 3.12s\n",
      "4380:\tlearn: 0.0000000\ttotal: 2.43s\tremaining: 3.12s\n",
      "4381:\tlearn: 0.0000000\ttotal: 2.43s\tremaining: 3.11s\n",
      "4382:\tlearn: 0.0000000\ttotal: 2.43s\tremaining: 3.11s\n",
      "4383:\tlearn: 0.0000000\ttotal: 2.43s\tremaining: 3.11s\n",
      "4384:\tlearn: 0.0000000\ttotal: 2.43s\tremaining: 3.11s\n",
      "4385:\tlearn: 0.0000000\ttotal: 2.43s\tremaining: 3.11s\n",
      "4386:\tlearn: 0.0000000\ttotal: 2.43s\tremaining: 3.11s\n",
      "4387:\tlearn: 0.0000000\ttotal: 2.43s\tremaining: 3.11s\n",
      "4388:\tlearn: 0.0000000\ttotal: 2.43s\tremaining: 3.11s\n",
      "4389:\tlearn: 0.0000000\ttotal: 2.43s\tremaining: 3.11s\n",
      "4390:\tlearn: 0.0000000\ttotal: 2.43s\tremaining: 3.11s\n",
      "4391:\tlearn: 0.0000000\ttotal: 2.43s\tremaining: 3.11s\n",
      "4392:\tlearn: 0.0000000\ttotal: 2.43s\tremaining: 3.11s\n",
      "4393:\tlearn: 0.0000000\ttotal: 2.44s\tremaining: 3.11s\n",
      "4394:\tlearn: 0.0000000\ttotal: 2.44s\tremaining: 3.11s\n",
      "4395:\tlearn: 0.0000000\ttotal: 2.44s\tremaining: 3.1s\n",
      "4396:\tlearn: 0.0000000\ttotal: 2.44s\tremaining: 3.1s\n",
      "4397:\tlearn: 0.0000000\ttotal: 2.44s\tremaining: 3.1s\n",
      "4398:\tlearn: 0.0000000\ttotal: 2.44s\tremaining: 3.1s\n",
      "4399:\tlearn: 0.0000000\ttotal: 2.44s\tremaining: 3.1s\n",
      "4400:\tlearn: 0.0000000\ttotal: 2.44s\tremaining: 3.1s\n",
      "4401:\tlearn: 0.0000000\ttotal: 2.44s\tremaining: 3.1s\n",
      "4402:\tlearn: 0.0000000\ttotal: 2.44s\tremaining: 3.1s\n",
      "4403:\tlearn: 0.0000000\ttotal: 2.44s\tremaining: 3.1s\n",
      "4404:\tlearn: 0.0000000\ttotal: 2.44s\tremaining: 3.1s\n",
      "4405:\tlearn: 0.0000000\ttotal: 2.44s\tremaining: 3.1s\n",
      "4406:\tlearn: 0.0000000\ttotal: 2.44s\tremaining: 3.1s\n",
      "4407:\tlearn: 0.0000000\ttotal: 2.44s\tremaining: 3.1s\n",
      "4408:\tlearn: 0.0000000\ttotal: 2.44s\tremaining: 3.1s\n",
      "4409:\tlearn: 0.0000000\ttotal: 2.44s\tremaining: 3.1s\n",
      "4410:\tlearn: 0.0000000\ttotal: 2.44s\tremaining: 3.1s\n",
      "4411:\tlearn: 0.0000000\ttotal: 2.44s\tremaining: 3.1s\n",
      "4412:\tlearn: 0.0000000\ttotal: 2.44s\tremaining: 3.1s\n",
      "4413:\tlearn: 0.0000000\ttotal: 2.44s\tremaining: 3.09s\n",
      "4414:\tlearn: 0.0000000\ttotal: 2.45s\tremaining: 3.09s\n",
      "4415:\tlearn: 0.0000000\ttotal: 2.45s\tremaining: 3.09s\n",
      "4416:\tlearn: 0.0000000\ttotal: 2.45s\tremaining: 3.09s\n",
      "4417:\tlearn: 0.0000000\ttotal: 2.45s\tremaining: 3.09s\n",
      "4418:\tlearn: 0.0000000\ttotal: 2.45s\tremaining: 3.09s\n",
      "4419:\tlearn: 0.0000000\ttotal: 2.45s\tremaining: 3.09s\n",
      "4420:\tlearn: 0.0000000\ttotal: 2.45s\tremaining: 3.09s\n",
      "4421:\tlearn: 0.0000000\ttotal: 2.45s\tremaining: 3.09s\n",
      "4422:\tlearn: 0.0000000\ttotal: 2.45s\tremaining: 3.09s\n",
      "4423:\tlearn: 0.0000000\ttotal: 2.45s\tremaining: 3.09s\n",
      "4424:\tlearn: 0.0000000\ttotal: 2.45s\tremaining: 3.09s\n",
      "4425:\tlearn: 0.0000000\ttotal: 2.45s\tremaining: 3.09s\n",
      "4426:\tlearn: 0.0000000\ttotal: 2.45s\tremaining: 3.09s\n",
      "4427:\tlearn: 0.0000000\ttotal: 2.45s\tremaining: 3.09s\n",
      "4428:\tlearn: 0.0000000\ttotal: 2.45s\tremaining: 3.08s\n",
      "4429:\tlearn: 0.0000000\ttotal: 2.45s\tremaining: 3.08s\n",
      "4430:\tlearn: 0.0000000\ttotal: 2.45s\tremaining: 3.08s\n",
      "4431:\tlearn: 0.0000000\ttotal: 2.45s\tremaining: 3.08s\n",
      "4432:\tlearn: 0.0000000\ttotal: 2.45s\tremaining: 3.08s\n",
      "4433:\tlearn: 0.0000000\ttotal: 2.46s\tremaining: 3.08s\n",
      "4434:\tlearn: 0.0000000\ttotal: 2.46s\tremaining: 3.08s\n",
      "4435:\tlearn: 0.0000000\ttotal: 2.46s\tremaining: 3.08s\n",
      "4436:\tlearn: 0.0000000\ttotal: 2.46s\tremaining: 3.08s\n",
      "4437:\tlearn: 0.0000000\ttotal: 2.46s\tremaining: 3.08s\n",
      "4438:\tlearn: 0.0000000\ttotal: 2.46s\tremaining: 3.08s\n",
      "4439:\tlearn: 0.0000000\ttotal: 2.46s\tremaining: 3.08s\n",
      "4440:\tlearn: 0.0000000\ttotal: 2.46s\tremaining: 3.08s\n",
      "4441:\tlearn: 0.0000000\ttotal: 2.46s\tremaining: 3.08s\n",
      "4442:\tlearn: 0.0000000\ttotal: 2.46s\tremaining: 3.08s\n",
      "4443:\tlearn: 0.0000000\ttotal: 2.46s\tremaining: 3.08s\n",
      "4444:\tlearn: 0.0000000\ttotal: 2.46s\tremaining: 3.07s\n",
      "4445:\tlearn: 0.0000000\ttotal: 2.46s\tremaining: 3.07s\n",
      "4446:\tlearn: 0.0000000\ttotal: 2.46s\tremaining: 3.07s\n",
      "4447:\tlearn: 0.0000000\ttotal: 2.46s\tremaining: 3.07s\n",
      "4448:\tlearn: 0.0000000\ttotal: 2.46s\tremaining: 3.07s\n",
      "4449:\tlearn: 0.0000000\ttotal: 2.46s\tremaining: 3.07s\n",
      "4450:\tlearn: 0.0000000\ttotal: 2.46s\tremaining: 3.07s\n",
      "4451:\tlearn: 0.0000000\ttotal: 2.46s\tremaining: 3.07s\n",
      "4452:\tlearn: 0.0000000\ttotal: 2.46s\tremaining: 3.07s\n",
      "4453:\tlearn: 0.0000000\ttotal: 2.46s\tremaining: 3.07s\n",
      "4454:\tlearn: 0.0000000\ttotal: 2.47s\tremaining: 3.07s\n",
      "4455:\tlearn: 0.0000000\ttotal: 2.47s\tremaining: 3.07s\n",
      "4456:\tlearn: 0.0000000\ttotal: 2.47s\tremaining: 3.07s\n",
      "4457:\tlearn: 0.0000000\ttotal: 2.47s\tremaining: 3.07s\n",
      "4458:\tlearn: 0.0000000\ttotal: 2.47s\tremaining: 3.07s\n",
      "4459:\tlearn: 0.0000000\ttotal: 2.47s\tremaining: 3.07s\n",
      "4460:\tlearn: 0.0000000\ttotal: 2.47s\tremaining: 3.07s\n",
      "4461:\tlearn: 0.0000000\ttotal: 2.47s\tremaining: 3.07s\n",
      "4462:\tlearn: 0.0000000\ttotal: 2.47s\tremaining: 3.06s\n",
      "4463:\tlearn: 0.0000000\ttotal: 2.47s\tremaining: 3.06s\n",
      "4464:\tlearn: 0.0000000\ttotal: 2.47s\tremaining: 3.06s\n",
      "4465:\tlearn: 0.0000000\ttotal: 2.47s\tremaining: 3.06s\n",
      "4466:\tlearn: 0.0000000\ttotal: 2.47s\tremaining: 3.06s\n",
      "4467:\tlearn: 0.0000000\ttotal: 2.47s\tremaining: 3.06s\n",
      "4468:\tlearn: 0.0000000\ttotal: 2.47s\tremaining: 3.06s\n",
      "4469:\tlearn: 0.0000000\ttotal: 2.47s\tremaining: 3.06s\n",
      "4470:\tlearn: 0.0000000\ttotal: 2.48s\tremaining: 3.06s\n",
      "4471:\tlearn: 0.0000000\ttotal: 2.48s\tremaining: 3.06s\n",
      "4472:\tlearn: 0.0000000\ttotal: 2.48s\tremaining: 3.06s\n",
      "4473:\tlearn: 0.0000000\ttotal: 2.48s\tremaining: 3.06s\n",
      "4474:\tlearn: 0.0000000\ttotal: 2.48s\tremaining: 3.06s\n",
      "4475:\tlearn: 0.0000000\ttotal: 2.48s\tremaining: 3.06s\n",
      "4476:\tlearn: 0.0000000\ttotal: 2.48s\tremaining: 3.06s\n",
      "4477:\tlearn: 0.0000000\ttotal: 2.48s\tremaining: 3.06s\n",
      "4478:\tlearn: 0.0000000\ttotal: 2.48s\tremaining: 3.06s\n",
      "4479:\tlearn: 0.0000000\ttotal: 2.48s\tremaining: 3.06s\n",
      "4480:\tlearn: 0.0000000\ttotal: 2.48s\tremaining: 3.05s\n",
      "4481:\tlearn: 0.0000000\ttotal: 2.48s\tremaining: 3.05s\n",
      "4482:\tlearn: 0.0000000\ttotal: 2.48s\tremaining: 3.05s\n",
      "4483:\tlearn: 0.0000000\ttotal: 2.48s\tremaining: 3.05s\n",
      "4484:\tlearn: 0.0000000\ttotal: 2.48s\tremaining: 3.05s\n",
      "4485:\tlearn: 0.0000000\ttotal: 2.48s\tremaining: 3.05s\n",
      "4486:\tlearn: 0.0000000\ttotal: 2.48s\tremaining: 3.05s\n",
      "4487:\tlearn: 0.0000000\ttotal: 2.48s\tremaining: 3.05s\n",
      "4488:\tlearn: 0.0000000\ttotal: 2.48s\tremaining: 3.05s\n",
      "4489:\tlearn: 0.0000000\ttotal: 2.48s\tremaining: 3.05s\n",
      "4490:\tlearn: 0.0000000\ttotal: 2.49s\tremaining: 3.05s\n",
      "4491:\tlearn: 0.0000000\ttotal: 2.49s\tremaining: 3.05s\n",
      "4492:\tlearn: 0.0000000\ttotal: 2.49s\tremaining: 3.05s\n",
      "4493:\tlearn: 0.0000000\ttotal: 2.49s\tremaining: 3.05s\n",
      "4494:\tlearn: 0.0000000\ttotal: 2.49s\tremaining: 3.05s\n",
      "4495:\tlearn: 0.0000000\ttotal: 2.49s\tremaining: 3.05s\n",
      "4496:\tlearn: 0.0000000\ttotal: 2.49s\tremaining: 3.05s\n",
      "4497:\tlearn: 0.0000000\ttotal: 2.49s\tremaining: 3.04s\n",
      "4498:\tlearn: 0.0000000\ttotal: 2.49s\tremaining: 3.04s\n",
      "4499:\tlearn: 0.0000000\ttotal: 2.49s\tremaining: 3.04s\n",
      "4500:\tlearn: 0.0000000\ttotal: 2.49s\tremaining: 3.04s\n",
      "4501:\tlearn: 0.0000000\ttotal: 2.49s\tremaining: 3.04s\n",
      "4502:\tlearn: 0.0000000\ttotal: 2.49s\tremaining: 3.04s\n",
      "4503:\tlearn: 0.0000000\ttotal: 2.49s\tremaining: 3.04s\n",
      "4504:\tlearn: 0.0000000\ttotal: 2.49s\tremaining: 3.04s\n",
      "4505:\tlearn: 0.0000000\ttotal: 2.49s\tremaining: 3.04s\n",
      "4506:\tlearn: 0.0000000\ttotal: 2.5s\tremaining: 3.04s\n",
      "4507:\tlearn: 0.0000000\ttotal: 2.5s\tremaining: 3.04s\n",
      "4508:\tlearn: 0.0000000\ttotal: 2.5s\tremaining: 3.04s\n",
      "4509:\tlearn: 0.0000000\ttotal: 2.5s\tremaining: 3.04s\n",
      "4510:\tlearn: 0.0000000\ttotal: 2.5s\tremaining: 3.04s\n",
      "4511:\tlearn: 0.0000000\ttotal: 2.5s\tremaining: 3.04s\n",
      "4512:\tlearn: 0.0000000\ttotal: 2.5s\tremaining: 3.04s\n",
      "4513:\tlearn: 0.0000000\ttotal: 2.5s\tremaining: 3.04s\n",
      "4514:\tlearn: 0.0000000\ttotal: 2.5s\tremaining: 3.04s\n",
      "4515:\tlearn: 0.0000000\ttotal: 2.5s\tremaining: 3.04s\n",
      "4516:\tlearn: 0.0000000\ttotal: 2.5s\tremaining: 3.03s\n",
      "4517:\tlearn: 0.0000000\ttotal: 2.5s\tremaining: 3.03s\n",
      "4518:\tlearn: 0.0000000\ttotal: 2.5s\tremaining: 3.03s\n",
      "4519:\tlearn: 0.0000000\ttotal: 2.5s\tremaining: 3.03s\n",
      "4520:\tlearn: 0.0000000\ttotal: 2.5s\tremaining: 3.03s\n",
      "4521:\tlearn: 0.0000000\ttotal: 2.5s\tremaining: 3.03s\n",
      "4522:\tlearn: 0.0000000\ttotal: 2.5s\tremaining: 3.03s\n",
      "4523:\tlearn: 0.0000000\ttotal: 2.5s\tremaining: 3.03s\n",
      "4524:\tlearn: 0.0000000\ttotal: 2.5s\tremaining: 3.03s\n",
      "4525:\tlearn: 0.0000000\ttotal: 2.5s\tremaining: 3.03s\n",
      "4526:\tlearn: 0.0000000\ttotal: 2.5s\tremaining: 3.03s\n",
      "4527:\tlearn: 0.0000000\ttotal: 2.5s\tremaining: 3.03s\n",
      "4528:\tlearn: 0.0000000\ttotal: 2.5s\tremaining: 3.03s\n",
      "4529:\tlearn: 0.0000000\ttotal: 2.51s\tremaining: 3.03s\n",
      "4530:\tlearn: 0.0000000\ttotal: 2.51s\tremaining: 3.02s\n",
      "4531:\tlearn: 0.0000000\ttotal: 2.51s\tremaining: 3.02s\n",
      "4532:\tlearn: 0.0000000\ttotal: 2.51s\tremaining: 3.02s\n",
      "4533:\tlearn: 0.0000000\ttotal: 2.51s\tremaining: 3.02s\n",
      "4534:\tlearn: 0.0000000\ttotal: 2.51s\tremaining: 3.02s\n",
      "4535:\tlearn: 0.0000000\ttotal: 2.51s\tremaining: 3.02s\n",
      "4536:\tlearn: 0.0000000\ttotal: 2.51s\tremaining: 3.02s\n",
      "4537:\tlearn: 0.0000000\ttotal: 2.51s\tremaining: 3.02s\n",
      "4538:\tlearn: 0.0000000\ttotal: 2.51s\tremaining: 3.02s\n",
      "4539:\tlearn: 0.0000000\ttotal: 2.51s\tremaining: 3.02s\n",
      "4540:\tlearn: 0.0000000\ttotal: 2.51s\tremaining: 3.02s\n",
      "4541:\tlearn: 0.0000000\ttotal: 2.51s\tremaining: 3.02s\n",
      "4542:\tlearn: 0.0000000\ttotal: 2.51s\tremaining: 3.02s\n",
      "4543:\tlearn: 0.0000000\ttotal: 2.51s\tremaining: 3.02s\n",
      "4544:\tlearn: 0.0000000\ttotal: 2.51s\tremaining: 3.02s\n",
      "4545:\tlearn: 0.0000000\ttotal: 2.52s\tremaining: 3.02s\n",
      "4546:\tlearn: 0.0000000\ttotal: 2.52s\tremaining: 3.02s\n",
      "4547:\tlearn: 0.0000000\ttotal: 2.52s\tremaining: 3.02s\n",
      "4548:\tlearn: 0.0000000\ttotal: 2.52s\tremaining: 3.02s\n",
      "4549:\tlearn: 0.0000000\ttotal: 2.52s\tremaining: 3.01s\n",
      "4550:\tlearn: 0.0000000\ttotal: 2.52s\tremaining: 3.01s\n",
      "4551:\tlearn: 0.0000000\ttotal: 2.52s\tremaining: 3.01s\n",
      "4552:\tlearn: 0.0000000\ttotal: 2.52s\tremaining: 3.01s\n",
      "4553:\tlearn: 0.0000000\ttotal: 2.52s\tremaining: 3.01s\n",
      "4554:\tlearn: 0.0000000\ttotal: 2.52s\tremaining: 3.01s\n",
      "4555:\tlearn: 0.0000000\ttotal: 2.52s\tremaining: 3.01s\n",
      "4556:\tlearn: 0.0000000\ttotal: 2.52s\tremaining: 3.01s\n",
      "4557:\tlearn: 0.0000000\ttotal: 2.52s\tremaining: 3.01s\n",
      "4558:\tlearn: 0.0000000\ttotal: 2.52s\tremaining: 3.01s\n",
      "4559:\tlearn: 0.0000000\ttotal: 2.52s\tremaining: 3.01s\n",
      "4560:\tlearn: 0.0000000\ttotal: 2.52s\tremaining: 3.01s\n",
      "4561:\tlearn: 0.0000000\ttotal: 2.52s\tremaining: 3.01s\n",
      "4562:\tlearn: 0.0000000\ttotal: 2.52s\tremaining: 3.01s\n",
      "4563:\tlearn: 0.0000000\ttotal: 2.52s\tremaining: 3.01s\n",
      "4564:\tlearn: 0.0000000\ttotal: 2.52s\tremaining: 3.01s\n",
      "4565:\tlearn: 0.0000000\ttotal: 2.53s\tremaining: 3.01s\n",
      "4566:\tlearn: 0.0000000\ttotal: 2.53s\tremaining: 3s\n",
      "4567:\tlearn: 0.0000000\ttotal: 2.53s\tremaining: 3s\n",
      "4568:\tlearn: 0.0000000\ttotal: 2.53s\tremaining: 3s\n",
      "4569:\tlearn: 0.0000000\ttotal: 2.53s\tremaining: 3s\n",
      "4570:\tlearn: 0.0000000\ttotal: 2.53s\tremaining: 3s\n",
      "4571:\tlearn: 0.0000000\ttotal: 2.53s\tremaining: 3s\n",
      "4572:\tlearn: 0.0000000\ttotal: 2.53s\tremaining: 3s\n",
      "4573:\tlearn: 0.0000000\ttotal: 2.53s\tremaining: 3s\n",
      "4574:\tlearn: 0.0000000\ttotal: 2.53s\tremaining: 3s\n",
      "4575:\tlearn: 0.0000000\ttotal: 2.53s\tremaining: 3s\n",
      "4576:\tlearn: 0.0000000\ttotal: 2.53s\tremaining: 3s\n",
      "4577:\tlearn: 0.0000000\ttotal: 2.53s\tremaining: 3s\n",
      "4578:\tlearn: 0.0000000\ttotal: 2.53s\tremaining: 3s\n",
      "4579:\tlearn: 0.0000000\ttotal: 2.53s\tremaining: 3s\n",
      "4580:\tlearn: 0.0000000\ttotal: 2.53s\tremaining: 3s\n",
      "4581:\tlearn: 0.0000000\ttotal: 2.53s\tremaining: 3s\n",
      "4582:\tlearn: 0.0000000\ttotal: 2.53s\tremaining: 2.99s\n",
      "4583:\tlearn: 0.0000000\ttotal: 2.53s\tremaining: 2.99s\n",
      "4584:\tlearn: 0.0000000\ttotal: 2.53s\tremaining: 2.99s\n",
      "4585:\tlearn: 0.0000000\ttotal: 2.54s\tremaining: 2.99s\n",
      "4586:\tlearn: 0.0000000\ttotal: 2.54s\tremaining: 2.99s\n",
      "4587:\tlearn: 0.0000000\ttotal: 2.54s\tremaining: 2.99s\n",
      "4588:\tlearn: 0.0000000\ttotal: 2.54s\tremaining: 2.99s\n",
      "4589:\tlearn: 0.0000000\ttotal: 2.54s\tremaining: 2.99s\n",
      "4590:\tlearn: 0.0000000\ttotal: 2.54s\tremaining: 2.99s\n",
      "4591:\tlearn: 0.0000000\ttotal: 2.54s\tremaining: 2.99s\n",
      "4592:\tlearn: 0.0000000\ttotal: 2.54s\tremaining: 2.99s\n",
      "4593:\tlearn: 0.0000000\ttotal: 2.54s\tremaining: 2.99s\n",
      "4594:\tlearn: 0.0000000\ttotal: 2.54s\tremaining: 2.99s\n",
      "4595:\tlearn: 0.0000000\ttotal: 2.54s\tremaining: 2.99s\n",
      "4596:\tlearn: 0.0000000\ttotal: 2.54s\tremaining: 2.99s\n",
      "4597:\tlearn: 0.0000000\ttotal: 2.54s\tremaining: 2.99s\n",
      "4598:\tlearn: 0.0000000\ttotal: 2.54s\tremaining: 2.98s\n",
      "4599:\tlearn: 0.0000000\ttotal: 2.54s\tremaining: 2.98s\n",
      "4600:\tlearn: 0.0000000\ttotal: 2.54s\tremaining: 2.98s\n",
      "4601:\tlearn: 0.0000000\ttotal: 2.54s\tremaining: 2.98s\n",
      "4602:\tlearn: 0.0000000\ttotal: 2.54s\tremaining: 2.98s\n",
      "4603:\tlearn: 0.0000000\ttotal: 2.54s\tremaining: 2.98s\n",
      "4604:\tlearn: 0.0000000\ttotal: 2.54s\tremaining: 2.98s\n",
      "4605:\tlearn: 0.0000000\ttotal: 2.54s\tremaining: 2.98s\n",
      "4606:\tlearn: 0.0000000\ttotal: 2.54s\tremaining: 2.98s\n",
      "4607:\tlearn: 0.0000000\ttotal: 2.55s\tremaining: 2.98s\n",
      "4608:\tlearn: 0.0000000\ttotal: 2.55s\tremaining: 2.98s\n",
      "4609:\tlearn: 0.0000000\ttotal: 2.55s\tremaining: 2.98s\n",
      "4610:\tlearn: 0.0000000\ttotal: 2.55s\tremaining: 2.98s\n",
      "4611:\tlearn: 0.0000000\ttotal: 2.55s\tremaining: 2.98s\n",
      "4612:\tlearn: 0.0000000\ttotal: 2.55s\tremaining: 2.98s\n",
      "4613:\tlearn: 0.0000000\ttotal: 2.55s\tremaining: 2.98s\n",
      "4614:\tlearn: 0.0000000\ttotal: 2.55s\tremaining: 2.97s\n",
      "4615:\tlearn: 0.0000000\ttotal: 2.55s\tremaining: 2.97s\n",
      "4616:\tlearn: 0.0000000\ttotal: 2.55s\tremaining: 2.97s\n",
      "4617:\tlearn: 0.0000000\ttotal: 2.55s\tremaining: 2.97s\n",
      "4618:\tlearn: 0.0000000\ttotal: 2.55s\tremaining: 2.97s\n",
      "4619:\tlearn: 0.0000000\ttotal: 2.55s\tremaining: 2.97s\n",
      "4620:\tlearn: 0.0000000\ttotal: 2.55s\tremaining: 2.97s\n",
      "4621:\tlearn: 0.0000000\ttotal: 2.55s\tremaining: 2.97s\n",
      "4622:\tlearn: 0.0000000\ttotal: 2.55s\tremaining: 2.97s\n",
      "4623:\tlearn: 0.0000000\ttotal: 2.55s\tremaining: 2.97s\n",
      "4624:\tlearn: 0.0000000\ttotal: 2.56s\tremaining: 2.97s\n",
      "4625:\tlearn: 0.0000000\ttotal: 2.56s\tremaining: 2.97s\n",
      "4626:\tlearn: 0.0000000\ttotal: 2.56s\tremaining: 2.97s\n",
      "4627:\tlearn: 0.0000000\ttotal: 2.56s\tremaining: 2.97s\n",
      "4628:\tlearn: 0.0000000\ttotal: 2.56s\tremaining: 2.97s\n",
      "4629:\tlearn: 0.0000000\ttotal: 2.56s\tremaining: 2.97s\n",
      "4630:\tlearn: 0.0000000\ttotal: 2.56s\tremaining: 2.96s\n",
      "4631:\tlearn: 0.0000000\ttotal: 2.56s\tremaining: 2.96s\n",
      "4632:\tlearn: 0.0000000\ttotal: 2.56s\tremaining: 2.96s\n",
      "4633:\tlearn: 0.0000000\ttotal: 2.56s\tremaining: 2.96s\n",
      "4634:\tlearn: 0.0000000\ttotal: 2.56s\tremaining: 2.96s\n",
      "4635:\tlearn: 0.0000000\ttotal: 2.56s\tremaining: 2.96s\n",
      "4636:\tlearn: 0.0000000\ttotal: 2.56s\tremaining: 2.96s\n",
      "4637:\tlearn: 0.0000000\ttotal: 2.56s\tremaining: 2.96s\n",
      "4638:\tlearn: 0.0000000\ttotal: 2.56s\tremaining: 2.96s\n",
      "4639:\tlearn: 0.0000000\ttotal: 2.56s\tremaining: 2.96s\n",
      "4640:\tlearn: 0.0000000\ttotal: 2.56s\tremaining: 2.96s\n",
      "4641:\tlearn: 0.0000000\ttotal: 2.56s\tremaining: 2.96s\n",
      "4642:\tlearn: 0.0000000\ttotal: 2.56s\tremaining: 2.96s\n",
      "4643:\tlearn: 0.0000000\ttotal: 2.56s\tremaining: 2.96s\n",
      "4644:\tlearn: 0.0000000\ttotal: 2.56s\tremaining: 2.96s\n",
      "4645:\tlearn: 0.0000000\ttotal: 2.56s\tremaining: 2.96s\n",
      "4646:\tlearn: 0.0000000\ttotal: 2.56s\tremaining: 2.96s\n",
      "4647:\tlearn: 0.0000000\ttotal: 2.57s\tremaining: 2.96s\n",
      "4648:\tlearn: 0.0000000\ttotal: 2.57s\tremaining: 2.96s\n",
      "4649:\tlearn: 0.0000000\ttotal: 2.57s\tremaining: 2.95s\n",
      "4650:\tlearn: 0.0000000\ttotal: 2.57s\tremaining: 2.95s\n",
      "4651:\tlearn: 0.0000000\ttotal: 2.57s\tremaining: 2.95s\n",
      "4652:\tlearn: 0.0000000\ttotal: 2.57s\tremaining: 2.95s\n",
      "4653:\tlearn: 0.0000000\ttotal: 2.57s\tremaining: 2.95s\n",
      "4654:\tlearn: 0.0000000\ttotal: 2.57s\tremaining: 2.95s\n",
      "4655:\tlearn: 0.0000000\ttotal: 2.57s\tremaining: 2.95s\n",
      "4656:\tlearn: 0.0000000\ttotal: 2.57s\tremaining: 2.95s\n",
      "4657:\tlearn: 0.0000000\ttotal: 2.57s\tremaining: 2.95s\n",
      "4658:\tlearn: 0.0000000\ttotal: 2.57s\tremaining: 2.95s\n",
      "4659:\tlearn: 0.0000000\ttotal: 2.57s\tremaining: 2.95s\n",
      "4660:\tlearn: 0.0000000\ttotal: 2.57s\tremaining: 2.95s\n",
      "4661:\tlearn: 0.0000000\ttotal: 2.57s\tremaining: 2.95s\n",
      "4662:\tlearn: 0.0000000\ttotal: 2.57s\tremaining: 2.95s\n",
      "4663:\tlearn: 0.0000000\ttotal: 2.57s\tremaining: 2.94s\n",
      "4664:\tlearn: 0.0000000\ttotal: 2.58s\tremaining: 2.94s\n",
      "4665:\tlearn: 0.0000000\ttotal: 2.58s\tremaining: 2.94s\n",
      "4666:\tlearn: 0.0000000\ttotal: 2.58s\tremaining: 2.94s\n",
      "4667:\tlearn: 0.0000000\ttotal: 2.58s\tremaining: 2.94s\n",
      "4668:\tlearn: 0.0000000\ttotal: 2.58s\tremaining: 2.94s\n",
      "4669:\tlearn: 0.0000000\ttotal: 2.58s\tremaining: 2.94s\n",
      "4670:\tlearn: 0.0000000\ttotal: 2.58s\tremaining: 2.94s\n",
      "4671:\tlearn: 0.0000000\ttotal: 2.58s\tremaining: 2.94s\n",
      "4672:\tlearn: 0.0000000\ttotal: 2.58s\tremaining: 2.94s\n",
      "4673:\tlearn: 0.0000000\ttotal: 2.58s\tremaining: 2.94s\n",
      "4674:\tlearn: 0.0000000\ttotal: 2.58s\tremaining: 2.94s\n",
      "4675:\tlearn: 0.0000000\ttotal: 2.58s\tremaining: 2.94s\n",
      "4676:\tlearn: 0.0000000\ttotal: 2.58s\tremaining: 2.94s\n",
      "4677:\tlearn: 0.0000000\ttotal: 2.58s\tremaining: 2.94s\n",
      "4678:\tlearn: 0.0000000\ttotal: 2.58s\tremaining: 2.94s\n",
      "4679:\tlearn: 0.0000000\ttotal: 2.58s\tremaining: 2.94s\n",
      "4680:\tlearn: 0.0000000\ttotal: 2.58s\tremaining: 2.94s\n",
      "4681:\tlearn: 0.0000000\ttotal: 2.58s\tremaining: 2.94s\n",
      "4682:\tlearn: 0.0000000\ttotal: 2.58s\tremaining: 2.93s\n",
      "4683:\tlearn: 0.0000000\ttotal: 2.58s\tremaining: 2.93s\n",
      "4684:\tlearn: 0.0000000\ttotal: 2.58s\tremaining: 2.93s\n",
      "4685:\tlearn: 0.0000000\ttotal: 2.59s\tremaining: 2.93s\n",
      "4686:\tlearn: 0.0000000\ttotal: 2.59s\tremaining: 2.93s\n",
      "4687:\tlearn: 0.0000000\ttotal: 2.59s\tremaining: 2.93s\n",
      "4688:\tlearn: 0.0000000\ttotal: 2.59s\tremaining: 2.93s\n",
      "4689:\tlearn: 0.0000000\ttotal: 2.59s\tremaining: 2.93s\n",
      "4690:\tlearn: 0.0000000\ttotal: 2.59s\tremaining: 2.93s\n",
      "4691:\tlearn: 0.0000000\ttotal: 2.59s\tremaining: 2.93s\n",
      "4692:\tlearn: 0.0000000\ttotal: 2.59s\tremaining: 2.93s\n",
      "4693:\tlearn: 0.0000000\ttotal: 2.59s\tremaining: 2.93s\n",
      "4694:\tlearn: 0.0000000\ttotal: 2.59s\tremaining: 2.93s\n",
      "4695:\tlearn: 0.0000000\ttotal: 2.59s\tremaining: 2.93s\n",
      "4696:\tlearn: 0.0000000\ttotal: 2.59s\tremaining: 2.93s\n",
      "4697:\tlearn: 0.0000000\ttotal: 2.59s\tremaining: 2.92s\n",
      "4698:\tlearn: 0.0000000\ttotal: 2.59s\tremaining: 2.92s\n",
      "4699:\tlearn: 0.0000000\ttotal: 2.59s\tremaining: 2.92s\n",
      "4700:\tlearn: 0.0000000\ttotal: 2.59s\tremaining: 2.92s\n",
      "4701:\tlearn: 0.0000000\ttotal: 2.6s\tremaining: 2.92s\n",
      "4702:\tlearn: 0.0000000\ttotal: 2.6s\tremaining: 2.92s\n",
      "4703:\tlearn: 0.0000000\ttotal: 2.6s\tremaining: 2.92s\n",
      "4704:\tlearn: 0.0000000\ttotal: 2.6s\tremaining: 2.92s\n",
      "4705:\tlearn: 0.0000000\ttotal: 2.6s\tremaining: 2.92s\n",
      "4706:\tlearn: 0.0000000\ttotal: 2.6s\tremaining: 2.92s\n",
      "4707:\tlearn: 0.0000000\ttotal: 2.6s\tremaining: 2.92s\n",
      "4708:\tlearn: 0.0000000\ttotal: 2.6s\tremaining: 2.92s\n",
      "4709:\tlearn: 0.0000000\ttotal: 2.6s\tremaining: 2.92s\n",
      "4710:\tlearn: 0.0000000\ttotal: 2.6s\tremaining: 2.92s\n",
      "4711:\tlearn: 0.0000000\ttotal: 2.6s\tremaining: 2.92s\n",
      "4712:\tlearn: 0.0000000\ttotal: 2.6s\tremaining: 2.92s\n",
      "4713:\tlearn: 0.0000000\ttotal: 2.6s\tremaining: 2.92s\n",
      "4714:\tlearn: 0.0000000\ttotal: 2.6s\tremaining: 2.92s\n",
      "4715:\tlearn: 0.0000000\ttotal: 2.6s\tremaining: 2.92s\n",
      "4716:\tlearn: 0.0000000\ttotal: 2.6s\tremaining: 2.92s\n",
      "4717:\tlearn: 0.0000000\ttotal: 2.6s\tremaining: 2.91s\n",
      "4718:\tlearn: 0.0000000\ttotal: 2.6s\tremaining: 2.91s\n",
      "4719:\tlearn: 0.0000000\ttotal: 2.6s\tremaining: 2.91s\n",
      "4720:\tlearn: 0.0000000\ttotal: 2.6s\tremaining: 2.91s\n",
      "4721:\tlearn: 0.0000000\ttotal: 2.6s\tremaining: 2.91s\n",
      "4722:\tlearn: 0.0000000\ttotal: 2.6s\tremaining: 2.91s\n",
      "4723:\tlearn: 0.0000000\ttotal: 2.61s\tremaining: 2.91s\n",
      "4724:\tlearn: 0.0000000\ttotal: 2.61s\tremaining: 2.91s\n",
      "4725:\tlearn: 0.0000000\ttotal: 2.61s\tremaining: 2.91s\n",
      "4726:\tlearn: 0.0000000\ttotal: 2.61s\tremaining: 2.91s\n",
      "4727:\tlearn: 0.0000000\ttotal: 2.61s\tremaining: 2.91s\n",
      "4728:\tlearn: 0.0000000\ttotal: 2.61s\tremaining: 2.91s\n",
      "4729:\tlearn: 0.0000000\ttotal: 2.61s\tremaining: 2.91s\n",
      "4730:\tlearn: 0.0000000\ttotal: 2.61s\tremaining: 2.91s\n",
      "4731:\tlearn: 0.0000000\ttotal: 2.61s\tremaining: 2.91s\n",
      "4732:\tlearn: 0.0000000\ttotal: 2.61s\tremaining: 2.9s\n",
      "4733:\tlearn: 0.0000000\ttotal: 2.61s\tremaining: 2.9s\n",
      "4734:\tlearn: 0.0000000\ttotal: 2.61s\tremaining: 2.9s\n",
      "4735:\tlearn: 0.0000000\ttotal: 2.61s\tremaining: 2.9s\n",
      "4736:\tlearn: 0.0000000\ttotal: 2.61s\tremaining: 2.9s\n",
      "4737:\tlearn: 0.0000000\ttotal: 2.61s\tremaining: 2.9s\n",
      "4738:\tlearn: 0.0000000\ttotal: 2.61s\tremaining: 2.9s\n",
      "4739:\tlearn: 0.0000000\ttotal: 2.61s\tremaining: 2.9s\n",
      "4740:\tlearn: 0.0000000\ttotal: 2.62s\tremaining: 2.9s\n",
      "4741:\tlearn: 0.0000000\ttotal: 2.62s\tremaining: 2.9s\n",
      "4742:\tlearn: 0.0000000\ttotal: 2.62s\tremaining: 2.9s\n",
      "4743:\tlearn: 0.0000000\ttotal: 2.62s\tremaining: 2.9s\n",
      "4744:\tlearn: 0.0000000\ttotal: 2.62s\tremaining: 2.9s\n",
      "4745:\tlearn: 0.0000000\ttotal: 2.62s\tremaining: 2.9s\n",
      "4746:\tlearn: 0.0000000\ttotal: 2.62s\tremaining: 2.9s\n",
      "4747:\tlearn: 0.0000000\ttotal: 2.62s\tremaining: 2.9s\n",
      "4748:\tlearn: 0.0000000\ttotal: 2.62s\tremaining: 2.9s\n",
      "4749:\tlearn: 0.0000000\ttotal: 2.62s\tremaining: 2.9s\n",
      "4750:\tlearn: 0.0000000\ttotal: 2.62s\tremaining: 2.89s\n",
      "4751:\tlearn: 0.0000000\ttotal: 2.62s\tremaining: 2.89s\n",
      "4752:\tlearn: 0.0000000\ttotal: 2.62s\tremaining: 2.89s\n",
      "4753:\tlearn: 0.0000000\ttotal: 2.62s\tremaining: 2.89s\n",
      "4754:\tlearn: 0.0000000\ttotal: 2.62s\tremaining: 2.89s\n",
      "4755:\tlearn: 0.0000000\ttotal: 2.62s\tremaining: 2.89s\n",
      "4756:\tlearn: 0.0000000\ttotal: 2.62s\tremaining: 2.89s\n",
      "4757:\tlearn: 0.0000000\ttotal: 2.62s\tremaining: 2.89s\n",
      "4758:\tlearn: 0.0000000\ttotal: 2.62s\tremaining: 2.89s\n",
      "4759:\tlearn: 0.0000000\ttotal: 2.62s\tremaining: 2.89s\n",
      "4760:\tlearn: 0.0000000\ttotal: 2.62s\tremaining: 2.89s\n",
      "4761:\tlearn: 0.0000000\ttotal: 2.63s\tremaining: 2.89s\n",
      "4762:\tlearn: 0.0000000\ttotal: 2.63s\tremaining: 2.89s\n",
      "4763:\tlearn: 0.0000000\ttotal: 2.63s\tremaining: 2.89s\n",
      "4764:\tlearn: 0.0000000\ttotal: 2.63s\tremaining: 2.89s\n",
      "4765:\tlearn: 0.0000000\ttotal: 2.63s\tremaining: 2.88s\n",
      "4766:\tlearn: 0.0000000\ttotal: 2.63s\tremaining: 2.88s\n",
      "4767:\tlearn: 0.0000000\ttotal: 2.63s\tremaining: 2.88s\n",
      "4768:\tlearn: 0.0000000\ttotal: 2.63s\tremaining: 2.88s\n",
      "4769:\tlearn: 0.0000000\ttotal: 2.63s\tremaining: 2.88s\n",
      "4770:\tlearn: 0.0000000\ttotal: 2.63s\tremaining: 2.88s\n",
      "4771:\tlearn: 0.0000000\ttotal: 2.63s\tremaining: 2.88s\n",
      "4772:\tlearn: 0.0000000\ttotal: 2.63s\tremaining: 2.88s\n",
      "4773:\tlearn: 0.0000000\ttotal: 2.63s\tremaining: 2.88s\n",
      "4774:\tlearn: 0.0000000\ttotal: 2.63s\tremaining: 2.88s\n",
      "4775:\tlearn: 0.0000000\ttotal: 2.63s\tremaining: 2.88s\n",
      "4776:\tlearn: 0.0000000\ttotal: 2.63s\tremaining: 2.88s\n",
      "4777:\tlearn: 0.0000000\ttotal: 2.63s\tremaining: 2.88s\n",
      "4778:\tlearn: 0.0000000\ttotal: 2.63s\tremaining: 2.88s\n",
      "4779:\tlearn: 0.0000000\ttotal: 2.63s\tremaining: 2.88s\n",
      "4780:\tlearn: 0.0000000\ttotal: 2.63s\tremaining: 2.88s\n",
      "4781:\tlearn: 0.0000000\ttotal: 2.63s\tremaining: 2.87s\n",
      "4782:\tlearn: 0.0000000\ttotal: 2.63s\tremaining: 2.87s\n",
      "4783:\tlearn: 0.0000000\ttotal: 2.63s\tremaining: 2.87s\n",
      "4784:\tlearn: 0.0000000\ttotal: 2.63s\tremaining: 2.87s\n",
      "4785:\tlearn: 0.0000000\ttotal: 2.64s\tremaining: 2.87s\n",
      "4786:\tlearn: 0.0000000\ttotal: 2.64s\tremaining: 2.87s\n",
      "4787:\tlearn: 0.0000000\ttotal: 2.64s\tremaining: 2.87s\n",
      "4788:\tlearn: 0.0000000\ttotal: 2.64s\tremaining: 2.87s\n",
      "4789:\tlearn: 0.0000000\ttotal: 2.64s\tremaining: 2.87s\n",
      "4790:\tlearn: 0.0000000\ttotal: 2.64s\tremaining: 2.87s\n",
      "4791:\tlearn: 0.0000000\ttotal: 2.64s\tremaining: 2.87s\n",
      "4792:\tlearn: 0.0000000\ttotal: 2.64s\tremaining: 2.87s\n",
      "4793:\tlearn: 0.0000000\ttotal: 2.64s\tremaining: 2.87s\n",
      "4794:\tlearn: 0.0000000\ttotal: 2.64s\tremaining: 2.87s\n",
      "4795:\tlearn: 0.0000000\ttotal: 2.64s\tremaining: 2.87s\n",
      "4796:\tlearn: 0.0000000\ttotal: 2.64s\tremaining: 2.87s\n",
      "4797:\tlearn: 0.0000000\ttotal: 2.64s\tremaining: 2.87s\n",
      "4798:\tlearn: 0.0000000\ttotal: 2.64s\tremaining: 2.87s\n",
      "4799:\tlearn: 0.0000000\ttotal: 2.64s\tremaining: 2.86s\n",
      "4800:\tlearn: 0.0000000\ttotal: 2.64s\tremaining: 2.86s\n",
      "4801:\tlearn: 0.0000000\ttotal: 2.65s\tremaining: 2.86s\n",
      "4802:\tlearn: 0.0000000\ttotal: 2.65s\tremaining: 2.86s\n",
      "4803:\tlearn: 0.0000000\ttotal: 2.65s\tremaining: 2.86s\n",
      "4804:\tlearn: 0.0000000\ttotal: 2.65s\tremaining: 2.86s\n",
      "4805:\tlearn: 0.0000000\ttotal: 2.65s\tremaining: 2.86s\n",
      "4806:\tlearn: 0.0000000\ttotal: 2.65s\tremaining: 2.86s\n",
      "4807:\tlearn: 0.0000000\ttotal: 2.65s\tremaining: 2.86s\n",
      "4808:\tlearn: 0.0000000\ttotal: 2.65s\tremaining: 2.86s\n",
      "4809:\tlearn: 0.0000000\ttotal: 2.65s\tremaining: 2.86s\n",
      "4810:\tlearn: 0.0000000\ttotal: 2.65s\tremaining: 2.86s\n",
      "4811:\tlearn: 0.0000000\ttotal: 2.65s\tremaining: 2.86s\n",
      "4812:\tlearn: 0.0000000\ttotal: 2.65s\tremaining: 2.86s\n",
      "4813:\tlearn: 0.0000000\ttotal: 2.65s\tremaining: 2.85s\n",
      "4814:\tlearn: 0.0000000\ttotal: 2.65s\tremaining: 2.85s\n",
      "4815:\tlearn: 0.0000000\ttotal: 2.65s\tremaining: 2.85s\n",
      "4816:\tlearn: 0.0000000\ttotal: 2.65s\tremaining: 2.85s\n",
      "4817:\tlearn: 0.0000000\ttotal: 2.65s\tremaining: 2.85s\n",
      "4818:\tlearn: 0.0000000\ttotal: 2.65s\tremaining: 2.85s\n",
      "4819:\tlearn: 0.0000000\ttotal: 2.65s\tremaining: 2.85s\n",
      "4820:\tlearn: 0.0000000\ttotal: 2.65s\tremaining: 2.85s\n",
      "4821:\tlearn: 0.0000000\ttotal: 2.65s\tremaining: 2.85s\n",
      "4822:\tlearn: 0.0000000\ttotal: 2.65s\tremaining: 2.85s\n",
      "4823:\tlearn: 0.0000000\ttotal: 2.66s\tremaining: 2.85s\n",
      "4824:\tlearn: 0.0000000\ttotal: 2.66s\tremaining: 2.85s\n",
      "4825:\tlearn: 0.0000000\ttotal: 2.66s\tremaining: 2.85s\n",
      "4826:\tlearn: 0.0000000\ttotal: 2.66s\tremaining: 2.85s\n",
      "4827:\tlearn: 0.0000000\ttotal: 2.66s\tremaining: 2.85s\n",
      "4828:\tlearn: 0.0000000\ttotal: 2.66s\tremaining: 2.85s\n",
      "4829:\tlearn: 0.0000000\ttotal: 2.66s\tremaining: 2.85s\n",
      "4830:\tlearn: 0.0000000\ttotal: 2.66s\tremaining: 2.85s\n",
      "4831:\tlearn: 0.0000000\ttotal: 2.66s\tremaining: 2.85s\n",
      "4832:\tlearn: 0.0000000\ttotal: 2.66s\tremaining: 2.84s\n",
      "4833:\tlearn: 0.0000000\ttotal: 2.66s\tremaining: 2.84s\n",
      "4834:\tlearn: 0.0000000\ttotal: 2.66s\tremaining: 2.84s\n",
      "4835:\tlearn: 0.0000000\ttotal: 2.66s\tremaining: 2.84s\n",
      "4836:\tlearn: 0.0000000\ttotal: 2.66s\tremaining: 2.84s\n",
      "4837:\tlearn: 0.0000000\ttotal: 2.66s\tremaining: 2.84s\n",
      "4838:\tlearn: 0.0000000\ttotal: 2.66s\tremaining: 2.84s\n",
      "4839:\tlearn: 0.0000000\ttotal: 2.66s\tremaining: 2.84s\n",
      "4840:\tlearn: 0.0000000\ttotal: 2.66s\tremaining: 2.84s\n",
      "4841:\tlearn: 0.0000000\ttotal: 2.66s\tremaining: 2.84s\n",
      "4842:\tlearn: 0.0000000\ttotal: 2.67s\tremaining: 2.84s\n",
      "4843:\tlearn: 0.0000000\ttotal: 2.67s\tremaining: 2.84s\n",
      "4844:\tlearn: 0.0000000\ttotal: 2.67s\tremaining: 2.84s\n",
      "4845:\tlearn: 0.0000000\ttotal: 2.67s\tremaining: 2.84s\n",
      "4846:\tlearn: 0.0000000\ttotal: 2.67s\tremaining: 2.84s\n",
      "4847:\tlearn: 0.0000000\ttotal: 2.67s\tremaining: 2.83s\n",
      "4848:\tlearn: 0.0000000\ttotal: 2.67s\tremaining: 2.83s\n",
      "4849:\tlearn: 0.0000000\ttotal: 2.67s\tremaining: 2.83s\n",
      "4850:\tlearn: 0.0000000\ttotal: 2.67s\tremaining: 2.83s\n",
      "4851:\tlearn: 0.0000000\ttotal: 2.67s\tremaining: 2.83s\n",
      "4852:\tlearn: 0.0000000\ttotal: 2.67s\tremaining: 2.83s\n",
      "4853:\tlearn: 0.0000000\ttotal: 2.67s\tremaining: 2.83s\n",
      "4854:\tlearn: 0.0000000\ttotal: 2.67s\tremaining: 2.83s\n",
      "4855:\tlearn: 0.0000000\ttotal: 2.67s\tremaining: 2.83s\n",
      "4856:\tlearn: 0.0000000\ttotal: 2.67s\tremaining: 2.83s\n",
      "4857:\tlearn: 0.0000000\ttotal: 2.67s\tremaining: 2.83s\n",
      "4858:\tlearn: 0.0000000\ttotal: 2.67s\tremaining: 2.83s\n",
      "4859:\tlearn: 0.0000000\ttotal: 2.67s\tremaining: 2.83s\n",
      "4860:\tlearn: 0.0000000\ttotal: 2.67s\tremaining: 2.83s\n",
      "4861:\tlearn: 0.0000000\ttotal: 2.67s\tremaining: 2.83s\n",
      "4862:\tlearn: 0.0000000\ttotal: 2.67s\tremaining: 2.83s\n",
      "4863:\tlearn: 0.0000000\ttotal: 2.68s\tremaining: 2.83s\n",
      "4864:\tlearn: 0.0000000\ttotal: 2.68s\tremaining: 2.83s\n",
      "4865:\tlearn: 0.0000000\ttotal: 2.68s\tremaining: 2.82s\n",
      "4866:\tlearn: 0.0000000\ttotal: 2.68s\tremaining: 2.82s\n",
      "4867:\tlearn: 0.0000000\ttotal: 2.68s\tremaining: 2.82s\n",
      "4868:\tlearn: 0.0000000\ttotal: 2.68s\tremaining: 2.82s\n",
      "4869:\tlearn: 0.0000000\ttotal: 2.68s\tremaining: 2.82s\n",
      "4870:\tlearn: 0.0000000\ttotal: 2.68s\tremaining: 2.82s\n",
      "4871:\tlearn: 0.0000000\ttotal: 2.68s\tremaining: 2.82s\n",
      "4872:\tlearn: 0.0000000\ttotal: 2.68s\tremaining: 2.82s\n",
      "4873:\tlearn: 0.0000000\ttotal: 2.68s\tremaining: 2.82s\n",
      "4874:\tlearn: 0.0000000\ttotal: 2.68s\tremaining: 2.82s\n",
      "4875:\tlearn: 0.0000000\ttotal: 2.68s\tremaining: 2.82s\n",
      "4876:\tlearn: 0.0000000\ttotal: 2.68s\tremaining: 2.82s\n",
      "4877:\tlearn: 0.0000000\ttotal: 2.69s\tremaining: 2.82s\n",
      "4878:\tlearn: 0.0000000\ttotal: 2.69s\tremaining: 2.82s\n",
      "4879:\tlearn: 0.0000000\ttotal: 2.69s\tremaining: 2.82s\n",
      "4880:\tlearn: 0.0000000\ttotal: 2.69s\tremaining: 2.82s\n",
      "4881:\tlearn: 0.0000000\ttotal: 2.69s\tremaining: 2.82s\n",
      "4882:\tlearn: 0.0000000\ttotal: 2.69s\tremaining: 2.82s\n",
      "4883:\tlearn: 0.0000000\ttotal: 2.69s\tremaining: 2.81s\n",
      "4884:\tlearn: 0.0000000\ttotal: 2.69s\tremaining: 2.81s\n",
      "4885:\tlearn: 0.0000000\ttotal: 2.69s\tremaining: 2.81s\n",
      "4886:\tlearn: 0.0000000\ttotal: 2.69s\tremaining: 2.81s\n",
      "4887:\tlearn: 0.0000000\ttotal: 2.69s\tremaining: 2.81s\n",
      "4888:\tlearn: 0.0000000\ttotal: 2.69s\tremaining: 2.81s\n",
      "4889:\tlearn: 0.0000000\ttotal: 2.69s\tremaining: 2.81s\n",
      "4890:\tlearn: 0.0000000\ttotal: 2.69s\tremaining: 2.81s\n",
      "4891:\tlearn: 0.0000000\ttotal: 2.69s\tremaining: 2.81s\n",
      "4892:\tlearn: 0.0000000\ttotal: 2.69s\tremaining: 2.81s\n",
      "4893:\tlearn: 0.0000000\ttotal: 2.69s\tremaining: 2.81s\n",
      "4894:\tlearn: 0.0000000\ttotal: 2.69s\tremaining: 2.81s\n",
      "4895:\tlearn: 0.0000000\ttotal: 2.69s\tremaining: 2.81s\n",
      "4896:\tlearn: 0.0000000\ttotal: 2.7s\tremaining: 2.81s\n",
      "4897:\tlearn: 0.0000000\ttotal: 2.7s\tremaining: 2.81s\n",
      "4898:\tlearn: 0.0000000\ttotal: 2.7s\tremaining: 2.81s\n",
      "4899:\tlearn: 0.0000000\ttotal: 2.7s\tremaining: 2.81s\n",
      "4900:\tlearn: 0.0000000\ttotal: 2.7s\tremaining: 2.81s\n",
      "4901:\tlearn: 0.0000000\ttotal: 2.7s\tremaining: 2.81s\n",
      "4902:\tlearn: 0.0000000\ttotal: 2.7s\tremaining: 2.81s\n",
      "4903:\tlearn: 0.0000000\ttotal: 2.7s\tremaining: 2.81s\n",
      "4904:\tlearn: 0.0000000\ttotal: 2.7s\tremaining: 2.81s\n",
      "4905:\tlearn: 0.0000000\ttotal: 2.7s\tremaining: 2.8s\n",
      "4906:\tlearn: 0.0000000\ttotal: 2.7s\tremaining: 2.8s\n",
      "4907:\tlearn: 0.0000000\ttotal: 2.7s\tremaining: 2.8s\n",
      "4908:\tlearn: 0.0000000\ttotal: 2.7s\tremaining: 2.8s\n",
      "4909:\tlearn: 0.0000000\ttotal: 2.7s\tremaining: 2.8s\n",
      "4910:\tlearn: 0.0000000\ttotal: 2.7s\tremaining: 2.8s\n",
      "4911:\tlearn: 0.0000000\ttotal: 2.71s\tremaining: 2.8s\n",
      "4912:\tlearn: 0.0000000\ttotal: 2.71s\tremaining: 2.8s\n",
      "4913:\tlearn: 0.0000000\ttotal: 2.71s\tremaining: 2.8s\n",
      "4914:\tlearn: 0.0000000\ttotal: 2.71s\tremaining: 2.8s\n",
      "4915:\tlearn: 0.0000000\ttotal: 2.71s\tremaining: 2.8s\n",
      "4916:\tlearn: 0.0000000\ttotal: 2.71s\tremaining: 2.8s\n",
      "4917:\tlearn: 0.0000000\ttotal: 2.71s\tremaining: 2.8s\n",
      "4918:\tlearn: 0.0000000\ttotal: 2.71s\tremaining: 2.8s\n",
      "4919:\tlearn: 0.0000000\ttotal: 2.71s\tremaining: 2.8s\n",
      "4920:\tlearn: 0.0000000\ttotal: 2.71s\tremaining: 2.8s\n",
      "4921:\tlearn: 0.0000000\ttotal: 2.71s\tremaining: 2.8s\n",
      "4922:\tlearn: 0.0000000\ttotal: 2.71s\tremaining: 2.8s\n",
      "4923:\tlearn: 0.0000000\ttotal: 2.71s\tremaining: 2.79s\n",
      "4924:\tlearn: 0.0000000\ttotal: 2.71s\tremaining: 2.79s\n",
      "4925:\tlearn: 0.0000000\ttotal: 2.71s\tremaining: 2.79s\n",
      "4926:\tlearn: 0.0000000\ttotal: 2.71s\tremaining: 2.79s\n",
      "4927:\tlearn: 0.0000000\ttotal: 2.71s\tremaining: 2.79s\n",
      "4928:\tlearn: 0.0000000\ttotal: 2.71s\tremaining: 2.79s\n",
      "4929:\tlearn: 0.0000000\ttotal: 2.71s\tremaining: 2.79s\n",
      "4930:\tlearn: 0.0000000\ttotal: 2.71s\tremaining: 2.79s\n",
      "4931:\tlearn: 0.0000000\ttotal: 2.71s\tremaining: 2.79s\n",
      "4932:\tlearn: 0.0000000\ttotal: 2.72s\tremaining: 2.79s\n",
      "4933:\tlearn: 0.0000000\ttotal: 2.72s\tremaining: 2.79s\n",
      "4934:\tlearn: 0.0000000\ttotal: 2.72s\tremaining: 2.79s\n",
      "4935:\tlearn: 0.0000000\ttotal: 2.72s\tremaining: 2.79s\n",
      "4936:\tlearn: 0.0000000\ttotal: 2.72s\tremaining: 2.79s\n",
      "4937:\tlearn: 0.0000000\ttotal: 2.72s\tremaining: 2.79s\n",
      "4938:\tlearn: 0.0000000\ttotal: 2.72s\tremaining: 2.79s\n",
      "4939:\tlearn: 0.0000000\ttotal: 2.72s\tremaining: 2.79s\n",
      "4940:\tlearn: 0.0000000\ttotal: 2.72s\tremaining: 2.79s\n",
      "4941:\tlearn: 0.0000000\ttotal: 2.72s\tremaining: 2.78s\n",
      "4942:\tlearn: 0.0000000\ttotal: 2.72s\tremaining: 2.78s\n",
      "4943:\tlearn: 0.0000000\ttotal: 2.72s\tremaining: 2.78s\n",
      "4944:\tlearn: 0.0000000\ttotal: 2.72s\tremaining: 2.78s\n",
      "4945:\tlearn: 0.0000000\ttotal: 2.72s\tremaining: 2.78s\n",
      "4946:\tlearn: 0.0000000\ttotal: 2.72s\tremaining: 2.78s\n",
      "4947:\tlearn: 0.0000000\ttotal: 2.72s\tremaining: 2.78s\n",
      "4948:\tlearn: 0.0000000\ttotal: 2.72s\tremaining: 2.78s\n",
      "4949:\tlearn: 0.0000000\ttotal: 2.73s\tremaining: 2.78s\n",
      "4950:\tlearn: 0.0000000\ttotal: 2.73s\tremaining: 2.78s\n",
      "4951:\tlearn: 0.0000000\ttotal: 2.73s\tremaining: 2.78s\n",
      "4952:\tlearn: 0.0000000\ttotal: 2.73s\tremaining: 2.78s\n",
      "4953:\tlearn: 0.0000000\ttotal: 2.73s\tremaining: 2.78s\n",
      "4954:\tlearn: 0.0000000\ttotal: 2.73s\tremaining: 2.78s\n",
      "4955:\tlearn: 0.0000000\ttotal: 2.73s\tremaining: 2.78s\n",
      "4956:\tlearn: 0.0000000\ttotal: 2.73s\tremaining: 2.77s\n",
      "4957:\tlearn: 0.0000000\ttotal: 2.73s\tremaining: 2.77s\n",
      "4958:\tlearn: 0.0000000\ttotal: 2.73s\tremaining: 2.77s\n",
      "4959:\tlearn: 0.0000000\ttotal: 2.73s\tremaining: 2.77s\n",
      "4960:\tlearn: 0.0000000\ttotal: 2.73s\tremaining: 2.77s\n",
      "4961:\tlearn: 0.0000000\ttotal: 2.73s\tremaining: 2.77s\n",
      "4962:\tlearn: 0.0000000\ttotal: 2.73s\tremaining: 2.77s\n",
      "4963:\tlearn: 0.0000000\ttotal: 2.73s\tremaining: 2.77s\n",
      "4964:\tlearn: 0.0000000\ttotal: 2.73s\tremaining: 2.77s\n",
      "4965:\tlearn: 0.0000000\ttotal: 2.73s\tremaining: 2.77s\n",
      "4966:\tlearn: 0.0000000\ttotal: 2.73s\tremaining: 2.77s\n",
      "4967:\tlearn: 0.0000000\ttotal: 2.73s\tremaining: 2.77s\n",
      "4968:\tlearn: 0.0000000\ttotal: 2.73s\tremaining: 2.77s\n",
      "4969:\tlearn: 0.0000000\ttotal: 2.73s\tremaining: 2.77s\n",
      "4970:\tlearn: 0.0000000\ttotal: 2.73s\tremaining: 2.77s\n",
      "4971:\tlearn: 0.0000000\ttotal: 2.74s\tremaining: 2.77s\n",
      "4972:\tlearn: 0.0000000\ttotal: 2.74s\tremaining: 2.77s\n",
      "4973:\tlearn: 0.0000000\ttotal: 2.74s\tremaining: 2.77s\n",
      "4974:\tlearn: 0.0000000\ttotal: 2.74s\tremaining: 2.77s\n",
      "4975:\tlearn: 0.0000000\ttotal: 2.74s\tremaining: 2.76s\n",
      "4976:\tlearn: 0.0000000\ttotal: 2.74s\tremaining: 2.76s\n",
      "4977:\tlearn: 0.0000000\ttotal: 2.74s\tremaining: 2.76s\n",
      "4978:\tlearn: 0.0000000\ttotal: 2.74s\tremaining: 2.76s\n",
      "4979:\tlearn: 0.0000000\ttotal: 2.74s\tremaining: 2.76s\n",
      "4980:\tlearn: 0.0000000\ttotal: 2.74s\tremaining: 2.76s\n",
      "4981:\tlearn: 0.0000000\ttotal: 2.74s\tremaining: 2.76s\n",
      "4982:\tlearn: 0.0000000\ttotal: 2.74s\tremaining: 2.76s\n",
      "4983:\tlearn: 0.0000000\ttotal: 2.74s\tremaining: 2.76s\n",
      "4984:\tlearn: 0.0000000\ttotal: 2.74s\tremaining: 2.76s\n",
      "4985:\tlearn: 0.0000000\ttotal: 2.74s\tremaining: 2.76s\n",
      "4986:\tlearn: 0.0000000\ttotal: 2.74s\tremaining: 2.76s\n",
      "4987:\tlearn: 0.0000000\ttotal: 2.74s\tremaining: 2.76s\n",
      "4988:\tlearn: 0.0000000\ttotal: 2.75s\tremaining: 2.76s\n",
      "4989:\tlearn: 0.0000000\ttotal: 2.75s\tremaining: 2.76s\n",
      "4990:\tlearn: 0.0000000\ttotal: 2.75s\tremaining: 2.76s\n",
      "4991:\tlearn: 0.0000000\ttotal: 2.75s\tremaining: 2.75s\n",
      "4992:\tlearn: 0.0000000\ttotal: 2.75s\tremaining: 2.75s\n",
      "4993:\tlearn: 0.0000000\ttotal: 2.75s\tremaining: 2.75s\n",
      "4994:\tlearn: 0.0000000\ttotal: 2.75s\tremaining: 2.75s\n",
      "4995:\tlearn: 0.0000000\ttotal: 2.75s\tremaining: 2.75s\n",
      "4996:\tlearn: 0.0000000\ttotal: 2.75s\tremaining: 2.75s\n",
      "4997:\tlearn: 0.0000000\ttotal: 2.75s\tremaining: 2.75s\n",
      "4998:\tlearn: 0.0000000\ttotal: 2.75s\tremaining: 2.75s\n",
      "4999:\tlearn: 0.0000000\ttotal: 2.75s\tremaining: 2.75s\n",
      "5000:\tlearn: 0.0000000\ttotal: 2.75s\tremaining: 2.75s\n",
      "5001:\tlearn: 0.0000000\ttotal: 2.75s\tremaining: 2.75s\n",
      "5002:\tlearn: 0.0000000\ttotal: 2.75s\tremaining: 2.75s\n",
      "5003:\tlearn: 0.0000000\ttotal: 2.75s\tremaining: 2.75s\n",
      "5004:\tlearn: 0.0000000\ttotal: 2.75s\tremaining: 2.75s\n",
      "5005:\tlearn: 0.0000000\ttotal: 2.75s\tremaining: 2.75s\n",
      "5006:\tlearn: 0.0000000\ttotal: 2.75s\tremaining: 2.75s\n",
      "5007:\tlearn: 0.0000000\ttotal: 2.76s\tremaining: 2.75s\n",
      "5008:\tlearn: 0.0000000\ttotal: 2.76s\tremaining: 2.75s\n",
      "5009:\tlearn: 0.0000000\ttotal: 2.76s\tremaining: 2.75s\n",
      "5010:\tlearn: 0.0000000\ttotal: 2.76s\tremaining: 2.75s\n",
      "5011:\tlearn: 0.0000000\ttotal: 2.76s\tremaining: 2.75s\n",
      "5012:\tlearn: 0.0000000\ttotal: 2.76s\tremaining: 2.74s\n",
      "5013:\tlearn: 0.0000000\ttotal: 2.76s\tremaining: 2.74s\n",
      "5014:\tlearn: 0.0000000\ttotal: 2.76s\tremaining: 2.74s\n",
      "5015:\tlearn: 0.0000000\ttotal: 2.76s\tremaining: 2.74s\n",
      "5016:\tlearn: 0.0000000\ttotal: 2.76s\tremaining: 2.74s\n",
      "5017:\tlearn: 0.0000000\ttotal: 2.76s\tremaining: 2.74s\n",
      "5018:\tlearn: 0.0000000\ttotal: 2.76s\tremaining: 2.74s\n",
      "5019:\tlearn: 0.0000000\ttotal: 2.76s\tremaining: 2.74s\n",
      "5020:\tlearn: 0.0000000\ttotal: 2.76s\tremaining: 2.74s\n",
      "5021:\tlearn: 0.0000000\ttotal: 2.77s\tremaining: 2.74s\n",
      "5022:\tlearn: 0.0000000\ttotal: 2.77s\tremaining: 2.74s\n",
      "5023:\tlearn: 0.0000000\ttotal: 2.77s\tremaining: 2.74s\n",
      "5024:\tlearn: 0.0000000\ttotal: 2.77s\tremaining: 2.74s\n",
      "5025:\tlearn: 0.0000000\ttotal: 2.77s\tremaining: 2.74s\n",
      "5026:\tlearn: 0.0000000\ttotal: 2.77s\tremaining: 2.74s\n",
      "5027:\tlearn: 0.0000000\ttotal: 2.77s\tremaining: 2.74s\n",
      "5028:\tlearn: 0.0000000\ttotal: 2.77s\tremaining: 2.74s\n",
      "5029:\tlearn: 0.0000000\ttotal: 2.77s\tremaining: 2.74s\n",
      "5030:\tlearn: 0.0000000\ttotal: 2.77s\tremaining: 2.73s\n",
      "5031:\tlearn: 0.0000000\ttotal: 2.77s\tremaining: 2.73s\n",
      "5032:\tlearn: 0.0000000\ttotal: 2.77s\tremaining: 2.73s\n",
      "5033:\tlearn: 0.0000000\ttotal: 2.77s\tremaining: 2.73s\n",
      "5034:\tlearn: 0.0000000\ttotal: 2.77s\tremaining: 2.73s\n",
      "5035:\tlearn: 0.0000000\ttotal: 2.77s\tremaining: 2.73s\n",
      "5036:\tlearn: 0.0000000\ttotal: 2.77s\tremaining: 2.73s\n",
      "5037:\tlearn: 0.0000000\ttotal: 2.77s\tremaining: 2.73s\n",
      "5038:\tlearn: 0.0000000\ttotal: 2.77s\tremaining: 2.73s\n",
      "5039:\tlearn: 0.0000000\ttotal: 2.77s\tremaining: 2.73s\n",
      "5040:\tlearn: 0.0000000\ttotal: 2.77s\tremaining: 2.73s\n",
      "5041:\tlearn: 0.0000000\ttotal: 2.78s\tremaining: 2.73s\n",
      "5042:\tlearn: 0.0000000\ttotal: 2.78s\tremaining: 2.73s\n",
      "5043:\tlearn: 0.0000000\ttotal: 2.78s\tremaining: 2.73s\n",
      "5044:\tlearn: 0.0000000\ttotal: 2.78s\tremaining: 2.73s\n",
      "5045:\tlearn: 0.0000000\ttotal: 2.78s\tremaining: 2.73s\n",
      "5046:\tlearn: 0.0000000\ttotal: 2.78s\tremaining: 2.73s\n",
      "5047:\tlearn: 0.0000000\ttotal: 2.78s\tremaining: 2.73s\n",
      "5048:\tlearn: 0.0000000\ttotal: 2.78s\tremaining: 2.73s\n",
      "5049:\tlearn: 0.0000000\ttotal: 2.78s\tremaining: 2.73s\n",
      "5050:\tlearn: 0.0000000\ttotal: 2.78s\tremaining: 2.73s\n",
      "5051:\tlearn: 0.0000000\ttotal: 2.78s\tremaining: 2.73s\n",
      "5052:\tlearn: 0.0000000\ttotal: 2.78s\tremaining: 2.72s\n",
      "5053:\tlearn: 0.0000000\ttotal: 2.78s\tremaining: 2.72s\n",
      "5054:\tlearn: 0.0000000\ttotal: 2.78s\tremaining: 2.72s\n",
      "5055:\tlearn: 0.0000000\ttotal: 2.78s\tremaining: 2.72s\n",
      "5056:\tlearn: 0.0000000\ttotal: 2.79s\tremaining: 2.72s\n",
      "5057:\tlearn: 0.0000000\ttotal: 2.79s\tremaining: 2.72s\n",
      "5058:\tlearn: 0.0000000\ttotal: 2.79s\tremaining: 2.72s\n",
      "5059:\tlearn: 0.0000000\ttotal: 2.79s\tremaining: 2.72s\n",
      "5060:\tlearn: 0.0000000\ttotal: 2.79s\tremaining: 2.72s\n",
      "5061:\tlearn: 0.0000000\ttotal: 2.79s\tremaining: 2.72s\n",
      "5062:\tlearn: 0.0000000\ttotal: 2.79s\tremaining: 2.72s\n",
      "5063:\tlearn: 0.0000000\ttotal: 2.79s\tremaining: 2.72s\n",
      "5064:\tlearn: 0.0000000\ttotal: 2.79s\tremaining: 2.72s\n",
      "5065:\tlearn: 0.0000000\ttotal: 2.79s\tremaining: 2.72s\n",
      "5066:\tlearn: 0.0000000\ttotal: 2.79s\tremaining: 2.71s\n",
      "5067:\tlearn: 0.0000000\ttotal: 2.79s\tremaining: 2.71s\n",
      "5068:\tlearn: 0.0000000\ttotal: 2.79s\tremaining: 2.71s\n",
      "5069:\tlearn: 0.0000000\ttotal: 2.79s\tremaining: 2.71s\n",
      "5070:\tlearn: 0.0000000\ttotal: 2.79s\tremaining: 2.71s\n",
      "5071:\tlearn: 0.0000000\ttotal: 2.79s\tremaining: 2.71s\n",
      "5072:\tlearn: 0.0000000\ttotal: 2.79s\tremaining: 2.71s\n",
      "5073:\tlearn: 0.0000000\ttotal: 2.79s\tremaining: 2.71s\n",
      "5074:\tlearn: 0.0000000\ttotal: 2.79s\tremaining: 2.71s\n",
      "5075:\tlearn: 0.0000000\ttotal: 2.79s\tremaining: 2.71s\n",
      "5076:\tlearn: 0.0000000\ttotal: 2.79s\tremaining: 2.71s\n",
      "5077:\tlearn: 0.0000000\ttotal: 2.79s\tremaining: 2.71s\n",
      "5078:\tlearn: 0.0000000\ttotal: 2.79s\tremaining: 2.71s\n",
      "5079:\tlearn: 0.0000000\ttotal: 2.8s\tremaining: 2.71s\n",
      "5080:\tlearn: 0.0000000\ttotal: 2.8s\tremaining: 2.71s\n",
      "5081:\tlearn: 0.0000000\ttotal: 2.8s\tremaining: 2.71s\n",
      "5082:\tlearn: 0.0000000\ttotal: 2.8s\tremaining: 2.71s\n",
      "5083:\tlearn: 0.0000000\ttotal: 2.8s\tremaining: 2.71s\n",
      "5084:\tlearn: 0.0000000\ttotal: 2.8s\tremaining: 2.71s\n",
      "5085:\tlearn: 0.0000000\ttotal: 2.8s\tremaining: 2.7s\n",
      "5086:\tlearn: 0.0000000\ttotal: 2.8s\tremaining: 2.7s\n",
      "5087:\tlearn: 0.0000000\ttotal: 2.8s\tremaining: 2.7s\n",
      "5088:\tlearn: 0.0000000\ttotal: 2.8s\tremaining: 2.7s\n",
      "5089:\tlearn: 0.0000000\ttotal: 2.8s\tremaining: 2.7s\n",
      "5090:\tlearn: 0.0000000\ttotal: 2.8s\tremaining: 2.7s\n",
      "5091:\tlearn: 0.0000000\ttotal: 2.8s\tremaining: 2.7s\n",
      "5092:\tlearn: 0.0000000\ttotal: 2.8s\tremaining: 2.7s\n",
      "5093:\tlearn: 0.0000000\ttotal: 2.8s\tremaining: 2.7s\n",
      "5094:\tlearn: 0.0000000\ttotal: 2.8s\tremaining: 2.7s\n",
      "5095:\tlearn: 0.0000000\ttotal: 2.8s\tremaining: 2.7s\n",
      "5096:\tlearn: 0.0000000\ttotal: 2.8s\tremaining: 2.7s\n",
      "5097:\tlearn: 0.0000000\ttotal: 2.8s\tremaining: 2.7s\n",
      "5098:\tlearn: 0.0000000\ttotal: 2.81s\tremaining: 2.7s\n",
      "5099:\tlearn: 0.0000000\ttotal: 2.81s\tremaining: 2.69s\n",
      "5100:\tlearn: 0.0000000\ttotal: 2.81s\tremaining: 2.69s\n",
      "5101:\tlearn: 0.0000000\ttotal: 2.81s\tremaining: 2.69s\n",
      "5102:\tlearn: 0.0000000\ttotal: 2.81s\tremaining: 2.69s\n",
      "5103:\tlearn: 0.0000000\ttotal: 2.81s\tremaining: 2.69s\n",
      "5104:\tlearn: 0.0000000\ttotal: 2.81s\tremaining: 2.69s\n",
      "5105:\tlearn: 0.0000000\ttotal: 2.81s\tremaining: 2.69s\n",
      "5106:\tlearn: 0.0000000\ttotal: 2.81s\tremaining: 2.69s\n",
      "5107:\tlearn: 0.0000000\ttotal: 2.81s\tremaining: 2.69s\n",
      "5108:\tlearn: 0.0000000\ttotal: 2.81s\tremaining: 2.69s\n",
      "5109:\tlearn: 0.0000000\ttotal: 2.81s\tremaining: 2.69s\n",
      "5110:\tlearn: 0.0000000\ttotal: 2.81s\tremaining: 2.69s\n",
      "5111:\tlearn: 0.0000000\ttotal: 2.81s\tremaining: 2.69s\n",
      "5112:\tlearn: 0.0000000\ttotal: 2.81s\tremaining: 2.69s\n",
      "5113:\tlearn: 0.0000000\ttotal: 2.81s\tremaining: 2.69s\n",
      "5114:\tlearn: 0.0000000\ttotal: 2.81s\tremaining: 2.69s\n",
      "5115:\tlearn: 0.0000000\ttotal: 2.81s\tremaining: 2.69s\n",
      "5116:\tlearn: 0.0000000\ttotal: 2.81s\tremaining: 2.69s\n",
      "5117:\tlearn: 0.0000000\ttotal: 2.81s\tremaining: 2.68s\n",
      "5118:\tlearn: 0.0000000\ttotal: 2.81s\tremaining: 2.68s\n",
      "5119:\tlearn: 0.0000000\ttotal: 2.81s\tremaining: 2.68s\n",
      "5120:\tlearn: 0.0000000\ttotal: 2.81s\tremaining: 2.68s\n",
      "5121:\tlearn: 0.0000000\ttotal: 2.82s\tremaining: 2.68s\n",
      "5122:\tlearn: 0.0000000\ttotal: 2.82s\tremaining: 2.68s\n",
      "5123:\tlearn: 0.0000000\ttotal: 2.82s\tremaining: 2.68s\n",
      "5124:\tlearn: 0.0000000\ttotal: 2.82s\tremaining: 2.68s\n",
      "5125:\tlearn: 0.0000000\ttotal: 2.82s\tremaining: 2.68s\n",
      "5126:\tlearn: 0.0000000\ttotal: 2.82s\tremaining: 2.68s\n",
      "5127:\tlearn: 0.0000000\ttotal: 2.82s\tremaining: 2.68s\n",
      "5128:\tlearn: 0.0000000\ttotal: 2.82s\tremaining: 2.68s\n",
      "5129:\tlearn: 0.0000000\ttotal: 2.82s\tremaining: 2.68s\n",
      "5130:\tlearn: 0.0000000\ttotal: 2.82s\tremaining: 2.68s\n",
      "5131:\tlearn: 0.0000000\ttotal: 2.82s\tremaining: 2.68s\n",
      "5132:\tlearn: 0.0000000\ttotal: 2.82s\tremaining: 2.67s\n",
      "5133:\tlearn: 0.0000000\ttotal: 2.82s\tremaining: 2.67s\n",
      "5134:\tlearn: 0.0000000\ttotal: 2.82s\tremaining: 2.67s\n",
      "5135:\tlearn: 0.0000000\ttotal: 2.82s\tremaining: 2.67s\n",
      "5136:\tlearn: 0.0000000\ttotal: 2.82s\tremaining: 2.67s\n",
      "5137:\tlearn: 0.0000000\ttotal: 2.82s\tremaining: 2.67s\n",
      "5138:\tlearn: 0.0000000\ttotal: 2.82s\tremaining: 2.67s\n",
      "5139:\tlearn: 0.0000000\ttotal: 2.83s\tremaining: 2.67s\n",
      "5140:\tlearn: 0.0000000\ttotal: 2.83s\tremaining: 2.67s\n",
      "5141:\tlearn: 0.0000000\ttotal: 2.83s\tremaining: 2.67s\n",
      "5142:\tlearn: 0.0000000\ttotal: 2.83s\tremaining: 2.67s\n",
      "5143:\tlearn: 0.0000000\ttotal: 2.83s\tremaining: 2.67s\n",
      "5144:\tlearn: 0.0000000\ttotal: 2.83s\tremaining: 2.67s\n",
      "5145:\tlearn: 0.0000000\ttotal: 2.83s\tremaining: 2.67s\n",
      "5146:\tlearn: 0.0000000\ttotal: 2.83s\tremaining: 2.67s\n",
      "5147:\tlearn: 0.0000000\ttotal: 2.83s\tremaining: 2.67s\n",
      "5148:\tlearn: 0.0000000\ttotal: 2.83s\tremaining: 2.67s\n",
      "5149:\tlearn: 0.0000000\ttotal: 2.83s\tremaining: 2.67s\n",
      "5150:\tlearn: 0.0000000\ttotal: 2.83s\tremaining: 2.67s\n",
      "5151:\tlearn: 0.0000000\ttotal: 2.83s\tremaining: 2.66s\n",
      "5152:\tlearn: 0.0000000\ttotal: 2.83s\tremaining: 2.66s\n",
      "5153:\tlearn: 0.0000000\ttotal: 2.83s\tremaining: 2.66s\n",
      "5154:\tlearn: 0.0000000\ttotal: 2.83s\tremaining: 2.66s\n",
      "5155:\tlearn: 0.0000000\ttotal: 2.83s\tremaining: 2.66s\n",
      "5156:\tlearn: 0.0000000\ttotal: 2.83s\tremaining: 2.66s\n",
      "5157:\tlearn: 0.0000000\ttotal: 2.83s\tremaining: 2.66s\n",
      "5158:\tlearn: 0.0000000\ttotal: 2.83s\tremaining: 2.66s\n",
      "5159:\tlearn: 0.0000000\ttotal: 2.83s\tremaining: 2.66s\n",
      "5160:\tlearn: 0.0000000\ttotal: 2.84s\tremaining: 2.66s\n",
      "5161:\tlearn: 0.0000000\ttotal: 2.84s\tremaining: 2.66s\n",
      "5162:\tlearn: 0.0000000\ttotal: 2.84s\tremaining: 2.66s\n",
      "5163:\tlearn: 0.0000000\ttotal: 2.84s\tremaining: 2.66s\n",
      "5164:\tlearn: 0.0000000\ttotal: 2.84s\tremaining: 2.66s\n",
      "5165:\tlearn: 0.0000000\ttotal: 2.84s\tremaining: 2.66s\n",
      "5166:\tlearn: 0.0000000\ttotal: 2.84s\tremaining: 2.65s\n",
      "5167:\tlearn: 0.0000000\ttotal: 2.84s\tremaining: 2.65s\n",
      "5168:\tlearn: 0.0000000\ttotal: 2.84s\tremaining: 2.65s\n",
      "5169:\tlearn: 0.0000000\ttotal: 2.84s\tremaining: 2.65s\n",
      "5170:\tlearn: 0.0000000\ttotal: 2.84s\tremaining: 2.65s\n",
      "5171:\tlearn: 0.0000000\ttotal: 2.84s\tremaining: 2.65s\n",
      "5172:\tlearn: 0.0000000\ttotal: 2.84s\tremaining: 2.65s\n",
      "5173:\tlearn: 0.0000000\ttotal: 2.84s\tremaining: 2.65s\n",
      "5174:\tlearn: 0.0000000\ttotal: 2.84s\tremaining: 2.65s\n",
      "5175:\tlearn: 0.0000000\ttotal: 2.85s\tremaining: 2.65s\n",
      "5176:\tlearn: 0.0000000\ttotal: 2.85s\tremaining: 2.65s\n",
      "5177:\tlearn: 0.0000000\ttotal: 2.85s\tremaining: 2.65s\n",
      "5178:\tlearn: 0.0000000\ttotal: 2.85s\tremaining: 2.65s\n",
      "5179:\tlearn: 0.0000000\ttotal: 2.85s\tremaining: 2.65s\n",
      "5180:\tlearn: 0.0000000\ttotal: 2.85s\tremaining: 2.65s\n",
      "5181:\tlearn: 0.0000000\ttotal: 2.85s\tremaining: 2.65s\n",
      "5182:\tlearn: 0.0000000\ttotal: 2.85s\tremaining: 2.65s\n",
      "5183:\tlearn: 0.0000000\ttotal: 2.85s\tremaining: 2.65s\n",
      "5184:\tlearn: 0.0000000\ttotal: 2.85s\tremaining: 2.65s\n",
      "5185:\tlearn: 0.0000000\ttotal: 2.85s\tremaining: 2.65s\n",
      "5186:\tlearn: 0.0000000\ttotal: 2.85s\tremaining: 2.64s\n",
      "5187:\tlearn: 0.0000000\ttotal: 2.85s\tremaining: 2.64s\n",
      "5188:\tlearn: 0.0000000\ttotal: 2.85s\tremaining: 2.64s\n",
      "5189:\tlearn: 0.0000000\ttotal: 2.85s\tremaining: 2.64s\n",
      "5190:\tlearn: 0.0000000\ttotal: 2.85s\tremaining: 2.64s\n",
      "5191:\tlearn: 0.0000000\ttotal: 2.85s\tremaining: 2.64s\n",
      "5192:\tlearn: 0.0000000\ttotal: 2.85s\tremaining: 2.64s\n",
      "5193:\tlearn: 0.0000000\ttotal: 2.85s\tremaining: 2.64s\n",
      "5194:\tlearn: 0.0000000\ttotal: 2.85s\tremaining: 2.64s\n",
      "5195:\tlearn: 0.0000000\ttotal: 2.85s\tremaining: 2.64s\n",
      "5196:\tlearn: 0.0000000\ttotal: 2.85s\tremaining: 2.64s\n",
      "5197:\tlearn: 0.0000000\ttotal: 2.85s\tremaining: 2.64s\n",
      "5198:\tlearn: 0.0000000\ttotal: 2.86s\tremaining: 2.64s\n",
      "5199:\tlearn: 0.0000000\ttotal: 2.86s\tremaining: 2.64s\n",
      "5200:\tlearn: 0.0000000\ttotal: 2.86s\tremaining: 2.64s\n",
      "5201:\tlearn: 0.0000000\ttotal: 2.86s\tremaining: 2.64s\n",
      "5202:\tlearn: 0.0000000\ttotal: 2.86s\tremaining: 2.64s\n",
      "5203:\tlearn: 0.0000000\ttotal: 2.86s\tremaining: 2.63s\n",
      "5204:\tlearn: 0.0000000\ttotal: 2.86s\tremaining: 2.63s\n",
      "5205:\tlearn: 0.0000000\ttotal: 2.86s\tremaining: 2.63s\n",
      "5206:\tlearn: 0.0000000\ttotal: 2.86s\tremaining: 2.63s\n",
      "5207:\tlearn: 0.0000000\ttotal: 2.86s\tremaining: 2.63s\n",
      "5208:\tlearn: 0.0000000\ttotal: 2.86s\tremaining: 2.63s\n",
      "5209:\tlearn: 0.0000000\ttotal: 2.86s\tremaining: 2.63s\n",
      "5210:\tlearn: 0.0000000\ttotal: 2.86s\tremaining: 2.63s\n",
      "5211:\tlearn: 0.0000000\ttotal: 2.86s\tremaining: 2.63s\n",
      "5212:\tlearn: 0.0000000\ttotal: 2.86s\tremaining: 2.63s\n",
      "5213:\tlearn: 0.0000000\ttotal: 2.86s\tremaining: 2.63s\n",
      "5214:\tlearn: 0.0000000\ttotal: 2.87s\tremaining: 2.63s\n",
      "5215:\tlearn: 0.0000000\ttotal: 2.87s\tremaining: 2.63s\n",
      "5216:\tlearn: 0.0000000\ttotal: 2.87s\tremaining: 2.63s\n",
      "5217:\tlearn: 0.0000000\ttotal: 2.87s\tremaining: 2.63s\n",
      "5218:\tlearn: 0.0000000\ttotal: 2.87s\tremaining: 2.63s\n",
      "5219:\tlearn: 0.0000000\ttotal: 2.87s\tremaining: 2.63s\n",
      "5220:\tlearn: 0.0000000\ttotal: 2.87s\tremaining: 2.62s\n",
      "5221:\tlearn: 0.0000000\ttotal: 2.87s\tremaining: 2.62s\n",
      "5222:\tlearn: 0.0000000\ttotal: 2.87s\tremaining: 2.62s\n",
      "5223:\tlearn: 0.0000000\ttotal: 2.87s\tremaining: 2.62s\n",
      "5224:\tlearn: 0.0000000\ttotal: 2.87s\tremaining: 2.62s\n",
      "5225:\tlearn: 0.0000000\ttotal: 2.87s\tremaining: 2.62s\n",
      "5226:\tlearn: 0.0000000\ttotal: 2.87s\tremaining: 2.62s\n",
      "5227:\tlearn: 0.0000000\ttotal: 2.87s\tremaining: 2.62s\n",
      "5228:\tlearn: 0.0000000\ttotal: 2.87s\tremaining: 2.62s\n",
      "5229:\tlearn: 0.0000000\ttotal: 2.87s\tremaining: 2.62s\n",
      "5230:\tlearn: 0.0000000\ttotal: 2.87s\tremaining: 2.62s\n",
      "5231:\tlearn: 0.0000000\ttotal: 2.87s\tremaining: 2.62s\n",
      "5232:\tlearn: 0.0000000\ttotal: 2.87s\tremaining: 2.62s\n",
      "5233:\tlearn: 0.0000000\ttotal: 2.87s\tremaining: 2.62s\n",
      "5234:\tlearn: 0.0000000\ttotal: 2.88s\tremaining: 2.62s\n",
      "5235:\tlearn: 0.0000000\ttotal: 2.88s\tremaining: 2.62s\n",
      "5236:\tlearn: 0.0000000\ttotal: 2.88s\tremaining: 2.62s\n",
      "5237:\tlearn: 0.0000000\ttotal: 2.88s\tremaining: 2.62s\n",
      "5238:\tlearn: 0.0000000\ttotal: 2.88s\tremaining: 2.61s\n",
      "5239:\tlearn: 0.0000000\ttotal: 2.88s\tremaining: 2.61s\n",
      "5240:\tlearn: 0.0000000\ttotal: 2.88s\tremaining: 2.61s\n",
      "5241:\tlearn: 0.0000000\ttotal: 2.88s\tremaining: 2.61s\n",
      "5242:\tlearn: 0.0000000\ttotal: 2.88s\tremaining: 2.61s\n",
      "5243:\tlearn: 0.0000000\ttotal: 2.88s\tremaining: 2.61s\n",
      "5244:\tlearn: 0.0000000\ttotal: 2.88s\tremaining: 2.61s\n",
      "5245:\tlearn: 0.0000000\ttotal: 2.88s\tremaining: 2.61s\n",
      "5246:\tlearn: 0.0000000\ttotal: 2.88s\tremaining: 2.61s\n",
      "5247:\tlearn: 0.0000000\ttotal: 2.88s\tremaining: 2.61s\n",
      "5248:\tlearn: 0.0000000\ttotal: 2.88s\tremaining: 2.61s\n",
      "5249:\tlearn: 0.0000000\ttotal: 2.88s\tremaining: 2.61s\n",
      "5250:\tlearn: 0.0000000\ttotal: 2.88s\tremaining: 2.61s\n",
      "5251:\tlearn: 0.0000000\ttotal: 2.88s\tremaining: 2.61s\n",
      "5252:\tlearn: 0.0000000\ttotal: 2.88s\tremaining: 2.6s\n",
      "5253:\tlearn: 0.0000000\ttotal: 2.88s\tremaining: 2.6s\n",
      "5254:\tlearn: 0.0000000\ttotal: 2.88s\tremaining: 2.6s\n",
      "5255:\tlearn: 0.0000000\ttotal: 2.88s\tremaining: 2.6s\n",
      "5256:\tlearn: 0.0000000\ttotal: 2.88s\tremaining: 2.6s\n",
      "5257:\tlearn: 0.0000000\ttotal: 2.89s\tremaining: 2.6s\n",
      "5258:\tlearn: 0.0000000\ttotal: 2.89s\tremaining: 2.6s\n",
      "5259:\tlearn: 0.0000000\ttotal: 2.89s\tremaining: 2.6s\n",
      "5260:\tlearn: 0.0000000\ttotal: 2.89s\tremaining: 2.6s\n",
      "5261:\tlearn: 0.0000000\ttotal: 2.89s\tremaining: 2.6s\n",
      "5262:\tlearn: 0.0000000\ttotal: 2.89s\tremaining: 2.6s\n",
      "5263:\tlearn: 0.0000000\ttotal: 2.89s\tremaining: 2.6s\n",
      "5264:\tlearn: 0.0000000\ttotal: 2.89s\tremaining: 2.6s\n",
      "5265:\tlearn: 0.0000000\ttotal: 2.89s\tremaining: 2.6s\n",
      "5266:\tlearn: 0.0000000\ttotal: 2.89s\tremaining: 2.6s\n",
      "5267:\tlearn: 0.0000000\ttotal: 2.89s\tremaining: 2.6s\n",
      "5268:\tlearn: 0.0000000\ttotal: 2.89s\tremaining: 2.6s\n",
      "5269:\tlearn: 0.0000000\ttotal: 2.89s\tremaining: 2.6s\n",
      "5270:\tlearn: 0.0000000\ttotal: 2.89s\tremaining: 2.59s\n",
      "5271:\tlearn: 0.0000000\ttotal: 2.89s\tremaining: 2.59s\n",
      "5272:\tlearn: 0.0000000\ttotal: 2.89s\tremaining: 2.59s\n",
      "5273:\tlearn: 0.0000000\ttotal: 2.89s\tremaining: 2.59s\n",
      "5274:\tlearn: 0.0000000\ttotal: 2.89s\tremaining: 2.59s\n",
      "5275:\tlearn: 0.0000000\ttotal: 2.89s\tremaining: 2.59s\n",
      "5276:\tlearn: 0.0000000\ttotal: 2.9s\tremaining: 2.59s\n",
      "5277:\tlearn: 0.0000000\ttotal: 2.9s\tremaining: 2.59s\n",
      "5278:\tlearn: 0.0000000\ttotal: 2.9s\tremaining: 2.59s\n",
      "5279:\tlearn: 0.0000000\ttotal: 2.9s\tremaining: 2.59s\n",
      "5280:\tlearn: 0.0000000\ttotal: 2.9s\tremaining: 2.59s\n",
      "5281:\tlearn: 0.0000000\ttotal: 2.9s\tremaining: 2.59s\n",
      "5282:\tlearn: 0.0000000\ttotal: 2.9s\tremaining: 2.59s\n",
      "5283:\tlearn: 0.0000000\ttotal: 2.9s\tremaining: 2.59s\n",
      "5284:\tlearn: 0.0000000\ttotal: 2.9s\tremaining: 2.59s\n",
      "5285:\tlearn: 0.0000000\ttotal: 2.9s\tremaining: 2.59s\n",
      "5286:\tlearn: 0.0000000\ttotal: 2.9s\tremaining: 2.58s\n",
      "5287:\tlearn: 0.0000000\ttotal: 2.9s\tremaining: 2.58s\n",
      "5288:\tlearn: 0.0000000\ttotal: 2.9s\tremaining: 2.58s\n",
      "5289:\tlearn: 0.0000000\ttotal: 2.9s\tremaining: 2.58s\n",
      "5290:\tlearn: 0.0000000\ttotal: 2.9s\tremaining: 2.58s\n",
      "5291:\tlearn: 0.0000000\ttotal: 2.9s\tremaining: 2.58s\n",
      "5292:\tlearn: 0.0000000\ttotal: 2.9s\tremaining: 2.58s\n",
      "5293:\tlearn: 0.0000000\ttotal: 2.9s\tremaining: 2.58s\n",
      "5294:\tlearn: 0.0000000\ttotal: 2.9s\tremaining: 2.58s\n",
      "5295:\tlearn: 0.0000000\ttotal: 2.9s\tremaining: 2.58s\n",
      "5296:\tlearn: 0.0000000\ttotal: 2.9s\tremaining: 2.58s\n",
      "5297:\tlearn: 0.0000000\ttotal: 2.9s\tremaining: 2.58s\n",
      "5298:\tlearn: 0.0000000\ttotal: 2.9s\tremaining: 2.58s\n",
      "5299:\tlearn: 0.0000000\ttotal: 2.91s\tremaining: 2.58s\n",
      "5300:\tlearn: 0.0000000\ttotal: 2.91s\tremaining: 2.58s\n",
      "5301:\tlearn: 0.0000000\ttotal: 2.91s\tremaining: 2.58s\n",
      "5302:\tlearn: 0.0000000\ttotal: 2.91s\tremaining: 2.58s\n",
      "5303:\tlearn: 0.0000000\ttotal: 2.91s\tremaining: 2.57s\n",
      "5304:\tlearn: 0.0000000\ttotal: 2.91s\tremaining: 2.57s\n",
      "5305:\tlearn: 0.0000000\ttotal: 2.91s\tremaining: 2.57s\n",
      "5306:\tlearn: 0.0000000\ttotal: 2.91s\tremaining: 2.57s\n",
      "5307:\tlearn: 0.0000000\ttotal: 2.91s\tremaining: 2.57s\n",
      "5308:\tlearn: 0.0000000\ttotal: 2.91s\tremaining: 2.57s\n",
      "5309:\tlearn: 0.0000000\ttotal: 2.91s\tremaining: 2.57s\n",
      "5310:\tlearn: 0.0000000\ttotal: 2.91s\tremaining: 2.57s\n",
      "5311:\tlearn: 0.0000000\ttotal: 2.91s\tremaining: 2.57s\n",
      "5312:\tlearn: 0.0000000\ttotal: 2.91s\tremaining: 2.57s\n",
      "5313:\tlearn: 0.0000000\ttotal: 2.91s\tremaining: 2.57s\n",
      "5314:\tlearn: 0.0000000\ttotal: 2.91s\tremaining: 2.57s\n",
      "5315:\tlearn: 0.0000000\ttotal: 2.91s\tremaining: 2.57s\n",
      "5316:\tlearn: 0.0000000\ttotal: 2.91s\tremaining: 2.57s\n",
      "5317:\tlearn: 0.0000000\ttotal: 2.92s\tremaining: 2.57s\n",
      "5318:\tlearn: 0.0000000\ttotal: 2.92s\tremaining: 2.56s\n",
      "5319:\tlearn: 0.0000000\ttotal: 2.92s\tremaining: 2.56s\n",
      "5320:\tlearn: 0.0000000\ttotal: 2.92s\tremaining: 2.56s\n",
      "5321:\tlearn: 0.0000000\ttotal: 2.92s\tremaining: 2.56s\n",
      "5322:\tlearn: 0.0000000\ttotal: 2.92s\tremaining: 2.56s\n",
      "5323:\tlearn: 0.0000000\ttotal: 2.92s\tremaining: 2.56s\n",
      "5324:\tlearn: 0.0000000\ttotal: 2.92s\tremaining: 2.56s\n",
      "5325:\tlearn: 0.0000000\ttotal: 2.92s\tremaining: 2.56s\n",
      "5326:\tlearn: 0.0000000\ttotal: 2.92s\tremaining: 2.56s\n",
      "5327:\tlearn: 0.0000000\ttotal: 2.92s\tremaining: 2.56s\n",
      "5328:\tlearn: 0.0000000\ttotal: 2.92s\tremaining: 2.56s\n",
      "5329:\tlearn: 0.0000000\ttotal: 2.92s\tremaining: 2.56s\n",
      "5330:\tlearn: 0.0000000\ttotal: 2.92s\tremaining: 2.56s\n",
      "5331:\tlearn: 0.0000000\ttotal: 2.92s\tremaining: 2.56s\n",
      "5332:\tlearn: 0.0000000\ttotal: 2.92s\tremaining: 2.56s\n",
      "5333:\tlearn: 0.0000000\ttotal: 2.92s\tremaining: 2.56s\n",
      "5334:\tlearn: 0.0000000\ttotal: 2.92s\tremaining: 2.56s\n",
      "5335:\tlearn: 0.0000000\ttotal: 2.92s\tremaining: 2.56s\n",
      "5336:\tlearn: 0.0000000\ttotal: 2.92s\tremaining: 2.55s\n",
      "5337:\tlearn: 0.0000000\ttotal: 2.92s\tremaining: 2.55s\n",
      "5338:\tlearn: 0.0000000\ttotal: 2.92s\tremaining: 2.55s\n",
      "5339:\tlearn: 0.0000000\ttotal: 2.92s\tremaining: 2.55s\n",
      "5340:\tlearn: 0.0000000\ttotal: 2.92s\tremaining: 2.55s\n",
      "5341:\tlearn: 0.0000000\ttotal: 2.92s\tremaining: 2.55s\n",
      "5342:\tlearn: 0.0000000\ttotal: 2.93s\tremaining: 2.55s\n",
      "5343:\tlearn: 0.0000000\ttotal: 2.93s\tremaining: 2.55s\n",
      "5344:\tlearn: 0.0000000\ttotal: 2.93s\tremaining: 2.55s\n",
      "5345:\tlearn: 0.0000000\ttotal: 2.93s\tremaining: 2.55s\n",
      "5346:\tlearn: 0.0000000\ttotal: 2.93s\tremaining: 2.55s\n",
      "5347:\tlearn: 0.0000000\ttotal: 2.93s\tremaining: 2.55s\n",
      "5348:\tlearn: 0.0000000\ttotal: 2.93s\tremaining: 2.55s\n",
      "5349:\tlearn: 0.0000000\ttotal: 2.93s\tremaining: 2.55s\n",
      "5350:\tlearn: 0.0000000\ttotal: 2.93s\tremaining: 2.55s\n",
      "5351:\tlearn: 0.0000000\ttotal: 2.93s\tremaining: 2.54s\n",
      "5352:\tlearn: 0.0000000\ttotal: 2.93s\tremaining: 2.54s\n",
      "5353:\tlearn: 0.0000000\ttotal: 2.93s\tremaining: 2.54s\n",
      "5354:\tlearn: 0.0000000\ttotal: 2.93s\tremaining: 2.54s\n",
      "5355:\tlearn: 0.0000000\ttotal: 2.93s\tremaining: 2.54s\n",
      "5356:\tlearn: 0.0000000\ttotal: 2.93s\tremaining: 2.54s\n",
      "5357:\tlearn: 0.0000000\ttotal: 2.93s\tremaining: 2.54s\n",
      "5358:\tlearn: 0.0000000\ttotal: 2.93s\tremaining: 2.54s\n",
      "5359:\tlearn: 0.0000000\ttotal: 2.93s\tremaining: 2.54s\n",
      "5360:\tlearn: 0.0000000\ttotal: 2.94s\tremaining: 2.54s\n",
      "5361:\tlearn: 0.0000000\ttotal: 2.94s\tremaining: 2.54s\n",
      "5362:\tlearn: 0.0000000\ttotal: 2.94s\tremaining: 2.54s\n",
      "5363:\tlearn: 0.0000000\ttotal: 2.94s\tremaining: 2.54s\n",
      "5364:\tlearn: 0.0000000\ttotal: 2.94s\tremaining: 2.54s\n",
      "5365:\tlearn: 0.0000000\ttotal: 2.94s\tremaining: 2.54s\n",
      "5366:\tlearn: 0.0000000\ttotal: 2.94s\tremaining: 2.54s\n",
      "5367:\tlearn: 0.0000000\ttotal: 2.94s\tremaining: 2.54s\n",
      "5368:\tlearn: 0.0000000\ttotal: 2.94s\tremaining: 2.54s\n",
      "5369:\tlearn: 0.0000000\ttotal: 2.94s\tremaining: 2.53s\n",
      "5370:\tlearn: 0.0000000\ttotal: 2.94s\tremaining: 2.53s\n",
      "5371:\tlearn: 0.0000000\ttotal: 2.94s\tremaining: 2.53s\n",
      "5372:\tlearn: 0.0000000\ttotal: 2.94s\tremaining: 2.53s\n",
      "5373:\tlearn: 0.0000000\ttotal: 2.94s\tremaining: 2.53s\n",
      "5374:\tlearn: 0.0000000\ttotal: 2.94s\tremaining: 2.53s\n",
      "5375:\tlearn: 0.0000000\ttotal: 2.94s\tremaining: 2.53s\n",
      "5376:\tlearn: 0.0000000\ttotal: 2.94s\tremaining: 2.53s\n",
      "5377:\tlearn: 0.0000000\ttotal: 2.94s\tremaining: 2.53s\n",
      "5378:\tlearn: 0.0000000\ttotal: 2.94s\tremaining: 2.53s\n",
      "5379:\tlearn: 0.0000000\ttotal: 2.94s\tremaining: 2.53s\n",
      "5380:\tlearn: 0.0000000\ttotal: 2.94s\tremaining: 2.53s\n",
      "5381:\tlearn: 0.0000000\ttotal: 2.94s\tremaining: 2.53s\n",
      "5382:\tlearn: 0.0000000\ttotal: 2.95s\tremaining: 2.53s\n",
      "5383:\tlearn: 0.0000000\ttotal: 2.95s\tremaining: 2.53s\n",
      "5384:\tlearn: 0.0000000\ttotal: 2.95s\tremaining: 2.52s\n",
      "5385:\tlearn: 0.0000000\ttotal: 2.95s\tremaining: 2.52s\n",
      "5386:\tlearn: 0.0000000\ttotal: 2.95s\tremaining: 2.52s\n",
      "5387:\tlearn: 0.0000000\ttotal: 2.95s\tremaining: 2.52s\n",
      "5388:\tlearn: 0.0000000\ttotal: 2.95s\tremaining: 2.52s\n",
      "5389:\tlearn: 0.0000000\ttotal: 2.95s\tremaining: 2.52s\n",
      "5390:\tlearn: 0.0000000\ttotal: 2.95s\tremaining: 2.52s\n",
      "5391:\tlearn: 0.0000000\ttotal: 2.95s\tremaining: 2.52s\n",
      "5392:\tlearn: 0.0000000\ttotal: 2.95s\tremaining: 2.52s\n",
      "5393:\tlearn: 0.0000000\ttotal: 2.95s\tremaining: 2.52s\n",
      "5394:\tlearn: 0.0000000\ttotal: 2.95s\tremaining: 2.52s\n",
      "5395:\tlearn: 0.0000000\ttotal: 2.95s\tremaining: 2.52s\n",
      "5396:\tlearn: 0.0000000\ttotal: 2.95s\tremaining: 2.52s\n",
      "5397:\tlearn: 0.0000000\ttotal: 2.95s\tremaining: 2.52s\n",
      "5398:\tlearn: 0.0000000\ttotal: 2.95s\tremaining: 2.52s\n",
      "5399:\tlearn: 0.0000000\ttotal: 2.95s\tremaining: 2.52s\n",
      "5400:\tlearn: 0.0000000\ttotal: 2.95s\tremaining: 2.52s\n",
      "5401:\tlearn: 0.0000000\ttotal: 2.96s\tremaining: 2.52s\n",
      "5402:\tlearn: 0.0000000\ttotal: 2.96s\tremaining: 2.52s\n",
      "5403:\tlearn: 0.0000000\ttotal: 2.96s\tremaining: 2.51s\n",
      "5404:\tlearn: 0.0000000\ttotal: 2.96s\tremaining: 2.51s\n",
      "5405:\tlearn: 0.0000000\ttotal: 2.96s\tremaining: 2.51s\n",
      "5406:\tlearn: 0.0000000\ttotal: 2.96s\tremaining: 2.51s\n",
      "5407:\tlearn: 0.0000000\ttotal: 2.96s\tremaining: 2.51s\n",
      "5408:\tlearn: 0.0000000\ttotal: 2.96s\tremaining: 2.51s\n",
      "5409:\tlearn: 0.0000000\ttotal: 2.96s\tremaining: 2.51s\n",
      "5410:\tlearn: 0.0000000\ttotal: 2.96s\tremaining: 2.51s\n",
      "5411:\tlearn: 0.0000000\ttotal: 2.96s\tremaining: 2.51s\n",
      "5412:\tlearn: 0.0000000\ttotal: 2.96s\tremaining: 2.51s\n",
      "5413:\tlearn: 0.0000000\ttotal: 2.96s\tremaining: 2.51s\n",
      "5414:\tlearn: 0.0000000\ttotal: 2.96s\tremaining: 2.51s\n",
      "5415:\tlearn: 0.0000000\ttotal: 2.96s\tremaining: 2.51s\n",
      "5416:\tlearn: 0.0000000\ttotal: 2.96s\tremaining: 2.51s\n",
      "5417:\tlearn: 0.0000000\ttotal: 2.96s\tremaining: 2.51s\n",
      "5418:\tlearn: 0.0000000\ttotal: 2.96s\tremaining: 2.5s\n",
      "5419:\tlearn: 0.0000000\ttotal: 2.96s\tremaining: 2.5s\n",
      "5420:\tlearn: 0.0000000\ttotal: 2.96s\tremaining: 2.5s\n",
      "5421:\tlearn: 0.0000000\ttotal: 2.96s\tremaining: 2.5s\n",
      "5422:\tlearn: 0.0000000\ttotal: 2.96s\tremaining: 2.5s\n",
      "5423:\tlearn: 0.0000000\ttotal: 2.97s\tremaining: 2.5s\n",
      "5424:\tlearn: 0.0000000\ttotal: 2.97s\tremaining: 2.5s\n",
      "5425:\tlearn: 0.0000000\ttotal: 2.97s\tremaining: 2.5s\n",
      "5426:\tlearn: 0.0000000\ttotal: 2.97s\tremaining: 2.5s\n",
      "5427:\tlearn: 0.0000000\ttotal: 2.97s\tremaining: 2.5s\n",
      "5428:\tlearn: 0.0000000\ttotal: 2.97s\tremaining: 2.5s\n",
      "5429:\tlearn: 0.0000000\ttotal: 2.97s\tremaining: 2.5s\n",
      "5430:\tlearn: 0.0000000\ttotal: 2.97s\tremaining: 2.5s\n",
      "5431:\tlearn: 0.0000000\ttotal: 2.97s\tremaining: 2.5s\n",
      "5432:\tlearn: 0.0000000\ttotal: 2.97s\tremaining: 2.5s\n",
      "5433:\tlearn: 0.0000000\ttotal: 2.97s\tremaining: 2.5s\n",
      "5434:\tlearn: 0.0000000\ttotal: 2.97s\tremaining: 2.5s\n",
      "5435:\tlearn: 0.0000000\ttotal: 2.97s\tremaining: 2.5s\n",
      "5436:\tlearn: 0.0000000\ttotal: 2.97s\tremaining: 2.5s\n",
      "5437:\tlearn: 0.0000000\ttotal: 2.97s\tremaining: 2.49s\n",
      "5438:\tlearn: 0.0000000\ttotal: 2.97s\tremaining: 2.49s\n",
      "5439:\tlearn: 0.0000000\ttotal: 2.97s\tremaining: 2.49s\n",
      "5440:\tlearn: 0.0000000\ttotal: 2.98s\tremaining: 2.49s\n",
      "5441:\tlearn: 0.0000000\ttotal: 2.98s\tremaining: 2.49s\n",
      "5442:\tlearn: 0.0000000\ttotal: 2.98s\tremaining: 2.49s\n",
      "5443:\tlearn: 0.0000000\ttotal: 2.98s\tremaining: 2.49s\n",
      "5444:\tlearn: 0.0000000\ttotal: 2.98s\tremaining: 2.49s\n",
      "5445:\tlearn: 0.0000000\ttotal: 2.98s\tremaining: 2.49s\n",
      "5446:\tlearn: 0.0000000\ttotal: 2.98s\tremaining: 2.49s\n",
      "5447:\tlearn: 0.0000000\ttotal: 2.98s\tremaining: 2.49s\n",
      "5448:\tlearn: 0.0000000\ttotal: 2.98s\tremaining: 2.49s\n",
      "5449:\tlearn: 0.0000000\ttotal: 2.98s\tremaining: 2.49s\n",
      "5450:\tlearn: 0.0000000\ttotal: 2.98s\tremaining: 2.49s\n",
      "5451:\tlearn: 0.0000000\ttotal: 2.98s\tremaining: 2.49s\n",
      "5452:\tlearn: 0.0000000\ttotal: 2.98s\tremaining: 2.48s\n",
      "5453:\tlearn: 0.0000000\ttotal: 2.98s\tremaining: 2.48s\n",
      "5454:\tlearn: 0.0000000\ttotal: 2.98s\tremaining: 2.48s\n",
      "5455:\tlearn: 0.0000000\ttotal: 2.98s\tremaining: 2.48s\n",
      "5456:\tlearn: 0.0000000\ttotal: 2.98s\tremaining: 2.48s\n",
      "5457:\tlearn: 0.0000000\ttotal: 2.98s\tremaining: 2.48s\n",
      "5458:\tlearn: 0.0000000\ttotal: 2.98s\tremaining: 2.48s\n",
      "5459:\tlearn: 0.0000000\ttotal: 2.98s\tremaining: 2.48s\n",
      "5460:\tlearn: 0.0000000\ttotal: 2.98s\tremaining: 2.48s\n",
      "5461:\tlearn: 0.0000000\ttotal: 2.98s\tremaining: 2.48s\n",
      "5462:\tlearn: 0.0000000\ttotal: 2.98s\tremaining: 2.48s\n",
      "5463:\tlearn: 0.0000000\ttotal: 2.99s\tremaining: 2.48s\n",
      "5464:\tlearn: 0.0000000\ttotal: 2.99s\tremaining: 2.48s\n",
      "5465:\tlearn: 0.0000000\ttotal: 2.99s\tremaining: 2.48s\n",
      "5466:\tlearn: 0.0000000\ttotal: 2.99s\tremaining: 2.48s\n",
      "5467:\tlearn: 0.0000000\ttotal: 2.99s\tremaining: 2.48s\n",
      "5468:\tlearn: 0.0000000\ttotal: 2.99s\tremaining: 2.48s\n",
      "5469:\tlearn: 0.0000000\ttotal: 2.99s\tremaining: 2.48s\n",
      "5470:\tlearn: 0.0000000\ttotal: 2.99s\tremaining: 2.47s\n",
      "5471:\tlearn: 0.0000000\ttotal: 2.99s\tremaining: 2.47s\n",
      "5472:\tlearn: 0.0000000\ttotal: 2.99s\tremaining: 2.47s\n",
      "5473:\tlearn: 0.0000000\ttotal: 2.99s\tremaining: 2.47s\n",
      "5474:\tlearn: 0.0000000\ttotal: 2.99s\tremaining: 2.47s\n",
      "5475:\tlearn: 0.0000000\ttotal: 2.99s\tremaining: 2.47s\n",
      "5476:\tlearn: 0.0000000\ttotal: 2.99s\tremaining: 2.47s\n",
      "5477:\tlearn: 0.0000000\ttotal: 2.99s\tremaining: 2.47s\n",
      "5478:\tlearn: 0.0000000\ttotal: 2.99s\tremaining: 2.47s\n",
      "5479:\tlearn: 0.0000000\ttotal: 2.99s\tremaining: 2.47s\n",
      "5480:\tlearn: 0.0000000\ttotal: 2.99s\tremaining: 2.47s\n",
      "5481:\tlearn: 0.0000000\ttotal: 3s\tremaining: 2.47s\n",
      "5482:\tlearn: 0.0000000\ttotal: 3s\tremaining: 2.47s\n",
      "5483:\tlearn: 0.0000000\ttotal: 3s\tremaining: 2.47s\n",
      "5484:\tlearn: 0.0000000\ttotal: 3s\tremaining: 2.47s\n",
      "5485:\tlearn: 0.0000000\ttotal: 3s\tremaining: 2.47s\n",
      "5486:\tlearn: 0.0000000\ttotal: 3s\tremaining: 2.46s\n",
      "5487:\tlearn: 0.0000000\ttotal: 3s\tremaining: 2.46s\n",
      "5488:\tlearn: 0.0000000\ttotal: 3s\tremaining: 2.46s\n",
      "5489:\tlearn: 0.0000000\ttotal: 3s\tremaining: 2.46s\n",
      "5490:\tlearn: 0.0000000\ttotal: 3s\tremaining: 2.46s\n",
      "5491:\tlearn: 0.0000000\ttotal: 3s\tremaining: 2.46s\n",
      "5492:\tlearn: 0.0000000\ttotal: 3s\tremaining: 2.46s\n",
      "5493:\tlearn: 0.0000000\ttotal: 3s\tremaining: 2.46s\n",
      "5494:\tlearn: 0.0000000\ttotal: 3s\tremaining: 2.46s\n",
      "5495:\tlearn: 0.0000000\ttotal: 3s\tremaining: 2.46s\n",
      "5496:\tlearn: 0.0000000\ttotal: 3s\tremaining: 2.46s\n",
      "5497:\tlearn: 0.0000000\ttotal: 3s\tremaining: 2.46s\n",
      "5498:\tlearn: 0.0000000\ttotal: 3s\tremaining: 2.46s\n",
      "5499:\tlearn: 0.0000000\ttotal: 3s\tremaining: 2.46s\n",
      "5500:\tlearn: 0.0000000\ttotal: 3s\tremaining: 2.46s\n",
      "5501:\tlearn: 0.0000000\ttotal: 3s\tremaining: 2.46s\n",
      "5502:\tlearn: 0.0000000\ttotal: 3.01s\tremaining: 2.46s\n",
      "5503:\tlearn: 0.0000000\ttotal: 3.01s\tremaining: 2.46s\n",
      "5504:\tlearn: 0.0000000\ttotal: 3.01s\tremaining: 2.46s\n",
      "5505:\tlearn: 0.0000000\ttotal: 3.01s\tremaining: 2.45s\n",
      "5506:\tlearn: 0.0000000\ttotal: 3.01s\tremaining: 2.45s\n",
      "5507:\tlearn: 0.0000000\ttotal: 3.01s\tremaining: 2.45s\n",
      "5508:\tlearn: 0.0000000\ttotal: 3.01s\tremaining: 2.45s\n",
      "5509:\tlearn: 0.0000000\ttotal: 3.01s\tremaining: 2.45s\n",
      "5510:\tlearn: 0.0000000\ttotal: 3.01s\tremaining: 2.45s\n",
      "5511:\tlearn: 0.0000000\ttotal: 3.01s\tremaining: 2.45s\n",
      "5512:\tlearn: 0.0000000\ttotal: 3.01s\tremaining: 2.45s\n",
      "5513:\tlearn: 0.0000000\ttotal: 3.01s\tremaining: 2.45s\n",
      "5514:\tlearn: 0.0000000\ttotal: 3.01s\tremaining: 2.45s\n",
      "5515:\tlearn: 0.0000000\ttotal: 3.01s\tremaining: 2.45s\n",
      "5516:\tlearn: 0.0000000\ttotal: 3.01s\tremaining: 2.45s\n",
      "5517:\tlearn: 0.0000000\ttotal: 3.01s\tremaining: 2.45s\n",
      "5518:\tlearn: 0.0000000\ttotal: 3.02s\tremaining: 2.45s\n",
      "5519:\tlearn: 0.0000000\ttotal: 3.02s\tremaining: 2.45s\n",
      "5520:\tlearn: 0.0000000\ttotal: 3.02s\tremaining: 2.45s\n",
      "5521:\tlearn: 0.0000000\ttotal: 3.02s\tremaining: 2.45s\n",
      "5522:\tlearn: 0.0000000\ttotal: 3.02s\tremaining: 2.44s\n",
      "5523:\tlearn: 0.0000000\ttotal: 3.02s\tremaining: 2.44s\n",
      "5524:\tlearn: 0.0000000\ttotal: 3.02s\tremaining: 2.44s\n",
      "5525:\tlearn: 0.0000000\ttotal: 3.02s\tremaining: 2.44s\n",
      "5526:\tlearn: 0.0000000\ttotal: 3.02s\tremaining: 2.44s\n",
      "5527:\tlearn: 0.0000000\ttotal: 3.02s\tremaining: 2.44s\n",
      "5528:\tlearn: 0.0000000\ttotal: 3.02s\tremaining: 2.44s\n",
      "5529:\tlearn: 0.0000000\ttotal: 3.02s\tremaining: 2.44s\n",
      "5530:\tlearn: 0.0000000\ttotal: 3.02s\tremaining: 2.44s\n",
      "5531:\tlearn: 0.0000000\ttotal: 3.02s\tremaining: 2.44s\n",
      "5532:\tlearn: 0.0000000\ttotal: 3.02s\tremaining: 2.44s\n",
      "5533:\tlearn: 0.0000000\ttotal: 3.02s\tremaining: 2.44s\n",
      "5534:\tlearn: 0.0000000\ttotal: 3.02s\tremaining: 2.44s\n",
      "5535:\tlearn: 0.0000000\ttotal: 3.02s\tremaining: 2.44s\n",
      "5536:\tlearn: 0.0000000\ttotal: 3.02s\tremaining: 2.44s\n",
      "5537:\tlearn: 0.0000000\ttotal: 3.02s\tremaining: 2.44s\n",
      "5538:\tlearn: 0.0000000\ttotal: 3.02s\tremaining: 2.44s\n",
      "5539:\tlearn: 0.0000000\ttotal: 3.02s\tremaining: 2.43s\n",
      "5540:\tlearn: 0.0000000\ttotal: 3.02s\tremaining: 2.43s\n",
      "5541:\tlearn: 0.0000000\ttotal: 3.02s\tremaining: 2.43s\n",
      "5542:\tlearn: 0.0000000\ttotal: 3.02s\tremaining: 2.43s\n",
      "5543:\tlearn: 0.0000000\ttotal: 3.03s\tremaining: 2.43s\n",
      "5544:\tlearn: 0.0000000\ttotal: 3.03s\tremaining: 2.43s\n",
      "5545:\tlearn: 0.0000000\ttotal: 3.03s\tremaining: 2.43s\n",
      "5546:\tlearn: 0.0000000\ttotal: 3.03s\tremaining: 2.43s\n",
      "5547:\tlearn: 0.0000000\ttotal: 3.03s\tremaining: 2.43s\n",
      "5548:\tlearn: 0.0000000\ttotal: 3.03s\tremaining: 2.43s\n",
      "5549:\tlearn: 0.0000000\ttotal: 3.03s\tremaining: 2.43s\n",
      "5550:\tlearn: 0.0000000\ttotal: 3.03s\tremaining: 2.43s\n",
      "5551:\tlearn: 0.0000000\ttotal: 3.03s\tremaining: 2.43s\n",
      "5552:\tlearn: 0.0000000\ttotal: 3.03s\tremaining: 2.43s\n",
      "5553:\tlearn: 0.0000000\ttotal: 3.03s\tremaining: 2.43s\n",
      "5554:\tlearn: 0.0000000\ttotal: 3.03s\tremaining: 2.43s\n",
      "5555:\tlearn: 0.0000000\ttotal: 3.03s\tremaining: 2.43s\n",
      "5556:\tlearn: 0.0000000\ttotal: 3.03s\tremaining: 2.43s\n",
      "5557:\tlearn: 0.0000000\ttotal: 3.03s\tremaining: 2.42s\n",
      "5558:\tlearn: 0.0000000\ttotal: 3.04s\tremaining: 2.42s\n",
      "5559:\tlearn: 0.0000000\ttotal: 3.04s\tremaining: 2.42s\n",
      "5560:\tlearn: 0.0000000\ttotal: 3.04s\tremaining: 2.42s\n",
      "5561:\tlearn: 0.0000000\ttotal: 3.04s\tremaining: 2.42s\n",
      "5562:\tlearn: 0.0000000\ttotal: 3.04s\tremaining: 2.42s\n",
      "5563:\tlearn: 0.0000000\ttotal: 3.04s\tremaining: 2.42s\n",
      "5564:\tlearn: 0.0000000\ttotal: 3.04s\tremaining: 2.42s\n",
      "5565:\tlearn: 0.0000000\ttotal: 3.04s\tremaining: 2.42s\n",
      "5566:\tlearn: 0.0000000\ttotal: 3.04s\tremaining: 2.42s\n",
      "5567:\tlearn: 0.0000000\ttotal: 3.04s\tremaining: 2.42s\n",
      "5568:\tlearn: 0.0000000\ttotal: 3.04s\tremaining: 2.42s\n",
      "5569:\tlearn: 0.0000000\ttotal: 3.04s\tremaining: 2.42s\n",
      "5570:\tlearn: 0.0000000\ttotal: 3.04s\tremaining: 2.42s\n",
      "5571:\tlearn: 0.0000000\ttotal: 3.04s\tremaining: 2.42s\n",
      "5572:\tlearn: 0.0000000\ttotal: 3.04s\tremaining: 2.42s\n",
      "5573:\tlearn: 0.0000000\ttotal: 3.04s\tremaining: 2.42s\n",
      "5574:\tlearn: 0.0000000\ttotal: 3.04s\tremaining: 2.42s\n",
      "5575:\tlearn: 0.0000000\ttotal: 3.04s\tremaining: 2.42s\n",
      "5576:\tlearn: 0.0000000\ttotal: 3.04s\tremaining: 2.42s\n",
      "5577:\tlearn: 0.0000000\ttotal: 3.05s\tremaining: 2.41s\n",
      "5578:\tlearn: 0.0000000\ttotal: 3.05s\tremaining: 2.41s\n",
      "5579:\tlearn: 0.0000000\ttotal: 3.05s\tremaining: 2.41s\n",
      "5580:\tlearn: 0.0000000\ttotal: 3.05s\tremaining: 2.41s\n",
      "5581:\tlearn: 0.0000000\ttotal: 3.05s\tremaining: 2.41s\n",
      "5582:\tlearn: 0.0000000\ttotal: 3.05s\tremaining: 2.41s\n",
      "5583:\tlearn: 0.0000000\ttotal: 3.05s\tremaining: 2.41s\n",
      "5584:\tlearn: 0.0000000\ttotal: 3.05s\tremaining: 2.41s\n",
      "5585:\tlearn: 0.0000000\ttotal: 3.05s\tremaining: 2.41s\n",
      "5586:\tlearn: 0.0000000\ttotal: 3.05s\tremaining: 2.41s\n",
      "5587:\tlearn: 0.0000000\ttotal: 3.05s\tremaining: 2.41s\n",
      "5588:\tlearn: 0.0000000\ttotal: 3.05s\tremaining: 2.41s\n",
      "5589:\tlearn: 0.0000000\ttotal: 3.05s\tremaining: 2.41s\n",
      "5590:\tlearn: 0.0000000\ttotal: 3.05s\tremaining: 2.41s\n",
      "5591:\tlearn: 0.0000000\ttotal: 3.05s\tremaining: 2.41s\n",
      "5592:\tlearn: 0.0000000\ttotal: 3.05s\tremaining: 2.41s\n",
      "5593:\tlearn: 0.0000000\ttotal: 3.05s\tremaining: 2.4s\n",
      "5594:\tlearn: 0.0000000\ttotal: 3.05s\tremaining: 2.4s\n",
      "5595:\tlearn: 0.0000000\ttotal: 3.06s\tremaining: 2.4s\n",
      "5596:\tlearn: 0.0000000\ttotal: 3.06s\tremaining: 2.4s\n",
      "5597:\tlearn: 0.0000000\ttotal: 3.06s\tremaining: 2.4s\n",
      "5598:\tlearn: 0.0000000\ttotal: 3.06s\tremaining: 2.4s\n",
      "5599:\tlearn: 0.0000000\ttotal: 3.06s\tremaining: 2.4s\n",
      "5600:\tlearn: 0.0000000\ttotal: 3.06s\tremaining: 2.4s\n",
      "5601:\tlearn: 0.0000000\ttotal: 3.06s\tremaining: 2.4s\n",
      "5602:\tlearn: 0.0000000\ttotal: 3.06s\tremaining: 2.4s\n",
      "5603:\tlearn: 0.0000000\ttotal: 3.06s\tremaining: 2.4s\n",
      "5604:\tlearn: 0.0000000\ttotal: 3.06s\tremaining: 2.4s\n",
      "5605:\tlearn: 0.0000000\ttotal: 3.06s\tremaining: 2.4s\n",
      "5606:\tlearn: 0.0000000\ttotal: 3.06s\tremaining: 2.4s\n",
      "5607:\tlearn: 0.0000000\ttotal: 3.06s\tremaining: 2.4s\n",
      "5608:\tlearn: 0.0000000\ttotal: 3.06s\tremaining: 2.4s\n",
      "5609:\tlearn: 0.0000000\ttotal: 3.06s\tremaining: 2.4s\n",
      "5610:\tlearn: 0.0000000\ttotal: 3.06s\tremaining: 2.4s\n",
      "5611:\tlearn: 0.0000000\ttotal: 3.06s\tremaining: 2.4s\n",
      "5612:\tlearn: 0.0000000\ttotal: 3.06s\tremaining: 2.39s\n",
      "5613:\tlearn: 0.0000000\ttotal: 3.06s\tremaining: 2.39s\n",
      "5614:\tlearn: 0.0000000\ttotal: 3.06s\tremaining: 2.39s\n",
      "5615:\tlearn: 0.0000000\ttotal: 3.06s\tremaining: 2.39s\n",
      "5616:\tlearn: 0.0000000\ttotal: 3.06s\tremaining: 2.39s\n",
      "5617:\tlearn: 0.0000000\ttotal: 3.07s\tremaining: 2.39s\n",
      "5618:\tlearn: 0.0000000\ttotal: 3.07s\tremaining: 2.39s\n",
      "5619:\tlearn: 0.0000000\ttotal: 3.07s\tremaining: 2.39s\n",
      "5620:\tlearn: 0.0000000\ttotal: 3.07s\tremaining: 2.39s\n",
      "5621:\tlearn: 0.0000000\ttotal: 3.07s\tremaining: 2.39s\n",
      "5622:\tlearn: 0.0000000\ttotal: 3.07s\tremaining: 2.39s\n",
      "5623:\tlearn: 0.0000000\ttotal: 3.07s\tremaining: 2.39s\n",
      "5624:\tlearn: 0.0000000\ttotal: 3.07s\tremaining: 2.39s\n",
      "5625:\tlearn: 0.0000000\ttotal: 3.07s\tremaining: 2.39s\n",
      "5626:\tlearn: 0.0000000\ttotal: 3.07s\tremaining: 2.39s\n",
      "5627:\tlearn: 0.0000000\ttotal: 3.07s\tremaining: 2.39s\n",
      "5628:\tlearn: 0.0000000\ttotal: 3.07s\tremaining: 2.38s\n",
      "5629:\tlearn: 0.0000000\ttotal: 3.07s\tremaining: 2.38s\n",
      "5630:\tlearn: 0.0000000\ttotal: 3.07s\tremaining: 2.38s\n",
      "5631:\tlearn: 0.0000000\ttotal: 3.07s\tremaining: 2.38s\n",
      "5632:\tlearn: 0.0000000\ttotal: 3.07s\tremaining: 2.38s\n",
      "5633:\tlearn: 0.0000000\ttotal: 3.07s\tremaining: 2.38s\n",
      "5634:\tlearn: 0.0000000\ttotal: 3.08s\tremaining: 2.38s\n",
      "5635:\tlearn: 0.0000000\ttotal: 3.08s\tremaining: 2.38s\n",
      "5636:\tlearn: 0.0000000\ttotal: 3.08s\tremaining: 2.38s\n",
      "5637:\tlearn: 0.0000000\ttotal: 3.08s\tremaining: 2.38s\n",
      "5638:\tlearn: 0.0000000\ttotal: 3.08s\tremaining: 2.38s\n",
      "5639:\tlearn: 0.0000000\ttotal: 3.08s\tremaining: 2.38s\n",
      "5640:\tlearn: 0.0000000\ttotal: 3.08s\tremaining: 2.38s\n",
      "5641:\tlearn: 0.0000000\ttotal: 3.08s\tremaining: 2.38s\n",
      "5642:\tlearn: 0.0000000\ttotal: 3.08s\tremaining: 2.38s\n",
      "5643:\tlearn: 0.0000000\ttotal: 3.08s\tremaining: 2.38s\n",
      "5644:\tlearn: 0.0000000\ttotal: 3.08s\tremaining: 2.38s\n",
      "5645:\tlearn: 0.0000000\ttotal: 3.08s\tremaining: 2.38s\n",
      "5646:\tlearn: 0.0000000\ttotal: 3.08s\tremaining: 2.37s\n",
      "5647:\tlearn: 0.0000000\ttotal: 3.08s\tremaining: 2.37s\n",
      "5648:\tlearn: 0.0000000\ttotal: 3.08s\tremaining: 2.37s\n",
      "5649:\tlearn: 0.0000000\ttotal: 3.08s\tremaining: 2.37s\n",
      "5650:\tlearn: 0.0000000\ttotal: 3.08s\tremaining: 2.37s\n",
      "5651:\tlearn: 0.0000000\ttotal: 3.08s\tremaining: 2.37s\n",
      "5652:\tlearn: 0.0000000\ttotal: 3.08s\tremaining: 2.37s\n",
      "5653:\tlearn: 0.0000000\ttotal: 3.08s\tremaining: 2.37s\n",
      "5654:\tlearn: 0.0000000\ttotal: 3.08s\tremaining: 2.37s\n",
      "5655:\tlearn: 0.0000000\ttotal: 3.08s\tremaining: 2.37s\n",
      "5656:\tlearn: 0.0000000\ttotal: 3.09s\tremaining: 2.37s\n",
      "5657:\tlearn: 0.0000000\ttotal: 3.09s\tremaining: 2.37s\n",
      "5658:\tlearn: 0.0000000\ttotal: 3.09s\tremaining: 2.37s\n",
      "5659:\tlearn: 0.0000000\ttotal: 3.09s\tremaining: 2.37s\n",
      "5660:\tlearn: 0.0000000\ttotal: 3.09s\tremaining: 2.37s\n",
      "5661:\tlearn: 0.0000000\ttotal: 3.09s\tremaining: 2.37s\n",
      "5662:\tlearn: 0.0000000\ttotal: 3.09s\tremaining: 2.37s\n",
      "5663:\tlearn: 0.0000000\ttotal: 3.09s\tremaining: 2.36s\n",
      "5664:\tlearn: 0.0000000\ttotal: 3.09s\tremaining: 2.36s\n",
      "5665:\tlearn: 0.0000000\ttotal: 3.09s\tremaining: 2.36s\n",
      "5666:\tlearn: 0.0000000\ttotal: 3.09s\tremaining: 2.36s\n",
      "5667:\tlearn: 0.0000000\ttotal: 3.09s\tremaining: 2.36s\n",
      "5668:\tlearn: 0.0000000\ttotal: 3.09s\tremaining: 2.36s\n",
      "5669:\tlearn: 0.0000000\ttotal: 3.09s\tremaining: 2.36s\n",
      "5670:\tlearn: 0.0000000\ttotal: 3.09s\tremaining: 2.36s\n",
      "5671:\tlearn: 0.0000000\ttotal: 3.09s\tremaining: 2.36s\n",
      "5672:\tlearn: 0.0000000\ttotal: 3.09s\tremaining: 2.36s\n",
      "5673:\tlearn: 0.0000000\ttotal: 3.09s\tremaining: 2.36s\n",
      "5674:\tlearn: 0.0000000\ttotal: 3.09s\tremaining: 2.36s\n",
      "5675:\tlearn: 0.0000000\ttotal: 3.09s\tremaining: 2.36s\n",
      "5676:\tlearn: 0.0000000\ttotal: 3.1s\tremaining: 2.36s\n",
      "5677:\tlearn: 0.0000000\ttotal: 3.1s\tremaining: 2.36s\n",
      "5678:\tlearn: 0.0000000\ttotal: 3.1s\tremaining: 2.35s\n",
      "5679:\tlearn: 0.0000000\ttotal: 3.1s\tremaining: 2.35s\n",
      "5680:\tlearn: 0.0000000\ttotal: 3.1s\tremaining: 2.35s\n",
      "5681:\tlearn: 0.0000000\ttotal: 3.1s\tremaining: 2.35s\n",
      "5682:\tlearn: 0.0000000\ttotal: 3.1s\tremaining: 2.35s\n",
      "5683:\tlearn: 0.0000000\ttotal: 3.1s\tremaining: 2.35s\n",
      "5684:\tlearn: 0.0000000\ttotal: 3.1s\tremaining: 2.35s\n",
      "5685:\tlearn: 0.0000000\ttotal: 3.1s\tremaining: 2.35s\n",
      "5686:\tlearn: 0.0000000\ttotal: 3.1s\tremaining: 2.35s\n",
      "5687:\tlearn: 0.0000000\ttotal: 3.1s\tremaining: 2.35s\n",
      "5688:\tlearn: 0.0000000\ttotal: 3.1s\tremaining: 2.35s\n",
      "5689:\tlearn: 0.0000000\ttotal: 3.1s\tremaining: 2.35s\n",
      "5690:\tlearn: 0.0000000\ttotal: 3.1s\tremaining: 2.35s\n",
      "5691:\tlearn: 0.0000000\ttotal: 3.1s\tremaining: 2.35s\n",
      "5692:\tlearn: 0.0000000\ttotal: 3.1s\tremaining: 2.35s\n",
      "5693:\tlearn: 0.0000000\ttotal: 3.1s\tremaining: 2.35s\n",
      "5694:\tlearn: 0.0000000\ttotal: 3.1s\tremaining: 2.35s\n",
      "5695:\tlearn: 0.0000000\ttotal: 3.1s\tremaining: 2.35s\n",
      "5696:\tlearn: 0.0000000\ttotal: 3.1s\tremaining: 2.35s\n",
      "5697:\tlearn: 0.0000000\ttotal: 3.1s\tremaining: 2.34s\n",
      "5698:\tlearn: 0.0000000\ttotal: 3.11s\tremaining: 2.34s\n",
      "5699:\tlearn: 0.0000000\ttotal: 3.11s\tremaining: 2.34s\n",
      "5700:\tlearn: 0.0000000\ttotal: 3.11s\tremaining: 2.34s\n",
      "5701:\tlearn: 0.0000000\ttotal: 3.11s\tremaining: 2.34s\n",
      "5702:\tlearn: 0.0000000\ttotal: 3.11s\tremaining: 2.34s\n",
      "5703:\tlearn: 0.0000000\ttotal: 3.11s\tremaining: 2.34s\n",
      "5704:\tlearn: 0.0000000\ttotal: 3.11s\tremaining: 2.34s\n",
      "5705:\tlearn: 0.0000000\ttotal: 3.11s\tremaining: 2.34s\n",
      "5706:\tlearn: 0.0000000\ttotal: 3.11s\tremaining: 2.34s\n",
      "5707:\tlearn: 0.0000000\ttotal: 3.11s\tremaining: 2.34s\n",
      "5708:\tlearn: 0.0000000\ttotal: 3.11s\tremaining: 2.34s\n",
      "5709:\tlearn: 0.0000000\ttotal: 3.11s\tremaining: 2.34s\n",
      "5710:\tlearn: 0.0000000\ttotal: 3.11s\tremaining: 2.34s\n",
      "5711:\tlearn: 0.0000000\ttotal: 3.11s\tremaining: 2.34s\n",
      "5712:\tlearn: 0.0000000\ttotal: 3.11s\tremaining: 2.33s\n",
      "5713:\tlearn: 0.0000000\ttotal: 3.11s\tremaining: 2.33s\n",
      "5714:\tlearn: 0.0000000\ttotal: 3.11s\tremaining: 2.33s\n",
      "5715:\tlearn: 0.0000000\ttotal: 3.11s\tremaining: 2.33s\n",
      "5716:\tlearn: 0.0000000\ttotal: 3.11s\tremaining: 2.33s\n",
      "5717:\tlearn: 0.0000000\ttotal: 3.12s\tremaining: 2.33s\n",
      "5718:\tlearn: 0.0000000\ttotal: 3.12s\tremaining: 2.33s\n",
      "5719:\tlearn: 0.0000000\ttotal: 3.12s\tremaining: 2.33s\n",
      "5720:\tlearn: 0.0000000\ttotal: 3.12s\tremaining: 2.33s\n",
      "5721:\tlearn: 0.0000000\ttotal: 3.12s\tremaining: 2.33s\n",
      "5722:\tlearn: 0.0000000\ttotal: 3.12s\tremaining: 2.33s\n",
      "5723:\tlearn: 0.0000000\ttotal: 3.12s\tremaining: 2.33s\n",
      "5724:\tlearn: 0.0000000\ttotal: 3.12s\tremaining: 2.33s\n",
      "5725:\tlearn: 0.0000000\ttotal: 3.12s\tremaining: 2.33s\n",
      "5726:\tlearn: 0.0000000\ttotal: 3.12s\tremaining: 2.33s\n",
      "5727:\tlearn: 0.0000000\ttotal: 3.12s\tremaining: 2.33s\n",
      "5728:\tlearn: 0.0000000\ttotal: 3.12s\tremaining: 2.33s\n",
      "5729:\tlearn: 0.0000000\ttotal: 3.12s\tremaining: 2.33s\n",
      "5730:\tlearn: 0.0000000\ttotal: 3.12s\tremaining: 2.32s\n",
      "5731:\tlearn: 0.0000000\ttotal: 3.12s\tremaining: 2.32s\n",
      "5732:\tlearn: 0.0000000\ttotal: 3.12s\tremaining: 2.32s\n",
      "5733:\tlearn: 0.0000000\ttotal: 3.12s\tremaining: 2.32s\n",
      "5734:\tlearn: 0.0000000\ttotal: 3.12s\tremaining: 2.32s\n",
      "5735:\tlearn: 0.0000000\ttotal: 3.12s\tremaining: 2.32s\n",
      "5736:\tlearn: 0.0000000\ttotal: 3.12s\tremaining: 2.32s\n",
      "5737:\tlearn: 0.0000000\ttotal: 3.12s\tremaining: 2.32s\n",
      "5738:\tlearn: 0.0000000\ttotal: 3.12s\tremaining: 2.32s\n",
      "5739:\tlearn: 0.0000000\ttotal: 3.12s\tremaining: 2.32s\n",
      "5740:\tlearn: 0.0000000\ttotal: 3.13s\tremaining: 2.32s\n",
      "5741:\tlearn: 0.0000000\ttotal: 3.13s\tremaining: 2.32s\n",
      "5742:\tlearn: 0.0000000\ttotal: 3.13s\tremaining: 2.32s\n",
      "5743:\tlearn: 0.0000000\ttotal: 3.13s\tremaining: 2.32s\n",
      "5744:\tlearn: 0.0000000\ttotal: 3.13s\tremaining: 2.32s\n",
      "5745:\tlearn: 0.0000000\ttotal: 3.13s\tremaining: 2.32s\n",
      "5746:\tlearn: 0.0000000\ttotal: 3.13s\tremaining: 2.31s\n",
      "5747:\tlearn: 0.0000000\ttotal: 3.13s\tremaining: 2.31s\n",
      "5748:\tlearn: 0.0000000\ttotal: 3.13s\tremaining: 2.31s\n",
      "5749:\tlearn: 0.0000000\ttotal: 3.13s\tremaining: 2.31s\n",
      "5750:\tlearn: 0.0000000\ttotal: 3.13s\tremaining: 2.31s\n",
      "5751:\tlearn: 0.0000000\ttotal: 3.13s\tremaining: 2.31s\n",
      "5752:\tlearn: 0.0000000\ttotal: 3.13s\tremaining: 2.31s\n",
      "5753:\tlearn: 0.0000000\ttotal: 3.13s\tremaining: 2.31s\n",
      "5754:\tlearn: 0.0000000\ttotal: 3.13s\tremaining: 2.31s\n",
      "5755:\tlearn: 0.0000000\ttotal: 3.13s\tremaining: 2.31s\n",
      "5756:\tlearn: 0.0000000\ttotal: 3.13s\tremaining: 2.31s\n",
      "5757:\tlearn: 0.0000000\ttotal: 3.13s\tremaining: 2.31s\n",
      "5758:\tlearn: 0.0000000\ttotal: 3.13s\tremaining: 2.31s\n",
      "5759:\tlearn: 0.0000000\ttotal: 3.13s\tremaining: 2.31s\n",
      "5760:\tlearn: 0.0000000\ttotal: 3.13s\tremaining: 2.31s\n",
      "5761:\tlearn: 0.0000000\ttotal: 3.14s\tremaining: 2.31s\n",
      "5762:\tlearn: 0.0000000\ttotal: 3.14s\tremaining: 2.31s\n",
      "5763:\tlearn: 0.0000000\ttotal: 3.14s\tremaining: 2.31s\n",
      "5764:\tlearn: 0.0000000\ttotal: 3.14s\tremaining: 2.3s\n",
      "5765:\tlearn: 0.0000000\ttotal: 3.14s\tremaining: 2.3s\n",
      "5766:\tlearn: 0.0000000\ttotal: 3.14s\tremaining: 2.3s\n",
      "5767:\tlearn: 0.0000000\ttotal: 3.14s\tremaining: 2.3s\n",
      "5768:\tlearn: 0.0000000\ttotal: 3.14s\tremaining: 2.3s\n",
      "5769:\tlearn: 0.0000000\ttotal: 3.14s\tremaining: 2.3s\n",
      "5770:\tlearn: 0.0000000\ttotal: 3.14s\tremaining: 2.3s\n",
      "5771:\tlearn: 0.0000000\ttotal: 3.14s\tremaining: 2.3s\n",
      "5772:\tlearn: 0.0000000\ttotal: 3.14s\tremaining: 2.3s\n",
      "5773:\tlearn: 0.0000000\ttotal: 3.14s\tremaining: 2.3s\n",
      "5774:\tlearn: 0.0000000\ttotal: 3.14s\tremaining: 2.3s\n",
      "5775:\tlearn: 0.0000000\ttotal: 3.14s\tremaining: 2.3s\n",
      "5776:\tlearn: 0.0000000\ttotal: 3.14s\tremaining: 2.3s\n",
      "5777:\tlearn: 0.0000000\ttotal: 3.14s\tremaining: 2.3s\n",
      "5778:\tlearn: 0.0000000\ttotal: 3.15s\tremaining: 2.3s\n",
      "5779:\tlearn: 0.0000000\ttotal: 3.15s\tremaining: 2.3s\n",
      "5780:\tlearn: 0.0000000\ttotal: 3.15s\tremaining: 2.3s\n",
      "5781:\tlearn: 0.0000000\ttotal: 3.15s\tremaining: 2.29s\n",
      "5782:\tlearn: 0.0000000\ttotal: 3.15s\tremaining: 2.29s\n",
      "5783:\tlearn: 0.0000000\ttotal: 3.15s\tremaining: 2.29s\n",
      "5784:\tlearn: 0.0000000\ttotal: 3.15s\tremaining: 2.29s\n",
      "5785:\tlearn: 0.0000000\ttotal: 3.15s\tremaining: 2.29s\n",
      "5786:\tlearn: 0.0000000\ttotal: 3.15s\tremaining: 2.29s\n",
      "5787:\tlearn: 0.0000000\ttotal: 3.15s\tremaining: 2.29s\n",
      "5788:\tlearn: 0.0000000\ttotal: 3.15s\tremaining: 2.29s\n",
      "5789:\tlearn: 0.0000000\ttotal: 3.15s\tremaining: 2.29s\n",
      "5790:\tlearn: 0.0000000\ttotal: 3.15s\tremaining: 2.29s\n",
      "5791:\tlearn: 0.0000000\ttotal: 3.15s\tremaining: 2.29s\n",
      "5792:\tlearn: 0.0000000\ttotal: 3.15s\tremaining: 2.29s\n",
      "5793:\tlearn: 0.0000000\ttotal: 3.15s\tremaining: 2.29s\n",
      "5794:\tlearn: 0.0000000\ttotal: 3.15s\tremaining: 2.29s\n",
      "5795:\tlearn: 0.0000000\ttotal: 3.15s\tremaining: 2.29s\n",
      "5796:\tlearn: 0.0000000\ttotal: 3.15s\tremaining: 2.29s\n",
      "5797:\tlearn: 0.0000000\ttotal: 3.15s\tremaining: 2.29s\n",
      "5798:\tlearn: 0.0000000\ttotal: 3.15s\tremaining: 2.29s\n",
      "5799:\tlearn: 0.0000000\ttotal: 3.15s\tremaining: 2.29s\n",
      "5800:\tlearn: 0.0000000\ttotal: 3.16s\tremaining: 2.28s\n",
      "5801:\tlearn: 0.0000000\ttotal: 3.16s\tremaining: 2.28s\n",
      "5802:\tlearn: 0.0000000\ttotal: 3.16s\tremaining: 2.28s\n",
      "5803:\tlearn: 0.0000000\ttotal: 3.16s\tremaining: 2.28s\n",
      "5804:\tlearn: 0.0000000\ttotal: 3.16s\tremaining: 2.28s\n",
      "5805:\tlearn: 0.0000000\ttotal: 3.16s\tremaining: 2.28s\n",
      "5806:\tlearn: 0.0000000\ttotal: 3.16s\tremaining: 2.28s\n",
      "5807:\tlearn: 0.0000000\ttotal: 3.16s\tremaining: 2.28s\n",
      "5808:\tlearn: 0.0000000\ttotal: 3.16s\tremaining: 2.28s\n",
      "5809:\tlearn: 0.0000000\ttotal: 3.16s\tremaining: 2.28s\n",
      "5810:\tlearn: 0.0000000\ttotal: 3.16s\tremaining: 2.28s\n",
      "5811:\tlearn: 0.0000000\ttotal: 3.16s\tremaining: 2.28s\n",
      "5812:\tlearn: 0.0000000\ttotal: 3.16s\tremaining: 2.28s\n",
      "5813:\tlearn: 0.0000000\ttotal: 3.16s\tremaining: 2.28s\n",
      "5814:\tlearn: 0.0000000\ttotal: 3.16s\tremaining: 2.28s\n",
      "5815:\tlearn: 0.0000000\ttotal: 3.16s\tremaining: 2.28s\n",
      "5816:\tlearn: 0.0000000\ttotal: 3.16s\tremaining: 2.27s\n",
      "5817:\tlearn: 0.0000000\ttotal: 3.16s\tremaining: 2.27s\n",
      "5818:\tlearn: 0.0000000\ttotal: 3.17s\tremaining: 2.27s\n",
      "5819:\tlearn: 0.0000000\ttotal: 3.17s\tremaining: 2.27s\n",
      "5820:\tlearn: 0.0000000\ttotal: 3.17s\tremaining: 2.27s\n",
      "5821:\tlearn: 0.0000000\ttotal: 3.17s\tremaining: 2.27s\n",
      "5822:\tlearn: 0.0000000\ttotal: 3.17s\tremaining: 2.27s\n",
      "5823:\tlearn: 0.0000000\ttotal: 3.17s\tremaining: 2.27s\n",
      "5824:\tlearn: 0.0000000\ttotal: 3.17s\tremaining: 2.27s\n",
      "5825:\tlearn: 0.0000000\ttotal: 3.17s\tremaining: 2.27s\n",
      "5826:\tlearn: 0.0000000\ttotal: 3.17s\tremaining: 2.27s\n",
      "5827:\tlearn: 0.0000000\ttotal: 3.17s\tremaining: 2.27s\n",
      "5828:\tlearn: 0.0000000\ttotal: 3.17s\tremaining: 2.27s\n",
      "5829:\tlearn: 0.0000000\ttotal: 3.17s\tremaining: 2.27s\n",
      "5830:\tlearn: 0.0000000\ttotal: 3.17s\tremaining: 2.27s\n",
      "5831:\tlearn: 0.0000000\ttotal: 3.17s\tremaining: 2.27s\n",
      "5832:\tlearn: 0.0000000\ttotal: 3.17s\tremaining: 2.27s\n",
      "5833:\tlearn: 0.0000000\ttotal: 3.17s\tremaining: 2.27s\n",
      "5834:\tlearn: 0.0000000\ttotal: 3.17s\tremaining: 2.26s\n",
      "5835:\tlearn: 0.0000000\ttotal: 3.17s\tremaining: 2.26s\n",
      "5836:\tlearn: 0.0000000\ttotal: 3.17s\tremaining: 2.26s\n",
      "5837:\tlearn: 0.0000000\ttotal: 3.17s\tremaining: 2.26s\n",
      "5838:\tlearn: 0.0000000\ttotal: 3.17s\tremaining: 2.26s\n",
      "5839:\tlearn: 0.0000000\ttotal: 3.18s\tremaining: 2.26s\n",
      "5840:\tlearn: 0.0000000\ttotal: 3.18s\tremaining: 2.26s\n",
      "5841:\tlearn: 0.0000000\ttotal: 3.18s\tremaining: 2.26s\n",
      "5842:\tlearn: 0.0000000\ttotal: 3.18s\tremaining: 2.26s\n",
      "5843:\tlearn: 0.0000000\ttotal: 3.18s\tremaining: 2.26s\n",
      "5844:\tlearn: 0.0000000\ttotal: 3.18s\tremaining: 2.26s\n",
      "5845:\tlearn: 0.0000000\ttotal: 3.18s\tremaining: 2.26s\n",
      "5846:\tlearn: 0.0000000\ttotal: 3.18s\tremaining: 2.26s\n",
      "5847:\tlearn: 0.0000000\ttotal: 3.18s\tremaining: 2.26s\n",
      "5848:\tlearn: 0.0000000\ttotal: 3.18s\tremaining: 2.26s\n",
      "5849:\tlearn: 0.0000000\ttotal: 3.18s\tremaining: 2.26s\n",
      "5850:\tlearn: 0.0000000\ttotal: 3.18s\tremaining: 2.26s\n",
      "5851:\tlearn: 0.0000000\ttotal: 3.18s\tremaining: 2.25s\n",
      "5852:\tlearn: 0.0000000\ttotal: 3.18s\tremaining: 2.25s\n",
      "5853:\tlearn: 0.0000000\ttotal: 3.18s\tremaining: 2.25s\n",
      "5854:\tlearn: 0.0000000\ttotal: 3.18s\tremaining: 2.25s\n",
      "5855:\tlearn: 0.0000000\ttotal: 3.19s\tremaining: 2.25s\n",
      "5856:\tlearn: 0.0000000\ttotal: 3.19s\tremaining: 2.25s\n",
      "5857:\tlearn: 0.0000000\ttotal: 3.19s\tremaining: 2.25s\n",
      "5858:\tlearn: 0.0000000\ttotal: 3.19s\tremaining: 2.25s\n",
      "5859:\tlearn: 0.0000000\ttotal: 3.19s\tremaining: 2.25s\n",
      "5860:\tlearn: 0.0000000\ttotal: 3.19s\tremaining: 2.25s\n",
      "5861:\tlearn: 0.0000000\ttotal: 3.19s\tremaining: 2.25s\n",
      "5862:\tlearn: 0.0000000\ttotal: 3.19s\tremaining: 2.25s\n",
      "5863:\tlearn: 0.0000000\ttotal: 3.19s\tremaining: 2.25s\n",
      "5864:\tlearn: 0.0000000\ttotal: 3.19s\tremaining: 2.25s\n",
      "5865:\tlearn: 0.0000000\ttotal: 3.19s\tremaining: 2.25s\n",
      "5866:\tlearn: 0.0000000\ttotal: 3.19s\tremaining: 2.25s\n",
      "5867:\tlearn: 0.0000000\ttotal: 3.19s\tremaining: 2.25s\n",
      "5868:\tlearn: 0.0000000\ttotal: 3.19s\tremaining: 2.25s\n",
      "5869:\tlearn: 0.0000000\ttotal: 3.19s\tremaining: 2.25s\n",
      "5870:\tlearn: 0.0000000\ttotal: 3.19s\tremaining: 2.24s\n",
      "5871:\tlearn: 0.0000000\ttotal: 3.19s\tremaining: 2.24s\n",
      "5872:\tlearn: 0.0000000\ttotal: 3.19s\tremaining: 2.24s\n",
      "5873:\tlearn: 0.0000000\ttotal: 3.19s\tremaining: 2.24s\n",
      "5874:\tlearn: 0.0000000\ttotal: 3.19s\tremaining: 2.24s\n",
      "5875:\tlearn: 0.0000000\ttotal: 3.19s\tremaining: 2.24s\n",
      "5876:\tlearn: 0.0000000\ttotal: 3.19s\tremaining: 2.24s\n",
      "5877:\tlearn: 0.0000000\ttotal: 3.19s\tremaining: 2.24s\n",
      "5878:\tlearn: 0.0000000\ttotal: 3.19s\tremaining: 2.24s\n",
      "5879:\tlearn: 0.0000000\ttotal: 3.2s\tremaining: 2.24s\n",
      "5880:\tlearn: 0.0000000\ttotal: 3.2s\tremaining: 2.24s\n",
      "5881:\tlearn: 0.0000000\ttotal: 3.2s\tremaining: 2.24s\n",
      "5882:\tlearn: 0.0000000\ttotal: 3.2s\tremaining: 2.24s\n",
      "5883:\tlearn: 0.0000000\ttotal: 3.2s\tremaining: 2.24s\n",
      "5884:\tlearn: 0.0000000\ttotal: 3.2s\tremaining: 2.24s\n",
      "5885:\tlearn: 0.0000000\ttotal: 3.2s\tremaining: 2.24s\n",
      "5886:\tlearn: 0.0000000\ttotal: 3.2s\tremaining: 2.24s\n",
      "5887:\tlearn: 0.0000000\ttotal: 3.2s\tremaining: 2.23s\n",
      "5888:\tlearn: 0.0000000\ttotal: 3.2s\tremaining: 2.23s\n",
      "5889:\tlearn: 0.0000000\ttotal: 3.2s\tremaining: 2.23s\n",
      "5890:\tlearn: 0.0000000\ttotal: 3.2s\tremaining: 2.23s\n",
      "5891:\tlearn: 0.0000000\ttotal: 3.2s\tremaining: 2.23s\n",
      "5892:\tlearn: 0.0000000\ttotal: 3.2s\tremaining: 2.23s\n",
      "5893:\tlearn: 0.0000000\ttotal: 3.2s\tremaining: 2.23s\n",
      "5894:\tlearn: 0.0000000\ttotal: 3.2s\tremaining: 2.23s\n",
      "5895:\tlearn: 0.0000000\ttotal: 3.21s\tremaining: 2.23s\n",
      "5896:\tlearn: 0.0000000\ttotal: 3.21s\tremaining: 2.23s\n",
      "5897:\tlearn: 0.0000000\ttotal: 3.21s\tremaining: 2.23s\n",
      "5898:\tlearn: 0.0000000\ttotal: 3.21s\tremaining: 2.23s\n",
      "5899:\tlearn: 0.0000000\ttotal: 3.21s\tremaining: 2.23s\n",
      "5900:\tlearn: 0.0000000\ttotal: 3.21s\tremaining: 2.23s\n",
      "5901:\tlearn: 0.0000000\ttotal: 3.21s\tremaining: 2.23s\n",
      "5902:\tlearn: 0.0000000\ttotal: 3.21s\tremaining: 2.23s\n",
      "5903:\tlearn: 0.0000000\ttotal: 3.21s\tremaining: 2.23s\n",
      "5904:\tlearn: 0.0000000\ttotal: 3.21s\tremaining: 2.23s\n",
      "5905:\tlearn: 0.0000000\ttotal: 3.21s\tremaining: 2.22s\n",
      "5906:\tlearn: 0.0000000\ttotal: 3.21s\tremaining: 2.22s\n",
      "5907:\tlearn: 0.0000000\ttotal: 3.21s\tremaining: 2.22s\n",
      "5908:\tlearn: 0.0000000\ttotal: 3.21s\tremaining: 2.22s\n",
      "5909:\tlearn: 0.0000000\ttotal: 3.21s\tremaining: 2.22s\n",
      "5910:\tlearn: 0.0000000\ttotal: 3.21s\tremaining: 2.22s\n",
      "5911:\tlearn: 0.0000000\ttotal: 3.21s\tremaining: 2.22s\n",
      "5912:\tlearn: 0.0000000\ttotal: 3.21s\tremaining: 2.22s\n",
      "5913:\tlearn: 0.0000000\ttotal: 3.21s\tremaining: 2.22s\n",
      "5914:\tlearn: 0.0000000\ttotal: 3.21s\tremaining: 2.22s\n",
      "5915:\tlearn: 0.0000000\ttotal: 3.21s\tremaining: 2.22s\n",
      "5916:\tlearn: 0.0000000\ttotal: 3.22s\tremaining: 2.22s\n",
      "5917:\tlearn: 0.0000000\ttotal: 3.22s\tremaining: 2.22s\n",
      "5918:\tlearn: 0.0000000\ttotal: 3.22s\tremaining: 2.22s\n",
      "5919:\tlearn: 0.0000000\ttotal: 3.22s\tremaining: 2.22s\n",
      "5920:\tlearn: 0.0000000\ttotal: 3.22s\tremaining: 2.22s\n",
      "5921:\tlearn: 0.0000000\ttotal: 3.22s\tremaining: 2.22s\n",
      "5922:\tlearn: 0.0000000\ttotal: 3.22s\tremaining: 2.21s\n",
      "5923:\tlearn: 0.0000000\ttotal: 3.22s\tremaining: 2.21s\n",
      "5924:\tlearn: 0.0000000\ttotal: 3.22s\tremaining: 2.21s\n",
      "5925:\tlearn: 0.0000000\ttotal: 3.22s\tremaining: 2.21s\n",
      "5926:\tlearn: 0.0000000\ttotal: 3.22s\tremaining: 2.21s\n",
      "5927:\tlearn: 0.0000000\ttotal: 3.22s\tremaining: 2.21s\n",
      "5928:\tlearn: 0.0000000\ttotal: 3.22s\tremaining: 2.21s\n",
      "5929:\tlearn: 0.0000000\ttotal: 3.22s\tremaining: 2.21s\n",
      "5930:\tlearn: 0.0000000\ttotal: 3.22s\tremaining: 2.21s\n",
      "5931:\tlearn: 0.0000000\ttotal: 3.22s\tremaining: 2.21s\n",
      "5932:\tlearn: 0.0000000\ttotal: 3.22s\tremaining: 2.21s\n",
      "5933:\tlearn: 0.0000000\ttotal: 3.22s\tremaining: 2.21s\n",
      "5934:\tlearn: 0.0000000\ttotal: 3.22s\tremaining: 2.21s\n",
      "5935:\tlearn: 0.0000000\ttotal: 3.23s\tremaining: 2.21s\n",
      "5936:\tlearn: 0.0000000\ttotal: 3.23s\tremaining: 2.21s\n",
      "5937:\tlearn: 0.0000000\ttotal: 3.23s\tremaining: 2.21s\n",
      "5938:\tlearn: 0.0000000\ttotal: 3.23s\tremaining: 2.21s\n",
      "5939:\tlearn: 0.0000000\ttotal: 3.23s\tremaining: 2.21s\n",
      "5940:\tlearn: 0.0000000\ttotal: 3.23s\tremaining: 2.21s\n",
      "5941:\tlearn: 0.0000000\ttotal: 3.23s\tremaining: 2.21s\n",
      "5942:\tlearn: 0.0000000\ttotal: 3.23s\tremaining: 2.2s\n",
      "5943:\tlearn: 0.0000000\ttotal: 3.23s\tremaining: 2.2s\n",
      "5944:\tlearn: 0.0000000\ttotal: 3.23s\tremaining: 2.2s\n",
      "5945:\tlearn: 0.0000000\ttotal: 3.23s\tremaining: 2.2s\n",
      "5946:\tlearn: 0.0000000\ttotal: 3.23s\tremaining: 2.2s\n",
      "5947:\tlearn: 0.0000000\ttotal: 3.23s\tremaining: 2.2s\n",
      "5948:\tlearn: 0.0000000\ttotal: 3.23s\tremaining: 2.2s\n",
      "5949:\tlearn: 0.0000000\ttotal: 3.23s\tremaining: 2.2s\n",
      "5950:\tlearn: 0.0000000\ttotal: 3.23s\tremaining: 2.2s\n",
      "5951:\tlearn: 0.0000000\ttotal: 3.23s\tremaining: 2.2s\n",
      "5952:\tlearn: 0.0000000\ttotal: 3.23s\tremaining: 2.2s\n",
      "5953:\tlearn: 0.0000000\ttotal: 3.23s\tremaining: 2.2s\n",
      "5954:\tlearn: 0.0000000\ttotal: 3.23s\tremaining: 2.2s\n",
      "5955:\tlearn: 0.0000000\ttotal: 3.23s\tremaining: 2.2s\n",
      "5956:\tlearn: 0.0000000\ttotal: 3.24s\tremaining: 2.2s\n",
      "5957:\tlearn: 0.0000000\ttotal: 3.24s\tremaining: 2.19s\n",
      "5958:\tlearn: 0.0000000\ttotal: 3.24s\tremaining: 2.19s\n",
      "5959:\tlearn: 0.0000000\ttotal: 3.24s\tremaining: 2.19s\n",
      "5960:\tlearn: 0.0000000\ttotal: 3.24s\tremaining: 2.19s\n",
      "5961:\tlearn: 0.0000000\ttotal: 3.24s\tremaining: 2.19s\n",
      "5962:\tlearn: 0.0000000\ttotal: 3.24s\tremaining: 2.19s\n",
      "5963:\tlearn: 0.0000000\ttotal: 3.24s\tremaining: 2.19s\n",
      "5964:\tlearn: 0.0000000\ttotal: 3.24s\tremaining: 2.19s\n",
      "5965:\tlearn: 0.0000000\ttotal: 3.24s\tremaining: 2.19s\n",
      "5966:\tlearn: 0.0000000\ttotal: 3.24s\tremaining: 2.19s\n",
      "5967:\tlearn: 0.0000000\ttotal: 3.24s\tremaining: 2.19s\n",
      "5968:\tlearn: 0.0000000\ttotal: 3.24s\tremaining: 2.19s\n",
      "5969:\tlearn: 0.0000000\ttotal: 3.24s\tremaining: 2.19s\n",
      "5970:\tlearn: 0.0000000\ttotal: 3.24s\tremaining: 2.19s\n",
      "5971:\tlearn: 0.0000000\ttotal: 3.24s\tremaining: 2.19s\n",
      "5972:\tlearn: 0.0000000\ttotal: 3.24s\tremaining: 2.19s\n",
      "5973:\tlearn: 0.0000000\ttotal: 3.24s\tremaining: 2.19s\n",
      "5974:\tlearn: 0.0000000\ttotal: 3.25s\tremaining: 2.19s\n",
      "5975:\tlearn: 0.0000000\ttotal: 3.25s\tremaining: 2.19s\n",
      "5976:\tlearn: 0.0000000\ttotal: 3.25s\tremaining: 2.18s\n",
      "5977:\tlearn: 0.0000000\ttotal: 3.25s\tremaining: 2.18s\n",
      "5978:\tlearn: 0.0000000\ttotal: 3.25s\tremaining: 2.18s\n",
      "5979:\tlearn: 0.0000000\ttotal: 3.25s\tremaining: 2.18s\n",
      "5980:\tlearn: 0.0000000\ttotal: 3.25s\tremaining: 2.18s\n",
      "5981:\tlearn: 0.0000000\ttotal: 3.25s\tremaining: 2.18s\n",
      "5982:\tlearn: 0.0000000\ttotal: 3.25s\tremaining: 2.18s\n",
      "5983:\tlearn: 0.0000000\ttotal: 3.25s\tremaining: 2.18s\n",
      "5984:\tlearn: 0.0000000\ttotal: 3.25s\tremaining: 2.18s\n",
      "5985:\tlearn: 0.0000000\ttotal: 3.25s\tremaining: 2.18s\n",
      "5986:\tlearn: 0.0000000\ttotal: 3.25s\tremaining: 2.18s\n",
      "5987:\tlearn: 0.0000000\ttotal: 3.25s\tremaining: 2.18s\n",
      "5988:\tlearn: 0.0000000\ttotal: 3.25s\tremaining: 2.18s\n",
      "5989:\tlearn: 0.0000000\ttotal: 3.25s\tremaining: 2.18s\n",
      "5990:\tlearn: 0.0000000\ttotal: 3.25s\tremaining: 2.18s\n",
      "5991:\tlearn: 0.0000000\ttotal: 3.25s\tremaining: 2.17s\n",
      "5992:\tlearn: 0.0000000\ttotal: 3.25s\tremaining: 2.17s\n",
      "5993:\tlearn: 0.0000000\ttotal: 3.25s\tremaining: 2.17s\n",
      "5994:\tlearn: 0.0000000\ttotal: 3.25s\tremaining: 2.17s\n",
      "5995:\tlearn: 0.0000000\ttotal: 3.25s\tremaining: 2.17s\n",
      "5996:\tlearn: 0.0000000\ttotal: 3.25s\tremaining: 2.17s\n",
      "5997:\tlearn: 0.0000000\ttotal: 3.26s\tremaining: 2.17s\n",
      "5998:\tlearn: 0.0000000\ttotal: 3.26s\tremaining: 2.17s\n",
      "5999:\tlearn: 0.0000000\ttotal: 3.26s\tremaining: 2.17s\n",
      "6000:\tlearn: 0.0000000\ttotal: 3.26s\tremaining: 2.17s\n",
      "6001:\tlearn: 0.0000000\ttotal: 3.26s\tremaining: 2.17s\n",
      "6002:\tlearn: 0.0000000\ttotal: 3.26s\tremaining: 2.17s\n",
      "6003:\tlearn: 0.0000000\ttotal: 3.26s\tremaining: 2.17s\n",
      "6004:\tlearn: 0.0000000\ttotal: 3.26s\tremaining: 2.17s\n",
      "6005:\tlearn: 0.0000000\ttotal: 3.26s\tremaining: 2.17s\n",
      "6006:\tlearn: 0.0000000\ttotal: 3.26s\tremaining: 2.17s\n",
      "6007:\tlearn: 0.0000000\ttotal: 3.26s\tremaining: 2.17s\n",
      "6008:\tlearn: 0.0000000\ttotal: 3.26s\tremaining: 2.17s\n",
      "6009:\tlearn: 0.0000000\ttotal: 3.26s\tremaining: 2.17s\n",
      "6010:\tlearn: 0.0000000\ttotal: 3.26s\tremaining: 2.17s\n",
      "6011:\tlearn: 0.0000000\ttotal: 3.26s\tremaining: 2.16s\n",
      "6012:\tlearn: 0.0000000\ttotal: 3.26s\tremaining: 2.16s\n",
      "6013:\tlearn: 0.0000000\ttotal: 3.26s\tremaining: 2.16s\n",
      "6014:\tlearn: 0.0000000\ttotal: 3.26s\tremaining: 2.16s\n",
      "6015:\tlearn: 0.0000000\ttotal: 3.27s\tremaining: 2.16s\n",
      "6016:\tlearn: 0.0000000\ttotal: 3.27s\tremaining: 2.16s\n",
      "6017:\tlearn: 0.0000000\ttotal: 3.27s\tremaining: 2.16s\n",
      "6018:\tlearn: 0.0000000\ttotal: 3.27s\tremaining: 2.16s\n",
      "6019:\tlearn: 0.0000000\ttotal: 3.27s\tremaining: 2.16s\n",
      "6020:\tlearn: 0.0000000\ttotal: 3.27s\tremaining: 2.16s\n",
      "6021:\tlearn: 0.0000000\ttotal: 3.27s\tremaining: 2.16s\n",
      "6022:\tlearn: 0.0000000\ttotal: 3.27s\tremaining: 2.16s\n",
      "6023:\tlearn: 0.0000000\ttotal: 3.27s\tremaining: 2.16s\n",
      "6024:\tlearn: 0.0000000\ttotal: 3.27s\tremaining: 2.16s\n",
      "6025:\tlearn: 0.0000000\ttotal: 3.27s\tremaining: 2.16s\n",
      "6026:\tlearn: 0.0000000\ttotal: 3.27s\tremaining: 2.16s\n",
      "6027:\tlearn: 0.0000000\ttotal: 3.27s\tremaining: 2.15s\n",
      "6028:\tlearn: 0.0000000\ttotal: 3.27s\tremaining: 2.15s\n",
      "6029:\tlearn: 0.0000000\ttotal: 3.27s\tremaining: 2.15s\n",
      "6030:\tlearn: 0.0000000\ttotal: 3.27s\tremaining: 2.15s\n",
      "6031:\tlearn: 0.0000000\ttotal: 3.27s\tremaining: 2.15s\n",
      "6032:\tlearn: 0.0000000\ttotal: 3.27s\tremaining: 2.15s\n",
      "6033:\tlearn: 0.0000000\ttotal: 3.27s\tremaining: 2.15s\n",
      "6034:\tlearn: 0.0000000\ttotal: 3.27s\tremaining: 2.15s\n",
      "6035:\tlearn: 0.0000000\ttotal: 3.27s\tremaining: 2.15s\n",
      "6036:\tlearn: 0.0000000\ttotal: 3.27s\tremaining: 2.15s\n",
      "6037:\tlearn: 0.0000000\ttotal: 3.28s\tremaining: 2.15s\n",
      "6038:\tlearn: 0.0000000\ttotal: 3.28s\tremaining: 2.15s\n",
      "6039:\tlearn: 0.0000000\ttotal: 3.28s\tremaining: 2.15s\n",
      "6040:\tlearn: 0.0000000\ttotal: 3.28s\tremaining: 2.15s\n",
      "6041:\tlearn: 0.0000000\ttotal: 3.28s\tremaining: 2.15s\n",
      "6042:\tlearn: 0.0000000\ttotal: 3.28s\tremaining: 2.15s\n",
      "6043:\tlearn: 0.0000000\ttotal: 3.28s\tremaining: 2.15s\n",
      "6044:\tlearn: 0.0000000\ttotal: 3.28s\tremaining: 2.15s\n",
      "6045:\tlearn: 0.0000000\ttotal: 3.28s\tremaining: 2.15s\n",
      "6046:\tlearn: 0.0000000\ttotal: 3.28s\tremaining: 2.14s\n",
      "6047:\tlearn: 0.0000000\ttotal: 3.28s\tremaining: 2.14s\n",
      "6048:\tlearn: 0.0000000\ttotal: 3.28s\tremaining: 2.14s\n",
      "6049:\tlearn: 0.0000000\ttotal: 3.28s\tremaining: 2.14s\n",
      "6050:\tlearn: 0.0000000\ttotal: 3.28s\tremaining: 2.14s\n",
      "6051:\tlearn: 0.0000000\ttotal: 3.28s\tremaining: 2.14s\n",
      "6052:\tlearn: 0.0000000\ttotal: 3.28s\tremaining: 2.14s\n",
      "6053:\tlearn: 0.0000000\ttotal: 3.28s\tremaining: 2.14s\n",
      "6054:\tlearn: 0.0000000\ttotal: 3.28s\tremaining: 2.14s\n",
      "6055:\tlearn: 0.0000000\ttotal: 3.28s\tremaining: 2.14s\n",
      "6056:\tlearn: 0.0000000\ttotal: 3.29s\tremaining: 2.14s\n",
      "6057:\tlearn: 0.0000000\ttotal: 3.29s\tremaining: 2.14s\n",
      "6058:\tlearn: 0.0000000\ttotal: 3.29s\tremaining: 2.14s\n",
      "6059:\tlearn: 0.0000000\ttotal: 3.29s\tremaining: 2.14s\n",
      "6060:\tlearn: 0.0000000\ttotal: 3.29s\tremaining: 2.14s\n",
      "6061:\tlearn: 0.0000000\ttotal: 3.29s\tremaining: 2.13s\n",
      "6062:\tlearn: 0.0000000\ttotal: 3.29s\tremaining: 2.13s\n",
      "6063:\tlearn: 0.0000000\ttotal: 3.29s\tremaining: 2.13s\n",
      "6064:\tlearn: 0.0000000\ttotal: 3.29s\tremaining: 2.13s\n",
      "6065:\tlearn: 0.0000000\ttotal: 3.29s\tremaining: 2.13s\n",
      "6066:\tlearn: 0.0000000\ttotal: 3.29s\tremaining: 2.13s\n",
      "6067:\tlearn: 0.0000000\ttotal: 3.29s\tremaining: 2.13s\n",
      "6068:\tlearn: 0.0000000\ttotal: 3.29s\tremaining: 2.13s\n",
      "6069:\tlearn: 0.0000000\ttotal: 3.29s\tremaining: 2.13s\n",
      "6070:\tlearn: 0.0000000\ttotal: 3.29s\tremaining: 2.13s\n",
      "6071:\tlearn: 0.0000000\ttotal: 3.29s\tremaining: 2.13s\n",
      "6072:\tlearn: 0.0000000\ttotal: 3.29s\tremaining: 2.13s\n",
      "6073:\tlearn: 0.0000000\ttotal: 3.29s\tremaining: 2.13s\n",
      "6074:\tlearn: 0.0000000\ttotal: 3.29s\tremaining: 2.13s\n",
      "6075:\tlearn: 0.0000000\ttotal: 3.29s\tremaining: 2.13s\n",
      "6076:\tlearn: 0.0000000\ttotal: 3.29s\tremaining: 2.13s\n",
      "6077:\tlearn: 0.0000000\ttotal: 3.29s\tremaining: 2.13s\n",
      "6078:\tlearn: 0.0000000\ttotal: 3.29s\tremaining: 2.13s\n",
      "6079:\tlearn: 0.0000000\ttotal: 3.3s\tremaining: 2.13s\n",
      "6080:\tlearn: 0.0000000\ttotal: 3.3s\tremaining: 2.12s\n",
      "6081:\tlearn: 0.0000000\ttotal: 3.3s\tremaining: 2.12s\n",
      "6082:\tlearn: 0.0000000\ttotal: 3.3s\tremaining: 2.12s\n",
      "6083:\tlearn: 0.0000000\ttotal: 3.3s\tremaining: 2.12s\n",
      "6084:\tlearn: 0.0000000\ttotal: 3.3s\tremaining: 2.12s\n",
      "6085:\tlearn: 0.0000000\ttotal: 3.3s\tremaining: 2.12s\n",
      "6086:\tlearn: 0.0000000\ttotal: 3.3s\tremaining: 2.12s\n",
      "6087:\tlearn: 0.0000000\ttotal: 3.3s\tremaining: 2.12s\n",
      "6088:\tlearn: 0.0000000\ttotal: 3.3s\tremaining: 2.12s\n",
      "6089:\tlearn: 0.0000000\ttotal: 3.3s\tremaining: 2.12s\n",
      "6090:\tlearn: 0.0000000\ttotal: 3.3s\tremaining: 2.12s\n",
      "6091:\tlearn: 0.0000000\ttotal: 3.3s\tremaining: 2.12s\n",
      "6092:\tlearn: 0.0000000\ttotal: 3.3s\tremaining: 2.12s\n",
      "6093:\tlearn: 0.0000000\ttotal: 3.3s\tremaining: 2.12s\n",
      "6094:\tlearn: 0.0000000\ttotal: 3.3s\tremaining: 2.12s\n",
      "6095:\tlearn: 0.0000000\ttotal: 3.3s\tremaining: 2.12s\n",
      "6096:\tlearn: 0.0000000\ttotal: 3.3s\tremaining: 2.12s\n",
      "6097:\tlearn: 0.0000000\ttotal: 3.31s\tremaining: 2.12s\n",
      "6098:\tlearn: 0.0000000\ttotal: 3.31s\tremaining: 2.11s\n",
      "6099:\tlearn: 0.0000000\ttotal: 3.31s\tremaining: 2.11s\n",
      "6100:\tlearn: 0.0000000\ttotal: 3.31s\tremaining: 2.11s\n",
      "6101:\tlearn: 0.0000000\ttotal: 3.31s\tremaining: 2.11s\n",
      "6102:\tlearn: 0.0000000\ttotal: 3.31s\tremaining: 2.11s\n",
      "6103:\tlearn: 0.0000000\ttotal: 3.31s\tremaining: 2.11s\n",
      "6104:\tlearn: 0.0000000\ttotal: 3.31s\tremaining: 2.11s\n",
      "6105:\tlearn: 0.0000000\ttotal: 3.31s\tremaining: 2.11s\n",
      "6106:\tlearn: 0.0000000\ttotal: 3.31s\tremaining: 2.11s\n",
      "6107:\tlearn: 0.0000000\ttotal: 3.31s\tremaining: 2.11s\n",
      "6108:\tlearn: 0.0000000\ttotal: 3.31s\tremaining: 2.11s\n",
      "6109:\tlearn: 0.0000000\ttotal: 3.31s\tremaining: 2.11s\n",
      "6110:\tlearn: 0.0000000\ttotal: 3.31s\tremaining: 2.11s\n",
      "6111:\tlearn: 0.0000000\ttotal: 3.31s\tremaining: 2.11s\n",
      "6112:\tlearn: 0.0000000\ttotal: 3.31s\tremaining: 2.11s\n",
      "6113:\tlearn: 0.0000000\ttotal: 3.31s\tremaining: 2.11s\n",
      "6114:\tlearn: 0.0000000\ttotal: 3.31s\tremaining: 2.1s\n",
      "6115:\tlearn: 0.0000000\ttotal: 3.31s\tremaining: 2.1s\n",
      "6116:\tlearn: 0.0000000\ttotal: 3.31s\tremaining: 2.1s\n",
      "6117:\tlearn: 0.0000000\ttotal: 3.32s\tremaining: 2.1s\n",
      "6118:\tlearn: 0.0000000\ttotal: 3.32s\tremaining: 2.1s\n",
      "6119:\tlearn: 0.0000000\ttotal: 3.32s\tremaining: 2.1s\n",
      "6120:\tlearn: 0.0000000\ttotal: 3.32s\tremaining: 2.1s\n",
      "6121:\tlearn: 0.0000000\ttotal: 3.32s\tremaining: 2.1s\n",
      "6122:\tlearn: 0.0000000\ttotal: 3.32s\tremaining: 2.1s\n",
      "6123:\tlearn: 0.0000000\ttotal: 3.32s\tremaining: 2.1s\n",
      "6124:\tlearn: 0.0000000\ttotal: 3.32s\tremaining: 2.1s\n",
      "6125:\tlearn: 0.0000000\ttotal: 3.32s\tremaining: 2.1s\n",
      "6126:\tlearn: 0.0000000\ttotal: 3.32s\tremaining: 2.1s\n",
      "6127:\tlearn: 0.0000000\ttotal: 3.32s\tremaining: 2.1s\n",
      "6128:\tlearn: 0.0000000\ttotal: 3.32s\tremaining: 2.1s\n",
      "6129:\tlearn: 0.0000000\ttotal: 3.32s\tremaining: 2.1s\n",
      "6130:\tlearn: 0.0000000\ttotal: 3.32s\tremaining: 2.1s\n",
      "6131:\tlearn: 0.0000000\ttotal: 3.32s\tremaining: 2.1s\n",
      "6132:\tlearn: 0.0000000\ttotal: 3.32s\tremaining: 2.1s\n",
      "6133:\tlearn: 0.0000000\ttotal: 3.32s\tremaining: 2.1s\n",
      "6134:\tlearn: 0.0000000\ttotal: 3.32s\tremaining: 2.09s\n",
      "6135:\tlearn: 0.0000000\ttotal: 3.33s\tremaining: 2.09s\n",
      "6136:\tlearn: 0.0000000\ttotal: 3.33s\tremaining: 2.09s\n",
      "6137:\tlearn: 0.0000000\ttotal: 3.33s\tremaining: 2.09s\n",
      "6138:\tlearn: 0.0000000\ttotal: 3.33s\tremaining: 2.09s\n",
      "6139:\tlearn: 0.0000000\ttotal: 3.33s\tremaining: 2.09s\n",
      "6140:\tlearn: 0.0000000\ttotal: 3.33s\tremaining: 2.09s\n",
      "6141:\tlearn: 0.0000000\ttotal: 3.33s\tremaining: 2.09s\n",
      "6142:\tlearn: 0.0000000\ttotal: 3.33s\tremaining: 2.09s\n",
      "6143:\tlearn: 0.0000000\ttotal: 3.33s\tremaining: 2.09s\n",
      "6144:\tlearn: 0.0000000\ttotal: 3.33s\tremaining: 2.09s\n",
      "6145:\tlearn: 0.0000000\ttotal: 3.33s\tremaining: 2.09s\n",
      "6146:\tlearn: 0.0000000\ttotal: 3.33s\tremaining: 2.09s\n",
      "6147:\tlearn: 0.0000000\ttotal: 3.33s\tremaining: 2.09s\n",
      "6148:\tlearn: 0.0000000\ttotal: 3.33s\tremaining: 2.09s\n",
      "6149:\tlearn: 0.0000000\ttotal: 3.33s\tremaining: 2.09s\n",
      "6150:\tlearn: 0.0000000\ttotal: 3.33s\tremaining: 2.09s\n",
      "6151:\tlearn: 0.0000000\ttotal: 3.33s\tremaining: 2.09s\n",
      "6152:\tlearn: 0.0000000\ttotal: 3.33s\tremaining: 2.08s\n",
      "6153:\tlearn: 0.0000000\ttotal: 3.34s\tremaining: 2.08s\n",
      "6154:\tlearn: 0.0000000\ttotal: 3.34s\tremaining: 2.08s\n",
      "6155:\tlearn: 0.0000000\ttotal: 3.34s\tremaining: 2.08s\n",
      "6156:\tlearn: 0.0000000\ttotal: 3.34s\tremaining: 2.08s\n",
      "6157:\tlearn: 0.0000000\ttotal: 3.34s\tremaining: 2.08s\n",
      "6158:\tlearn: 0.0000000\ttotal: 3.34s\tremaining: 2.08s\n",
      "6159:\tlearn: 0.0000000\ttotal: 3.34s\tremaining: 2.08s\n",
      "6160:\tlearn: 0.0000000\ttotal: 3.34s\tremaining: 2.08s\n",
      "6161:\tlearn: 0.0000000\ttotal: 3.34s\tremaining: 2.08s\n",
      "6162:\tlearn: 0.0000000\ttotal: 3.34s\tremaining: 2.08s\n",
      "6163:\tlearn: 0.0000000\ttotal: 3.34s\tremaining: 2.08s\n",
      "6164:\tlearn: 0.0000000\ttotal: 3.34s\tremaining: 2.08s\n",
      "6165:\tlearn: 0.0000000\ttotal: 3.34s\tremaining: 2.08s\n",
      "6166:\tlearn: 0.0000000\ttotal: 3.34s\tremaining: 2.08s\n",
      "6167:\tlearn: 0.0000000\ttotal: 3.34s\tremaining: 2.08s\n",
      "6168:\tlearn: 0.0000000\ttotal: 3.34s\tremaining: 2.08s\n",
      "6169:\tlearn: 0.0000000\ttotal: 3.34s\tremaining: 2.08s\n",
      "6170:\tlearn: 0.0000000\ttotal: 3.34s\tremaining: 2.08s\n",
      "6171:\tlearn: 0.0000000\ttotal: 3.35s\tremaining: 2.07s\n",
      "6172:\tlearn: 0.0000000\ttotal: 3.35s\tremaining: 2.07s\n",
      "6173:\tlearn: 0.0000000\ttotal: 3.35s\tremaining: 2.07s\n",
      "6174:\tlearn: 0.0000000\ttotal: 3.35s\tremaining: 2.07s\n",
      "6175:\tlearn: 0.0000000\ttotal: 3.35s\tremaining: 2.07s\n",
      "6176:\tlearn: 0.0000000\ttotal: 3.35s\tremaining: 2.07s\n",
      "6177:\tlearn: 0.0000000\ttotal: 3.35s\tremaining: 2.07s\n",
      "6178:\tlearn: 0.0000000\ttotal: 3.35s\tremaining: 2.07s\n",
      "6179:\tlearn: 0.0000000\ttotal: 3.35s\tremaining: 2.07s\n",
      "6180:\tlearn: 0.0000000\ttotal: 3.35s\tremaining: 2.07s\n",
      "6181:\tlearn: 0.0000000\ttotal: 3.35s\tremaining: 2.07s\n",
      "6182:\tlearn: 0.0000000\ttotal: 3.35s\tremaining: 2.07s\n",
      "6183:\tlearn: 0.0000000\ttotal: 3.36s\tremaining: 2.07s\n",
      "6184:\tlearn: 0.0000000\ttotal: 3.36s\tremaining: 2.07s\n",
      "6185:\tlearn: 0.0000000\ttotal: 3.36s\tremaining: 2.07s\n",
      "6186:\tlearn: 0.0000000\ttotal: 3.36s\tremaining: 2.07s\n",
      "6187:\tlearn: 0.0000000\ttotal: 3.36s\tremaining: 2.07s\n",
      "6188:\tlearn: 0.0000000\ttotal: 3.36s\tremaining: 2.07s\n",
      "6189:\tlearn: 0.0000000\ttotal: 3.37s\tremaining: 2.07s\n",
      "6190:\tlearn: 0.0000000\ttotal: 3.37s\tremaining: 2.07s\n",
      "6191:\tlearn: 0.0000000\ttotal: 3.37s\tremaining: 2.07s\n",
      "6192:\tlearn: 0.0000000\ttotal: 3.37s\tremaining: 2.07s\n",
      "6193:\tlearn: 0.0000000\ttotal: 3.37s\tremaining: 2.07s\n",
      "6194:\tlearn: 0.0000000\ttotal: 3.37s\tremaining: 2.07s\n",
      "6195:\tlearn: 0.0000000\ttotal: 3.37s\tremaining: 2.07s\n",
      "6196:\tlearn: 0.0000000\ttotal: 3.37s\tremaining: 2.07s\n",
      "6197:\tlearn: 0.0000000\ttotal: 3.37s\tremaining: 2.07s\n",
      "6198:\tlearn: 0.0000000\ttotal: 3.37s\tremaining: 2.07s\n",
      "6199:\tlearn: 0.0000000\ttotal: 3.37s\tremaining: 2.07s\n",
      "6200:\tlearn: 0.0000000\ttotal: 3.37s\tremaining: 2.07s\n",
      "6201:\tlearn: 0.0000000\ttotal: 3.37s\tremaining: 2.07s\n",
      "6202:\tlearn: 0.0000000\ttotal: 3.37s\tremaining: 2.06s\n",
      "6203:\tlearn: 0.0000000\ttotal: 3.38s\tremaining: 2.06s\n",
      "6204:\tlearn: 0.0000000\ttotal: 3.38s\tremaining: 2.06s\n",
      "6205:\tlearn: 0.0000000\ttotal: 3.38s\tremaining: 2.06s\n",
      "6206:\tlearn: 0.0000000\ttotal: 3.38s\tremaining: 2.06s\n",
      "6207:\tlearn: 0.0000000\ttotal: 3.38s\tremaining: 2.06s\n",
      "6208:\tlearn: 0.0000000\ttotal: 3.38s\tremaining: 2.06s\n",
      "6209:\tlearn: 0.0000000\ttotal: 3.38s\tremaining: 2.06s\n",
      "6210:\tlearn: 0.0000000\ttotal: 3.38s\tremaining: 2.06s\n",
      "6211:\tlearn: 0.0000000\ttotal: 3.38s\tremaining: 2.06s\n",
      "6212:\tlearn: 0.0000000\ttotal: 3.38s\tremaining: 2.06s\n",
      "6213:\tlearn: 0.0000000\ttotal: 3.38s\tremaining: 2.06s\n",
      "6214:\tlearn: 0.0000000\ttotal: 3.38s\tremaining: 2.06s\n",
      "6215:\tlearn: 0.0000000\ttotal: 3.38s\tremaining: 2.06s\n",
      "6216:\tlearn: 0.0000000\ttotal: 3.38s\tremaining: 2.06s\n",
      "6217:\tlearn: 0.0000000\ttotal: 3.38s\tremaining: 2.06s\n",
      "6218:\tlearn: 0.0000000\ttotal: 3.38s\tremaining: 2.06s\n",
      "6219:\tlearn: 0.0000000\ttotal: 3.38s\tremaining: 2.06s\n",
      "6220:\tlearn: 0.0000000\ttotal: 3.38s\tremaining: 2.06s\n",
      "6221:\tlearn: 0.0000000\ttotal: 3.38s\tremaining: 2.06s\n",
      "6222:\tlearn: 0.0000000\ttotal: 3.38s\tremaining: 2.06s\n",
      "6223:\tlearn: 0.0000000\ttotal: 3.39s\tremaining: 2.05s\n",
      "6224:\tlearn: 0.0000000\ttotal: 3.39s\tremaining: 2.05s\n",
      "6225:\tlearn: 0.0000000\ttotal: 3.39s\tremaining: 2.05s\n",
      "6226:\tlearn: 0.0000000\ttotal: 3.39s\tremaining: 2.05s\n",
      "6227:\tlearn: 0.0000000\ttotal: 3.39s\tremaining: 2.05s\n",
      "6228:\tlearn: 0.0000000\ttotal: 3.39s\tremaining: 2.05s\n",
      "6229:\tlearn: 0.0000000\ttotal: 3.39s\tremaining: 2.05s\n",
      "6230:\tlearn: 0.0000000\ttotal: 3.39s\tremaining: 2.05s\n",
      "6231:\tlearn: 0.0000000\ttotal: 3.39s\tremaining: 2.05s\n",
      "6232:\tlearn: 0.0000000\ttotal: 3.39s\tremaining: 2.05s\n",
      "6233:\tlearn: 0.0000000\ttotal: 3.39s\tremaining: 2.05s\n",
      "6234:\tlearn: 0.0000000\ttotal: 3.39s\tremaining: 2.05s\n",
      "6235:\tlearn: 0.0000000\ttotal: 3.39s\tremaining: 2.05s\n",
      "6236:\tlearn: 0.0000000\ttotal: 3.39s\tremaining: 2.05s\n",
      "6237:\tlearn: 0.0000000\ttotal: 3.39s\tremaining: 2.05s\n",
      "6238:\tlearn: 0.0000000\ttotal: 3.4s\tremaining: 2.05s\n",
      "6239:\tlearn: 0.0000000\ttotal: 3.4s\tremaining: 2.05s\n",
      "6240:\tlearn: 0.0000000\ttotal: 3.4s\tremaining: 2.04s\n",
      "6241:\tlearn: 0.0000000\ttotal: 3.4s\tremaining: 2.04s\n",
      "6242:\tlearn: 0.0000000\ttotal: 3.4s\tremaining: 2.04s\n",
      "6243:\tlearn: 0.0000000\ttotal: 3.4s\tremaining: 2.04s\n",
      "6244:\tlearn: 0.0000000\ttotal: 3.4s\tremaining: 2.04s\n",
      "6245:\tlearn: 0.0000000\ttotal: 3.4s\tremaining: 2.04s\n",
      "6246:\tlearn: 0.0000000\ttotal: 3.4s\tremaining: 2.04s\n",
      "6247:\tlearn: 0.0000000\ttotal: 3.4s\tremaining: 2.04s\n",
      "6248:\tlearn: 0.0000000\ttotal: 3.4s\tremaining: 2.04s\n",
      "6249:\tlearn: 0.0000000\ttotal: 3.4s\tremaining: 2.04s\n",
      "6250:\tlearn: 0.0000000\ttotal: 3.4s\tremaining: 2.04s\n",
      "6251:\tlearn: 0.0000000\ttotal: 3.4s\tremaining: 2.04s\n",
      "6252:\tlearn: 0.0000000\ttotal: 3.4s\tremaining: 2.04s\n",
      "6253:\tlearn: 0.0000000\ttotal: 3.4s\tremaining: 2.04s\n",
      "6254:\tlearn: 0.0000000\ttotal: 3.4s\tremaining: 2.04s\n",
      "6255:\tlearn: 0.0000000\ttotal: 3.4s\tremaining: 2.04s\n",
      "6256:\tlearn: 0.0000000\ttotal: 3.4s\tremaining: 2.04s\n",
      "6257:\tlearn: 0.0000000\ttotal: 3.41s\tremaining: 2.04s\n",
      "6258:\tlearn: 0.0000000\ttotal: 3.41s\tremaining: 2.04s\n",
      "6259:\tlearn: 0.0000000\ttotal: 3.41s\tremaining: 2.04s\n",
      "6260:\tlearn: 0.0000000\ttotal: 3.41s\tremaining: 2.03s\n",
      "6261:\tlearn: 0.0000000\ttotal: 3.41s\tremaining: 2.03s\n",
      "6262:\tlearn: 0.0000000\ttotal: 3.41s\tremaining: 2.03s\n",
      "6263:\tlearn: 0.0000000\ttotal: 3.41s\tremaining: 2.03s\n",
      "6264:\tlearn: 0.0000000\ttotal: 3.41s\tremaining: 2.03s\n",
      "6265:\tlearn: 0.0000000\ttotal: 3.41s\tremaining: 2.03s\n",
      "6266:\tlearn: 0.0000000\ttotal: 3.41s\tremaining: 2.03s\n",
      "6267:\tlearn: 0.0000000\ttotal: 3.41s\tremaining: 2.03s\n",
      "6268:\tlearn: 0.0000000\ttotal: 3.41s\tremaining: 2.03s\n",
      "6269:\tlearn: 0.0000000\ttotal: 3.41s\tremaining: 2.03s\n",
      "6270:\tlearn: 0.0000000\ttotal: 3.41s\tremaining: 2.03s\n",
      "6271:\tlearn: 0.0000000\ttotal: 3.41s\tremaining: 2.03s\n",
      "6272:\tlearn: 0.0000000\ttotal: 3.41s\tremaining: 2.03s\n",
      "6273:\tlearn: 0.0000000\ttotal: 3.41s\tremaining: 2.03s\n",
      "6274:\tlearn: 0.0000000\ttotal: 3.42s\tremaining: 2.03s\n",
      "6275:\tlearn: 0.0000000\ttotal: 3.42s\tremaining: 2.03s\n",
      "6276:\tlearn: 0.0000000\ttotal: 3.42s\tremaining: 2.03s\n",
      "6277:\tlearn: 0.0000000\ttotal: 3.42s\tremaining: 2.02s\n",
      "6278:\tlearn: 0.0000000\ttotal: 3.42s\tremaining: 2.02s\n",
      "6279:\tlearn: 0.0000000\ttotal: 3.42s\tremaining: 2.02s\n",
      "6280:\tlearn: 0.0000000\ttotal: 3.42s\tremaining: 2.02s\n",
      "6281:\tlearn: 0.0000000\ttotal: 3.42s\tremaining: 2.02s\n",
      "6282:\tlearn: 0.0000000\ttotal: 3.42s\tremaining: 2.02s\n",
      "6283:\tlearn: 0.0000000\ttotal: 3.42s\tremaining: 2.02s\n",
      "6284:\tlearn: 0.0000000\ttotal: 3.42s\tremaining: 2.02s\n",
      "6285:\tlearn: 0.0000000\ttotal: 3.42s\tremaining: 2.02s\n",
      "6286:\tlearn: 0.0000000\ttotal: 3.42s\tremaining: 2.02s\n",
      "6287:\tlearn: 0.0000000\ttotal: 3.42s\tremaining: 2.02s\n",
      "6288:\tlearn: 0.0000000\ttotal: 3.42s\tremaining: 2.02s\n",
      "6289:\tlearn: 0.0000000\ttotal: 3.42s\tremaining: 2.02s\n",
      "6290:\tlearn: 0.0000000\ttotal: 3.42s\tremaining: 2.02s\n",
      "6291:\tlearn: 0.0000000\ttotal: 3.42s\tremaining: 2.02s\n",
      "6292:\tlearn: 0.0000000\ttotal: 3.42s\tremaining: 2.02s\n",
      "6293:\tlearn: 0.0000000\ttotal: 3.42s\tremaining: 2.02s\n",
      "6294:\tlearn: 0.0000000\ttotal: 3.42s\tremaining: 2.02s\n",
      "6295:\tlearn: 0.0000000\ttotal: 3.43s\tremaining: 2.02s\n",
      "6296:\tlearn: 0.0000000\ttotal: 3.43s\tremaining: 2.02s\n",
      "6297:\tlearn: 0.0000000\ttotal: 3.43s\tremaining: 2.01s\n",
      "6298:\tlearn: 0.0000000\ttotal: 3.43s\tremaining: 2.01s\n",
      "6299:\tlearn: 0.0000000\ttotal: 3.43s\tremaining: 2.01s\n",
      "6300:\tlearn: 0.0000000\ttotal: 3.43s\tremaining: 2.01s\n",
      "6301:\tlearn: 0.0000000\ttotal: 3.43s\tremaining: 2.01s\n",
      "6302:\tlearn: 0.0000000\ttotal: 3.43s\tremaining: 2.01s\n",
      "6303:\tlearn: 0.0000000\ttotal: 3.43s\tremaining: 2.01s\n",
      "6304:\tlearn: 0.0000000\ttotal: 3.43s\tremaining: 2.01s\n",
      "6305:\tlearn: 0.0000000\ttotal: 3.43s\tremaining: 2.01s\n",
      "6306:\tlearn: 0.0000000\ttotal: 3.43s\tremaining: 2.01s\n",
      "6307:\tlearn: 0.0000000\ttotal: 3.43s\tremaining: 2.01s\n",
      "6308:\tlearn: 0.0000000\ttotal: 3.43s\tremaining: 2.01s\n",
      "6309:\tlearn: 0.0000000\ttotal: 3.43s\tremaining: 2.01s\n",
      "6310:\tlearn: 0.0000000\ttotal: 3.43s\tremaining: 2.01s\n",
      "6311:\tlearn: 0.0000000\ttotal: 3.43s\tremaining: 2.01s\n",
      "6312:\tlearn: 0.0000000\ttotal: 3.44s\tremaining: 2.01s\n",
      "6313:\tlearn: 0.0000000\ttotal: 3.44s\tremaining: 2s\n",
      "6314:\tlearn: 0.0000000\ttotal: 3.44s\tremaining: 2s\n",
      "6315:\tlearn: 0.0000000\ttotal: 3.44s\tremaining: 2s\n",
      "6316:\tlearn: 0.0000000\ttotal: 3.44s\tremaining: 2s\n",
      "6317:\tlearn: 0.0000000\ttotal: 3.44s\tremaining: 2s\n",
      "6318:\tlearn: 0.0000000\ttotal: 3.44s\tremaining: 2s\n",
      "6319:\tlearn: 0.0000000\ttotal: 3.44s\tremaining: 2s\n",
      "6320:\tlearn: 0.0000000\ttotal: 3.44s\tremaining: 2s\n",
      "6321:\tlearn: 0.0000000\ttotal: 3.44s\tremaining: 2s\n",
      "6322:\tlearn: 0.0000000\ttotal: 3.44s\tremaining: 2s\n",
      "6323:\tlearn: 0.0000000\ttotal: 3.44s\tremaining: 2s\n",
      "6324:\tlearn: 0.0000000\ttotal: 3.44s\tremaining: 2s\n",
      "6325:\tlearn: 0.0000000\ttotal: 3.44s\tremaining: 2s\n",
      "6326:\tlearn: 0.0000000\ttotal: 3.44s\tremaining: 2s\n",
      "6327:\tlearn: 0.0000000\ttotal: 3.44s\tremaining: 2s\n",
      "6328:\tlearn: 0.0000000\ttotal: 3.44s\tremaining: 2s\n",
      "6329:\tlearn: 0.0000000\ttotal: 3.44s\tremaining: 2s\n",
      "6330:\tlearn: 0.0000000\ttotal: 3.44s\tremaining: 2s\n",
      "6331:\tlearn: 0.0000000\ttotal: 3.44s\tremaining: 2s\n",
      "6332:\tlearn: 0.0000000\ttotal: 3.44s\tremaining: 2s\n",
      "6333:\tlearn: 0.0000000\ttotal: 3.45s\tremaining: 1.99s\n",
      "6334:\tlearn: 0.0000000\ttotal: 3.45s\tremaining: 1.99s\n",
      "6335:\tlearn: 0.0000000\ttotal: 3.45s\tremaining: 1.99s\n",
      "6336:\tlearn: 0.0000000\ttotal: 3.45s\tremaining: 1.99s\n",
      "6337:\tlearn: 0.0000000\ttotal: 3.45s\tremaining: 1.99s\n",
      "6338:\tlearn: 0.0000000\ttotal: 3.45s\tremaining: 1.99s\n",
      "6339:\tlearn: 0.0000000\ttotal: 3.45s\tremaining: 1.99s\n",
      "6340:\tlearn: 0.0000000\ttotal: 3.45s\tremaining: 1.99s\n",
      "6341:\tlearn: 0.0000000\ttotal: 3.45s\tremaining: 1.99s\n",
      "6342:\tlearn: 0.0000000\ttotal: 3.45s\tremaining: 1.99s\n",
      "6343:\tlearn: 0.0000000\ttotal: 3.45s\tremaining: 1.99s\n",
      "6344:\tlearn: 0.0000000\ttotal: 3.45s\tremaining: 1.99s\n",
      "6345:\tlearn: 0.0000000\ttotal: 3.45s\tremaining: 1.99s\n",
      "6346:\tlearn: 0.0000000\ttotal: 3.45s\tremaining: 1.99s\n",
      "6347:\tlearn: 0.0000000\ttotal: 3.45s\tremaining: 1.99s\n",
      "6348:\tlearn: 0.0000000\ttotal: 3.45s\tremaining: 1.99s\n",
      "6349:\tlearn: 0.0000000\ttotal: 3.45s\tremaining: 1.99s\n",
      "6350:\tlearn: 0.0000000\ttotal: 3.46s\tremaining: 1.99s\n",
      "6351:\tlearn: 0.0000000\ttotal: 3.46s\tremaining: 1.98s\n",
      "6352:\tlearn: 0.0000000\ttotal: 3.46s\tremaining: 1.98s\n",
      "6353:\tlearn: 0.0000000\ttotal: 3.46s\tremaining: 1.98s\n",
      "6354:\tlearn: 0.0000000\ttotal: 3.46s\tremaining: 1.98s\n",
      "6355:\tlearn: 0.0000000\ttotal: 3.46s\tremaining: 1.98s\n",
      "6356:\tlearn: 0.0000000\ttotal: 3.46s\tremaining: 1.98s\n",
      "6357:\tlearn: 0.0000000\ttotal: 3.46s\tremaining: 1.98s\n",
      "6358:\tlearn: 0.0000000\ttotal: 3.46s\tremaining: 1.98s\n",
      "6359:\tlearn: 0.0000000\ttotal: 3.46s\tremaining: 1.98s\n",
      "6360:\tlearn: 0.0000000\ttotal: 3.46s\tremaining: 1.98s\n",
      "6361:\tlearn: 0.0000000\ttotal: 3.46s\tremaining: 1.98s\n",
      "6362:\tlearn: 0.0000000\ttotal: 3.46s\tremaining: 1.98s\n",
      "6363:\tlearn: 0.0000000\ttotal: 3.46s\tremaining: 1.98s\n",
      "6364:\tlearn: 0.0000000\ttotal: 3.46s\tremaining: 1.98s\n",
      "6365:\tlearn: 0.0000000\ttotal: 3.46s\tremaining: 1.98s\n",
      "6366:\tlearn: 0.0000000\ttotal: 3.46s\tremaining: 1.98s\n",
      "6367:\tlearn: 0.0000000\ttotal: 3.46s\tremaining: 1.98s\n",
      "6368:\tlearn: 0.0000000\ttotal: 3.46s\tremaining: 1.98s\n",
      "6369:\tlearn: 0.0000000\ttotal: 3.46s\tremaining: 1.97s\n",
      "6370:\tlearn: 0.0000000\ttotal: 3.47s\tremaining: 1.97s\n",
      "6371:\tlearn: 0.0000000\ttotal: 3.47s\tremaining: 1.97s\n",
      "6372:\tlearn: 0.0000000\ttotal: 3.47s\tremaining: 1.97s\n",
      "6373:\tlearn: 0.0000000\ttotal: 3.47s\tremaining: 1.97s\n",
      "6374:\tlearn: 0.0000000\ttotal: 3.47s\tremaining: 1.97s\n",
      "6375:\tlearn: 0.0000000\ttotal: 3.47s\tremaining: 1.97s\n",
      "6376:\tlearn: 0.0000000\ttotal: 3.47s\tremaining: 1.97s\n",
      "6377:\tlearn: 0.0000000\ttotal: 3.47s\tremaining: 1.97s\n",
      "6378:\tlearn: 0.0000000\ttotal: 3.47s\tremaining: 1.97s\n",
      "6379:\tlearn: 0.0000000\ttotal: 3.47s\tremaining: 1.97s\n",
      "6380:\tlearn: 0.0000000\ttotal: 3.47s\tremaining: 1.97s\n",
      "6381:\tlearn: 0.0000000\ttotal: 3.47s\tremaining: 1.97s\n",
      "6382:\tlearn: 0.0000000\ttotal: 3.47s\tremaining: 1.97s\n",
      "6383:\tlearn: 0.0000000\ttotal: 3.47s\tremaining: 1.97s\n",
      "6384:\tlearn: 0.0000000\ttotal: 3.47s\tremaining: 1.97s\n",
      "6385:\tlearn: 0.0000000\ttotal: 3.47s\tremaining: 1.97s\n",
      "6386:\tlearn: 0.0000000\ttotal: 3.47s\tremaining: 1.97s\n",
      "6387:\tlearn: 0.0000000\ttotal: 3.48s\tremaining: 1.97s\n",
      "6388:\tlearn: 0.0000000\ttotal: 3.48s\tremaining: 1.96s\n",
      "6389:\tlearn: 0.0000000\ttotal: 3.48s\tremaining: 1.96s\n",
      "6390:\tlearn: 0.0000000\ttotal: 3.48s\tremaining: 1.96s\n",
      "6391:\tlearn: 0.0000000\ttotal: 3.48s\tremaining: 1.96s\n",
      "6392:\tlearn: 0.0000000\ttotal: 3.48s\tremaining: 1.96s\n",
      "6393:\tlearn: 0.0000000\ttotal: 3.48s\tremaining: 1.96s\n",
      "6394:\tlearn: 0.0000000\ttotal: 3.48s\tremaining: 1.96s\n",
      "6395:\tlearn: 0.0000000\ttotal: 3.48s\tremaining: 1.96s\n",
      "6396:\tlearn: 0.0000000\ttotal: 3.48s\tremaining: 1.96s\n",
      "6397:\tlearn: 0.0000000\ttotal: 3.48s\tremaining: 1.96s\n",
      "6398:\tlearn: 0.0000000\ttotal: 3.48s\tremaining: 1.96s\n",
      "6399:\tlearn: 0.0000000\ttotal: 3.48s\tremaining: 1.96s\n",
      "6400:\tlearn: 0.0000000\ttotal: 3.48s\tremaining: 1.96s\n",
      "6401:\tlearn: 0.0000000\ttotal: 3.48s\tremaining: 1.96s\n",
      "6402:\tlearn: 0.0000000\ttotal: 3.48s\tremaining: 1.96s\n",
      "6403:\tlearn: 0.0000000\ttotal: 3.48s\tremaining: 1.96s\n",
      "6404:\tlearn: 0.0000000\ttotal: 3.48s\tremaining: 1.95s\n",
      "6405:\tlearn: 0.0000000\ttotal: 3.48s\tremaining: 1.95s\n",
      "6406:\tlearn: 0.0000000\ttotal: 3.48s\tremaining: 1.95s\n",
      "6407:\tlearn: 0.0000000\ttotal: 3.48s\tremaining: 1.95s\n",
      "6408:\tlearn: 0.0000000\ttotal: 3.48s\tremaining: 1.95s\n",
      "6409:\tlearn: 0.0000000\ttotal: 3.48s\tremaining: 1.95s\n",
      "6410:\tlearn: 0.0000000\ttotal: 3.49s\tremaining: 1.95s\n",
      "6411:\tlearn: 0.0000000\ttotal: 3.49s\tremaining: 1.95s\n",
      "6412:\tlearn: 0.0000000\ttotal: 3.49s\tremaining: 1.95s\n",
      "6413:\tlearn: 0.0000000\ttotal: 3.49s\tremaining: 1.95s\n",
      "6414:\tlearn: 0.0000000\ttotal: 3.49s\tremaining: 1.95s\n",
      "6415:\tlearn: 0.0000000\ttotal: 3.49s\tremaining: 1.95s\n",
      "6416:\tlearn: 0.0000000\ttotal: 3.49s\tremaining: 1.95s\n",
      "6417:\tlearn: 0.0000000\ttotal: 3.49s\tremaining: 1.95s\n",
      "6418:\tlearn: 0.0000000\ttotal: 3.49s\tremaining: 1.95s\n",
      "6419:\tlearn: 0.0000000\ttotal: 3.49s\tremaining: 1.95s\n",
      "6420:\tlearn: 0.0000000\ttotal: 3.49s\tremaining: 1.95s\n",
      "6421:\tlearn: 0.0000000\ttotal: 3.49s\tremaining: 1.95s\n",
      "6422:\tlearn: 0.0000000\ttotal: 3.49s\tremaining: 1.94s\n",
      "6423:\tlearn: 0.0000000\ttotal: 3.49s\tremaining: 1.94s\n",
      "6424:\tlearn: 0.0000000\ttotal: 3.49s\tremaining: 1.94s\n",
      "6425:\tlearn: 0.0000000\ttotal: 3.49s\tremaining: 1.94s\n",
      "6426:\tlearn: 0.0000000\ttotal: 3.49s\tremaining: 1.94s\n",
      "6427:\tlearn: 0.0000000\ttotal: 3.49s\tremaining: 1.94s\n",
      "6428:\tlearn: 0.0000000\ttotal: 3.49s\tremaining: 1.94s\n",
      "6429:\tlearn: 0.0000000\ttotal: 3.49s\tremaining: 1.94s\n",
      "6430:\tlearn: 0.0000000\ttotal: 3.5s\tremaining: 1.94s\n",
      "6431:\tlearn: 0.0000000\ttotal: 3.5s\tremaining: 1.94s\n",
      "6432:\tlearn: 0.0000000\ttotal: 3.5s\tremaining: 1.94s\n",
      "6433:\tlearn: 0.0000000\ttotal: 3.5s\tremaining: 1.94s\n",
      "6434:\tlearn: 0.0000000\ttotal: 3.5s\tremaining: 1.94s\n",
      "6435:\tlearn: 0.0000000\ttotal: 3.5s\tremaining: 1.94s\n",
      "6436:\tlearn: 0.0000000\ttotal: 3.5s\tremaining: 1.94s\n",
      "6437:\tlearn: 0.0000000\ttotal: 3.5s\tremaining: 1.94s\n",
      "6438:\tlearn: 0.0000000\ttotal: 3.5s\tremaining: 1.94s\n",
      "6439:\tlearn: 0.0000000\ttotal: 3.5s\tremaining: 1.93s\n",
      "6440:\tlearn: 0.0000000\ttotal: 3.5s\tremaining: 1.93s\n",
      "6441:\tlearn: 0.0000000\ttotal: 3.5s\tremaining: 1.93s\n",
      "6442:\tlearn: 0.0000000\ttotal: 3.5s\tremaining: 1.93s\n",
      "6443:\tlearn: 0.0000000\ttotal: 3.5s\tremaining: 1.93s\n",
      "6444:\tlearn: 0.0000000\ttotal: 3.5s\tremaining: 1.93s\n",
      "6445:\tlearn: 0.0000000\ttotal: 3.5s\tremaining: 1.93s\n",
      "6446:\tlearn: 0.0000000\ttotal: 3.5s\tremaining: 1.93s\n",
      "6447:\tlearn: 0.0000000\ttotal: 3.5s\tremaining: 1.93s\n",
      "6448:\tlearn: 0.0000000\ttotal: 3.5s\tremaining: 1.93s\n",
      "6449:\tlearn: 0.0000000\ttotal: 3.5s\tremaining: 1.93s\n",
      "6450:\tlearn: 0.0000000\ttotal: 3.5s\tremaining: 1.93s\n",
      "6451:\tlearn: 0.0000000\ttotal: 3.5s\tremaining: 1.93s\n",
      "6452:\tlearn: 0.0000000\ttotal: 3.51s\tremaining: 1.93s\n",
      "6453:\tlearn: 0.0000000\ttotal: 3.51s\tremaining: 1.93s\n",
      "6454:\tlearn: 0.0000000\ttotal: 3.51s\tremaining: 1.93s\n",
      "6455:\tlearn: 0.0000000\ttotal: 3.51s\tremaining: 1.93s\n",
      "6456:\tlearn: 0.0000000\ttotal: 3.51s\tremaining: 1.92s\n",
      "6457:\tlearn: 0.0000000\ttotal: 3.51s\tremaining: 1.92s\n",
      "6458:\tlearn: 0.0000000\ttotal: 3.51s\tremaining: 1.92s\n",
      "6459:\tlearn: 0.0000000\ttotal: 3.51s\tremaining: 1.92s\n",
      "6460:\tlearn: 0.0000000\ttotal: 3.51s\tremaining: 1.92s\n",
      "6461:\tlearn: 0.0000000\ttotal: 3.51s\tremaining: 1.92s\n",
      "6462:\tlearn: 0.0000000\ttotal: 3.51s\tremaining: 1.92s\n",
      "6463:\tlearn: 0.0000000\ttotal: 3.51s\tremaining: 1.92s\n",
      "6464:\tlearn: 0.0000000\ttotal: 3.51s\tremaining: 1.92s\n",
      "6465:\tlearn: 0.0000000\ttotal: 3.51s\tremaining: 1.92s\n",
      "6466:\tlearn: 0.0000000\ttotal: 3.51s\tremaining: 1.92s\n",
      "6467:\tlearn: 0.0000000\ttotal: 3.51s\tremaining: 1.92s\n",
      "6468:\tlearn: 0.0000000\ttotal: 3.52s\tremaining: 1.92s\n",
      "6469:\tlearn: 0.0000000\ttotal: 3.52s\tremaining: 1.92s\n",
      "6470:\tlearn: 0.0000000\ttotal: 3.52s\tremaining: 1.92s\n",
      "6471:\tlearn: 0.0000000\ttotal: 3.52s\tremaining: 1.92s\n",
      "6472:\tlearn: 0.0000000\ttotal: 3.52s\tremaining: 1.92s\n",
      "6473:\tlearn: 0.0000000\ttotal: 3.52s\tremaining: 1.92s\n",
      "6474:\tlearn: 0.0000000\ttotal: 3.52s\tremaining: 1.92s\n",
      "6475:\tlearn: 0.0000000\ttotal: 3.52s\tremaining: 1.91s\n",
      "6476:\tlearn: 0.0000000\ttotal: 3.52s\tremaining: 1.91s\n",
      "6477:\tlearn: 0.0000000\ttotal: 3.52s\tremaining: 1.91s\n",
      "6478:\tlearn: 0.0000000\ttotal: 3.52s\tremaining: 1.91s\n",
      "6479:\tlearn: 0.0000000\ttotal: 3.52s\tremaining: 1.91s\n",
      "6480:\tlearn: 0.0000000\ttotal: 3.52s\tremaining: 1.91s\n",
      "6481:\tlearn: 0.0000000\ttotal: 3.52s\tremaining: 1.91s\n",
      "6482:\tlearn: 0.0000000\ttotal: 3.52s\tremaining: 1.91s\n",
      "6483:\tlearn: 0.0000000\ttotal: 3.52s\tremaining: 1.91s\n",
      "6484:\tlearn: 0.0000000\ttotal: 3.52s\tremaining: 1.91s\n",
      "6485:\tlearn: 0.0000000\ttotal: 3.52s\tremaining: 1.91s\n",
      "6486:\tlearn: 0.0000000\ttotal: 3.52s\tremaining: 1.91s\n",
      "6487:\tlearn: 0.0000000\ttotal: 3.52s\tremaining: 1.91s\n",
      "6488:\tlearn: 0.0000000\ttotal: 3.52s\tremaining: 1.91s\n",
      "6489:\tlearn: 0.0000000\ttotal: 3.52s\tremaining: 1.91s\n",
      "6490:\tlearn: 0.0000000\ttotal: 3.52s\tremaining: 1.91s\n",
      "6491:\tlearn: 0.0000000\ttotal: 3.53s\tremaining: 1.91s\n",
      "6492:\tlearn: 0.0000000\ttotal: 3.53s\tremaining: 1.9s\n",
      "6493:\tlearn: 0.0000000\ttotal: 3.53s\tremaining: 1.9s\n",
      "6494:\tlearn: 0.0000000\ttotal: 3.53s\tremaining: 1.9s\n",
      "6495:\tlearn: 0.0000000\ttotal: 3.53s\tremaining: 1.9s\n",
      "6496:\tlearn: 0.0000000\ttotal: 3.53s\tremaining: 1.9s\n",
      "6497:\tlearn: 0.0000000\ttotal: 3.53s\tremaining: 1.9s\n",
      "6498:\tlearn: 0.0000000\ttotal: 3.53s\tremaining: 1.9s\n",
      "6499:\tlearn: 0.0000000\ttotal: 3.53s\tremaining: 1.9s\n",
      "6500:\tlearn: 0.0000000\ttotal: 3.53s\tremaining: 1.9s\n",
      "6501:\tlearn: 0.0000000\ttotal: 3.53s\tremaining: 1.9s\n",
      "6502:\tlearn: 0.0000000\ttotal: 3.53s\tremaining: 1.9s\n",
      "6503:\tlearn: 0.0000000\ttotal: 3.53s\tremaining: 1.9s\n",
      "6504:\tlearn: 0.0000000\ttotal: 3.53s\tremaining: 1.9s\n",
      "6505:\tlearn: 0.0000000\ttotal: 3.53s\tremaining: 1.9s\n",
      "6506:\tlearn: 0.0000000\ttotal: 3.53s\tremaining: 1.9s\n",
      "6507:\tlearn: 0.0000000\ttotal: 3.53s\tremaining: 1.9s\n",
      "6508:\tlearn: 0.0000000\ttotal: 3.54s\tremaining: 1.9s\n",
      "6509:\tlearn: 0.0000000\ttotal: 3.54s\tremaining: 1.9s\n",
      "6510:\tlearn: 0.0000000\ttotal: 3.54s\tremaining: 1.89s\n",
      "6511:\tlearn: 0.0000000\ttotal: 3.54s\tremaining: 1.89s\n",
      "6512:\tlearn: 0.0000000\ttotal: 3.54s\tremaining: 1.89s\n",
      "6513:\tlearn: 0.0000000\ttotal: 3.54s\tremaining: 1.89s\n",
      "6514:\tlearn: 0.0000000\ttotal: 3.54s\tremaining: 1.89s\n",
      "6515:\tlearn: 0.0000000\ttotal: 3.54s\tremaining: 1.89s\n",
      "6516:\tlearn: 0.0000000\ttotal: 3.54s\tremaining: 1.89s\n",
      "6517:\tlearn: 0.0000000\ttotal: 3.54s\tremaining: 1.89s\n",
      "6518:\tlearn: 0.0000000\ttotal: 3.54s\tremaining: 1.89s\n",
      "6519:\tlearn: 0.0000000\ttotal: 3.54s\tremaining: 1.89s\n",
      "6520:\tlearn: 0.0000000\ttotal: 3.54s\tremaining: 1.89s\n",
      "6521:\tlearn: 0.0000000\ttotal: 3.54s\tremaining: 1.89s\n",
      "6522:\tlearn: 0.0000000\ttotal: 3.54s\tremaining: 1.89s\n",
      "6523:\tlearn: 0.0000000\ttotal: 3.54s\tremaining: 1.89s\n",
      "6524:\tlearn: 0.0000000\ttotal: 3.54s\tremaining: 1.89s\n",
      "6525:\tlearn: 0.0000000\ttotal: 3.54s\tremaining: 1.89s\n",
      "6526:\tlearn: 0.0000000\ttotal: 3.54s\tremaining: 1.89s\n",
      "6527:\tlearn: 0.0000000\ttotal: 3.55s\tremaining: 1.89s\n",
      "6528:\tlearn: 0.0000000\ttotal: 3.55s\tremaining: 1.89s\n",
      "6529:\tlearn: 0.0000000\ttotal: 3.55s\tremaining: 1.88s\n",
      "6530:\tlearn: 0.0000000\ttotal: 3.55s\tremaining: 1.88s\n",
      "6531:\tlearn: 0.0000000\ttotal: 3.55s\tremaining: 1.88s\n",
      "6532:\tlearn: 0.0000000\ttotal: 3.55s\tremaining: 1.88s\n",
      "6533:\tlearn: 0.0000000\ttotal: 3.55s\tremaining: 1.88s\n",
      "6534:\tlearn: 0.0000000\ttotal: 3.55s\tremaining: 1.88s\n",
      "6535:\tlearn: 0.0000000\ttotal: 3.55s\tremaining: 1.88s\n",
      "6536:\tlearn: 0.0000000\ttotal: 3.55s\tremaining: 1.88s\n",
      "6537:\tlearn: 0.0000000\ttotal: 3.55s\tremaining: 1.88s\n",
      "6538:\tlearn: 0.0000000\ttotal: 3.55s\tremaining: 1.88s\n",
      "6539:\tlearn: 0.0000000\ttotal: 3.55s\tremaining: 1.88s\n",
      "6540:\tlearn: 0.0000000\ttotal: 3.55s\tremaining: 1.88s\n",
      "6541:\tlearn: 0.0000000\ttotal: 3.55s\tremaining: 1.88s\n",
      "6542:\tlearn: 0.0000000\ttotal: 3.55s\tremaining: 1.88s\n",
      "6543:\tlearn: 0.0000000\ttotal: 3.55s\tremaining: 1.88s\n",
      "6544:\tlearn: 0.0000000\ttotal: 3.55s\tremaining: 1.88s\n",
      "6545:\tlearn: 0.0000000\ttotal: 3.55s\tremaining: 1.88s\n",
      "6546:\tlearn: 0.0000000\ttotal: 3.56s\tremaining: 1.88s\n",
      "6547:\tlearn: 0.0000000\ttotal: 3.56s\tremaining: 1.87s\n",
      "6548:\tlearn: 0.0000000\ttotal: 3.56s\tremaining: 1.87s\n",
      "6549:\tlearn: 0.0000000\ttotal: 3.56s\tremaining: 1.87s\n",
      "6550:\tlearn: 0.0000000\ttotal: 3.56s\tremaining: 1.87s\n",
      "6551:\tlearn: 0.0000000\ttotal: 3.56s\tremaining: 1.87s\n",
      "6552:\tlearn: 0.0000000\ttotal: 3.56s\tremaining: 1.87s\n",
      "6553:\tlearn: 0.0000000\ttotal: 3.56s\tremaining: 1.87s\n",
      "6554:\tlearn: 0.0000000\ttotal: 3.56s\tremaining: 1.87s\n",
      "6555:\tlearn: 0.0000000\ttotal: 3.56s\tremaining: 1.87s\n",
      "6556:\tlearn: 0.0000000\ttotal: 3.56s\tremaining: 1.87s\n",
      "6557:\tlearn: 0.0000000\ttotal: 3.56s\tremaining: 1.87s\n",
      "6558:\tlearn: 0.0000000\ttotal: 3.56s\tremaining: 1.87s\n",
      "6559:\tlearn: 0.0000000\ttotal: 3.56s\tremaining: 1.87s\n",
      "6560:\tlearn: 0.0000000\ttotal: 3.56s\tremaining: 1.87s\n",
      "6561:\tlearn: 0.0000000\ttotal: 3.56s\tremaining: 1.87s\n",
      "6562:\tlearn: 0.0000000\ttotal: 3.56s\tremaining: 1.87s\n",
      "6563:\tlearn: 0.0000000\ttotal: 3.56s\tremaining: 1.86s\n",
      "6564:\tlearn: 0.0000000\ttotal: 3.56s\tremaining: 1.86s\n",
      "6565:\tlearn: 0.0000000\ttotal: 3.56s\tremaining: 1.86s\n",
      "6566:\tlearn: 0.0000000\ttotal: 3.56s\tremaining: 1.86s\n",
      "6567:\tlearn: 0.0000000\ttotal: 3.56s\tremaining: 1.86s\n",
      "6568:\tlearn: 0.0000000\ttotal: 3.56s\tremaining: 1.86s\n",
      "6569:\tlearn: 0.0000000\ttotal: 3.57s\tremaining: 1.86s\n",
      "6570:\tlearn: 0.0000000\ttotal: 3.57s\tremaining: 1.86s\n",
      "6571:\tlearn: 0.0000000\ttotal: 3.57s\tremaining: 1.86s\n",
      "6572:\tlearn: 0.0000000\ttotal: 3.57s\tremaining: 1.86s\n",
      "6573:\tlearn: 0.0000000\ttotal: 3.57s\tremaining: 1.86s\n",
      "6574:\tlearn: 0.0000000\ttotal: 3.57s\tremaining: 1.86s\n",
      "6575:\tlearn: 0.0000000\ttotal: 3.57s\tremaining: 1.86s\n",
      "6576:\tlearn: 0.0000000\ttotal: 3.57s\tremaining: 1.86s\n",
      "6577:\tlearn: 0.0000000\ttotal: 3.57s\tremaining: 1.86s\n",
      "6578:\tlearn: 0.0000000\ttotal: 3.57s\tremaining: 1.86s\n",
      "6579:\tlearn: 0.0000000\ttotal: 3.57s\tremaining: 1.86s\n",
      "6580:\tlearn: 0.0000000\ttotal: 3.57s\tremaining: 1.86s\n",
      "6581:\tlearn: 0.0000000\ttotal: 3.57s\tremaining: 1.85s\n",
      "6582:\tlearn: 0.0000000\ttotal: 3.57s\tremaining: 1.85s\n",
      "6583:\tlearn: 0.0000000\ttotal: 3.57s\tremaining: 1.85s\n",
      "6584:\tlearn: 0.0000000\ttotal: 3.57s\tremaining: 1.85s\n",
      "6585:\tlearn: 0.0000000\ttotal: 3.57s\tremaining: 1.85s\n",
      "6586:\tlearn: 0.0000000\ttotal: 3.58s\tremaining: 1.85s\n",
      "6587:\tlearn: 0.0000000\ttotal: 3.58s\tremaining: 1.85s\n",
      "6588:\tlearn: 0.0000000\ttotal: 3.58s\tremaining: 1.85s\n",
      "6589:\tlearn: 0.0000000\ttotal: 3.58s\tremaining: 1.85s\n",
      "6590:\tlearn: 0.0000000\ttotal: 3.58s\tremaining: 1.85s\n",
      "6591:\tlearn: 0.0000000\ttotal: 3.58s\tremaining: 1.85s\n",
      "6592:\tlearn: 0.0000000\ttotal: 3.58s\tremaining: 1.85s\n",
      "6593:\tlearn: 0.0000000\ttotal: 3.58s\tremaining: 1.85s\n",
      "6594:\tlearn: 0.0000000\ttotal: 3.58s\tremaining: 1.85s\n",
      "6595:\tlearn: 0.0000000\ttotal: 3.58s\tremaining: 1.85s\n",
      "6596:\tlearn: 0.0000000\ttotal: 3.58s\tremaining: 1.85s\n",
      "6597:\tlearn: 0.0000000\ttotal: 3.58s\tremaining: 1.85s\n",
      "6598:\tlearn: 0.0000000\ttotal: 3.58s\tremaining: 1.84s\n",
      "6599:\tlearn: 0.0000000\ttotal: 3.58s\tremaining: 1.84s\n",
      "6600:\tlearn: 0.0000000\ttotal: 3.58s\tremaining: 1.84s\n",
      "6601:\tlearn: 0.0000000\ttotal: 3.58s\tremaining: 1.84s\n",
      "6602:\tlearn: 0.0000000\ttotal: 3.58s\tremaining: 1.84s\n",
      "6603:\tlearn: 0.0000000\ttotal: 3.58s\tremaining: 1.84s\n",
      "6604:\tlearn: 0.0000000\ttotal: 3.58s\tremaining: 1.84s\n",
      "6605:\tlearn: 0.0000000\ttotal: 3.58s\tremaining: 1.84s\n",
      "6606:\tlearn: 0.0000000\ttotal: 3.58s\tremaining: 1.84s\n",
      "6607:\tlearn: 0.0000000\ttotal: 3.58s\tremaining: 1.84s\n",
      "6608:\tlearn: 0.0000000\ttotal: 3.59s\tremaining: 1.84s\n",
      "6609:\tlearn: 0.0000000\ttotal: 3.59s\tremaining: 1.84s\n",
      "6610:\tlearn: 0.0000000\ttotal: 3.59s\tremaining: 1.84s\n",
      "6611:\tlearn: 0.0000000\ttotal: 3.59s\tremaining: 1.84s\n",
      "6612:\tlearn: 0.0000000\ttotal: 3.59s\tremaining: 1.84s\n",
      "6613:\tlearn: 0.0000000\ttotal: 3.59s\tremaining: 1.84s\n",
      "6614:\tlearn: 0.0000000\ttotal: 3.59s\tremaining: 1.84s\n",
      "6615:\tlearn: 0.0000000\ttotal: 3.59s\tremaining: 1.83s\n",
      "6616:\tlearn: 0.0000000\ttotal: 3.59s\tremaining: 1.83s\n",
      "6617:\tlearn: 0.0000000\ttotal: 3.59s\tremaining: 1.83s\n",
      "6618:\tlearn: 0.0000000\ttotal: 3.59s\tremaining: 1.83s\n",
      "6619:\tlearn: 0.0000000\ttotal: 3.59s\tremaining: 1.83s\n",
      "6620:\tlearn: 0.0000000\ttotal: 3.59s\tremaining: 1.83s\n",
      "6621:\tlearn: 0.0000000\ttotal: 3.59s\tremaining: 1.83s\n",
      "6622:\tlearn: 0.0000000\ttotal: 3.59s\tremaining: 1.83s\n",
      "6623:\tlearn: 0.0000000\ttotal: 3.59s\tremaining: 1.83s\n",
      "6624:\tlearn: 0.0000000\ttotal: 3.59s\tremaining: 1.83s\n",
      "6625:\tlearn: 0.0000000\ttotal: 3.59s\tremaining: 1.83s\n",
      "6626:\tlearn: 0.0000000\ttotal: 3.59s\tremaining: 1.83s\n",
      "6627:\tlearn: 0.0000000\ttotal: 3.59s\tremaining: 1.83s\n",
      "6628:\tlearn: 0.0000000\ttotal: 3.6s\tremaining: 1.83s\n",
      "6629:\tlearn: 0.0000000\ttotal: 3.6s\tremaining: 1.83s\n",
      "6630:\tlearn: 0.0000000\ttotal: 3.6s\tremaining: 1.83s\n",
      "6631:\tlearn: 0.0000000\ttotal: 3.6s\tremaining: 1.83s\n",
      "6632:\tlearn: 0.0000000\ttotal: 3.6s\tremaining: 1.83s\n",
      "6633:\tlearn: 0.0000000\ttotal: 3.6s\tremaining: 1.82s\n",
      "6634:\tlearn: 0.0000000\ttotal: 3.6s\tremaining: 1.82s\n",
      "6635:\tlearn: 0.0000000\ttotal: 3.6s\tremaining: 1.82s\n",
      "6636:\tlearn: 0.0000000\ttotal: 3.6s\tremaining: 1.82s\n",
      "6637:\tlearn: 0.0000000\ttotal: 3.6s\tremaining: 1.82s\n",
      "6638:\tlearn: 0.0000000\ttotal: 3.6s\tremaining: 1.82s\n",
      "6639:\tlearn: 0.0000000\ttotal: 3.6s\tremaining: 1.82s\n",
      "6640:\tlearn: 0.0000000\ttotal: 3.6s\tremaining: 1.82s\n",
      "6641:\tlearn: 0.0000000\ttotal: 3.6s\tremaining: 1.82s\n",
      "6642:\tlearn: 0.0000000\ttotal: 3.6s\tremaining: 1.82s\n",
      "6643:\tlearn: 0.0000000\ttotal: 3.6s\tremaining: 1.82s\n",
      "6644:\tlearn: 0.0000000\ttotal: 3.6s\tremaining: 1.82s\n",
      "6645:\tlearn: 0.0000000\ttotal: 3.6s\tremaining: 1.82s\n",
      "6646:\tlearn: 0.0000000\ttotal: 3.6s\tremaining: 1.82s\n",
      "6647:\tlearn: 0.0000000\ttotal: 3.6s\tremaining: 1.82s\n",
      "6648:\tlearn: 0.0000000\ttotal: 3.6s\tremaining: 1.82s\n",
      "6649:\tlearn: 0.0000000\ttotal: 3.61s\tremaining: 1.82s\n",
      "6650:\tlearn: 0.0000000\ttotal: 3.61s\tremaining: 1.82s\n",
      "6651:\tlearn: 0.0000000\ttotal: 3.61s\tremaining: 1.81s\n",
      "6652:\tlearn: 0.0000000\ttotal: 3.61s\tremaining: 1.81s\n",
      "6653:\tlearn: 0.0000000\ttotal: 3.61s\tremaining: 1.81s\n",
      "6654:\tlearn: 0.0000000\ttotal: 3.61s\tremaining: 1.81s\n",
      "6655:\tlearn: 0.0000000\ttotal: 3.61s\tremaining: 1.81s\n",
      "6656:\tlearn: 0.0000000\ttotal: 3.61s\tremaining: 1.81s\n",
      "6657:\tlearn: 0.0000000\ttotal: 3.61s\tremaining: 1.81s\n",
      "6658:\tlearn: 0.0000000\ttotal: 3.61s\tremaining: 1.81s\n",
      "6659:\tlearn: 0.0000000\ttotal: 3.61s\tremaining: 1.81s\n",
      "6660:\tlearn: 0.0000000\ttotal: 3.61s\tremaining: 1.81s\n",
      "6661:\tlearn: 0.0000000\ttotal: 3.61s\tremaining: 1.81s\n",
      "6662:\tlearn: 0.0000000\ttotal: 3.61s\tremaining: 1.81s\n",
      "6663:\tlearn: 0.0000000\ttotal: 3.61s\tremaining: 1.81s\n",
      "6664:\tlearn: 0.0000000\ttotal: 3.61s\tremaining: 1.81s\n",
      "6665:\tlearn: 0.0000000\ttotal: 3.61s\tremaining: 1.81s\n",
      "6666:\tlearn: 0.0000000\ttotal: 3.61s\tremaining: 1.81s\n",
      "6667:\tlearn: 0.0000000\ttotal: 3.62s\tremaining: 1.81s\n",
      "6668:\tlearn: 0.0000000\ttotal: 3.62s\tremaining: 1.8s\n",
      "6669:\tlearn: 0.0000000\ttotal: 3.62s\tremaining: 1.8s\n",
      "6670:\tlearn: 0.0000000\ttotal: 3.62s\tremaining: 1.8s\n",
      "6671:\tlearn: 0.0000000\ttotal: 3.62s\tremaining: 1.8s\n",
      "6672:\tlearn: 0.0000000\ttotal: 3.62s\tremaining: 1.8s\n",
      "6673:\tlearn: 0.0000000\ttotal: 3.62s\tremaining: 1.8s\n",
      "6674:\tlearn: 0.0000000\ttotal: 3.62s\tremaining: 1.8s\n",
      "6675:\tlearn: 0.0000000\ttotal: 3.62s\tremaining: 1.8s\n",
      "6676:\tlearn: 0.0000000\ttotal: 3.62s\tremaining: 1.8s\n",
      "6677:\tlearn: 0.0000000\ttotal: 3.62s\tremaining: 1.8s\n",
      "6678:\tlearn: 0.0000000\ttotal: 3.62s\tremaining: 1.8s\n",
      "6679:\tlearn: 0.0000000\ttotal: 3.62s\tremaining: 1.8s\n",
      "6680:\tlearn: 0.0000000\ttotal: 3.62s\tremaining: 1.8s\n",
      "6681:\tlearn: 0.0000000\ttotal: 3.62s\tremaining: 1.8s\n",
      "6682:\tlearn: 0.0000000\ttotal: 3.62s\tremaining: 1.8s\n",
      "6683:\tlearn: 0.0000000\ttotal: 3.62s\tremaining: 1.8s\n",
      "6684:\tlearn: 0.0000000\ttotal: 3.62s\tremaining: 1.8s\n",
      "6685:\tlearn: 0.0000000\ttotal: 3.62s\tremaining: 1.79s\n",
      "6686:\tlearn: 0.0000000\ttotal: 3.62s\tremaining: 1.79s\n",
      "6687:\tlearn: 0.0000000\ttotal: 3.62s\tremaining: 1.79s\n",
      "6688:\tlearn: 0.0000000\ttotal: 3.62s\tremaining: 1.79s\n",
      "6689:\tlearn: 0.0000000\ttotal: 3.63s\tremaining: 1.79s\n",
      "6690:\tlearn: 0.0000000\ttotal: 3.63s\tremaining: 1.79s\n",
      "6691:\tlearn: 0.0000000\ttotal: 3.63s\tremaining: 1.79s\n",
      "6692:\tlearn: 0.0000000\ttotal: 3.63s\tremaining: 1.79s\n",
      "6693:\tlearn: 0.0000000\ttotal: 3.63s\tremaining: 1.79s\n",
      "6694:\tlearn: 0.0000000\ttotal: 3.63s\tremaining: 1.79s\n",
      "6695:\tlearn: 0.0000000\ttotal: 3.63s\tremaining: 1.79s\n",
      "6696:\tlearn: 0.0000000\ttotal: 3.63s\tremaining: 1.79s\n",
      "6697:\tlearn: 0.0000000\ttotal: 3.63s\tremaining: 1.79s\n",
      "6698:\tlearn: 0.0000000\ttotal: 3.63s\tremaining: 1.79s\n",
      "6699:\tlearn: 0.0000000\ttotal: 3.63s\tremaining: 1.79s\n",
      "6700:\tlearn: 0.0000000\ttotal: 3.63s\tremaining: 1.79s\n",
      "6701:\tlearn: 0.0000000\ttotal: 3.63s\tremaining: 1.79s\n",
      "6702:\tlearn: 0.0000000\ttotal: 3.63s\tremaining: 1.79s\n",
      "6703:\tlearn: 0.0000000\ttotal: 3.63s\tremaining: 1.78s\n",
      "6704:\tlearn: 0.0000000\ttotal: 3.63s\tremaining: 1.78s\n",
      "6705:\tlearn: 0.0000000\ttotal: 3.63s\tremaining: 1.78s\n",
      "6706:\tlearn: 0.0000000\ttotal: 3.63s\tremaining: 1.78s\n",
      "6707:\tlearn: 0.0000000\ttotal: 3.63s\tremaining: 1.78s\n",
      "6708:\tlearn: 0.0000000\ttotal: 3.63s\tremaining: 1.78s\n",
      "6709:\tlearn: 0.0000000\ttotal: 3.63s\tremaining: 1.78s\n",
      "6710:\tlearn: 0.0000000\ttotal: 3.64s\tremaining: 1.78s\n",
      "6711:\tlearn: 0.0000000\ttotal: 3.64s\tremaining: 1.78s\n",
      "6712:\tlearn: 0.0000000\ttotal: 3.64s\tremaining: 1.78s\n",
      "6713:\tlearn: 0.0000000\ttotal: 3.64s\tremaining: 1.78s\n",
      "6714:\tlearn: 0.0000000\ttotal: 3.64s\tremaining: 1.78s\n",
      "6715:\tlearn: 0.0000000\ttotal: 3.64s\tremaining: 1.78s\n",
      "6716:\tlearn: 0.0000000\ttotal: 3.64s\tremaining: 1.78s\n",
      "6717:\tlearn: 0.0000000\ttotal: 3.64s\tremaining: 1.78s\n",
      "6718:\tlearn: 0.0000000\ttotal: 3.64s\tremaining: 1.78s\n",
      "6719:\tlearn: 0.0000000\ttotal: 3.64s\tremaining: 1.78s\n",
      "6720:\tlearn: 0.0000000\ttotal: 3.64s\tremaining: 1.78s\n",
      "6721:\tlearn: 0.0000000\ttotal: 3.64s\tremaining: 1.78s\n",
      "6722:\tlearn: 0.0000000\ttotal: 3.64s\tremaining: 1.77s\n",
      "6723:\tlearn: 0.0000000\ttotal: 3.64s\tremaining: 1.77s\n",
      "6724:\tlearn: 0.0000000\ttotal: 3.64s\tremaining: 1.77s\n",
      "6725:\tlearn: 0.0000000\ttotal: 3.64s\tremaining: 1.77s\n",
      "6726:\tlearn: 0.0000000\ttotal: 3.65s\tremaining: 1.77s\n",
      "6727:\tlearn: 0.0000000\ttotal: 3.65s\tremaining: 1.77s\n",
      "6728:\tlearn: 0.0000000\ttotal: 3.65s\tremaining: 1.77s\n",
      "6729:\tlearn: 0.0000000\ttotal: 3.65s\tremaining: 1.77s\n",
      "6730:\tlearn: 0.0000000\ttotal: 3.65s\tremaining: 1.77s\n",
      "6731:\tlearn: 0.0000000\ttotal: 3.65s\tremaining: 1.77s\n",
      "6732:\tlearn: 0.0000000\ttotal: 3.65s\tremaining: 1.77s\n",
      "6733:\tlearn: 0.0000000\ttotal: 3.65s\tremaining: 1.77s\n",
      "6734:\tlearn: 0.0000000\ttotal: 3.65s\tremaining: 1.77s\n",
      "6735:\tlearn: 0.0000000\ttotal: 3.65s\tremaining: 1.77s\n",
      "6736:\tlearn: 0.0000000\ttotal: 3.65s\tremaining: 1.77s\n",
      "6737:\tlearn: 0.0000000\ttotal: 3.65s\tremaining: 1.77s\n",
      "6738:\tlearn: 0.0000000\ttotal: 3.65s\tremaining: 1.77s\n",
      "6739:\tlearn: 0.0000000\ttotal: 3.65s\tremaining: 1.77s\n",
      "6740:\tlearn: 0.0000000\ttotal: 3.65s\tremaining: 1.76s\n",
      "6741:\tlearn: 0.0000000\ttotal: 3.65s\tremaining: 1.76s\n",
      "6742:\tlearn: 0.0000000\ttotal: 3.65s\tremaining: 1.76s\n",
      "6743:\tlearn: 0.0000000\ttotal: 3.65s\tremaining: 1.76s\n",
      "6744:\tlearn: 0.0000000\ttotal: 3.65s\tremaining: 1.76s\n",
      "6745:\tlearn: 0.0000000\ttotal: 3.66s\tremaining: 1.76s\n",
      "6746:\tlearn: 0.0000000\ttotal: 3.66s\tremaining: 1.76s\n",
      "6747:\tlearn: 0.0000000\ttotal: 3.66s\tremaining: 1.76s\n",
      "6748:\tlearn: 0.0000000\ttotal: 3.66s\tremaining: 1.76s\n",
      "6749:\tlearn: 0.0000000\ttotal: 3.66s\tremaining: 1.76s\n",
      "6750:\tlearn: 0.0000000\ttotal: 3.66s\tremaining: 1.76s\n",
      "6751:\tlearn: 0.0000000\ttotal: 3.66s\tremaining: 1.76s\n",
      "6752:\tlearn: 0.0000000\ttotal: 3.66s\tremaining: 1.76s\n",
      "6753:\tlearn: 0.0000000\ttotal: 3.66s\tremaining: 1.76s\n",
      "6754:\tlearn: 0.0000000\ttotal: 3.66s\tremaining: 1.76s\n",
      "6755:\tlearn: 0.0000000\ttotal: 3.66s\tremaining: 1.76s\n",
      "6756:\tlearn: 0.0000000\ttotal: 3.66s\tremaining: 1.76s\n",
      "6757:\tlearn: 0.0000000\ttotal: 3.66s\tremaining: 1.76s\n",
      "6758:\tlearn: 0.0000000\ttotal: 3.66s\tremaining: 1.76s\n",
      "6759:\tlearn: 0.0000000\ttotal: 3.66s\tremaining: 1.75s\n",
      "6760:\tlearn: 0.0000000\ttotal: 3.66s\tremaining: 1.75s\n",
      "6761:\tlearn: 0.0000000\ttotal: 3.66s\tremaining: 1.75s\n",
      "6762:\tlearn: 0.0000000\ttotal: 3.66s\tremaining: 1.75s\n",
      "6763:\tlearn: 0.0000000\ttotal: 3.67s\tremaining: 1.75s\n",
      "6764:\tlearn: 0.0000000\ttotal: 3.67s\tremaining: 1.75s\n",
      "6765:\tlearn: 0.0000000\ttotal: 3.67s\tremaining: 1.75s\n",
      "6766:\tlearn: 0.0000000\ttotal: 3.67s\tremaining: 1.75s\n",
      "6767:\tlearn: 0.0000000\ttotal: 3.67s\tremaining: 1.75s\n",
      "6768:\tlearn: 0.0000000\ttotal: 3.67s\tremaining: 1.75s\n",
      "6769:\tlearn: 0.0000000\ttotal: 3.67s\tremaining: 1.75s\n",
      "6770:\tlearn: 0.0000000\ttotal: 3.67s\tremaining: 1.75s\n",
      "6771:\tlearn: 0.0000000\ttotal: 3.67s\tremaining: 1.75s\n",
      "6772:\tlearn: 0.0000000\ttotal: 3.67s\tremaining: 1.75s\n",
      "6773:\tlearn: 0.0000000\ttotal: 3.67s\tremaining: 1.75s\n",
      "6774:\tlearn: 0.0000000\ttotal: 3.67s\tremaining: 1.75s\n",
      "6775:\tlearn: 0.0000000\ttotal: 3.67s\tremaining: 1.75s\n",
      "6776:\tlearn: 0.0000000\ttotal: 3.67s\tremaining: 1.75s\n",
      "6777:\tlearn: 0.0000000\ttotal: 3.67s\tremaining: 1.75s\n",
      "6778:\tlearn: 0.0000000\ttotal: 3.67s\tremaining: 1.75s\n",
      "6779:\tlearn: 0.0000000\ttotal: 3.67s\tremaining: 1.75s\n",
      "6780:\tlearn: 0.0000000\ttotal: 3.67s\tremaining: 1.74s\n",
      "6781:\tlearn: 0.0000000\ttotal: 3.67s\tremaining: 1.74s\n",
      "6782:\tlearn: 0.0000000\ttotal: 3.68s\tremaining: 1.74s\n",
      "6783:\tlearn: 0.0000000\ttotal: 3.68s\tremaining: 1.74s\n",
      "6784:\tlearn: 0.0000000\ttotal: 3.68s\tremaining: 1.74s\n",
      "6785:\tlearn: 0.0000000\ttotal: 3.68s\tremaining: 1.74s\n",
      "6786:\tlearn: 0.0000000\ttotal: 3.68s\tremaining: 1.74s\n",
      "6787:\tlearn: 0.0000000\ttotal: 3.68s\tremaining: 1.74s\n",
      "6788:\tlearn: 0.0000000\ttotal: 3.68s\tremaining: 1.74s\n",
      "6789:\tlearn: 0.0000000\ttotal: 3.68s\tremaining: 1.74s\n",
      "6790:\tlearn: 0.0000000\ttotal: 3.68s\tremaining: 1.74s\n",
      "6791:\tlearn: 0.0000000\ttotal: 3.68s\tremaining: 1.74s\n",
      "6792:\tlearn: 0.0000000\ttotal: 3.68s\tremaining: 1.74s\n",
      "6793:\tlearn: 0.0000000\ttotal: 3.68s\tremaining: 1.74s\n",
      "6794:\tlearn: 0.0000000\ttotal: 3.68s\tremaining: 1.74s\n",
      "6795:\tlearn: 0.0000000\ttotal: 3.68s\tremaining: 1.74s\n",
      "6796:\tlearn: 0.0000000\ttotal: 3.68s\tremaining: 1.74s\n",
      "6797:\tlearn: 0.0000000\ttotal: 3.68s\tremaining: 1.74s\n",
      "6798:\tlearn: 0.0000000\ttotal: 3.69s\tremaining: 1.74s\n",
      "6799:\tlearn: 0.0000000\ttotal: 3.69s\tremaining: 1.73s\n",
      "6800:\tlearn: 0.0000000\ttotal: 3.69s\tremaining: 1.73s\n",
      "6801:\tlearn: 0.0000000\ttotal: 3.69s\tremaining: 1.73s\n",
      "6802:\tlearn: 0.0000000\ttotal: 3.69s\tremaining: 1.73s\n",
      "6803:\tlearn: 0.0000000\ttotal: 3.69s\tremaining: 1.73s\n",
      "6804:\tlearn: 0.0000000\ttotal: 3.69s\tremaining: 1.73s\n",
      "6805:\tlearn: 0.0000000\ttotal: 3.69s\tremaining: 1.73s\n",
      "6806:\tlearn: 0.0000000\ttotal: 3.69s\tremaining: 1.73s\n",
      "6807:\tlearn: 0.0000000\ttotal: 3.69s\tremaining: 1.73s\n",
      "6808:\tlearn: 0.0000000\ttotal: 3.69s\tremaining: 1.73s\n",
      "6809:\tlearn: 0.0000000\ttotal: 3.69s\tremaining: 1.73s\n",
      "6810:\tlearn: 0.0000000\ttotal: 3.69s\tremaining: 1.73s\n",
      "6811:\tlearn: 0.0000000\ttotal: 3.69s\tremaining: 1.73s\n",
      "6812:\tlearn: 0.0000000\ttotal: 3.69s\tremaining: 1.73s\n",
      "6813:\tlearn: 0.0000000\ttotal: 3.69s\tremaining: 1.73s\n",
      "6814:\tlearn: 0.0000000\ttotal: 3.69s\tremaining: 1.73s\n",
      "6815:\tlearn: 0.0000000\ttotal: 3.69s\tremaining: 1.73s\n",
      "6816:\tlearn: 0.0000000\ttotal: 3.69s\tremaining: 1.72s\n",
      "6817:\tlearn: 0.0000000\ttotal: 3.69s\tremaining: 1.72s\n",
      "6818:\tlearn: 0.0000000\ttotal: 3.69s\tremaining: 1.72s\n",
      "6819:\tlearn: 0.0000000\ttotal: 3.69s\tremaining: 1.72s\n",
      "6820:\tlearn: 0.0000000\ttotal: 3.7s\tremaining: 1.72s\n",
      "6821:\tlearn: 0.0000000\ttotal: 3.7s\tremaining: 1.72s\n",
      "6822:\tlearn: 0.0000000\ttotal: 3.7s\tremaining: 1.72s\n",
      "6823:\tlearn: 0.0000000\ttotal: 3.7s\tremaining: 1.72s\n",
      "6824:\tlearn: 0.0000000\ttotal: 3.7s\tremaining: 1.72s\n",
      "6825:\tlearn: 0.0000000\ttotal: 3.7s\tremaining: 1.72s\n",
      "6826:\tlearn: 0.0000000\ttotal: 3.7s\tremaining: 1.72s\n",
      "6827:\tlearn: 0.0000000\ttotal: 3.7s\tremaining: 1.72s\n",
      "6828:\tlearn: 0.0000000\ttotal: 3.7s\tremaining: 1.72s\n",
      "6829:\tlearn: 0.0000000\ttotal: 3.7s\tremaining: 1.72s\n",
      "6830:\tlearn: 0.0000000\ttotal: 3.7s\tremaining: 1.72s\n",
      "6831:\tlearn: 0.0000000\ttotal: 3.7s\tremaining: 1.72s\n",
      "6832:\tlearn: 0.0000000\ttotal: 3.7s\tremaining: 1.72s\n",
      "6833:\tlearn: 0.0000000\ttotal: 3.7s\tremaining: 1.72s\n",
      "6834:\tlearn: 0.0000000\ttotal: 3.71s\tremaining: 1.72s\n",
      "6835:\tlearn: 0.0000000\ttotal: 3.71s\tremaining: 1.72s\n",
      "6836:\tlearn: 0.0000000\ttotal: 3.71s\tremaining: 1.71s\n",
      "6837:\tlearn: 0.0000000\ttotal: 3.71s\tremaining: 1.71s\n",
      "6838:\tlearn: 0.0000000\ttotal: 3.71s\tremaining: 1.71s\n",
      "6839:\tlearn: 0.0000000\ttotal: 3.71s\tremaining: 1.71s\n",
      "6840:\tlearn: 0.0000000\ttotal: 3.71s\tremaining: 1.71s\n",
      "6841:\tlearn: 0.0000000\ttotal: 3.71s\tremaining: 1.71s\n",
      "6842:\tlearn: 0.0000000\ttotal: 3.71s\tremaining: 1.71s\n",
      "6843:\tlearn: 0.0000000\ttotal: 3.71s\tremaining: 1.71s\n",
      "6844:\tlearn: 0.0000000\ttotal: 3.71s\tremaining: 1.71s\n",
      "6845:\tlearn: 0.0000000\ttotal: 3.71s\tremaining: 1.71s\n",
      "6846:\tlearn: 0.0000000\ttotal: 3.71s\tremaining: 1.71s\n",
      "6847:\tlearn: 0.0000000\ttotal: 3.71s\tremaining: 1.71s\n",
      "6848:\tlearn: 0.0000000\ttotal: 3.71s\tremaining: 1.71s\n",
      "6849:\tlearn: 0.0000000\ttotal: 3.71s\tremaining: 1.71s\n",
      "6850:\tlearn: 0.0000000\ttotal: 3.71s\tremaining: 1.71s\n",
      "6851:\tlearn: 0.0000000\ttotal: 3.71s\tremaining: 1.71s\n",
      "6852:\tlearn: 0.0000000\ttotal: 3.71s\tremaining: 1.71s\n",
      "6853:\tlearn: 0.0000000\ttotal: 3.72s\tremaining: 1.71s\n",
      "6854:\tlearn: 0.0000000\ttotal: 3.72s\tremaining: 1.71s\n",
      "6855:\tlearn: 0.0000000\ttotal: 3.72s\tremaining: 1.7s\n",
      "6856:\tlearn: 0.0000000\ttotal: 3.72s\tremaining: 1.7s\n",
      "6857:\tlearn: 0.0000000\ttotal: 3.72s\tremaining: 1.7s\n",
      "6858:\tlearn: 0.0000000\ttotal: 3.72s\tremaining: 1.7s\n",
      "6859:\tlearn: 0.0000000\ttotal: 3.72s\tremaining: 1.7s\n",
      "6860:\tlearn: 0.0000000\ttotal: 3.72s\tremaining: 1.7s\n",
      "6861:\tlearn: 0.0000000\ttotal: 3.72s\tremaining: 1.7s\n",
      "6862:\tlearn: 0.0000000\ttotal: 3.72s\tremaining: 1.7s\n",
      "6863:\tlearn: 0.0000000\ttotal: 3.72s\tremaining: 1.7s\n",
      "6864:\tlearn: 0.0000000\ttotal: 3.72s\tremaining: 1.7s\n",
      "6865:\tlearn: 0.0000000\ttotal: 3.72s\tremaining: 1.7s\n",
      "6866:\tlearn: 0.0000000\ttotal: 3.73s\tremaining: 1.7s\n",
      "6867:\tlearn: 0.0000000\ttotal: 3.73s\tremaining: 1.7s\n",
      "6868:\tlearn: 0.0000000\ttotal: 3.73s\tremaining: 1.7s\n",
      "6869:\tlearn: 0.0000000\ttotal: 3.73s\tremaining: 1.7s\n",
      "6870:\tlearn: 0.0000000\ttotal: 3.73s\tremaining: 1.7s\n",
      "6871:\tlearn: 0.0000000\ttotal: 3.73s\tremaining: 1.7s\n",
      "6872:\tlearn: 0.0000000\ttotal: 3.73s\tremaining: 1.7s\n",
      "6873:\tlearn: 0.0000000\ttotal: 3.73s\tremaining: 1.7s\n",
      "6874:\tlearn: 0.0000000\ttotal: 3.73s\tremaining: 1.7s\n",
      "6875:\tlearn: 0.0000000\ttotal: 3.73s\tremaining: 1.7s\n",
      "6876:\tlearn: 0.0000000\ttotal: 3.73s\tremaining: 1.7s\n",
      "6877:\tlearn: 0.0000000\ttotal: 3.73s\tremaining: 1.69s\n",
      "6878:\tlearn: 0.0000000\ttotal: 3.73s\tremaining: 1.69s\n",
      "6879:\tlearn: 0.0000000\ttotal: 3.73s\tremaining: 1.69s\n",
      "6880:\tlearn: 0.0000000\ttotal: 3.73s\tremaining: 1.69s\n",
      "6881:\tlearn: 0.0000000\ttotal: 3.73s\tremaining: 1.69s\n",
      "6882:\tlearn: 0.0000000\ttotal: 3.73s\tremaining: 1.69s\n",
      "6883:\tlearn: 0.0000000\ttotal: 3.74s\tremaining: 1.69s\n",
      "6884:\tlearn: 0.0000000\ttotal: 3.74s\tremaining: 1.69s\n",
      "6885:\tlearn: 0.0000000\ttotal: 3.74s\tremaining: 1.69s\n",
      "6886:\tlearn: 0.0000000\ttotal: 3.74s\tremaining: 1.69s\n",
      "6887:\tlearn: 0.0000000\ttotal: 3.74s\tremaining: 1.69s\n",
      "6888:\tlearn: 0.0000000\ttotal: 3.74s\tremaining: 1.69s\n",
      "6889:\tlearn: 0.0000000\ttotal: 3.74s\tremaining: 1.69s\n",
      "6890:\tlearn: 0.0000000\ttotal: 3.74s\tremaining: 1.69s\n",
      "6891:\tlearn: 0.0000000\ttotal: 3.74s\tremaining: 1.69s\n",
      "6892:\tlearn: 0.0000000\ttotal: 3.74s\tremaining: 1.69s\n",
      "6893:\tlearn: 0.0000000\ttotal: 3.74s\tremaining: 1.69s\n",
      "6894:\tlearn: 0.0000000\ttotal: 3.74s\tremaining: 1.69s\n",
      "6895:\tlearn: 0.0000000\ttotal: 3.74s\tremaining: 1.68s\n",
      "6896:\tlearn: 0.0000000\ttotal: 3.74s\tremaining: 1.68s\n",
      "6897:\tlearn: 0.0000000\ttotal: 3.74s\tremaining: 1.68s\n",
      "6898:\tlearn: 0.0000000\ttotal: 3.74s\tremaining: 1.68s\n",
      "6899:\tlearn: 0.0000000\ttotal: 3.75s\tremaining: 1.68s\n",
      "6900:\tlearn: 0.0000000\ttotal: 3.75s\tremaining: 1.68s\n",
      "6901:\tlearn: 0.0000000\ttotal: 3.75s\tremaining: 1.68s\n",
      "6902:\tlearn: 0.0000000\ttotal: 3.75s\tremaining: 1.68s\n",
      "6903:\tlearn: 0.0000000\ttotal: 3.75s\tremaining: 1.68s\n",
      "6904:\tlearn: 0.0000000\ttotal: 3.75s\tremaining: 1.68s\n",
      "6905:\tlearn: 0.0000000\ttotal: 3.75s\tremaining: 1.68s\n",
      "6906:\tlearn: 0.0000000\ttotal: 3.75s\tremaining: 1.68s\n",
      "6907:\tlearn: 0.0000000\ttotal: 3.75s\tremaining: 1.68s\n",
      "6908:\tlearn: 0.0000000\ttotal: 3.75s\tremaining: 1.68s\n",
      "6909:\tlearn: 0.0000000\ttotal: 3.75s\tremaining: 1.68s\n",
      "6910:\tlearn: 0.0000000\ttotal: 3.75s\tremaining: 1.68s\n",
      "6911:\tlearn: 0.0000000\ttotal: 3.75s\tremaining: 1.68s\n",
      "6912:\tlearn: 0.0000000\ttotal: 3.75s\tremaining: 1.68s\n",
      "6913:\tlearn: 0.0000000\ttotal: 3.75s\tremaining: 1.67s\n",
      "6914:\tlearn: 0.0000000\ttotal: 3.75s\tremaining: 1.67s\n",
      "6915:\tlearn: 0.0000000\ttotal: 3.75s\tremaining: 1.67s\n",
      "6916:\tlearn: 0.0000000\ttotal: 3.75s\tremaining: 1.67s\n",
      "6917:\tlearn: 0.0000000\ttotal: 3.75s\tremaining: 1.67s\n",
      "6918:\tlearn: 0.0000000\ttotal: 3.75s\tremaining: 1.67s\n",
      "6919:\tlearn: 0.0000000\ttotal: 3.76s\tremaining: 1.67s\n",
      "6920:\tlearn: 0.0000000\ttotal: 3.76s\tremaining: 1.67s\n",
      "6921:\tlearn: 0.0000000\ttotal: 3.76s\tremaining: 1.67s\n",
      "6922:\tlearn: 0.0000000\ttotal: 3.76s\tremaining: 1.67s\n",
      "6923:\tlearn: 0.0000000\ttotal: 3.76s\tremaining: 1.67s\n",
      "6924:\tlearn: 0.0000000\ttotal: 3.76s\tremaining: 1.67s\n",
      "6925:\tlearn: 0.0000000\ttotal: 3.76s\tremaining: 1.67s\n",
      "6926:\tlearn: 0.0000000\ttotal: 3.76s\tremaining: 1.67s\n",
      "6927:\tlearn: 0.0000000\ttotal: 3.76s\tremaining: 1.67s\n",
      "6928:\tlearn: 0.0000000\ttotal: 3.76s\tremaining: 1.67s\n",
      "6929:\tlearn: 0.0000000\ttotal: 3.76s\tremaining: 1.67s\n",
      "6930:\tlearn: 0.0000000\ttotal: 3.76s\tremaining: 1.67s\n",
      "6931:\tlearn: 0.0000000\ttotal: 3.76s\tremaining: 1.67s\n",
      "6932:\tlearn: 0.0000000\ttotal: 3.76s\tremaining: 1.66s\n",
      "6933:\tlearn: 0.0000000\ttotal: 3.76s\tremaining: 1.66s\n",
      "6934:\tlearn: 0.0000000\ttotal: 3.76s\tremaining: 1.66s\n",
      "6935:\tlearn: 0.0000000\ttotal: 3.77s\tremaining: 1.66s\n",
      "6936:\tlearn: 0.0000000\ttotal: 3.77s\tremaining: 1.66s\n",
      "6937:\tlearn: 0.0000000\ttotal: 3.77s\tremaining: 1.66s\n",
      "6938:\tlearn: 0.0000000\ttotal: 3.77s\tremaining: 1.66s\n",
      "6939:\tlearn: 0.0000000\ttotal: 3.77s\tremaining: 1.66s\n",
      "6940:\tlearn: 0.0000000\ttotal: 3.77s\tremaining: 1.66s\n",
      "6941:\tlearn: 0.0000000\ttotal: 3.77s\tremaining: 1.66s\n",
      "6942:\tlearn: 0.0000000\ttotal: 3.77s\tremaining: 1.66s\n",
      "6943:\tlearn: 0.0000000\ttotal: 3.77s\tremaining: 1.66s\n",
      "6944:\tlearn: 0.0000000\ttotal: 3.77s\tremaining: 1.66s\n",
      "6945:\tlearn: 0.0000000\ttotal: 3.77s\tremaining: 1.66s\n",
      "6946:\tlearn: 0.0000000\ttotal: 3.77s\tremaining: 1.66s\n",
      "6947:\tlearn: 0.0000000\ttotal: 3.77s\tremaining: 1.66s\n",
      "6948:\tlearn: 0.0000000\ttotal: 3.77s\tremaining: 1.66s\n",
      "6949:\tlearn: 0.0000000\ttotal: 3.77s\tremaining: 1.66s\n",
      "6950:\tlearn: 0.0000000\ttotal: 3.77s\tremaining: 1.66s\n",
      "6951:\tlearn: 0.0000000\ttotal: 3.77s\tremaining: 1.65s\n",
      "6952:\tlearn: 0.0000000\ttotal: 3.77s\tremaining: 1.65s\n",
      "6953:\tlearn: 0.0000000\ttotal: 3.77s\tremaining: 1.65s\n",
      "6954:\tlearn: 0.0000000\ttotal: 3.78s\tremaining: 1.65s\n",
      "6955:\tlearn: 0.0000000\ttotal: 3.78s\tremaining: 1.65s\n",
      "6956:\tlearn: 0.0000000\ttotal: 3.78s\tremaining: 1.65s\n",
      "6957:\tlearn: 0.0000000\ttotal: 3.78s\tremaining: 1.65s\n",
      "6958:\tlearn: 0.0000000\ttotal: 3.78s\tremaining: 1.65s\n",
      "6959:\tlearn: 0.0000000\ttotal: 3.78s\tremaining: 1.65s\n",
      "6960:\tlearn: 0.0000000\ttotal: 3.78s\tremaining: 1.65s\n",
      "6961:\tlearn: 0.0000000\ttotal: 3.78s\tremaining: 1.65s\n",
      "6962:\tlearn: 0.0000000\ttotal: 3.78s\tremaining: 1.65s\n",
      "6963:\tlearn: 0.0000000\ttotal: 3.78s\tremaining: 1.65s\n",
      "6964:\tlearn: 0.0000000\ttotal: 3.78s\tremaining: 1.65s\n",
      "6965:\tlearn: 0.0000000\ttotal: 3.78s\tremaining: 1.65s\n",
      "6966:\tlearn: 0.0000000\ttotal: 3.78s\tremaining: 1.65s\n",
      "6967:\tlearn: 0.0000000\ttotal: 3.78s\tremaining: 1.65s\n",
      "6968:\tlearn: 0.0000000\ttotal: 3.78s\tremaining: 1.65s\n",
      "6969:\tlearn: 0.0000000\ttotal: 3.78s\tremaining: 1.65s\n",
      "6970:\tlearn: 0.0000000\ttotal: 3.78s\tremaining: 1.64s\n",
      "6971:\tlearn: 0.0000000\ttotal: 3.79s\tremaining: 1.64s\n",
      "6972:\tlearn: 0.0000000\ttotal: 3.79s\tremaining: 1.64s\n",
      "6973:\tlearn: 0.0000000\ttotal: 3.79s\tremaining: 1.64s\n",
      "6974:\tlearn: 0.0000000\ttotal: 3.79s\tremaining: 1.64s\n",
      "6975:\tlearn: 0.0000000\ttotal: 3.79s\tremaining: 1.64s\n",
      "6976:\tlearn: 0.0000000\ttotal: 3.79s\tremaining: 1.64s\n",
      "6977:\tlearn: 0.0000000\ttotal: 3.79s\tremaining: 1.64s\n",
      "6978:\tlearn: 0.0000000\ttotal: 3.79s\tremaining: 1.64s\n",
      "6979:\tlearn: 0.0000000\ttotal: 3.79s\tremaining: 1.64s\n",
      "6980:\tlearn: 0.0000000\ttotal: 3.79s\tremaining: 1.64s\n",
      "6981:\tlearn: 0.0000000\ttotal: 3.79s\tremaining: 1.64s\n",
      "6982:\tlearn: 0.0000000\ttotal: 3.79s\tremaining: 1.64s\n",
      "6983:\tlearn: 0.0000000\ttotal: 3.79s\tremaining: 1.64s\n",
      "6984:\tlearn: 0.0000000\ttotal: 3.79s\tremaining: 1.64s\n",
      "6985:\tlearn: 0.0000000\ttotal: 3.79s\tremaining: 1.64s\n",
      "6986:\tlearn: 0.0000000\ttotal: 3.79s\tremaining: 1.64s\n",
      "6987:\tlearn: 0.0000000\ttotal: 3.79s\tremaining: 1.63s\n",
      "6988:\tlearn: 0.0000000\ttotal: 3.79s\tremaining: 1.63s\n",
      "6989:\tlearn: 0.0000000\ttotal: 3.79s\tremaining: 1.63s\n",
      "6990:\tlearn: 0.0000000\ttotal: 3.79s\tremaining: 1.63s\n",
      "6991:\tlearn: 0.0000000\ttotal: 3.79s\tremaining: 1.63s\n",
      "6992:\tlearn: 0.0000000\ttotal: 3.79s\tremaining: 1.63s\n",
      "6993:\tlearn: 0.0000000\ttotal: 3.8s\tremaining: 1.63s\n",
      "6994:\tlearn: 0.0000000\ttotal: 3.8s\tremaining: 1.63s\n",
      "6995:\tlearn: 0.0000000\ttotal: 3.8s\tremaining: 1.63s\n",
      "6996:\tlearn: 0.0000000\ttotal: 3.8s\tremaining: 1.63s\n",
      "6997:\tlearn: 0.0000000\ttotal: 3.8s\tremaining: 1.63s\n",
      "6998:\tlearn: 0.0000000\ttotal: 3.8s\tremaining: 1.63s\n",
      "6999:\tlearn: 0.0000000\ttotal: 3.8s\tremaining: 1.63s\n",
      "7000:\tlearn: 0.0000000\ttotal: 3.8s\tremaining: 1.63s\n",
      "7001:\tlearn: 0.0000000\ttotal: 3.8s\tremaining: 1.63s\n",
      "7002:\tlearn: 0.0000000\ttotal: 3.8s\tremaining: 1.63s\n",
      "7003:\tlearn: 0.0000000\ttotal: 3.8s\tremaining: 1.63s\n",
      "7004:\tlearn: 0.0000000\ttotal: 3.8s\tremaining: 1.63s\n",
      "7005:\tlearn: 0.0000000\ttotal: 3.8s\tremaining: 1.63s\n",
      "7006:\tlearn: 0.0000000\ttotal: 3.8s\tremaining: 1.62s\n",
      "7007:\tlearn: 0.0000000\ttotal: 3.8s\tremaining: 1.62s\n",
      "7008:\tlearn: 0.0000000\ttotal: 3.8s\tremaining: 1.62s\n",
      "7009:\tlearn: 0.0000000\ttotal: 3.8s\tremaining: 1.62s\n",
      "7010:\tlearn: 0.0000000\ttotal: 3.8s\tremaining: 1.62s\n",
      "7011:\tlearn: 0.0000000\ttotal: 3.81s\tremaining: 1.62s\n",
      "7012:\tlearn: 0.0000000\ttotal: 3.81s\tremaining: 1.62s\n",
      "7013:\tlearn: 0.0000000\ttotal: 3.81s\tremaining: 1.62s\n",
      "7014:\tlearn: 0.0000000\ttotal: 3.81s\tremaining: 1.62s\n",
      "7015:\tlearn: 0.0000000\ttotal: 3.81s\tremaining: 1.62s\n",
      "7016:\tlearn: 0.0000000\ttotal: 3.81s\tremaining: 1.62s\n",
      "7017:\tlearn: 0.0000000\ttotal: 3.81s\tremaining: 1.62s\n",
      "7018:\tlearn: 0.0000000\ttotal: 3.81s\tremaining: 1.62s\n",
      "7019:\tlearn: 0.0000000\ttotal: 3.81s\tremaining: 1.62s\n",
      "7020:\tlearn: 0.0000000\ttotal: 3.81s\tremaining: 1.62s\n",
      "7021:\tlearn: 0.0000000\ttotal: 3.81s\tremaining: 1.61s\n",
      "7022:\tlearn: 0.0000000\ttotal: 3.81s\tremaining: 1.61s\n",
      "7023:\tlearn: 0.0000000\ttotal: 3.81s\tremaining: 1.61s\n",
      "7024:\tlearn: 0.0000000\ttotal: 3.81s\tremaining: 1.61s\n",
      "7025:\tlearn: 0.0000000\ttotal: 3.81s\tremaining: 1.61s\n",
      "7026:\tlearn: 0.0000000\ttotal: 3.81s\tremaining: 1.61s\n",
      "7027:\tlearn: 0.0000000\ttotal: 3.81s\tremaining: 1.61s\n",
      "7028:\tlearn: 0.0000000\ttotal: 3.81s\tremaining: 1.61s\n",
      "7029:\tlearn: 0.0000000\ttotal: 3.81s\tremaining: 1.61s\n",
      "7030:\tlearn: 0.0000000\ttotal: 3.81s\tremaining: 1.61s\n",
      "7031:\tlearn: 0.0000000\ttotal: 3.81s\tremaining: 1.61s\n",
      "7032:\tlearn: 0.0000000\ttotal: 3.82s\tremaining: 1.61s\n",
      "7033:\tlearn: 0.0000000\ttotal: 3.82s\tremaining: 1.61s\n",
      "7034:\tlearn: 0.0000000\ttotal: 3.82s\tremaining: 1.61s\n",
      "7035:\tlearn: 0.0000000\ttotal: 3.82s\tremaining: 1.61s\n",
      "7036:\tlearn: 0.0000000\ttotal: 3.82s\tremaining: 1.61s\n",
      "7037:\tlearn: 0.0000000\ttotal: 3.82s\tremaining: 1.61s\n",
      "7038:\tlearn: 0.0000000\ttotal: 3.82s\tremaining: 1.61s\n",
      "7039:\tlearn: 0.0000000\ttotal: 3.82s\tremaining: 1.61s\n",
      "7040:\tlearn: 0.0000000\ttotal: 3.82s\tremaining: 1.6s\n",
      "7041:\tlearn: 0.0000000\ttotal: 3.82s\tremaining: 1.6s\n",
      "7042:\tlearn: 0.0000000\ttotal: 3.82s\tremaining: 1.6s\n",
      "7043:\tlearn: 0.0000000\ttotal: 3.82s\tremaining: 1.6s\n",
      "7044:\tlearn: 0.0000000\ttotal: 3.82s\tremaining: 1.6s\n",
      "7045:\tlearn: 0.0000000\ttotal: 3.82s\tremaining: 1.6s\n",
      "7046:\tlearn: 0.0000000\ttotal: 3.82s\tremaining: 1.6s\n",
      "7047:\tlearn: 0.0000000\ttotal: 3.82s\tremaining: 1.6s\n",
      "7048:\tlearn: 0.0000000\ttotal: 3.82s\tremaining: 1.6s\n",
      "7049:\tlearn: 0.0000000\ttotal: 3.82s\tremaining: 1.6s\n",
      "7050:\tlearn: 0.0000000\ttotal: 3.83s\tremaining: 1.6s\n",
      "7051:\tlearn: 0.0000000\ttotal: 3.83s\tremaining: 1.6s\n",
      "7052:\tlearn: 0.0000000\ttotal: 3.83s\tremaining: 1.6s\n",
      "7053:\tlearn: 0.0000000\ttotal: 3.83s\tremaining: 1.6s\n",
      "7054:\tlearn: 0.0000000\ttotal: 3.83s\tremaining: 1.6s\n",
      "7055:\tlearn: 0.0000000\ttotal: 3.83s\tremaining: 1.6s\n",
      "7056:\tlearn: 0.0000000\ttotal: 3.83s\tremaining: 1.6s\n",
      "7057:\tlearn: 0.0000000\ttotal: 3.83s\tremaining: 1.6s\n",
      "7058:\tlearn: 0.0000000\ttotal: 3.83s\tremaining: 1.59s\n",
      "7059:\tlearn: 0.0000000\ttotal: 3.83s\tremaining: 1.59s\n",
      "7060:\tlearn: 0.0000000\ttotal: 3.83s\tremaining: 1.59s\n",
      "7061:\tlearn: 0.0000000\ttotal: 3.83s\tremaining: 1.59s\n",
      "7062:\tlearn: 0.0000000\ttotal: 3.83s\tremaining: 1.59s\n",
      "7063:\tlearn: 0.0000000\ttotal: 3.83s\tremaining: 1.59s\n",
      "7064:\tlearn: 0.0000000\ttotal: 3.83s\tremaining: 1.59s\n",
      "7065:\tlearn: 0.0000000\ttotal: 3.83s\tremaining: 1.59s\n",
      "7066:\tlearn: 0.0000000\ttotal: 3.83s\tremaining: 1.59s\n",
      "7067:\tlearn: 0.0000000\ttotal: 3.83s\tremaining: 1.59s\n",
      "7068:\tlearn: 0.0000000\ttotal: 3.83s\tremaining: 1.59s\n",
      "7069:\tlearn: 0.0000000\ttotal: 3.83s\tremaining: 1.59s\n",
      "7070:\tlearn: 0.0000000\ttotal: 3.84s\tremaining: 1.59s\n",
      "7071:\tlearn: 0.0000000\ttotal: 3.84s\tremaining: 1.59s\n",
      "7072:\tlearn: 0.0000000\ttotal: 3.84s\tremaining: 1.59s\n",
      "7073:\tlearn: 0.0000000\ttotal: 3.84s\tremaining: 1.59s\n",
      "7074:\tlearn: 0.0000000\ttotal: 3.84s\tremaining: 1.59s\n",
      "7075:\tlearn: 0.0000000\ttotal: 3.84s\tremaining: 1.59s\n",
      "7076:\tlearn: 0.0000000\ttotal: 3.84s\tremaining: 1.58s\n",
      "7077:\tlearn: 0.0000000\ttotal: 3.84s\tremaining: 1.58s\n",
      "7078:\tlearn: 0.0000000\ttotal: 3.84s\tremaining: 1.58s\n",
      "7079:\tlearn: 0.0000000\ttotal: 3.84s\tremaining: 1.58s\n",
      "7080:\tlearn: 0.0000000\ttotal: 3.87s\tremaining: 1.59s\n",
      "7081:\tlearn: 0.0000000\ttotal: 3.87s\tremaining: 1.59s\n",
      "7082:\tlearn: 0.0000000\ttotal: 3.87s\tremaining: 1.59s\n",
      "7083:\tlearn: 0.0000000\ttotal: 3.87s\tremaining: 1.59s\n",
      "7084:\tlearn: 0.0000000\ttotal: 3.88s\tremaining: 1.6s\n",
      "7085:\tlearn: 0.0000000\ttotal: 3.88s\tremaining: 1.6s\n",
      "7086:\tlearn: 0.0000000\ttotal: 3.88s\tremaining: 1.6s\n",
      "7087:\tlearn: 0.0000000\ttotal: 3.88s\tremaining: 1.59s\n",
      "7088:\tlearn: 0.0000000\ttotal: 3.88s\tremaining: 1.59s\n",
      "7089:\tlearn: 0.0000000\ttotal: 3.88s\tremaining: 1.59s\n",
      "7090:\tlearn: 0.0000000\ttotal: 3.89s\tremaining: 1.59s\n",
      "7091:\tlearn: 0.0000000\ttotal: 3.89s\tremaining: 1.59s\n",
      "7092:\tlearn: 0.0000000\ttotal: 3.89s\tremaining: 1.59s\n",
      "7093:\tlearn: 0.0000000\ttotal: 3.89s\tremaining: 1.59s\n",
      "7094:\tlearn: 0.0000000\ttotal: 3.89s\tremaining: 1.59s\n",
      "7095:\tlearn: 0.0000000\ttotal: 3.89s\tremaining: 1.59s\n",
      "7096:\tlearn: 0.0000000\ttotal: 3.89s\tremaining: 1.59s\n",
      "7097:\tlearn: 0.0000000\ttotal: 3.89s\tremaining: 1.59s\n",
      "7098:\tlearn: 0.0000000\ttotal: 3.89s\tremaining: 1.59s\n",
      "7099:\tlearn: 0.0000000\ttotal: 3.89s\tremaining: 1.59s\n",
      "7100:\tlearn: 0.0000000\ttotal: 3.89s\tremaining: 1.59s\n",
      "7101:\tlearn: 0.0000000\ttotal: 3.89s\tremaining: 1.59s\n",
      "7102:\tlearn: 0.0000000\ttotal: 3.89s\tremaining: 1.59s\n",
      "7103:\tlearn: 0.0000000\ttotal: 3.89s\tremaining: 1.59s\n",
      "7104:\tlearn: 0.0000000\ttotal: 3.9s\tremaining: 1.59s\n",
      "7105:\tlearn: 0.0000000\ttotal: 3.9s\tremaining: 1.59s\n",
      "7106:\tlearn: 0.0000000\ttotal: 3.9s\tremaining: 1.59s\n",
      "7107:\tlearn: 0.0000000\ttotal: 3.9s\tremaining: 1.58s\n",
      "7108:\tlearn: 0.0000000\ttotal: 3.9s\tremaining: 1.58s\n",
      "7109:\tlearn: 0.0000000\ttotal: 3.9s\tremaining: 1.58s\n",
      "7110:\tlearn: 0.0000000\ttotal: 3.9s\tremaining: 1.58s\n",
      "7111:\tlearn: 0.0000000\ttotal: 3.9s\tremaining: 1.58s\n",
      "7112:\tlearn: 0.0000000\ttotal: 3.9s\tremaining: 1.58s\n",
      "7113:\tlearn: 0.0000000\ttotal: 3.9s\tremaining: 1.58s\n",
      "7114:\tlearn: 0.0000000\ttotal: 3.9s\tremaining: 1.58s\n",
      "7115:\tlearn: 0.0000000\ttotal: 3.9s\tremaining: 1.58s\n",
      "7116:\tlearn: 0.0000000\ttotal: 3.91s\tremaining: 1.58s\n",
      "7117:\tlearn: 0.0000000\ttotal: 3.91s\tremaining: 1.58s\n",
      "7118:\tlearn: 0.0000000\ttotal: 3.91s\tremaining: 1.58s\n",
      "7119:\tlearn: 0.0000000\ttotal: 3.91s\tremaining: 1.58s\n",
      "7120:\tlearn: 0.0000000\ttotal: 3.91s\tremaining: 1.58s\n",
      "7121:\tlearn: 0.0000000\ttotal: 3.91s\tremaining: 1.58s\n",
      "7122:\tlearn: 0.0000000\ttotal: 3.91s\tremaining: 1.58s\n",
      "7123:\tlearn: 0.0000000\ttotal: 3.91s\tremaining: 1.58s\n",
      "7124:\tlearn: 0.0000000\ttotal: 3.91s\tremaining: 1.58s\n",
      "7125:\tlearn: 0.0000000\ttotal: 3.91s\tremaining: 1.58s\n",
      "7126:\tlearn: 0.0000000\ttotal: 3.91s\tremaining: 1.58s\n",
      "7127:\tlearn: 0.0000000\ttotal: 3.91s\tremaining: 1.58s\n",
      "7128:\tlearn: 0.0000000\ttotal: 3.91s\tremaining: 1.58s\n",
      "7129:\tlearn: 0.0000000\ttotal: 3.91s\tremaining: 1.57s\n",
      "7130:\tlearn: 0.0000000\ttotal: 3.92s\tremaining: 1.57s\n",
      "7131:\tlearn: 0.0000000\ttotal: 3.92s\tremaining: 1.57s\n",
      "7132:\tlearn: 0.0000000\ttotal: 3.92s\tremaining: 1.57s\n",
      "7133:\tlearn: 0.0000000\ttotal: 3.92s\tremaining: 1.57s\n",
      "7134:\tlearn: 0.0000000\ttotal: 3.92s\tremaining: 1.57s\n",
      "7135:\tlearn: 0.0000000\ttotal: 3.92s\tremaining: 1.57s\n",
      "7136:\tlearn: 0.0000000\ttotal: 3.92s\tremaining: 1.57s\n",
      "7137:\tlearn: 0.0000000\ttotal: 3.92s\tremaining: 1.57s\n",
      "7138:\tlearn: 0.0000000\ttotal: 3.92s\tremaining: 1.57s\n",
      "7139:\tlearn: 0.0000000\ttotal: 3.92s\tremaining: 1.57s\n",
      "7140:\tlearn: 0.0000000\ttotal: 3.92s\tremaining: 1.57s\n",
      "7141:\tlearn: 0.0000000\ttotal: 3.92s\tremaining: 1.57s\n",
      "7142:\tlearn: 0.0000000\ttotal: 3.92s\tremaining: 1.57s\n",
      "7143:\tlearn: 0.0000000\ttotal: 3.92s\tremaining: 1.57s\n",
      "7144:\tlearn: 0.0000000\ttotal: 3.92s\tremaining: 1.57s\n",
      "7145:\tlearn: 0.0000000\ttotal: 3.92s\tremaining: 1.57s\n",
      "7146:\tlearn: 0.0000000\ttotal: 3.92s\tremaining: 1.57s\n",
      "7147:\tlearn: 0.0000000\ttotal: 3.92s\tremaining: 1.57s\n",
      "7148:\tlearn: 0.0000000\ttotal: 3.92s\tremaining: 1.56s\n",
      "7149:\tlearn: 0.0000000\ttotal: 3.93s\tremaining: 1.56s\n",
      "7150:\tlearn: 0.0000000\ttotal: 3.93s\tremaining: 1.56s\n",
      "7151:\tlearn: 0.0000000\ttotal: 3.93s\tremaining: 1.56s\n",
      "7152:\tlearn: 0.0000000\ttotal: 3.93s\tremaining: 1.56s\n",
      "7153:\tlearn: 0.0000000\ttotal: 3.93s\tremaining: 1.56s\n",
      "7154:\tlearn: 0.0000000\ttotal: 3.93s\tremaining: 1.56s\n",
      "7155:\tlearn: 0.0000000\ttotal: 3.93s\tremaining: 1.56s\n",
      "7156:\tlearn: 0.0000000\ttotal: 3.93s\tremaining: 1.56s\n",
      "7157:\tlearn: 0.0000000\ttotal: 3.93s\tremaining: 1.56s\n",
      "7158:\tlearn: 0.0000000\ttotal: 3.93s\tremaining: 1.56s\n",
      "7159:\tlearn: 0.0000000\ttotal: 3.93s\tremaining: 1.56s\n",
      "7160:\tlearn: 0.0000000\ttotal: 3.93s\tremaining: 1.56s\n",
      "7161:\tlearn: 0.0000000\ttotal: 3.93s\tremaining: 1.56s\n",
      "7162:\tlearn: 0.0000000\ttotal: 3.93s\tremaining: 1.56s\n",
      "7163:\tlearn: 0.0000000\ttotal: 3.94s\tremaining: 1.56s\n",
      "7164:\tlearn: 0.0000000\ttotal: 3.94s\tremaining: 1.56s\n",
      "7165:\tlearn: 0.0000000\ttotal: 3.94s\tremaining: 1.56s\n",
      "7166:\tlearn: 0.0000000\ttotal: 3.94s\tremaining: 1.56s\n",
      "7167:\tlearn: 0.0000000\ttotal: 3.94s\tremaining: 1.55s\n",
      "7168:\tlearn: 0.0000000\ttotal: 3.94s\tremaining: 1.55s\n",
      "7169:\tlearn: 0.0000000\ttotal: 3.94s\tremaining: 1.55s\n",
      "7170:\tlearn: 0.0000000\ttotal: 3.94s\tremaining: 1.55s\n",
      "7171:\tlearn: 0.0000000\ttotal: 3.94s\tremaining: 1.55s\n",
      "7172:\tlearn: 0.0000000\ttotal: 3.94s\tremaining: 1.55s\n",
      "7173:\tlearn: 0.0000000\ttotal: 3.94s\tremaining: 1.55s\n",
      "7174:\tlearn: 0.0000000\ttotal: 3.94s\tremaining: 1.55s\n",
      "7175:\tlearn: 0.0000000\ttotal: 3.94s\tremaining: 1.55s\n",
      "7176:\tlearn: 0.0000000\ttotal: 3.94s\tremaining: 1.55s\n",
      "7177:\tlearn: 0.0000000\ttotal: 3.94s\tremaining: 1.55s\n",
      "7178:\tlearn: 0.0000000\ttotal: 3.94s\tremaining: 1.55s\n",
      "7179:\tlearn: 0.0000000\ttotal: 3.94s\tremaining: 1.55s\n",
      "7180:\tlearn: 0.0000000\ttotal: 3.94s\tremaining: 1.55s\n",
      "7181:\tlearn: 0.0000000\ttotal: 3.94s\tremaining: 1.55s\n",
      "7182:\tlearn: 0.0000000\ttotal: 3.94s\tremaining: 1.55s\n",
      "7183:\tlearn: 0.0000000\ttotal: 3.94s\tremaining: 1.55s\n",
      "7184:\tlearn: 0.0000000\ttotal: 3.95s\tremaining: 1.55s\n",
      "7185:\tlearn: 0.0000000\ttotal: 3.95s\tremaining: 1.54s\n",
      "7186:\tlearn: 0.0000000\ttotal: 3.95s\tremaining: 1.54s\n",
      "7187:\tlearn: 0.0000000\ttotal: 3.95s\tremaining: 1.54s\n",
      "7188:\tlearn: 0.0000000\ttotal: 3.95s\tremaining: 1.54s\n",
      "7189:\tlearn: 0.0000000\ttotal: 3.95s\tremaining: 1.54s\n",
      "7190:\tlearn: 0.0000000\ttotal: 3.95s\tremaining: 1.54s\n",
      "7191:\tlearn: 0.0000000\ttotal: 3.95s\tremaining: 1.54s\n",
      "7192:\tlearn: 0.0000000\ttotal: 3.95s\tremaining: 1.54s\n",
      "7193:\tlearn: 0.0000000\ttotal: 3.95s\tremaining: 1.54s\n",
      "7194:\tlearn: 0.0000000\ttotal: 3.95s\tremaining: 1.54s\n",
      "7195:\tlearn: 0.0000000\ttotal: 3.95s\tremaining: 1.54s\n",
      "7196:\tlearn: 0.0000000\ttotal: 3.95s\tremaining: 1.54s\n",
      "7197:\tlearn: 0.0000000\ttotal: 3.95s\tremaining: 1.54s\n",
      "7198:\tlearn: 0.0000000\ttotal: 3.95s\tremaining: 1.54s\n",
      "7199:\tlearn: 0.0000000\ttotal: 3.95s\tremaining: 1.54s\n",
      "7200:\tlearn: 0.0000000\ttotal: 3.95s\tremaining: 1.54s\n",
      "7201:\tlearn: 0.0000000\ttotal: 3.95s\tremaining: 1.54s\n",
      "7202:\tlearn: 0.0000000\ttotal: 3.96s\tremaining: 1.53s\n",
      "7203:\tlearn: 0.0000000\ttotal: 3.96s\tremaining: 1.53s\n",
      "7204:\tlearn: 0.0000000\ttotal: 3.96s\tremaining: 1.53s\n",
      "7205:\tlearn: 0.0000000\ttotal: 3.96s\tremaining: 1.53s\n",
      "7206:\tlearn: 0.0000000\ttotal: 3.96s\tremaining: 1.53s\n",
      "7207:\tlearn: 0.0000000\ttotal: 3.96s\tremaining: 1.53s\n",
      "7208:\tlearn: 0.0000000\ttotal: 3.96s\tremaining: 1.53s\n",
      "7209:\tlearn: 0.0000000\ttotal: 3.96s\tremaining: 1.53s\n",
      "7210:\tlearn: 0.0000000\ttotal: 3.96s\tremaining: 1.53s\n",
      "7211:\tlearn: 0.0000000\ttotal: 3.96s\tremaining: 1.53s\n",
      "7212:\tlearn: 0.0000000\ttotal: 3.96s\tremaining: 1.53s\n",
      "7213:\tlearn: 0.0000000\ttotal: 3.96s\tremaining: 1.53s\n",
      "7214:\tlearn: 0.0000000\ttotal: 3.96s\tremaining: 1.53s\n",
      "7215:\tlearn: 0.0000000\ttotal: 3.96s\tremaining: 1.53s\n",
      "7216:\tlearn: 0.0000000\ttotal: 3.96s\tremaining: 1.53s\n",
      "7217:\tlearn: 0.0000000\ttotal: 3.96s\tremaining: 1.53s\n",
      "7218:\tlearn: 0.0000000\ttotal: 3.96s\tremaining: 1.53s\n",
      "7219:\tlearn: 0.0000000\ttotal: 3.96s\tremaining: 1.53s\n",
      "7220:\tlearn: 0.0000000\ttotal: 3.96s\tremaining: 1.53s\n",
      "7221:\tlearn: 0.0000000\ttotal: 3.97s\tremaining: 1.52s\n",
      "7222:\tlearn: 0.0000000\ttotal: 3.97s\tremaining: 1.52s\n",
      "7223:\tlearn: 0.0000000\ttotal: 3.97s\tremaining: 1.52s\n",
      "7224:\tlearn: 0.0000000\ttotal: 3.97s\tremaining: 1.52s\n",
      "7225:\tlearn: 0.0000000\ttotal: 3.97s\tremaining: 1.52s\n",
      "7226:\tlearn: 0.0000000\ttotal: 3.97s\tremaining: 1.52s\n",
      "7227:\tlearn: 0.0000000\ttotal: 3.97s\tremaining: 1.52s\n",
      "7228:\tlearn: 0.0000000\ttotal: 3.97s\tremaining: 1.52s\n",
      "7229:\tlearn: 0.0000000\ttotal: 3.97s\tremaining: 1.52s\n",
      "7230:\tlearn: 0.0000000\ttotal: 3.97s\tremaining: 1.52s\n",
      "7231:\tlearn: 0.0000000\ttotal: 3.97s\tremaining: 1.52s\n",
      "7232:\tlearn: 0.0000000\ttotal: 3.97s\tremaining: 1.52s\n",
      "7233:\tlearn: 0.0000000\ttotal: 3.97s\tremaining: 1.52s\n",
      "7234:\tlearn: 0.0000000\ttotal: 3.97s\tremaining: 1.52s\n",
      "7235:\tlearn: 0.0000000\ttotal: 3.97s\tremaining: 1.52s\n",
      "7236:\tlearn: 0.0000000\ttotal: 3.97s\tremaining: 1.52s\n",
      "7237:\tlearn: 0.0000000\ttotal: 3.97s\tremaining: 1.52s\n",
      "7238:\tlearn: 0.0000000\ttotal: 3.98s\tremaining: 1.52s\n",
      "7239:\tlearn: 0.0000000\ttotal: 3.98s\tremaining: 1.51s\n",
      "7240:\tlearn: 0.0000000\ttotal: 3.98s\tremaining: 1.51s\n",
      "7241:\tlearn: 0.0000000\ttotal: 3.98s\tremaining: 1.51s\n",
      "7242:\tlearn: 0.0000000\ttotal: 3.98s\tremaining: 1.51s\n",
      "7243:\tlearn: 0.0000000\ttotal: 3.98s\tremaining: 1.51s\n",
      "7244:\tlearn: 0.0000000\ttotal: 3.98s\tremaining: 1.51s\n",
      "7245:\tlearn: 0.0000000\ttotal: 3.98s\tremaining: 1.51s\n",
      "7246:\tlearn: 0.0000000\ttotal: 3.98s\tremaining: 1.51s\n",
      "7247:\tlearn: 0.0000000\ttotal: 3.98s\tremaining: 1.51s\n",
      "7248:\tlearn: 0.0000000\ttotal: 3.98s\tremaining: 1.51s\n",
      "7249:\tlearn: 0.0000000\ttotal: 3.98s\tremaining: 1.51s\n",
      "7250:\tlearn: 0.0000000\ttotal: 3.98s\tremaining: 1.51s\n",
      "7251:\tlearn: 0.0000000\ttotal: 3.98s\tremaining: 1.51s\n",
      "7252:\tlearn: 0.0000000\ttotal: 3.98s\tremaining: 1.51s\n",
      "7253:\tlearn: 0.0000000\ttotal: 3.98s\tremaining: 1.51s\n",
      "7254:\tlearn: 0.0000000\ttotal: 3.98s\tremaining: 1.51s\n",
      "7255:\tlearn: 0.0000000\ttotal: 3.98s\tremaining: 1.51s\n",
      "7256:\tlearn: 0.0000000\ttotal: 3.98s\tremaining: 1.51s\n",
      "7257:\tlearn: 0.0000000\ttotal: 3.98s\tremaining: 1.5s\n",
      "7258:\tlearn: 0.0000000\ttotal: 3.98s\tremaining: 1.5s\n",
      "7259:\tlearn: 0.0000000\ttotal: 3.99s\tremaining: 1.5s\n",
      "7260:\tlearn: 0.0000000\ttotal: 3.99s\tremaining: 1.5s\n",
      "7261:\tlearn: 0.0000000\ttotal: 3.99s\tremaining: 1.5s\n",
      "7262:\tlearn: 0.0000000\ttotal: 3.99s\tremaining: 1.5s\n",
      "7263:\tlearn: 0.0000000\ttotal: 3.99s\tremaining: 1.5s\n",
      "7264:\tlearn: 0.0000000\ttotal: 3.99s\tremaining: 1.5s\n",
      "7265:\tlearn: 0.0000000\ttotal: 3.99s\tremaining: 1.5s\n",
      "7266:\tlearn: 0.0000000\ttotal: 3.99s\tremaining: 1.5s\n",
      "7267:\tlearn: 0.0000000\ttotal: 3.99s\tremaining: 1.5s\n",
      "7268:\tlearn: 0.0000000\ttotal: 3.99s\tremaining: 1.5s\n",
      "7269:\tlearn: 0.0000000\ttotal: 3.99s\tremaining: 1.5s\n",
      "7270:\tlearn: 0.0000000\ttotal: 3.99s\tremaining: 1.5s\n",
      "7271:\tlearn: 0.0000000\ttotal: 3.99s\tremaining: 1.5s\n",
      "7272:\tlearn: 0.0000000\ttotal: 3.99s\tremaining: 1.5s\n",
      "7273:\tlearn: 0.0000000\ttotal: 3.99s\tremaining: 1.5s\n",
      "7274:\tlearn: 0.0000000\ttotal: 3.99s\tremaining: 1.5s\n",
      "7275:\tlearn: 0.0000000\ttotal: 4s\tremaining: 1.5s\n",
      "7276:\tlearn: 0.0000000\ttotal: 4s\tremaining: 1.5s\n",
      "7277:\tlearn: 0.0000000\ttotal: 4s\tremaining: 1.49s\n",
      "7278:\tlearn: 0.0000000\ttotal: 4s\tremaining: 1.49s\n",
      "7279:\tlearn: 0.0000000\ttotal: 4s\tremaining: 1.49s\n",
      "7280:\tlearn: 0.0000000\ttotal: 4s\tremaining: 1.49s\n",
      "7281:\tlearn: 0.0000000\ttotal: 4s\tremaining: 1.49s\n",
      "7282:\tlearn: 0.0000000\ttotal: 4s\tremaining: 1.49s\n",
      "7283:\tlearn: 0.0000000\ttotal: 4s\tremaining: 1.49s\n",
      "7284:\tlearn: 0.0000000\ttotal: 4s\tremaining: 1.49s\n",
      "7285:\tlearn: 0.0000000\ttotal: 4s\tremaining: 1.49s\n",
      "7286:\tlearn: 0.0000000\ttotal: 4s\tremaining: 1.49s\n",
      "7287:\tlearn: 0.0000000\ttotal: 4s\tremaining: 1.49s\n",
      "7288:\tlearn: 0.0000000\ttotal: 4s\tremaining: 1.49s\n",
      "7289:\tlearn: 0.0000000\ttotal: 4s\tremaining: 1.49s\n",
      "7290:\tlearn: 0.0000000\ttotal: 4s\tremaining: 1.49s\n",
      "7291:\tlearn: 0.0000000\ttotal: 4s\tremaining: 1.49s\n",
      "7292:\tlearn: 0.0000000\ttotal: 4s\tremaining: 1.49s\n",
      "7293:\tlearn: 0.0000000\ttotal: 4.01s\tremaining: 1.49s\n",
      "7294:\tlearn: 0.0000000\ttotal: 4.01s\tremaining: 1.49s\n",
      "7295:\tlearn: 0.0000000\ttotal: 4.01s\tremaining: 1.49s\n",
      "7296:\tlearn: 0.0000000\ttotal: 4.01s\tremaining: 1.48s\n",
      "7297:\tlearn: 0.0000000\ttotal: 4.01s\tremaining: 1.48s\n",
      "7298:\tlearn: 0.0000000\ttotal: 4.01s\tremaining: 1.48s\n",
      "7299:\tlearn: 0.0000000\ttotal: 4.01s\tremaining: 1.48s\n",
      "7300:\tlearn: 0.0000000\ttotal: 4.01s\tremaining: 1.48s\n",
      "7301:\tlearn: 0.0000000\ttotal: 4.01s\tremaining: 1.48s\n",
      "7302:\tlearn: 0.0000000\ttotal: 4.01s\tremaining: 1.48s\n",
      "7303:\tlearn: 0.0000000\ttotal: 4.01s\tremaining: 1.48s\n",
      "7304:\tlearn: 0.0000000\ttotal: 4.01s\tremaining: 1.48s\n",
      "7305:\tlearn: 0.0000000\ttotal: 4.01s\tremaining: 1.48s\n",
      "7306:\tlearn: 0.0000000\ttotal: 4.01s\tremaining: 1.48s\n",
      "7307:\tlearn: 0.0000000\ttotal: 4.01s\tremaining: 1.48s\n",
      "7308:\tlearn: 0.0000000\ttotal: 4.01s\tremaining: 1.48s\n",
      "7309:\tlearn: 0.0000000\ttotal: 4.01s\tremaining: 1.48s\n",
      "7310:\tlearn: 0.0000000\ttotal: 4.02s\tremaining: 1.48s\n",
      "7311:\tlearn: 0.0000000\ttotal: 4.02s\tremaining: 1.48s\n",
      "7312:\tlearn: 0.0000000\ttotal: 4.02s\tremaining: 1.48s\n",
      "7313:\tlearn: 0.0000000\ttotal: 4.02s\tremaining: 1.48s\n",
      "7314:\tlearn: 0.0000000\ttotal: 4.02s\tremaining: 1.48s\n",
      "7315:\tlearn: 0.0000000\ttotal: 4.02s\tremaining: 1.47s\n",
      "7316:\tlearn: 0.0000000\ttotal: 4.02s\tremaining: 1.47s\n",
      "7317:\tlearn: 0.0000000\ttotal: 4.02s\tremaining: 1.47s\n",
      "7318:\tlearn: 0.0000000\ttotal: 4.02s\tremaining: 1.47s\n",
      "7319:\tlearn: 0.0000000\ttotal: 4.02s\tremaining: 1.47s\n",
      "7320:\tlearn: 0.0000000\ttotal: 4.02s\tremaining: 1.47s\n",
      "7321:\tlearn: 0.0000000\ttotal: 4.02s\tremaining: 1.47s\n",
      "7322:\tlearn: 0.0000000\ttotal: 4.02s\tremaining: 1.47s\n",
      "7323:\tlearn: 0.0000000\ttotal: 4.02s\tremaining: 1.47s\n",
      "7324:\tlearn: 0.0000000\ttotal: 4.03s\tremaining: 1.47s\n",
      "7325:\tlearn: 0.0000000\ttotal: 4.03s\tremaining: 1.47s\n",
      "7326:\tlearn: 0.0000000\ttotal: 4.03s\tremaining: 1.47s\n",
      "7327:\tlearn: 0.0000000\ttotal: 4.03s\tremaining: 1.47s\n",
      "7328:\tlearn: 0.0000000\ttotal: 4.03s\tremaining: 1.47s\n",
      "7329:\tlearn: 0.0000000\ttotal: 4.03s\tremaining: 1.47s\n",
      "7330:\tlearn: 0.0000000\ttotal: 4.03s\tremaining: 1.47s\n",
      "7331:\tlearn: 0.0000000\ttotal: 4.03s\tremaining: 1.47s\n",
      "7332:\tlearn: 0.0000000\ttotal: 4.03s\tremaining: 1.47s\n",
      "7333:\tlearn: 0.0000000\ttotal: 4.03s\tremaining: 1.47s\n",
      "7334:\tlearn: 0.0000000\ttotal: 4.03s\tremaining: 1.46s\n",
      "7335:\tlearn: 0.0000000\ttotal: 4.03s\tremaining: 1.46s\n",
      "7336:\tlearn: 0.0000000\ttotal: 4.03s\tremaining: 1.46s\n",
      "7337:\tlearn: 0.0000000\ttotal: 4.03s\tremaining: 1.46s\n",
      "7338:\tlearn: 0.0000000\ttotal: 4.03s\tremaining: 1.46s\n",
      "7339:\tlearn: 0.0000000\ttotal: 4.03s\tremaining: 1.46s\n",
      "7340:\tlearn: 0.0000000\ttotal: 4.03s\tremaining: 1.46s\n",
      "7341:\tlearn: 0.0000000\ttotal: 4.04s\tremaining: 1.46s\n",
      "7342:\tlearn: 0.0000000\ttotal: 4.04s\tremaining: 1.46s\n",
      "7343:\tlearn: 0.0000000\ttotal: 4.04s\tremaining: 1.46s\n",
      "7344:\tlearn: 0.0000000\ttotal: 4.04s\tremaining: 1.46s\n",
      "7345:\tlearn: 0.0000000\ttotal: 4.04s\tremaining: 1.46s\n",
      "7346:\tlearn: 0.0000000\ttotal: 4.04s\tremaining: 1.46s\n",
      "7347:\tlearn: 0.0000000\ttotal: 4.04s\tremaining: 1.46s\n",
      "7348:\tlearn: 0.0000000\ttotal: 4.04s\tremaining: 1.46s\n",
      "7349:\tlearn: 0.0000000\ttotal: 4.04s\tremaining: 1.46s\n",
      "7350:\tlearn: 0.0000000\ttotal: 4.04s\tremaining: 1.46s\n",
      "7351:\tlearn: 0.0000000\ttotal: 4.04s\tremaining: 1.46s\n",
      "7352:\tlearn: 0.0000000\ttotal: 4.04s\tremaining: 1.45s\n",
      "7353:\tlearn: 0.0000000\ttotal: 4.04s\tremaining: 1.45s\n",
      "7354:\tlearn: 0.0000000\ttotal: 4.04s\tremaining: 1.45s\n",
      "7355:\tlearn: 0.0000000\ttotal: 4.04s\tremaining: 1.45s\n",
      "7356:\tlearn: 0.0000000\ttotal: 4.04s\tremaining: 1.45s\n",
      "7357:\tlearn: 0.0000000\ttotal: 4.04s\tremaining: 1.45s\n",
      "7358:\tlearn: 0.0000000\ttotal: 4.04s\tremaining: 1.45s\n",
      "7359:\tlearn: 0.0000000\ttotal: 4.04s\tremaining: 1.45s\n",
      "7360:\tlearn: 0.0000000\ttotal: 4.05s\tremaining: 1.45s\n",
      "7361:\tlearn: 0.0000000\ttotal: 4.05s\tremaining: 1.45s\n",
      "7362:\tlearn: 0.0000000\ttotal: 4.05s\tremaining: 1.45s\n",
      "7363:\tlearn: 0.0000000\ttotal: 4.05s\tremaining: 1.45s\n",
      "7364:\tlearn: 0.0000000\ttotal: 4.05s\tremaining: 1.45s\n",
      "7365:\tlearn: 0.0000000\ttotal: 4.05s\tremaining: 1.45s\n",
      "7366:\tlearn: 0.0000000\ttotal: 4.05s\tremaining: 1.45s\n",
      "7367:\tlearn: 0.0000000\ttotal: 4.05s\tremaining: 1.45s\n",
      "7368:\tlearn: 0.0000000\ttotal: 4.05s\tremaining: 1.45s\n",
      "7369:\tlearn: 0.0000000\ttotal: 4.05s\tremaining: 1.45s\n",
      "7370:\tlearn: 0.0000000\ttotal: 4.05s\tremaining: 1.45s\n",
      "7371:\tlearn: 0.0000000\ttotal: 4.05s\tremaining: 1.44s\n",
      "7372:\tlearn: 0.0000000\ttotal: 4.05s\tremaining: 1.44s\n",
      "7373:\tlearn: 0.0000000\ttotal: 4.05s\tremaining: 1.44s\n",
      "7374:\tlearn: 0.0000000\ttotal: 4.05s\tremaining: 1.44s\n",
      "7375:\tlearn: 0.0000000\ttotal: 4.05s\tremaining: 1.44s\n",
      "7376:\tlearn: 0.0000000\ttotal: 4.05s\tremaining: 1.44s\n",
      "7377:\tlearn: 0.0000000\ttotal: 4.05s\tremaining: 1.44s\n",
      "7378:\tlearn: 0.0000000\ttotal: 4.06s\tremaining: 1.44s\n",
      "7379:\tlearn: 0.0000000\ttotal: 4.06s\tremaining: 1.44s\n",
      "7380:\tlearn: 0.0000000\ttotal: 4.06s\tremaining: 1.44s\n",
      "7381:\tlearn: 0.0000000\ttotal: 4.06s\tremaining: 1.44s\n",
      "7382:\tlearn: 0.0000000\ttotal: 4.06s\tremaining: 1.44s\n",
      "7383:\tlearn: 0.0000000\ttotal: 4.06s\tremaining: 1.44s\n",
      "7384:\tlearn: 0.0000000\ttotal: 4.06s\tremaining: 1.44s\n",
      "7385:\tlearn: 0.0000000\ttotal: 4.06s\tremaining: 1.44s\n",
      "7386:\tlearn: 0.0000000\ttotal: 4.06s\tremaining: 1.44s\n",
      "7387:\tlearn: 0.0000000\ttotal: 4.06s\tremaining: 1.44s\n",
      "7388:\tlearn: 0.0000000\ttotal: 4.06s\tremaining: 1.44s\n",
      "7389:\tlearn: 0.0000000\ttotal: 4.06s\tremaining: 1.44s\n",
      "7390:\tlearn: 0.0000000\ttotal: 4.06s\tremaining: 1.43s\n",
      "7391:\tlearn: 0.0000000\ttotal: 4.07s\tremaining: 1.43s\n",
      "7392:\tlearn: 0.0000000\ttotal: 4.07s\tremaining: 1.43s\n",
      "7393:\tlearn: 0.0000000\ttotal: 4.07s\tremaining: 1.43s\n",
      "7394:\tlearn: 0.0000000\ttotal: 4.07s\tremaining: 1.43s\n",
      "7395:\tlearn: 0.0000000\ttotal: 4.07s\tremaining: 1.43s\n",
      "7396:\tlearn: 0.0000000\ttotal: 4.07s\tremaining: 1.43s\n",
      "7397:\tlearn: 0.0000000\ttotal: 4.07s\tremaining: 1.43s\n",
      "7398:\tlearn: 0.0000000\ttotal: 4.07s\tremaining: 1.43s\n",
      "7399:\tlearn: 0.0000000\ttotal: 4.07s\tremaining: 1.43s\n",
      "7400:\tlearn: 0.0000000\ttotal: 4.07s\tremaining: 1.43s\n",
      "7401:\tlearn: 0.0000000\ttotal: 4.07s\tremaining: 1.43s\n",
      "7402:\tlearn: 0.0000000\ttotal: 4.07s\tremaining: 1.43s\n",
      "7403:\tlearn: 0.0000000\ttotal: 4.07s\tremaining: 1.43s\n",
      "7404:\tlearn: 0.0000000\ttotal: 4.07s\tremaining: 1.43s\n",
      "7405:\tlearn: 0.0000000\ttotal: 4.07s\tremaining: 1.43s\n",
      "7406:\tlearn: 0.0000000\ttotal: 4.07s\tremaining: 1.43s\n",
      "7407:\tlearn: 0.0000000\ttotal: 4.07s\tremaining: 1.43s\n",
      "7408:\tlearn: 0.0000000\ttotal: 4.08s\tremaining: 1.43s\n",
      "7409:\tlearn: 0.0000000\ttotal: 4.08s\tremaining: 1.42s\n",
      "7410:\tlearn: 0.0000000\ttotal: 4.08s\tremaining: 1.42s\n",
      "7411:\tlearn: 0.0000000\ttotal: 4.08s\tremaining: 1.42s\n",
      "7412:\tlearn: 0.0000000\ttotal: 4.08s\tremaining: 1.42s\n",
      "7413:\tlearn: 0.0000000\ttotal: 4.08s\tremaining: 1.42s\n",
      "7414:\tlearn: 0.0000000\ttotal: 4.08s\tremaining: 1.42s\n",
      "7415:\tlearn: 0.0000000\ttotal: 4.08s\tremaining: 1.42s\n",
      "7416:\tlearn: 0.0000000\ttotal: 4.08s\tremaining: 1.42s\n",
      "7417:\tlearn: 0.0000000\ttotal: 4.08s\tremaining: 1.42s\n",
      "7418:\tlearn: 0.0000000\ttotal: 4.08s\tremaining: 1.42s\n",
      "7419:\tlearn: 0.0000000\ttotal: 4.08s\tremaining: 1.42s\n",
      "7420:\tlearn: 0.0000000\ttotal: 4.08s\tremaining: 1.42s\n",
      "7421:\tlearn: 0.0000000\ttotal: 4.08s\tremaining: 1.42s\n",
      "7422:\tlearn: 0.0000000\ttotal: 4.08s\tremaining: 1.42s\n",
      "7423:\tlearn: 0.0000000\ttotal: 4.08s\tremaining: 1.42s\n",
      "7424:\tlearn: 0.0000000\ttotal: 4.08s\tremaining: 1.42s\n",
      "7425:\tlearn: 0.0000000\ttotal: 4.08s\tremaining: 1.42s\n",
      "7426:\tlearn: 0.0000000\ttotal: 4.08s\tremaining: 1.42s\n",
      "7427:\tlearn: 0.0000000\ttotal: 4.09s\tremaining: 1.42s\n",
      "7428:\tlearn: 0.0000000\ttotal: 4.09s\tremaining: 1.41s\n",
      "7429:\tlearn: 0.0000000\ttotal: 4.09s\tremaining: 1.41s\n",
      "7430:\tlearn: 0.0000000\ttotal: 4.09s\tremaining: 1.41s\n",
      "7431:\tlearn: 0.0000000\ttotal: 4.09s\tremaining: 1.41s\n",
      "7432:\tlearn: 0.0000000\ttotal: 4.09s\tremaining: 1.41s\n",
      "7433:\tlearn: 0.0000000\ttotal: 4.09s\tremaining: 1.41s\n",
      "7434:\tlearn: 0.0000000\ttotal: 4.09s\tremaining: 1.41s\n",
      "7435:\tlearn: 0.0000000\ttotal: 4.09s\tremaining: 1.41s\n",
      "7436:\tlearn: 0.0000000\ttotal: 4.09s\tremaining: 1.41s\n",
      "7437:\tlearn: 0.0000000\ttotal: 4.09s\tremaining: 1.41s\n",
      "7438:\tlearn: 0.0000000\ttotal: 4.09s\tremaining: 1.41s\n",
      "7439:\tlearn: 0.0000000\ttotal: 4.09s\tremaining: 1.41s\n",
      "7440:\tlearn: 0.0000000\ttotal: 4.09s\tremaining: 1.41s\n",
      "7441:\tlearn: 0.0000000\ttotal: 4.09s\tremaining: 1.41s\n",
      "7442:\tlearn: 0.0000000\ttotal: 4.09s\tremaining: 1.41s\n",
      "7443:\tlearn: 0.0000000\ttotal: 4.1s\tremaining: 1.41s\n",
      "7444:\tlearn: 0.0000000\ttotal: 4.1s\tremaining: 1.41s\n",
      "7445:\tlearn: 0.0000000\ttotal: 4.1s\tremaining: 1.41s\n",
      "7446:\tlearn: 0.0000000\ttotal: 4.1s\tremaining: 1.4s\n",
      "7447:\tlearn: 0.0000000\ttotal: 4.1s\tremaining: 1.4s\n",
      "7448:\tlearn: 0.0000000\ttotal: 4.1s\tremaining: 1.4s\n",
      "7449:\tlearn: 0.0000000\ttotal: 4.1s\tremaining: 1.4s\n",
      "7450:\tlearn: 0.0000000\ttotal: 4.1s\tremaining: 1.4s\n",
      "7451:\tlearn: 0.0000000\ttotal: 4.1s\tremaining: 1.4s\n",
      "7452:\tlearn: 0.0000000\ttotal: 4.1s\tremaining: 1.4s\n",
      "7453:\tlearn: 0.0000000\ttotal: 4.1s\tremaining: 1.4s\n",
      "7454:\tlearn: 0.0000000\ttotal: 4.1s\tremaining: 1.4s\n",
      "7455:\tlearn: 0.0000000\ttotal: 4.1s\tremaining: 1.4s\n",
      "7456:\tlearn: 0.0000000\ttotal: 4.1s\tremaining: 1.4s\n",
      "7457:\tlearn: 0.0000000\ttotal: 4.1s\tremaining: 1.4s\n",
      "7458:\tlearn: 0.0000000\ttotal: 4.11s\tremaining: 1.4s\n",
      "7459:\tlearn: 0.0000000\ttotal: 4.11s\tremaining: 1.4s\n",
      "7460:\tlearn: 0.0000000\ttotal: 4.11s\tremaining: 1.4s\n",
      "7461:\tlearn: 0.0000000\ttotal: 4.11s\tremaining: 1.4s\n",
      "7462:\tlearn: 0.0000000\ttotal: 4.11s\tremaining: 1.4s\n",
      "7463:\tlearn: 0.0000000\ttotal: 4.11s\tremaining: 1.4s\n",
      "7464:\tlearn: 0.0000000\ttotal: 4.11s\tremaining: 1.4s\n",
      "7465:\tlearn: 0.0000000\ttotal: 4.11s\tremaining: 1.39s\n",
      "7466:\tlearn: 0.0000000\ttotal: 4.11s\tremaining: 1.39s\n",
      "7467:\tlearn: 0.0000000\ttotal: 4.11s\tremaining: 1.39s\n",
      "7468:\tlearn: 0.0000000\ttotal: 4.11s\tremaining: 1.39s\n",
      "7469:\tlearn: 0.0000000\ttotal: 4.11s\tremaining: 1.39s\n",
      "7470:\tlearn: 0.0000000\ttotal: 4.11s\tremaining: 1.39s\n",
      "7471:\tlearn: 0.0000000\ttotal: 4.11s\tremaining: 1.39s\n",
      "7472:\tlearn: 0.0000000\ttotal: 4.11s\tremaining: 1.39s\n",
      "7473:\tlearn: 0.0000000\ttotal: 4.11s\tremaining: 1.39s\n",
      "7474:\tlearn: 0.0000000\ttotal: 4.11s\tremaining: 1.39s\n",
      "7475:\tlearn: 0.0000000\ttotal: 4.11s\tremaining: 1.39s\n",
      "7476:\tlearn: 0.0000000\ttotal: 4.12s\tremaining: 1.39s\n",
      "7477:\tlearn: 0.0000000\ttotal: 4.12s\tremaining: 1.39s\n",
      "7478:\tlearn: 0.0000000\ttotal: 4.12s\tremaining: 1.39s\n",
      "7479:\tlearn: 0.0000000\ttotal: 4.12s\tremaining: 1.39s\n",
      "7480:\tlearn: 0.0000000\ttotal: 4.12s\tremaining: 1.39s\n",
      "7481:\tlearn: 0.0000000\ttotal: 4.12s\tremaining: 1.39s\n",
      "7482:\tlearn: 0.0000000\ttotal: 4.12s\tremaining: 1.39s\n",
      "7483:\tlearn: 0.0000000\ttotal: 4.12s\tremaining: 1.39s\n",
      "7484:\tlearn: 0.0000000\ttotal: 4.12s\tremaining: 1.38s\n",
      "7485:\tlearn: 0.0000000\ttotal: 4.12s\tremaining: 1.38s\n",
      "7486:\tlearn: 0.0000000\ttotal: 4.12s\tremaining: 1.38s\n",
      "7487:\tlearn: 0.0000000\ttotal: 4.12s\tremaining: 1.38s\n",
      "7488:\tlearn: 0.0000000\ttotal: 4.12s\tremaining: 1.38s\n",
      "7489:\tlearn: 0.0000000\ttotal: 4.12s\tremaining: 1.38s\n",
      "7490:\tlearn: 0.0000000\ttotal: 4.12s\tremaining: 1.38s\n",
      "7491:\tlearn: 0.0000000\ttotal: 4.12s\tremaining: 1.38s\n",
      "7492:\tlearn: 0.0000000\ttotal: 4.13s\tremaining: 1.38s\n",
      "7493:\tlearn: 0.0000000\ttotal: 4.13s\tremaining: 1.38s\n",
      "7494:\tlearn: 0.0000000\ttotal: 4.13s\tremaining: 1.38s\n",
      "7495:\tlearn: 0.0000000\ttotal: 4.13s\tremaining: 1.38s\n",
      "7496:\tlearn: 0.0000000\ttotal: 4.13s\tremaining: 1.38s\n",
      "7497:\tlearn: 0.0000000\ttotal: 4.13s\tremaining: 1.38s\n",
      "7498:\tlearn: 0.0000000\ttotal: 4.13s\tremaining: 1.38s\n",
      "7499:\tlearn: 0.0000000\ttotal: 4.13s\tremaining: 1.38s\n",
      "7500:\tlearn: 0.0000000\ttotal: 4.13s\tremaining: 1.38s\n",
      "7501:\tlearn: 0.0000000\ttotal: 4.13s\tremaining: 1.38s\n",
      "7502:\tlearn: 0.0000000\ttotal: 4.13s\tremaining: 1.38s\n",
      "7503:\tlearn: 0.0000000\ttotal: 4.13s\tremaining: 1.37s\n",
      "7504:\tlearn: 0.0000000\ttotal: 4.13s\tremaining: 1.37s\n",
      "7505:\tlearn: 0.0000000\ttotal: 4.13s\tremaining: 1.37s\n",
      "7506:\tlearn: 0.0000000\ttotal: 4.13s\tremaining: 1.37s\n",
      "7507:\tlearn: 0.0000000\ttotal: 4.13s\tremaining: 1.37s\n",
      "7508:\tlearn: 0.0000000\ttotal: 4.13s\tremaining: 1.37s\n",
      "7509:\tlearn: 0.0000000\ttotal: 4.14s\tremaining: 1.37s\n",
      "7510:\tlearn: 0.0000000\ttotal: 4.14s\tremaining: 1.37s\n",
      "7511:\tlearn: 0.0000000\ttotal: 4.14s\tremaining: 1.37s\n",
      "7512:\tlearn: 0.0000000\ttotal: 4.14s\tremaining: 1.37s\n",
      "7513:\tlearn: 0.0000000\ttotal: 4.14s\tremaining: 1.37s\n",
      "7514:\tlearn: 0.0000000\ttotal: 4.14s\tremaining: 1.37s\n",
      "7515:\tlearn: 0.0000000\ttotal: 4.14s\tremaining: 1.37s\n",
      "7516:\tlearn: 0.0000000\ttotal: 4.14s\tremaining: 1.37s\n",
      "7517:\tlearn: 0.0000000\ttotal: 4.14s\tremaining: 1.37s\n",
      "7518:\tlearn: 0.0000000\ttotal: 4.14s\tremaining: 1.37s\n",
      "7519:\tlearn: 0.0000000\ttotal: 4.14s\tremaining: 1.36s\n",
      "7520:\tlearn: 0.0000000\ttotal: 4.14s\tremaining: 1.36s\n",
      "7521:\tlearn: 0.0000000\ttotal: 4.14s\tremaining: 1.36s\n",
      "7522:\tlearn: 0.0000000\ttotal: 4.14s\tremaining: 1.36s\n",
      "7523:\tlearn: 0.0000000\ttotal: 4.14s\tremaining: 1.36s\n",
      "7524:\tlearn: 0.0000000\ttotal: 4.14s\tremaining: 1.36s\n",
      "7525:\tlearn: 0.0000000\ttotal: 4.15s\tremaining: 1.36s\n",
      "7526:\tlearn: 0.0000000\ttotal: 4.15s\tremaining: 1.36s\n",
      "7527:\tlearn: 0.0000000\ttotal: 4.15s\tremaining: 1.36s\n",
      "7528:\tlearn: 0.0000000\ttotal: 4.15s\tremaining: 1.36s\n",
      "7529:\tlearn: 0.0000000\ttotal: 4.15s\tremaining: 1.36s\n",
      "7530:\tlearn: 0.0000000\ttotal: 4.15s\tremaining: 1.36s\n",
      "7531:\tlearn: 0.0000000\ttotal: 4.15s\tremaining: 1.36s\n",
      "7532:\tlearn: 0.0000000\ttotal: 4.15s\tremaining: 1.36s\n",
      "7533:\tlearn: 0.0000000\ttotal: 4.15s\tremaining: 1.36s\n",
      "7534:\tlearn: 0.0000000\ttotal: 4.15s\tremaining: 1.36s\n",
      "7535:\tlearn: 0.0000000\ttotal: 4.15s\tremaining: 1.36s\n",
      "7536:\tlearn: 0.0000000\ttotal: 4.15s\tremaining: 1.36s\n",
      "7537:\tlearn: 0.0000000\ttotal: 4.15s\tremaining: 1.36s\n",
      "7538:\tlearn: 0.0000000\ttotal: 4.15s\tremaining: 1.35s\n",
      "7539:\tlearn: 0.0000000\ttotal: 4.15s\tremaining: 1.35s\n",
      "7540:\tlearn: 0.0000000\ttotal: 4.15s\tremaining: 1.35s\n",
      "7541:\tlearn: 0.0000000\ttotal: 4.16s\tremaining: 1.35s\n",
      "7542:\tlearn: 0.0000000\ttotal: 4.16s\tremaining: 1.35s\n",
      "7543:\tlearn: 0.0000000\ttotal: 4.16s\tremaining: 1.35s\n",
      "7544:\tlearn: 0.0000000\ttotal: 4.16s\tremaining: 1.35s\n",
      "7545:\tlearn: 0.0000000\ttotal: 4.16s\tremaining: 1.35s\n",
      "7546:\tlearn: 0.0000000\ttotal: 4.16s\tremaining: 1.35s\n",
      "7547:\tlearn: 0.0000000\ttotal: 4.16s\tremaining: 1.35s\n",
      "7548:\tlearn: 0.0000000\ttotal: 4.16s\tremaining: 1.35s\n",
      "7549:\tlearn: 0.0000000\ttotal: 4.16s\tremaining: 1.35s\n",
      "7550:\tlearn: 0.0000000\ttotal: 4.16s\tremaining: 1.35s\n",
      "7551:\tlearn: 0.0000000\ttotal: 4.16s\tremaining: 1.35s\n",
      "7552:\tlearn: 0.0000000\ttotal: 4.16s\tremaining: 1.35s\n",
      "7553:\tlearn: 0.0000000\ttotal: 4.16s\tremaining: 1.35s\n",
      "7554:\tlearn: 0.0000000\ttotal: 4.16s\tremaining: 1.35s\n",
      "7555:\tlearn: 0.0000000\ttotal: 4.16s\tremaining: 1.35s\n",
      "7556:\tlearn: 0.0000000\ttotal: 4.16s\tremaining: 1.35s\n",
      "7557:\tlearn: 0.0000000\ttotal: 4.16s\tremaining: 1.34s\n",
      "7558:\tlearn: 0.0000000\ttotal: 4.16s\tremaining: 1.34s\n",
      "7559:\tlearn: 0.0000000\ttotal: 4.17s\tremaining: 1.34s\n",
      "7560:\tlearn: 0.0000000\ttotal: 4.17s\tremaining: 1.34s\n",
      "7561:\tlearn: 0.0000000\ttotal: 4.17s\tremaining: 1.34s\n",
      "7562:\tlearn: 0.0000000\ttotal: 4.17s\tremaining: 1.34s\n",
      "7563:\tlearn: 0.0000000\ttotal: 4.17s\tremaining: 1.34s\n",
      "7564:\tlearn: 0.0000000\ttotal: 4.17s\tremaining: 1.34s\n",
      "7565:\tlearn: 0.0000000\ttotal: 4.17s\tremaining: 1.34s\n",
      "7566:\tlearn: 0.0000000\ttotal: 4.17s\tremaining: 1.34s\n",
      "7567:\tlearn: 0.0000000\ttotal: 4.17s\tremaining: 1.34s\n",
      "7568:\tlearn: 0.0000000\ttotal: 4.17s\tremaining: 1.34s\n",
      "7569:\tlearn: 0.0000000\ttotal: 4.17s\tremaining: 1.34s\n",
      "7570:\tlearn: 0.0000000\ttotal: 4.17s\tremaining: 1.34s\n",
      "7571:\tlearn: 0.0000000\ttotal: 4.17s\tremaining: 1.34s\n",
      "7572:\tlearn: 0.0000000\ttotal: 4.17s\tremaining: 1.34s\n",
      "7573:\tlearn: 0.0000000\ttotal: 4.17s\tremaining: 1.34s\n",
      "7574:\tlearn: 0.0000000\ttotal: 4.17s\tremaining: 1.34s\n",
      "7575:\tlearn: 0.0000000\ttotal: 4.17s\tremaining: 1.33s\n",
      "7576:\tlearn: 0.0000000\ttotal: 4.17s\tremaining: 1.33s\n",
      "7577:\tlearn: 0.0000000\ttotal: 4.18s\tremaining: 1.33s\n",
      "7578:\tlearn: 0.0000000\ttotal: 4.18s\tremaining: 1.33s\n",
      "7579:\tlearn: 0.0000000\ttotal: 4.18s\tremaining: 1.33s\n",
      "7580:\tlearn: 0.0000000\ttotal: 4.18s\tremaining: 1.33s\n",
      "7581:\tlearn: 0.0000000\ttotal: 4.18s\tremaining: 1.33s\n",
      "7582:\tlearn: 0.0000000\ttotal: 4.18s\tremaining: 1.33s\n",
      "7583:\tlearn: 0.0000000\ttotal: 4.18s\tremaining: 1.33s\n",
      "7584:\tlearn: 0.0000000\ttotal: 4.18s\tremaining: 1.33s\n",
      "7585:\tlearn: 0.0000000\ttotal: 4.18s\tremaining: 1.33s\n",
      "7586:\tlearn: 0.0000000\ttotal: 4.18s\tremaining: 1.33s\n",
      "7587:\tlearn: 0.0000000\ttotal: 4.18s\tremaining: 1.33s\n",
      "7588:\tlearn: 0.0000000\ttotal: 4.18s\tremaining: 1.33s\n",
      "7589:\tlearn: 0.0000000\ttotal: 4.18s\tremaining: 1.33s\n",
      "7590:\tlearn: 0.0000000\ttotal: 4.18s\tremaining: 1.33s\n",
      "7591:\tlearn: 0.0000000\ttotal: 4.18s\tremaining: 1.33s\n",
      "7592:\tlearn: 0.0000000\ttotal: 4.18s\tremaining: 1.33s\n",
      "7593:\tlearn: 0.0000000\ttotal: 4.18s\tremaining: 1.32s\n",
      "7594:\tlearn: 0.0000000\ttotal: 4.18s\tremaining: 1.32s\n",
      "7595:\tlearn: 0.0000000\ttotal: 4.19s\tremaining: 1.32s\n",
      "7596:\tlearn: 0.0000000\ttotal: 4.19s\tremaining: 1.32s\n",
      "7597:\tlearn: 0.0000000\ttotal: 4.19s\tremaining: 1.32s\n",
      "7598:\tlearn: 0.0000000\ttotal: 4.19s\tremaining: 1.32s\n",
      "7599:\tlearn: 0.0000000\ttotal: 4.19s\tremaining: 1.32s\n",
      "7600:\tlearn: 0.0000000\ttotal: 4.19s\tremaining: 1.32s\n",
      "7601:\tlearn: 0.0000000\ttotal: 4.19s\tremaining: 1.32s\n",
      "7602:\tlearn: 0.0000000\ttotal: 4.19s\tremaining: 1.32s\n",
      "7603:\tlearn: 0.0000000\ttotal: 4.19s\tremaining: 1.32s\n",
      "7604:\tlearn: 0.0000000\ttotal: 4.19s\tremaining: 1.32s\n",
      "7605:\tlearn: 0.0000000\ttotal: 4.19s\tremaining: 1.32s\n",
      "7606:\tlearn: 0.0000000\ttotal: 4.19s\tremaining: 1.32s\n",
      "7607:\tlearn: 0.0000000\ttotal: 4.19s\tremaining: 1.32s\n",
      "7608:\tlearn: 0.0000000\ttotal: 4.19s\tremaining: 1.32s\n",
      "7609:\tlearn: 0.0000000\ttotal: 4.19s\tremaining: 1.32s\n",
      "7610:\tlearn: 0.0000000\ttotal: 4.19s\tremaining: 1.32s\n",
      "7611:\tlearn: 0.0000000\ttotal: 4.2s\tremaining: 1.32s\n",
      "7612:\tlearn: 0.0000000\ttotal: 4.2s\tremaining: 1.31s\n",
      "7613:\tlearn: 0.0000000\ttotal: 4.2s\tremaining: 1.31s\n",
      "7614:\tlearn: 0.0000000\ttotal: 4.2s\tremaining: 1.31s\n",
      "7615:\tlearn: 0.0000000\ttotal: 4.2s\tremaining: 1.31s\n",
      "7616:\tlearn: 0.0000000\ttotal: 4.2s\tremaining: 1.31s\n",
      "7617:\tlearn: 0.0000000\ttotal: 4.2s\tremaining: 1.31s\n",
      "7618:\tlearn: 0.0000000\ttotal: 4.2s\tremaining: 1.31s\n",
      "7619:\tlearn: 0.0000000\ttotal: 4.2s\tremaining: 1.31s\n",
      "7620:\tlearn: 0.0000000\ttotal: 4.2s\tremaining: 1.31s\n",
      "7621:\tlearn: 0.0000000\ttotal: 4.2s\tremaining: 1.31s\n",
      "7622:\tlearn: 0.0000000\ttotal: 4.2s\tremaining: 1.31s\n",
      "7623:\tlearn: 0.0000000\ttotal: 4.2s\tremaining: 1.31s\n",
      "7624:\tlearn: 0.0000000\ttotal: 4.2s\tremaining: 1.31s\n",
      "7625:\tlearn: 0.0000000\ttotal: 4.2s\tremaining: 1.31s\n",
      "7626:\tlearn: 0.0000000\ttotal: 4.2s\tremaining: 1.31s\n",
      "7627:\tlearn: 0.0000000\ttotal: 4.2s\tremaining: 1.31s\n",
      "7628:\tlearn: 0.0000000\ttotal: 4.2s\tremaining: 1.31s\n",
      "7629:\tlearn: 0.0000000\ttotal: 4.21s\tremaining: 1.31s\n",
      "7630:\tlearn: 0.0000000\ttotal: 4.21s\tremaining: 1.3s\n",
      "7631:\tlearn: 0.0000000\ttotal: 4.21s\tremaining: 1.3s\n",
      "7632:\tlearn: 0.0000000\ttotal: 4.21s\tremaining: 1.3s\n",
      "7633:\tlearn: 0.0000000\ttotal: 4.21s\tremaining: 1.3s\n",
      "7634:\tlearn: 0.0000000\ttotal: 4.21s\tremaining: 1.3s\n",
      "7635:\tlearn: 0.0000000\ttotal: 4.21s\tremaining: 1.3s\n",
      "7636:\tlearn: 0.0000000\ttotal: 4.21s\tremaining: 1.3s\n",
      "7637:\tlearn: 0.0000000\ttotal: 4.21s\tremaining: 1.3s\n",
      "7638:\tlearn: 0.0000000\ttotal: 4.21s\tremaining: 1.3s\n",
      "7639:\tlearn: 0.0000000\ttotal: 4.21s\tremaining: 1.3s\n",
      "7640:\tlearn: 0.0000000\ttotal: 4.21s\tremaining: 1.3s\n",
      "7641:\tlearn: 0.0000000\ttotal: 4.21s\tremaining: 1.3s\n",
      "7642:\tlearn: 0.0000000\ttotal: 4.21s\tremaining: 1.3s\n",
      "7643:\tlearn: 0.0000000\ttotal: 4.21s\tremaining: 1.3s\n",
      "7644:\tlearn: 0.0000000\ttotal: 4.21s\tremaining: 1.3s\n",
      "7645:\tlearn: 0.0000000\ttotal: 4.21s\tremaining: 1.3s\n",
      "7646:\tlearn: 0.0000000\ttotal: 4.21s\tremaining: 1.3s\n",
      "7647:\tlearn: 0.0000000\ttotal: 4.21s\tremaining: 1.3s\n",
      "7648:\tlearn: 0.0000000\ttotal: 4.21s\tremaining: 1.29s\n",
      "7649:\tlearn: 0.0000000\ttotal: 4.21s\tremaining: 1.29s\n",
      "7650:\tlearn: 0.0000000\ttotal: 4.22s\tremaining: 1.29s\n",
      "7651:\tlearn: 0.0000000\ttotal: 4.22s\tremaining: 1.29s\n",
      "7652:\tlearn: 0.0000000\ttotal: 4.22s\tremaining: 1.29s\n",
      "7653:\tlearn: 0.0000000\ttotal: 4.22s\tremaining: 1.29s\n",
      "7654:\tlearn: 0.0000000\ttotal: 4.22s\tremaining: 1.29s\n",
      "7655:\tlearn: 0.0000000\ttotal: 4.22s\tremaining: 1.29s\n",
      "7656:\tlearn: 0.0000000\ttotal: 4.22s\tremaining: 1.29s\n",
      "7657:\tlearn: 0.0000000\ttotal: 4.22s\tremaining: 1.29s\n",
      "7658:\tlearn: 0.0000000\ttotal: 4.22s\tremaining: 1.29s\n",
      "7659:\tlearn: 0.0000000\ttotal: 4.22s\tremaining: 1.29s\n",
      "7660:\tlearn: 0.0000000\ttotal: 4.22s\tremaining: 1.29s\n",
      "7661:\tlearn: 0.0000000\ttotal: 4.22s\tremaining: 1.29s\n",
      "7662:\tlearn: 0.0000000\ttotal: 4.22s\tremaining: 1.29s\n",
      "7663:\tlearn: 0.0000000\ttotal: 4.22s\tremaining: 1.29s\n",
      "7664:\tlearn: 0.0000000\ttotal: 4.22s\tremaining: 1.29s\n",
      "7665:\tlearn: 0.0000000\ttotal: 4.22s\tremaining: 1.28s\n",
      "7666:\tlearn: 0.0000000\ttotal: 4.22s\tremaining: 1.28s\n",
      "7667:\tlearn: 0.0000000\ttotal: 4.22s\tremaining: 1.28s\n",
      "7668:\tlearn: 0.0000000\ttotal: 4.22s\tremaining: 1.28s\n",
      "7669:\tlearn: 0.0000000\ttotal: 4.22s\tremaining: 1.28s\n",
      "7670:\tlearn: 0.0000000\ttotal: 4.22s\tremaining: 1.28s\n",
      "7671:\tlearn: 0.0000000\ttotal: 4.23s\tremaining: 1.28s\n",
      "7672:\tlearn: 0.0000000\ttotal: 4.23s\tremaining: 1.28s\n",
      "7673:\tlearn: 0.0000000\ttotal: 4.23s\tremaining: 1.28s\n",
      "7674:\tlearn: 0.0000000\ttotal: 4.23s\tremaining: 1.28s\n",
      "7675:\tlearn: 0.0000000\ttotal: 4.23s\tremaining: 1.28s\n",
      "7676:\tlearn: 0.0000000\ttotal: 4.23s\tremaining: 1.28s\n",
      "7677:\tlearn: 0.0000000\ttotal: 4.23s\tremaining: 1.28s\n",
      "7678:\tlearn: 0.0000000\ttotal: 4.23s\tremaining: 1.28s\n",
      "7679:\tlearn: 0.0000000\ttotal: 4.23s\tremaining: 1.28s\n",
      "7680:\tlearn: 0.0000000\ttotal: 4.23s\tremaining: 1.28s\n",
      "7681:\tlearn: 0.0000000\ttotal: 4.23s\tremaining: 1.28s\n",
      "7682:\tlearn: 0.0000000\ttotal: 4.23s\tremaining: 1.28s\n",
      "7683:\tlearn: 0.0000000\ttotal: 4.23s\tremaining: 1.27s\n",
      "7684:\tlearn: 0.0000000\ttotal: 4.23s\tremaining: 1.27s\n",
      "7685:\tlearn: 0.0000000\ttotal: 4.23s\tremaining: 1.27s\n",
      "7686:\tlearn: 0.0000000\ttotal: 4.23s\tremaining: 1.27s\n",
      "7687:\tlearn: 0.0000000\ttotal: 4.23s\tremaining: 1.27s\n",
      "7688:\tlearn: 0.0000000\ttotal: 4.24s\tremaining: 1.27s\n",
      "7689:\tlearn: 0.0000000\ttotal: 4.24s\tremaining: 1.27s\n",
      "7690:\tlearn: 0.0000000\ttotal: 4.24s\tremaining: 1.27s\n",
      "7691:\tlearn: 0.0000000\ttotal: 4.24s\tremaining: 1.27s\n",
      "7692:\tlearn: 0.0000000\ttotal: 4.24s\tremaining: 1.27s\n",
      "7693:\tlearn: 0.0000000\ttotal: 4.24s\tremaining: 1.27s\n",
      "7694:\tlearn: 0.0000000\ttotal: 4.24s\tremaining: 1.27s\n",
      "7695:\tlearn: 0.0000000\ttotal: 4.24s\tremaining: 1.27s\n",
      "7696:\tlearn: 0.0000000\ttotal: 4.24s\tremaining: 1.27s\n",
      "7697:\tlearn: 0.0000000\ttotal: 4.24s\tremaining: 1.27s\n",
      "7698:\tlearn: 0.0000000\ttotal: 4.24s\tremaining: 1.27s\n",
      "7699:\tlearn: 0.0000000\ttotal: 4.24s\tremaining: 1.27s\n",
      "7700:\tlearn: 0.0000000\ttotal: 4.24s\tremaining: 1.27s\n",
      "7701:\tlearn: 0.0000000\ttotal: 4.24s\tremaining: 1.26s\n",
      "7702:\tlearn: 0.0000000\ttotal: 4.24s\tremaining: 1.26s\n",
      "7703:\tlearn: 0.0000000\ttotal: 4.24s\tremaining: 1.26s\n",
      "7704:\tlearn: 0.0000000\ttotal: 4.24s\tremaining: 1.26s\n",
      "7705:\tlearn: 0.0000000\ttotal: 4.24s\tremaining: 1.26s\n",
      "7706:\tlearn: 0.0000000\ttotal: 4.24s\tremaining: 1.26s\n",
      "7707:\tlearn: 0.0000000\ttotal: 4.25s\tremaining: 1.26s\n",
      "7708:\tlearn: 0.0000000\ttotal: 4.25s\tremaining: 1.26s\n",
      "7709:\tlearn: 0.0000000\ttotal: 4.25s\tremaining: 1.26s\n",
      "7710:\tlearn: 0.0000000\ttotal: 4.25s\tremaining: 1.26s\n",
      "7711:\tlearn: 0.0000000\ttotal: 4.25s\tremaining: 1.26s\n",
      "7712:\tlearn: 0.0000000\ttotal: 4.25s\tremaining: 1.26s\n",
      "7713:\tlearn: 0.0000000\ttotal: 4.25s\tremaining: 1.26s\n",
      "7714:\tlearn: 0.0000000\ttotal: 4.25s\tremaining: 1.26s\n",
      "7715:\tlearn: 0.0000000\ttotal: 4.25s\tremaining: 1.26s\n",
      "7716:\tlearn: 0.0000000\ttotal: 4.25s\tremaining: 1.26s\n",
      "7717:\tlearn: 0.0000000\ttotal: 4.25s\tremaining: 1.26s\n",
      "7718:\tlearn: 0.0000000\ttotal: 4.25s\tremaining: 1.26s\n",
      "7719:\tlearn: 0.0000000\ttotal: 4.25s\tremaining: 1.25s\n",
      "7720:\tlearn: 0.0000000\ttotal: 4.25s\tremaining: 1.25s\n",
      "7721:\tlearn: 0.0000000\ttotal: 4.25s\tremaining: 1.25s\n",
      "7722:\tlearn: 0.0000000\ttotal: 4.25s\tremaining: 1.25s\n",
      "7723:\tlearn: 0.0000000\ttotal: 4.25s\tremaining: 1.25s\n",
      "7724:\tlearn: 0.0000000\ttotal: 4.25s\tremaining: 1.25s\n",
      "7725:\tlearn: 0.0000000\ttotal: 4.25s\tremaining: 1.25s\n",
      "7726:\tlearn: 0.0000000\ttotal: 4.25s\tremaining: 1.25s\n",
      "7727:\tlearn: 0.0000000\ttotal: 4.26s\tremaining: 1.25s\n",
      "7728:\tlearn: 0.0000000\ttotal: 4.26s\tremaining: 1.25s\n",
      "7729:\tlearn: 0.0000000\ttotal: 4.26s\tremaining: 1.25s\n",
      "7730:\tlearn: 0.0000000\ttotal: 4.26s\tremaining: 1.25s\n",
      "7731:\tlearn: 0.0000000\ttotal: 4.26s\tremaining: 1.25s\n",
      "7732:\tlearn: 0.0000000\ttotal: 4.26s\tremaining: 1.25s\n",
      "7733:\tlearn: 0.0000000\ttotal: 4.26s\tremaining: 1.25s\n",
      "7734:\tlearn: 0.0000000\ttotal: 4.26s\tremaining: 1.25s\n",
      "7735:\tlearn: 0.0000000\ttotal: 4.26s\tremaining: 1.25s\n",
      "7736:\tlearn: 0.0000000\ttotal: 4.26s\tremaining: 1.25s\n",
      "7737:\tlearn: 0.0000000\ttotal: 4.26s\tremaining: 1.25s\n",
      "7738:\tlearn: 0.0000000\ttotal: 4.26s\tremaining: 1.25s\n",
      "7739:\tlearn: 0.0000000\ttotal: 4.26s\tremaining: 1.24s\n",
      "7740:\tlearn: 0.0000000\ttotal: 4.26s\tremaining: 1.24s\n",
      "7741:\tlearn: 0.0000000\ttotal: 4.26s\tremaining: 1.24s\n",
      "7742:\tlearn: 0.0000000\ttotal: 4.26s\tremaining: 1.24s\n",
      "7743:\tlearn: 0.0000000\ttotal: 4.26s\tremaining: 1.24s\n",
      "7744:\tlearn: 0.0000000\ttotal: 4.26s\tremaining: 1.24s\n",
      "7745:\tlearn: 0.0000000\ttotal: 4.26s\tremaining: 1.24s\n",
      "7746:\tlearn: 0.0000000\ttotal: 4.27s\tremaining: 1.24s\n",
      "7747:\tlearn: 0.0000000\ttotal: 4.27s\tremaining: 1.24s\n",
      "7748:\tlearn: 0.0000000\ttotal: 4.27s\tremaining: 1.24s\n",
      "7749:\tlearn: 0.0000000\ttotal: 4.27s\tremaining: 1.24s\n",
      "7750:\tlearn: 0.0000000\ttotal: 4.27s\tremaining: 1.24s\n",
      "7751:\tlearn: 0.0000000\ttotal: 4.27s\tremaining: 1.24s\n",
      "7752:\tlearn: 0.0000000\ttotal: 4.27s\tremaining: 1.24s\n",
      "7753:\tlearn: 0.0000000\ttotal: 4.28s\tremaining: 1.24s\n",
      "7754:\tlearn: 0.0000000\ttotal: 4.28s\tremaining: 1.24s\n",
      "7755:\tlearn: 0.0000000\ttotal: 4.28s\tremaining: 1.24s\n",
      "7756:\tlearn: 0.0000000\ttotal: 4.28s\tremaining: 1.24s\n",
      "7757:\tlearn: 0.0000000\ttotal: 4.28s\tremaining: 1.24s\n",
      "7758:\tlearn: 0.0000000\ttotal: 4.28s\tremaining: 1.24s\n",
      "7759:\tlearn: 0.0000000\ttotal: 4.28s\tremaining: 1.24s\n",
      "7760:\tlearn: 0.0000000\ttotal: 4.28s\tremaining: 1.24s\n",
      "7761:\tlearn: 0.0000000\ttotal: 4.28s\tremaining: 1.24s\n",
      "7762:\tlearn: 0.0000000\ttotal: 4.29s\tremaining: 1.23s\n",
      "7763:\tlearn: 0.0000000\ttotal: 4.29s\tremaining: 1.23s\n",
      "7764:\tlearn: 0.0000000\ttotal: 4.29s\tremaining: 1.23s\n",
      "7765:\tlearn: 0.0000000\ttotal: 4.29s\tremaining: 1.23s\n",
      "7766:\tlearn: 0.0000000\ttotal: 4.29s\tremaining: 1.23s\n",
      "7767:\tlearn: 0.0000000\ttotal: 4.29s\tremaining: 1.23s\n",
      "7768:\tlearn: 0.0000000\ttotal: 4.29s\tremaining: 1.23s\n",
      "7769:\tlearn: 0.0000000\ttotal: 4.29s\tremaining: 1.23s\n",
      "7770:\tlearn: 0.0000000\ttotal: 4.29s\tremaining: 1.23s\n",
      "7771:\tlearn: 0.0000000\ttotal: 4.29s\tremaining: 1.23s\n",
      "7772:\tlearn: 0.0000000\ttotal: 4.29s\tremaining: 1.23s\n",
      "7773:\tlearn: 0.0000000\ttotal: 4.29s\tremaining: 1.23s\n",
      "7774:\tlearn: 0.0000000\ttotal: 4.29s\tremaining: 1.23s\n",
      "7775:\tlearn: 0.0000000\ttotal: 4.29s\tremaining: 1.23s\n",
      "7776:\tlearn: 0.0000000\ttotal: 4.29s\tremaining: 1.23s\n",
      "7777:\tlearn: 0.0000000\ttotal: 4.29s\tremaining: 1.23s\n",
      "7778:\tlearn: 0.0000000\ttotal: 4.29s\tremaining: 1.23s\n",
      "7779:\tlearn: 0.0000000\ttotal: 4.29s\tremaining: 1.23s\n",
      "7780:\tlearn: 0.0000000\ttotal: 4.29s\tremaining: 1.22s\n",
      "7781:\tlearn: 0.0000000\ttotal: 4.29s\tremaining: 1.22s\n",
      "7782:\tlearn: 0.0000000\ttotal: 4.29s\tremaining: 1.22s\n",
      "7783:\tlearn: 0.0000000\ttotal: 4.3s\tremaining: 1.22s\n",
      "7784:\tlearn: 0.0000000\ttotal: 4.3s\tremaining: 1.22s\n",
      "7785:\tlearn: 0.0000000\ttotal: 4.3s\tremaining: 1.22s\n",
      "7786:\tlearn: 0.0000000\ttotal: 4.3s\tremaining: 1.22s\n",
      "7787:\tlearn: 0.0000000\ttotal: 4.3s\tremaining: 1.22s\n",
      "7788:\tlearn: 0.0000000\ttotal: 4.3s\tremaining: 1.22s\n",
      "7789:\tlearn: 0.0000000\ttotal: 4.3s\tremaining: 1.22s\n",
      "7790:\tlearn: 0.0000000\ttotal: 4.3s\tremaining: 1.22s\n",
      "7791:\tlearn: 0.0000000\ttotal: 4.3s\tremaining: 1.22s\n",
      "7792:\tlearn: 0.0000000\ttotal: 4.3s\tremaining: 1.22s\n",
      "7793:\tlearn: 0.0000000\ttotal: 4.3s\tremaining: 1.22s\n",
      "7794:\tlearn: 0.0000000\ttotal: 4.3s\tremaining: 1.22s\n",
      "7795:\tlearn: 0.0000000\ttotal: 4.3s\tremaining: 1.22s\n",
      "7796:\tlearn: 0.0000000\ttotal: 4.3s\tremaining: 1.22s\n",
      "7797:\tlearn: 0.0000000\ttotal: 4.3s\tremaining: 1.22s\n",
      "7798:\tlearn: 0.0000000\ttotal: 4.3s\tremaining: 1.21s\n",
      "7799:\tlearn: 0.0000000\ttotal: 4.3s\tremaining: 1.21s\n",
      "7800:\tlearn: 0.0000000\ttotal: 4.31s\tremaining: 1.21s\n",
      "7801:\tlearn: 0.0000000\ttotal: 4.31s\tremaining: 1.21s\n",
      "7802:\tlearn: 0.0000000\ttotal: 4.31s\tremaining: 1.21s\n",
      "7803:\tlearn: 0.0000000\ttotal: 4.31s\tremaining: 1.21s\n",
      "7804:\tlearn: 0.0000000\ttotal: 4.31s\tremaining: 1.21s\n",
      "7805:\tlearn: 0.0000000\ttotal: 4.31s\tremaining: 1.21s\n",
      "7806:\tlearn: 0.0000000\ttotal: 4.31s\tremaining: 1.21s\n",
      "7807:\tlearn: 0.0000000\ttotal: 4.31s\tremaining: 1.21s\n",
      "7808:\tlearn: 0.0000000\ttotal: 4.31s\tremaining: 1.21s\n",
      "7809:\tlearn: 0.0000000\ttotal: 4.31s\tremaining: 1.21s\n",
      "7810:\tlearn: 0.0000000\ttotal: 4.31s\tremaining: 1.21s\n",
      "7811:\tlearn: 0.0000000\ttotal: 4.31s\tremaining: 1.21s\n",
      "7812:\tlearn: 0.0000000\ttotal: 4.31s\tremaining: 1.21s\n",
      "7813:\tlearn: 0.0000000\ttotal: 4.31s\tremaining: 1.21s\n",
      "7814:\tlearn: 0.0000000\ttotal: 4.31s\tremaining: 1.21s\n",
      "7815:\tlearn: 0.0000000\ttotal: 4.31s\tremaining: 1.21s\n",
      "7816:\tlearn: 0.0000000\ttotal: 4.31s\tremaining: 1.2s\n",
      "7817:\tlearn: 0.0000000\ttotal: 4.31s\tremaining: 1.2s\n",
      "7818:\tlearn: 0.0000000\ttotal: 4.31s\tremaining: 1.2s\n",
      "7819:\tlearn: 0.0000000\ttotal: 4.32s\tremaining: 1.2s\n",
      "7820:\tlearn: 0.0000000\ttotal: 4.32s\tremaining: 1.2s\n",
      "7821:\tlearn: 0.0000000\ttotal: 4.32s\tremaining: 1.2s\n",
      "7822:\tlearn: 0.0000000\ttotal: 4.32s\tremaining: 1.2s\n",
      "7823:\tlearn: 0.0000000\ttotal: 4.32s\tremaining: 1.2s\n",
      "7824:\tlearn: 0.0000000\ttotal: 4.32s\tremaining: 1.2s\n",
      "7825:\tlearn: 0.0000000\ttotal: 4.32s\tremaining: 1.2s\n",
      "7826:\tlearn: 0.0000000\ttotal: 4.32s\tremaining: 1.2s\n",
      "7827:\tlearn: 0.0000000\ttotal: 4.32s\tremaining: 1.2s\n",
      "7828:\tlearn: 0.0000000\ttotal: 4.32s\tremaining: 1.2s\n",
      "7829:\tlearn: 0.0000000\ttotal: 4.32s\tremaining: 1.2s\n",
      "7830:\tlearn: 0.0000000\ttotal: 4.32s\tremaining: 1.2s\n",
      "7831:\tlearn: 0.0000000\ttotal: 4.32s\tremaining: 1.2s\n",
      "7832:\tlearn: 0.0000000\ttotal: 4.32s\tremaining: 1.2s\n",
      "7833:\tlearn: 0.0000000\ttotal: 4.32s\tremaining: 1.2s\n",
      "7834:\tlearn: 0.0000000\ttotal: 4.32s\tremaining: 1.19s\n",
      "7835:\tlearn: 0.0000000\ttotal: 4.32s\tremaining: 1.19s\n",
      "7836:\tlearn: 0.0000000\ttotal: 4.32s\tremaining: 1.19s\n",
      "7837:\tlearn: 0.0000000\ttotal: 4.32s\tremaining: 1.19s\n",
      "7838:\tlearn: 0.0000000\ttotal: 4.33s\tremaining: 1.19s\n",
      "7839:\tlearn: 0.0000000\ttotal: 4.33s\tremaining: 1.19s\n",
      "7840:\tlearn: 0.0000000\ttotal: 4.33s\tremaining: 1.19s\n",
      "7841:\tlearn: 0.0000000\ttotal: 4.33s\tremaining: 1.19s\n",
      "7842:\tlearn: 0.0000000\ttotal: 4.33s\tremaining: 1.19s\n",
      "7843:\tlearn: 0.0000000\ttotal: 4.33s\tremaining: 1.19s\n",
      "7844:\tlearn: 0.0000000\ttotal: 4.33s\tremaining: 1.19s\n",
      "7845:\tlearn: 0.0000000\ttotal: 4.33s\tremaining: 1.19s\n",
      "7846:\tlearn: 0.0000000\ttotal: 4.33s\tremaining: 1.19s\n",
      "7847:\tlearn: 0.0000000\ttotal: 4.33s\tremaining: 1.19s\n",
      "7848:\tlearn: 0.0000000\ttotal: 4.33s\tremaining: 1.19s\n",
      "7849:\tlearn: 0.0000000\ttotal: 4.33s\tremaining: 1.19s\n",
      "7850:\tlearn: 0.0000000\ttotal: 4.33s\tremaining: 1.19s\n",
      "7851:\tlearn: 0.0000000\ttotal: 4.33s\tremaining: 1.18s\n",
      "7852:\tlearn: 0.0000000\ttotal: 4.33s\tremaining: 1.18s\n",
      "7853:\tlearn: 0.0000000\ttotal: 4.33s\tremaining: 1.18s\n",
      "7854:\tlearn: 0.0000000\ttotal: 4.33s\tremaining: 1.18s\n",
      "7855:\tlearn: 0.0000000\ttotal: 4.33s\tremaining: 1.18s\n",
      "7856:\tlearn: 0.0000000\ttotal: 4.33s\tremaining: 1.18s\n",
      "7857:\tlearn: 0.0000000\ttotal: 4.33s\tremaining: 1.18s\n",
      "7858:\tlearn: 0.0000000\ttotal: 4.34s\tremaining: 1.18s\n",
      "7859:\tlearn: 0.0000000\ttotal: 4.34s\tremaining: 1.18s\n",
      "7860:\tlearn: 0.0000000\ttotal: 4.34s\tremaining: 1.18s\n",
      "7861:\tlearn: 0.0000000\ttotal: 4.34s\tremaining: 1.18s\n",
      "7862:\tlearn: 0.0000000\ttotal: 4.34s\tremaining: 1.18s\n",
      "7863:\tlearn: 0.0000000\ttotal: 4.34s\tremaining: 1.18s\n",
      "7864:\tlearn: 0.0000000\ttotal: 4.34s\tremaining: 1.18s\n",
      "7865:\tlearn: 0.0000000\ttotal: 4.34s\tremaining: 1.18s\n",
      "7866:\tlearn: 0.0000000\ttotal: 4.34s\tremaining: 1.18s\n",
      "7867:\tlearn: 0.0000000\ttotal: 4.34s\tremaining: 1.18s\n",
      "7868:\tlearn: 0.0000000\ttotal: 4.34s\tremaining: 1.18s\n",
      "7869:\tlearn: 0.0000000\ttotal: 4.34s\tremaining: 1.18s\n",
      "7870:\tlearn: 0.0000000\ttotal: 4.34s\tremaining: 1.17s\n",
      "7871:\tlearn: 0.0000000\ttotal: 4.34s\tremaining: 1.17s\n",
      "7872:\tlearn: 0.0000000\ttotal: 4.34s\tremaining: 1.17s\n",
      "7873:\tlearn: 0.0000000\ttotal: 4.34s\tremaining: 1.17s\n",
      "7874:\tlearn: 0.0000000\ttotal: 4.34s\tremaining: 1.17s\n",
      "7875:\tlearn: 0.0000000\ttotal: 4.34s\tremaining: 1.17s\n",
      "7876:\tlearn: 0.0000000\ttotal: 4.34s\tremaining: 1.17s\n",
      "7877:\tlearn: 0.0000000\ttotal: 4.35s\tremaining: 1.17s\n",
      "7878:\tlearn: 0.0000000\ttotal: 4.35s\tremaining: 1.17s\n",
      "7879:\tlearn: 0.0000000\ttotal: 4.35s\tremaining: 1.17s\n",
      "7880:\tlearn: 0.0000000\ttotal: 4.35s\tremaining: 1.17s\n",
      "7881:\tlearn: 0.0000000\ttotal: 4.35s\tremaining: 1.17s\n",
      "7882:\tlearn: 0.0000000\ttotal: 4.35s\tremaining: 1.17s\n",
      "7883:\tlearn: 0.0000000\ttotal: 4.35s\tremaining: 1.17s\n",
      "7884:\tlearn: 0.0000000\ttotal: 4.35s\tremaining: 1.17s\n",
      "7885:\tlearn: 0.0000000\ttotal: 4.35s\tremaining: 1.17s\n",
      "7886:\tlearn: 0.0000000\ttotal: 4.35s\tremaining: 1.17s\n",
      "7887:\tlearn: 0.0000000\ttotal: 4.35s\tremaining: 1.17s\n",
      "7888:\tlearn: 0.0000000\ttotal: 4.35s\tremaining: 1.16s\n",
      "7889:\tlearn: 0.0000000\ttotal: 4.35s\tremaining: 1.16s\n",
      "7890:\tlearn: 0.0000000\ttotal: 4.35s\tremaining: 1.16s\n",
      "7891:\tlearn: 0.0000000\ttotal: 4.35s\tremaining: 1.16s\n",
      "7892:\tlearn: 0.0000000\ttotal: 4.35s\tremaining: 1.16s\n",
      "7893:\tlearn: 0.0000000\ttotal: 4.35s\tremaining: 1.16s\n",
      "7894:\tlearn: 0.0000000\ttotal: 4.35s\tremaining: 1.16s\n",
      "7895:\tlearn: 0.0000000\ttotal: 4.36s\tremaining: 1.16s\n",
      "7896:\tlearn: 0.0000000\ttotal: 4.36s\tremaining: 1.16s\n",
      "7897:\tlearn: 0.0000000\ttotal: 4.36s\tremaining: 1.16s\n",
      "7898:\tlearn: 0.0000000\ttotal: 4.36s\tremaining: 1.16s\n",
      "7899:\tlearn: 0.0000000\ttotal: 4.36s\tremaining: 1.16s\n",
      "7900:\tlearn: 0.0000000\ttotal: 4.36s\tremaining: 1.16s\n",
      "7901:\tlearn: 0.0000000\ttotal: 4.36s\tremaining: 1.16s\n",
      "7902:\tlearn: 0.0000000\ttotal: 4.36s\tremaining: 1.16s\n",
      "7903:\tlearn: 0.0000000\ttotal: 4.36s\tremaining: 1.16s\n",
      "7904:\tlearn: 0.0000000\ttotal: 4.36s\tremaining: 1.16s\n",
      "7905:\tlearn: 0.0000000\ttotal: 4.36s\tremaining: 1.15s\n",
      "7906:\tlearn: 0.0000000\ttotal: 4.36s\tremaining: 1.15s\n",
      "7907:\tlearn: 0.0000000\ttotal: 4.36s\tremaining: 1.15s\n",
      "7908:\tlearn: 0.0000000\ttotal: 4.36s\tremaining: 1.15s\n",
      "7909:\tlearn: 0.0000000\ttotal: 4.36s\tremaining: 1.15s\n",
      "7910:\tlearn: 0.0000000\ttotal: 4.36s\tremaining: 1.15s\n",
      "7911:\tlearn: 0.0000000\ttotal: 4.36s\tremaining: 1.15s\n",
      "7912:\tlearn: 0.0000000\ttotal: 4.36s\tremaining: 1.15s\n",
      "7913:\tlearn: 0.0000000\ttotal: 4.36s\tremaining: 1.15s\n",
      "7914:\tlearn: 0.0000000\ttotal: 4.36s\tremaining: 1.15s\n",
      "7915:\tlearn: 0.0000000\ttotal: 4.37s\tremaining: 1.15s\n",
      "7916:\tlearn: 0.0000000\ttotal: 4.37s\tremaining: 1.15s\n",
      "7917:\tlearn: 0.0000000\ttotal: 4.37s\tremaining: 1.15s\n",
      "7918:\tlearn: 0.0000000\ttotal: 4.37s\tremaining: 1.15s\n",
      "7919:\tlearn: 0.0000000\ttotal: 4.37s\tremaining: 1.15s\n",
      "7920:\tlearn: 0.0000000\ttotal: 4.37s\tremaining: 1.15s\n",
      "7921:\tlearn: 0.0000000\ttotal: 4.37s\tremaining: 1.15s\n",
      "7922:\tlearn: 0.0000000\ttotal: 4.37s\tremaining: 1.15s\n",
      "7923:\tlearn: 0.0000000\ttotal: 4.37s\tremaining: 1.14s\n",
      "7924:\tlearn: 0.0000000\ttotal: 4.37s\tremaining: 1.14s\n",
      "7925:\tlearn: 0.0000000\ttotal: 4.37s\tremaining: 1.14s\n",
      "7926:\tlearn: 0.0000000\ttotal: 4.37s\tremaining: 1.14s\n",
      "7927:\tlearn: 0.0000000\ttotal: 4.37s\tremaining: 1.14s\n",
      "7928:\tlearn: 0.0000000\ttotal: 4.37s\tremaining: 1.14s\n",
      "7929:\tlearn: 0.0000000\ttotal: 4.37s\tremaining: 1.14s\n",
      "7930:\tlearn: 0.0000000\ttotal: 4.37s\tremaining: 1.14s\n",
      "7931:\tlearn: 0.0000000\ttotal: 4.37s\tremaining: 1.14s\n",
      "7932:\tlearn: 0.0000000\ttotal: 4.37s\tremaining: 1.14s\n",
      "7933:\tlearn: 0.0000000\ttotal: 4.37s\tremaining: 1.14s\n",
      "7934:\tlearn: 0.0000000\ttotal: 4.37s\tremaining: 1.14s\n",
      "7935:\tlearn: 0.0000000\ttotal: 4.38s\tremaining: 1.14s\n",
      "7936:\tlearn: 0.0000000\ttotal: 4.38s\tremaining: 1.14s\n",
      "7937:\tlearn: 0.0000000\ttotal: 4.38s\tremaining: 1.14s\n",
      "7938:\tlearn: 0.0000000\ttotal: 4.38s\tremaining: 1.14s\n",
      "7939:\tlearn: 0.0000000\ttotal: 4.38s\tremaining: 1.14s\n",
      "7940:\tlearn: 0.0000000\ttotal: 4.38s\tremaining: 1.14s\n",
      "7941:\tlearn: 0.0000000\ttotal: 4.38s\tremaining: 1.13s\n",
      "7942:\tlearn: 0.0000000\ttotal: 4.38s\tremaining: 1.13s\n",
      "7943:\tlearn: 0.0000000\ttotal: 4.38s\tremaining: 1.13s\n",
      "7944:\tlearn: 0.0000000\ttotal: 4.38s\tremaining: 1.13s\n",
      "7945:\tlearn: 0.0000000\ttotal: 4.38s\tremaining: 1.13s\n",
      "7946:\tlearn: 0.0000000\ttotal: 4.38s\tremaining: 1.13s\n",
      "7947:\tlearn: 0.0000000\ttotal: 4.38s\tremaining: 1.13s\n",
      "7948:\tlearn: 0.0000000\ttotal: 4.38s\tremaining: 1.13s\n",
      "7949:\tlearn: 0.0000000\ttotal: 4.38s\tremaining: 1.13s\n",
      "7950:\tlearn: 0.0000000\ttotal: 4.38s\tremaining: 1.13s\n",
      "7951:\tlearn: 0.0000000\ttotal: 4.38s\tremaining: 1.13s\n",
      "7952:\tlearn: 0.0000000\ttotal: 4.38s\tremaining: 1.13s\n",
      "7953:\tlearn: 0.0000000\ttotal: 4.38s\tremaining: 1.13s\n",
      "7954:\tlearn: 0.0000000\ttotal: 4.38s\tremaining: 1.13s\n",
      "7955:\tlearn: 0.0000000\ttotal: 4.38s\tremaining: 1.13s\n",
      "7956:\tlearn: 0.0000000\ttotal: 4.38s\tremaining: 1.13s\n",
      "7957:\tlearn: 0.0000000\ttotal: 4.39s\tremaining: 1.13s\n",
      "7958:\tlearn: 0.0000000\ttotal: 4.39s\tremaining: 1.12s\n",
      "7959:\tlearn: 0.0000000\ttotal: 4.39s\tremaining: 1.12s\n",
      "7960:\tlearn: 0.0000000\ttotal: 4.39s\tremaining: 1.12s\n",
      "7961:\tlearn: 0.0000000\ttotal: 4.39s\tremaining: 1.12s\n",
      "7962:\tlearn: 0.0000000\ttotal: 4.39s\tremaining: 1.12s\n",
      "7963:\tlearn: 0.0000000\ttotal: 4.39s\tremaining: 1.12s\n",
      "7964:\tlearn: 0.0000000\ttotal: 4.39s\tremaining: 1.12s\n",
      "7965:\tlearn: 0.0000000\ttotal: 4.39s\tremaining: 1.12s\n",
      "7966:\tlearn: 0.0000000\ttotal: 4.39s\tremaining: 1.12s\n",
      "7967:\tlearn: 0.0000000\ttotal: 4.39s\tremaining: 1.12s\n",
      "7968:\tlearn: 0.0000000\ttotal: 4.39s\tremaining: 1.12s\n",
      "7969:\tlearn: 0.0000000\ttotal: 4.39s\tremaining: 1.12s\n",
      "7970:\tlearn: 0.0000000\ttotal: 4.39s\tremaining: 1.12s\n",
      "7971:\tlearn: 0.0000000\ttotal: 4.39s\tremaining: 1.12s\n",
      "7972:\tlearn: 0.0000000\ttotal: 4.39s\tremaining: 1.12s\n",
      "7973:\tlearn: 0.0000000\ttotal: 4.39s\tremaining: 1.12s\n",
      "7974:\tlearn: 0.0000000\ttotal: 4.39s\tremaining: 1.11s\n",
      "7975:\tlearn: 0.0000000\ttotal: 4.39s\tremaining: 1.11s\n",
      "7976:\tlearn: 0.0000000\ttotal: 4.4s\tremaining: 1.11s\n",
      "7977:\tlearn: 0.0000000\ttotal: 4.4s\tremaining: 1.11s\n",
      "7978:\tlearn: 0.0000000\ttotal: 4.4s\tremaining: 1.11s\n",
      "7979:\tlearn: 0.0000000\ttotal: 4.4s\tremaining: 1.11s\n",
      "7980:\tlearn: 0.0000000\ttotal: 4.4s\tremaining: 1.11s\n",
      "7981:\tlearn: 0.0000000\ttotal: 4.4s\tremaining: 1.11s\n",
      "7982:\tlearn: 0.0000000\ttotal: 4.4s\tremaining: 1.11s\n",
      "7983:\tlearn: 0.0000000\ttotal: 4.4s\tremaining: 1.11s\n",
      "7984:\tlearn: 0.0000000\ttotal: 4.4s\tremaining: 1.11s\n",
      "7985:\tlearn: 0.0000000\ttotal: 4.4s\tremaining: 1.11s\n",
      "7986:\tlearn: 0.0000000\ttotal: 4.4s\tremaining: 1.11s\n",
      "7987:\tlearn: 0.0000000\ttotal: 4.4s\tremaining: 1.11s\n",
      "7988:\tlearn: 0.0000000\ttotal: 4.4s\tremaining: 1.11s\n",
      "7989:\tlearn: 0.0000000\ttotal: 4.4s\tremaining: 1.11s\n",
      "7990:\tlearn: 0.0000000\ttotal: 4.4s\tremaining: 1.11s\n",
      "7991:\tlearn: 0.0000000\ttotal: 4.4s\tremaining: 1.11s\n",
      "7992:\tlearn: 0.0000000\ttotal: 4.4s\tremaining: 1.1s\n",
      "7993:\tlearn: 0.0000000\ttotal: 4.4s\tremaining: 1.1s\n",
      "7994:\tlearn: 0.0000000\ttotal: 4.41s\tremaining: 1.1s\n",
      "7995:\tlearn: 0.0000000\ttotal: 4.41s\tremaining: 1.1s\n",
      "7996:\tlearn: 0.0000000\ttotal: 4.41s\tremaining: 1.1s\n",
      "7997:\tlearn: 0.0000000\ttotal: 4.41s\tremaining: 1.1s\n",
      "7998:\tlearn: 0.0000000\ttotal: 4.41s\tremaining: 1.1s\n",
      "7999:\tlearn: 0.0000000\ttotal: 4.41s\tremaining: 1.1s\n",
      "8000:\tlearn: 0.0000000\ttotal: 4.41s\tremaining: 1.1s\n",
      "8001:\tlearn: 0.0000000\ttotal: 4.41s\tremaining: 1.1s\n",
      "8002:\tlearn: 0.0000000\ttotal: 4.41s\tremaining: 1.1s\n",
      "8003:\tlearn: 0.0000000\ttotal: 4.41s\tremaining: 1.1s\n",
      "8004:\tlearn: 0.0000000\ttotal: 4.41s\tremaining: 1.1s\n",
      "8005:\tlearn: 0.0000000\ttotal: 4.41s\tremaining: 1.1s\n",
      "8006:\tlearn: 0.0000000\ttotal: 4.41s\tremaining: 1.1s\n",
      "8007:\tlearn: 0.0000000\ttotal: 4.41s\tremaining: 1.1s\n",
      "8008:\tlearn: 0.0000000\ttotal: 4.41s\tremaining: 1.1s\n",
      "8009:\tlearn: 0.0000000\ttotal: 4.41s\tremaining: 1.1s\n",
      "8010:\tlearn: 0.0000000\ttotal: 4.41s\tremaining: 1.09s\n",
      "8011:\tlearn: 0.0000000\ttotal: 4.41s\tremaining: 1.09s\n",
      "8012:\tlearn: 0.0000000\ttotal: 4.41s\tremaining: 1.09s\n",
      "8013:\tlearn: 0.0000000\ttotal: 4.41s\tremaining: 1.09s\n",
      "8014:\tlearn: 0.0000000\ttotal: 4.41s\tremaining: 1.09s\n",
      "8015:\tlearn: 0.0000000\ttotal: 4.42s\tremaining: 1.09s\n",
      "8016:\tlearn: 0.0000000\ttotal: 4.42s\tremaining: 1.09s\n",
      "8017:\tlearn: 0.0000000\ttotal: 4.42s\tremaining: 1.09s\n",
      "8018:\tlearn: 0.0000000\ttotal: 4.42s\tremaining: 1.09s\n",
      "8019:\tlearn: 0.0000000\ttotal: 4.42s\tremaining: 1.09s\n",
      "8020:\tlearn: 0.0000000\ttotal: 4.42s\tremaining: 1.09s\n",
      "8021:\tlearn: 0.0000000\ttotal: 4.42s\tremaining: 1.09s\n",
      "8022:\tlearn: 0.0000000\ttotal: 4.42s\tremaining: 1.09s\n",
      "8023:\tlearn: 0.0000000\ttotal: 4.42s\tremaining: 1.09s\n",
      "8024:\tlearn: 0.0000000\ttotal: 4.42s\tremaining: 1.09s\n",
      "8025:\tlearn: 0.0000000\ttotal: 4.42s\tremaining: 1.09s\n",
      "8026:\tlearn: 0.0000000\ttotal: 4.42s\tremaining: 1.09s\n",
      "8027:\tlearn: 0.0000000\ttotal: 4.42s\tremaining: 1.09s\n",
      "8028:\tlearn: 0.0000000\ttotal: 4.42s\tremaining: 1.08s\n",
      "8029:\tlearn: 0.0000000\ttotal: 4.42s\tremaining: 1.08s\n",
      "8030:\tlearn: 0.0000000\ttotal: 4.42s\tremaining: 1.08s\n",
      "8031:\tlearn: 0.0000000\ttotal: 4.42s\tremaining: 1.08s\n",
      "8032:\tlearn: 0.0000000\ttotal: 4.42s\tremaining: 1.08s\n",
      "8033:\tlearn: 0.0000000\ttotal: 4.42s\tremaining: 1.08s\n",
      "8034:\tlearn: 0.0000000\ttotal: 4.42s\tremaining: 1.08s\n",
      "8035:\tlearn: 0.0000000\ttotal: 4.42s\tremaining: 1.08s\n",
      "8036:\tlearn: 0.0000000\ttotal: 4.42s\tremaining: 1.08s\n",
      "8037:\tlearn: 0.0000000\ttotal: 4.43s\tremaining: 1.08s\n",
      "8038:\tlearn: 0.0000000\ttotal: 4.43s\tremaining: 1.08s\n",
      "8039:\tlearn: 0.0000000\ttotal: 4.43s\tremaining: 1.08s\n",
      "8040:\tlearn: 0.0000000\ttotal: 4.43s\tremaining: 1.08s\n",
      "8041:\tlearn: 0.0000000\ttotal: 4.43s\tremaining: 1.08s\n",
      "8042:\tlearn: 0.0000000\ttotal: 4.43s\tremaining: 1.08s\n",
      "8043:\tlearn: 0.0000000\ttotal: 4.43s\tremaining: 1.08s\n",
      "8044:\tlearn: 0.0000000\ttotal: 4.43s\tremaining: 1.08s\n",
      "8045:\tlearn: 0.0000000\ttotal: 4.43s\tremaining: 1.07s\n",
      "8046:\tlearn: 0.0000000\ttotal: 4.43s\tremaining: 1.07s\n",
      "8047:\tlearn: 0.0000000\ttotal: 4.43s\tremaining: 1.07s\n",
      "8048:\tlearn: 0.0000000\ttotal: 4.43s\tremaining: 1.07s\n",
      "8049:\tlearn: 0.0000000\ttotal: 4.43s\tremaining: 1.07s\n",
      "8050:\tlearn: 0.0000000\ttotal: 4.43s\tremaining: 1.07s\n",
      "8051:\tlearn: 0.0000000\ttotal: 4.43s\tremaining: 1.07s\n",
      "8052:\tlearn: 0.0000000\ttotal: 4.43s\tremaining: 1.07s\n",
      "8053:\tlearn: 0.0000000\ttotal: 4.43s\tremaining: 1.07s\n",
      "8054:\tlearn: 0.0000000\ttotal: 4.44s\tremaining: 1.07s\n",
      "8055:\tlearn: 0.0000000\ttotal: 4.44s\tremaining: 1.07s\n",
      "8056:\tlearn: 0.0000000\ttotal: 4.44s\tremaining: 1.07s\n",
      "8057:\tlearn: 0.0000000\ttotal: 4.44s\tremaining: 1.07s\n",
      "8058:\tlearn: 0.0000000\ttotal: 4.44s\tremaining: 1.07s\n",
      "8059:\tlearn: 0.0000000\ttotal: 4.44s\tremaining: 1.07s\n",
      "8060:\tlearn: 0.0000000\ttotal: 4.44s\tremaining: 1.07s\n",
      "8061:\tlearn: 0.0000000\ttotal: 4.44s\tremaining: 1.07s\n",
      "8062:\tlearn: 0.0000000\ttotal: 4.44s\tremaining: 1.07s\n",
      "8063:\tlearn: 0.0000000\ttotal: 4.44s\tremaining: 1.07s\n",
      "8064:\tlearn: 0.0000000\ttotal: 4.44s\tremaining: 1.06s\n",
      "8065:\tlearn: 0.0000000\ttotal: 4.44s\tremaining: 1.06s\n",
      "8066:\tlearn: 0.0000000\ttotal: 4.44s\tremaining: 1.06s\n",
      "8067:\tlearn: 0.0000000\ttotal: 4.44s\tremaining: 1.06s\n",
      "8068:\tlearn: 0.0000000\ttotal: 4.44s\tremaining: 1.06s\n",
      "8069:\tlearn: 0.0000000\ttotal: 4.44s\tremaining: 1.06s\n",
      "8070:\tlearn: 0.0000000\ttotal: 4.44s\tremaining: 1.06s\n",
      "8071:\tlearn: 0.0000000\ttotal: 4.44s\tremaining: 1.06s\n",
      "8072:\tlearn: 0.0000000\ttotal: 4.45s\tremaining: 1.06s\n",
      "8073:\tlearn: 0.0000000\ttotal: 4.45s\tremaining: 1.06s\n",
      "8074:\tlearn: 0.0000000\ttotal: 4.45s\tremaining: 1.06s\n",
      "8075:\tlearn: 0.0000000\ttotal: 4.45s\tremaining: 1.06s\n",
      "8076:\tlearn: 0.0000000\ttotal: 4.45s\tremaining: 1.06s\n",
      "8077:\tlearn: 0.0000000\ttotal: 4.45s\tremaining: 1.06s\n",
      "8078:\tlearn: 0.0000000\ttotal: 4.45s\tremaining: 1.06s\n",
      "8079:\tlearn: 0.0000000\ttotal: 4.45s\tremaining: 1.06s\n",
      "8080:\tlearn: 0.0000000\ttotal: 4.45s\tremaining: 1.06s\n",
      "8081:\tlearn: 0.0000000\ttotal: 4.45s\tremaining: 1.06s\n",
      "8082:\tlearn: 0.0000000\ttotal: 4.45s\tremaining: 1.05s\n",
      "8083:\tlearn: 0.0000000\ttotal: 4.45s\tremaining: 1.05s\n",
      "8084:\tlearn: 0.0000000\ttotal: 4.45s\tremaining: 1.05s\n",
      "8085:\tlearn: 0.0000000\ttotal: 4.45s\tremaining: 1.05s\n",
      "8086:\tlearn: 0.0000000\ttotal: 4.45s\tremaining: 1.05s\n",
      "8087:\tlearn: 0.0000000\ttotal: 4.45s\tremaining: 1.05s\n",
      "8088:\tlearn: 0.0000000\ttotal: 4.45s\tremaining: 1.05s\n",
      "8089:\tlearn: 0.0000000\ttotal: 4.45s\tremaining: 1.05s\n",
      "8090:\tlearn: 0.0000000\ttotal: 4.46s\tremaining: 1.05s\n",
      "8091:\tlearn: 0.0000000\ttotal: 4.46s\tremaining: 1.05s\n",
      "8092:\tlearn: 0.0000000\ttotal: 4.46s\tremaining: 1.05s\n",
      "8093:\tlearn: 0.0000000\ttotal: 4.46s\tremaining: 1.05s\n",
      "8094:\tlearn: 0.0000000\ttotal: 4.46s\tremaining: 1.05s\n",
      "8095:\tlearn: 0.0000000\ttotal: 4.46s\tremaining: 1.05s\n",
      "8096:\tlearn: 0.0000000\ttotal: 4.46s\tremaining: 1.05s\n",
      "8097:\tlearn: 0.0000000\ttotal: 4.46s\tremaining: 1.05s\n",
      "8098:\tlearn: 0.0000000\ttotal: 4.46s\tremaining: 1.05s\n",
      "8099:\tlearn: 0.0000000\ttotal: 4.46s\tremaining: 1.05s\n",
      "8100:\tlearn: 0.0000000\ttotal: 4.46s\tremaining: 1.04s\n",
      "8101:\tlearn: 0.0000000\ttotal: 4.46s\tremaining: 1.04s\n",
      "8102:\tlearn: 0.0000000\ttotal: 4.46s\tremaining: 1.04s\n",
      "8103:\tlearn: 0.0000000\ttotal: 4.46s\tremaining: 1.04s\n",
      "8104:\tlearn: 0.0000000\ttotal: 4.46s\tremaining: 1.04s\n",
      "8105:\tlearn: 0.0000000\ttotal: 4.46s\tremaining: 1.04s\n",
      "8106:\tlearn: 0.0000000\ttotal: 4.46s\tremaining: 1.04s\n",
      "8107:\tlearn: 0.0000000\ttotal: 4.46s\tremaining: 1.04s\n",
      "8108:\tlearn: 0.0000000\ttotal: 4.46s\tremaining: 1.04s\n",
      "8109:\tlearn: 0.0000000\ttotal: 4.46s\tremaining: 1.04s\n",
      "8110:\tlearn: 0.0000000\ttotal: 4.47s\tremaining: 1.04s\n",
      "8111:\tlearn: 0.0000000\ttotal: 4.47s\tremaining: 1.04s\n",
      "8112:\tlearn: 0.0000000\ttotal: 4.47s\tremaining: 1.04s\n",
      "8113:\tlearn: 0.0000000\ttotal: 4.47s\tremaining: 1.04s\n",
      "8114:\tlearn: 0.0000000\ttotal: 4.47s\tremaining: 1.04s\n",
      "8115:\tlearn: 0.0000000\ttotal: 4.47s\tremaining: 1.04s\n",
      "8116:\tlearn: 0.0000000\ttotal: 4.47s\tremaining: 1.04s\n",
      "8117:\tlearn: 0.0000000\ttotal: 4.47s\tremaining: 1.04s\n",
      "8118:\tlearn: 0.0000000\ttotal: 4.47s\tremaining: 1.03s\n",
      "8119:\tlearn: 0.0000000\ttotal: 4.47s\tremaining: 1.03s\n",
      "8120:\tlearn: 0.0000000\ttotal: 4.47s\tremaining: 1.03s\n",
      "8121:\tlearn: 0.0000000\ttotal: 4.47s\tremaining: 1.03s\n",
      "8122:\tlearn: 0.0000000\ttotal: 4.47s\tremaining: 1.03s\n",
      "8123:\tlearn: 0.0000000\ttotal: 4.47s\tremaining: 1.03s\n",
      "8124:\tlearn: 0.0000000\ttotal: 4.47s\tremaining: 1.03s\n",
      "8125:\tlearn: 0.0000000\ttotal: 4.47s\tremaining: 1.03s\n",
      "8126:\tlearn: 0.0000000\ttotal: 4.47s\tremaining: 1.03s\n",
      "8127:\tlearn: 0.0000000\ttotal: 4.47s\tremaining: 1.03s\n",
      "8128:\tlearn: 0.0000000\ttotal: 4.47s\tremaining: 1.03s\n",
      "8129:\tlearn: 0.0000000\ttotal: 4.48s\tremaining: 1.03s\n",
      "8130:\tlearn: 0.0000000\ttotal: 4.48s\tremaining: 1.03s\n",
      "8131:\tlearn: 0.0000000\ttotal: 4.48s\tremaining: 1.03s\n",
      "8132:\tlearn: 0.0000000\ttotal: 4.48s\tremaining: 1.03s\n",
      "8133:\tlearn: 0.0000000\ttotal: 4.48s\tremaining: 1.03s\n",
      "8134:\tlearn: 0.0000000\ttotal: 4.48s\tremaining: 1.03s\n",
      "8135:\tlearn: 0.0000000\ttotal: 4.48s\tremaining: 1.03s\n",
      "8136:\tlearn: 0.0000000\ttotal: 4.48s\tremaining: 1.02s\n",
      "8137:\tlearn: 0.0000000\ttotal: 4.48s\tremaining: 1.02s\n",
      "8138:\tlearn: 0.0000000\ttotal: 4.48s\tremaining: 1.02s\n",
      "8139:\tlearn: 0.0000000\ttotal: 4.48s\tremaining: 1.02s\n",
      "8140:\tlearn: 0.0000000\ttotal: 4.48s\tremaining: 1.02s\n",
      "8141:\tlearn: 0.0000000\ttotal: 4.48s\tremaining: 1.02s\n",
      "8142:\tlearn: 0.0000000\ttotal: 4.48s\tremaining: 1.02s\n",
      "8143:\tlearn: 0.0000000\ttotal: 4.48s\tremaining: 1.02s\n",
      "8144:\tlearn: 0.0000000\ttotal: 4.48s\tremaining: 1.02s\n",
      "8145:\tlearn: 0.0000000\ttotal: 4.48s\tremaining: 1.02s\n",
      "8146:\tlearn: 0.0000000\ttotal: 4.48s\tremaining: 1.02s\n",
      "8147:\tlearn: 0.0000000\ttotal: 4.49s\tremaining: 1.02s\n",
      "8148:\tlearn: 0.0000000\ttotal: 4.49s\tremaining: 1.02s\n",
      "8149:\tlearn: 0.0000000\ttotal: 4.49s\tremaining: 1.02s\n",
      "8150:\tlearn: 0.0000000\ttotal: 4.49s\tremaining: 1.02s\n",
      "8151:\tlearn: 0.0000000\ttotal: 4.49s\tremaining: 1.02s\n",
      "8152:\tlearn: 0.0000000\ttotal: 4.49s\tremaining: 1.02s\n",
      "8153:\tlearn: 0.0000000\ttotal: 4.49s\tremaining: 1.02s\n",
      "8154:\tlearn: 0.0000000\ttotal: 4.49s\tremaining: 1.01s\n",
      "8155:\tlearn: 0.0000000\ttotal: 4.49s\tremaining: 1.01s\n",
      "8156:\tlearn: 0.0000000\ttotal: 4.49s\tremaining: 1.01s\n",
      "8157:\tlearn: 0.0000000\ttotal: 4.49s\tremaining: 1.01s\n",
      "8158:\tlearn: 0.0000000\ttotal: 4.49s\tremaining: 1.01s\n",
      "8159:\tlearn: 0.0000000\ttotal: 4.49s\tremaining: 1.01s\n",
      "8160:\tlearn: 0.0000000\ttotal: 4.49s\tremaining: 1.01s\n",
      "8161:\tlearn: 0.0000000\ttotal: 4.49s\tremaining: 1.01s\n",
      "8162:\tlearn: 0.0000000\ttotal: 4.49s\tremaining: 1.01s\n",
      "8163:\tlearn: 0.0000000\ttotal: 4.49s\tremaining: 1.01s\n",
      "8164:\tlearn: 0.0000000\ttotal: 4.5s\tremaining: 1.01s\n",
      "8165:\tlearn: 0.0000000\ttotal: 4.5s\tremaining: 1.01s\n",
      "8166:\tlearn: 0.0000000\ttotal: 4.5s\tremaining: 1.01s\n",
      "8167:\tlearn: 0.0000000\ttotal: 4.5s\tremaining: 1.01s\n",
      "8168:\tlearn: 0.0000000\ttotal: 4.5s\tremaining: 1.01s\n",
      "8169:\tlearn: 0.0000000\ttotal: 4.5s\tremaining: 1.01s\n",
      "8170:\tlearn: 0.0000000\ttotal: 4.5s\tremaining: 1.01s\n",
      "8171:\tlearn: 0.0000000\ttotal: 4.5s\tremaining: 1.01s\n",
      "8172:\tlearn: 0.0000000\ttotal: 4.5s\tremaining: 1s\n",
      "8173:\tlearn: 0.0000000\ttotal: 4.5s\tremaining: 1s\n",
      "8174:\tlearn: 0.0000000\ttotal: 4.5s\tremaining: 1s\n",
      "8175:\tlearn: 0.0000000\ttotal: 4.5s\tremaining: 1s\n",
      "8176:\tlearn: 0.0000000\ttotal: 4.5s\tremaining: 1s\n",
      "8177:\tlearn: 0.0000000\ttotal: 4.5s\tremaining: 1s\n",
      "8178:\tlearn: 0.0000000\ttotal: 4.5s\tremaining: 1s\n",
      "8179:\tlearn: 0.0000000\ttotal: 4.5s\tremaining: 1s\n",
      "8180:\tlearn: 0.0000000\ttotal: 4.5s\tremaining: 1s\n",
      "8181:\tlearn: 0.0000000\ttotal: 4.5s\tremaining: 1s\n",
      "8182:\tlearn: 0.0000000\ttotal: 4.5s\tremaining: 1s\n",
      "8183:\tlearn: 0.0000000\ttotal: 4.51s\tremaining: 1000ms\n",
      "8184:\tlearn: 0.0000000\ttotal: 4.51s\tremaining: 999ms\n",
      "8185:\tlearn: 0.0000000\ttotal: 4.51s\tremaining: 999ms\n",
      "8186:\tlearn: 0.0000000\ttotal: 4.51s\tremaining: 998ms\n",
      "8187:\tlearn: 0.0000000\ttotal: 4.51s\tremaining: 998ms\n",
      "8188:\tlearn: 0.0000000\ttotal: 4.51s\tremaining: 997ms\n",
      "8189:\tlearn: 0.0000000\ttotal: 4.51s\tremaining: 996ms\n",
      "8190:\tlearn: 0.0000000\ttotal: 4.51s\tremaining: 996ms\n",
      "8191:\tlearn: 0.0000000\ttotal: 4.51s\tremaining: 995ms\n",
      "8192:\tlearn: 0.0000000\ttotal: 4.51s\tremaining: 995ms\n",
      "8193:\tlearn: 0.0000000\ttotal: 4.51s\tremaining: 994ms\n",
      "8194:\tlearn: 0.0000000\ttotal: 4.51s\tremaining: 994ms\n",
      "8195:\tlearn: 0.0000000\ttotal: 4.51s\tremaining: 993ms\n",
      "8196:\tlearn: 0.0000000\ttotal: 4.51s\tremaining: 993ms\n",
      "8197:\tlearn: 0.0000000\ttotal: 4.51s\tremaining: 992ms\n",
      "8198:\tlearn: 0.0000000\ttotal: 4.51s\tremaining: 992ms\n",
      "8199:\tlearn: 0.0000000\ttotal: 4.51s\tremaining: 991ms\n",
      "8200:\tlearn: 0.0000000\ttotal: 4.51s\tremaining: 990ms\n",
      "8201:\tlearn: 0.0000000\ttotal: 4.51s\tremaining: 990ms\n",
      "8202:\tlearn: 0.0000000\ttotal: 4.51s\tremaining: 989ms\n",
      "8203:\tlearn: 0.0000000\ttotal: 4.52s\tremaining: 989ms\n",
      "8204:\tlearn: 0.0000000\ttotal: 4.52s\tremaining: 988ms\n",
      "8205:\tlearn: 0.0000000\ttotal: 4.52s\tremaining: 988ms\n",
      "8206:\tlearn: 0.0000000\ttotal: 4.52s\tremaining: 987ms\n",
      "8207:\tlearn: 0.0000000\ttotal: 4.52s\tremaining: 987ms\n",
      "8208:\tlearn: 0.0000000\ttotal: 4.52s\tremaining: 986ms\n",
      "8209:\tlearn: 0.0000000\ttotal: 4.52s\tremaining: 986ms\n",
      "8210:\tlearn: 0.0000000\ttotal: 4.52s\tremaining: 985ms\n",
      "8211:\tlearn: 0.0000000\ttotal: 4.52s\tremaining: 985ms\n",
      "8212:\tlearn: 0.0000000\ttotal: 4.52s\tremaining: 984ms\n",
      "8213:\tlearn: 0.0000000\ttotal: 4.52s\tremaining: 983ms\n",
      "8214:\tlearn: 0.0000000\ttotal: 4.52s\tremaining: 983ms\n",
      "8215:\tlearn: 0.0000000\ttotal: 4.52s\tremaining: 982ms\n",
      "8216:\tlearn: 0.0000000\ttotal: 4.52s\tremaining: 982ms\n",
      "8217:\tlearn: 0.0000000\ttotal: 4.52s\tremaining: 981ms\n",
      "8218:\tlearn: 0.0000000\ttotal: 4.53s\tremaining: 981ms\n",
      "8219:\tlearn: 0.0000000\ttotal: 4.53s\tremaining: 980ms\n",
      "8220:\tlearn: 0.0000000\ttotal: 4.53s\tremaining: 979ms\n",
      "8221:\tlearn: 0.0000000\ttotal: 4.53s\tremaining: 979ms\n",
      "8222:\tlearn: 0.0000000\ttotal: 4.53s\tremaining: 978ms\n",
      "8223:\tlearn: 0.0000000\ttotal: 4.53s\tremaining: 978ms\n",
      "8224:\tlearn: 0.0000000\ttotal: 4.53s\tremaining: 977ms\n",
      "8225:\tlearn: 0.0000000\ttotal: 4.53s\tremaining: 977ms\n",
      "8226:\tlearn: 0.0000000\ttotal: 4.53s\tremaining: 976ms\n",
      "8227:\tlearn: 0.0000000\ttotal: 4.53s\tremaining: 976ms\n",
      "8228:\tlearn: 0.0000000\ttotal: 4.53s\tremaining: 975ms\n",
      "8229:\tlearn: 0.0000000\ttotal: 4.53s\tremaining: 974ms\n",
      "8230:\tlearn: 0.0000000\ttotal: 4.53s\tremaining: 974ms\n",
      "8231:\tlearn: 0.0000000\ttotal: 4.53s\tremaining: 973ms\n",
      "8232:\tlearn: 0.0000000\ttotal: 4.53s\tremaining: 973ms\n",
      "8233:\tlearn: 0.0000000\ttotal: 4.53s\tremaining: 972ms\n",
      "8234:\tlearn: 0.0000000\ttotal: 4.53s\tremaining: 972ms\n",
      "8235:\tlearn: 0.0000000\ttotal: 4.53s\tremaining: 971ms\n",
      "8236:\tlearn: 0.0000000\ttotal: 4.53s\tremaining: 971ms\n",
      "8237:\tlearn: 0.0000000\ttotal: 4.53s\tremaining: 970ms\n",
      "8238:\tlearn: 0.0000000\ttotal: 4.54s\tremaining: 969ms\n",
      "8239:\tlearn: 0.0000000\ttotal: 4.54s\tremaining: 969ms\n",
      "8240:\tlearn: 0.0000000\ttotal: 4.54s\tremaining: 968ms\n",
      "8241:\tlearn: 0.0000000\ttotal: 4.54s\tremaining: 968ms\n",
      "8242:\tlearn: 0.0000000\ttotal: 4.54s\tremaining: 967ms\n",
      "8243:\tlearn: 0.0000000\ttotal: 4.54s\tremaining: 967ms\n",
      "8244:\tlearn: 0.0000000\ttotal: 4.54s\tremaining: 966ms\n",
      "8245:\tlearn: 0.0000000\ttotal: 4.54s\tremaining: 965ms\n",
      "8246:\tlearn: 0.0000000\ttotal: 4.54s\tremaining: 965ms\n",
      "8247:\tlearn: 0.0000000\ttotal: 4.54s\tremaining: 964ms\n",
      "8248:\tlearn: 0.0000000\ttotal: 4.54s\tremaining: 964ms\n",
      "8249:\tlearn: 0.0000000\ttotal: 4.54s\tremaining: 963ms\n",
      "8250:\tlearn: 0.0000000\ttotal: 4.54s\tremaining: 963ms\n",
      "8251:\tlearn: 0.0000000\ttotal: 4.54s\tremaining: 962ms\n",
      "8252:\tlearn: 0.0000000\ttotal: 4.54s\tremaining: 961ms\n",
      "8253:\tlearn: 0.0000000\ttotal: 4.54s\tremaining: 961ms\n",
      "8254:\tlearn: 0.0000000\ttotal: 4.54s\tremaining: 960ms\n",
      "8255:\tlearn: 0.0000000\ttotal: 4.54s\tremaining: 960ms\n",
      "8256:\tlearn: 0.0000000\ttotal: 4.54s\tremaining: 959ms\n",
      "8257:\tlearn: 0.0000000\ttotal: 4.54s\tremaining: 959ms\n",
      "8258:\tlearn: 0.0000000\ttotal: 4.54s\tremaining: 958ms\n",
      "8259:\tlearn: 0.0000000\ttotal: 4.54s\tremaining: 957ms\n",
      "8260:\tlearn: 0.0000000\ttotal: 4.54s\tremaining: 957ms\n",
      "8261:\tlearn: 0.0000000\ttotal: 4.55s\tremaining: 956ms\n",
      "8262:\tlearn: 0.0000000\ttotal: 4.55s\tremaining: 956ms\n",
      "8263:\tlearn: 0.0000000\ttotal: 4.55s\tremaining: 955ms\n",
      "8264:\tlearn: 0.0000000\ttotal: 4.55s\tremaining: 955ms\n",
      "8265:\tlearn: 0.0000000\ttotal: 4.55s\tremaining: 954ms\n",
      "8266:\tlearn: 0.0000000\ttotal: 4.55s\tremaining: 954ms\n",
      "8267:\tlearn: 0.0000000\ttotal: 4.55s\tremaining: 953ms\n",
      "8268:\tlearn: 0.0000000\ttotal: 4.55s\tremaining: 952ms\n",
      "8269:\tlearn: 0.0000000\ttotal: 4.55s\tremaining: 952ms\n",
      "8270:\tlearn: 0.0000000\ttotal: 4.55s\tremaining: 951ms\n",
      "8271:\tlearn: 0.0000000\ttotal: 4.55s\tremaining: 951ms\n",
      "8272:\tlearn: 0.0000000\ttotal: 4.55s\tremaining: 950ms\n",
      "8273:\tlearn: 0.0000000\ttotal: 4.55s\tremaining: 950ms\n",
      "8274:\tlearn: 0.0000000\ttotal: 4.55s\tremaining: 949ms\n",
      "8275:\tlearn: 0.0000000\ttotal: 4.55s\tremaining: 949ms\n",
      "8276:\tlearn: 0.0000000\ttotal: 4.55s\tremaining: 948ms\n",
      "8277:\tlearn: 0.0000000\ttotal: 4.55s\tremaining: 947ms\n",
      "8278:\tlearn: 0.0000000\ttotal: 4.55s\tremaining: 947ms\n",
      "8279:\tlearn: 0.0000000\ttotal: 4.55s\tremaining: 946ms\n",
      "8280:\tlearn: 0.0000000\ttotal: 4.55s\tremaining: 946ms\n",
      "8281:\tlearn: 0.0000000\ttotal: 4.56s\tremaining: 945ms\n",
      "8282:\tlearn: 0.0000000\ttotal: 4.56s\tremaining: 945ms\n",
      "8283:\tlearn: 0.0000000\ttotal: 4.56s\tremaining: 944ms\n",
      "8284:\tlearn: 0.0000000\ttotal: 4.56s\tremaining: 943ms\n",
      "8285:\tlearn: 0.0000000\ttotal: 4.56s\tremaining: 943ms\n",
      "8286:\tlearn: 0.0000000\ttotal: 4.56s\tremaining: 942ms\n",
      "8287:\tlearn: 0.0000000\ttotal: 4.56s\tremaining: 942ms\n",
      "8288:\tlearn: 0.0000000\ttotal: 4.56s\tremaining: 941ms\n",
      "8289:\tlearn: 0.0000000\ttotal: 4.56s\tremaining: 941ms\n",
      "8290:\tlearn: 0.0000000\ttotal: 4.56s\tremaining: 940ms\n",
      "8291:\tlearn: 0.0000000\ttotal: 4.56s\tremaining: 940ms\n",
      "8292:\tlearn: 0.0000000\ttotal: 4.56s\tremaining: 939ms\n",
      "8293:\tlearn: 0.0000000\ttotal: 4.56s\tremaining: 939ms\n",
      "8294:\tlearn: 0.0000000\ttotal: 4.56s\tremaining: 938ms\n",
      "8295:\tlearn: 0.0000000\ttotal: 4.56s\tremaining: 937ms\n",
      "8296:\tlearn: 0.0000000\ttotal: 4.56s\tremaining: 937ms\n",
      "8297:\tlearn: 0.0000000\ttotal: 4.56s\tremaining: 936ms\n",
      "8298:\tlearn: 0.0000000\ttotal: 4.57s\tremaining: 936ms\n",
      "8299:\tlearn: 0.0000000\ttotal: 4.57s\tremaining: 935ms\n",
      "8300:\tlearn: 0.0000000\ttotal: 4.57s\tremaining: 935ms\n",
      "8301:\tlearn: 0.0000000\ttotal: 4.57s\tremaining: 934ms\n",
      "8302:\tlearn: 0.0000000\ttotal: 4.57s\tremaining: 933ms\n",
      "8303:\tlearn: 0.0000000\ttotal: 4.57s\tremaining: 933ms\n",
      "8304:\tlearn: 0.0000000\ttotal: 4.57s\tremaining: 932ms\n",
      "8305:\tlearn: 0.0000000\ttotal: 4.57s\tremaining: 932ms\n",
      "8306:\tlearn: 0.0000000\ttotal: 4.57s\tremaining: 931ms\n",
      "8307:\tlearn: 0.0000000\ttotal: 4.57s\tremaining: 931ms\n",
      "8308:\tlearn: 0.0000000\ttotal: 4.57s\tremaining: 930ms\n",
      "8309:\tlearn: 0.0000000\ttotal: 4.57s\tremaining: 930ms\n",
      "8310:\tlearn: 0.0000000\ttotal: 4.57s\tremaining: 929ms\n",
      "8311:\tlearn: 0.0000000\ttotal: 4.57s\tremaining: 928ms\n",
      "8312:\tlearn: 0.0000000\ttotal: 4.57s\tremaining: 928ms\n",
      "8313:\tlearn: 0.0000000\ttotal: 4.57s\tremaining: 927ms\n",
      "8314:\tlearn: 0.0000000\ttotal: 4.57s\tremaining: 927ms\n",
      "8315:\tlearn: 0.0000000\ttotal: 4.57s\tremaining: 926ms\n",
      "8316:\tlearn: 0.0000000\ttotal: 4.57s\tremaining: 926ms\n",
      "8317:\tlearn: 0.0000000\ttotal: 4.57s\tremaining: 925ms\n",
      "8318:\tlearn: 0.0000000\ttotal: 4.57s\tremaining: 924ms\n",
      "8319:\tlearn: 0.0000000\ttotal: 4.58s\tremaining: 924ms\n",
      "8320:\tlearn: 0.0000000\ttotal: 4.58s\tremaining: 923ms\n",
      "8321:\tlearn: 0.0000000\ttotal: 4.58s\tremaining: 923ms\n",
      "8322:\tlearn: 0.0000000\ttotal: 4.58s\tremaining: 922ms\n",
      "8323:\tlearn: 0.0000000\ttotal: 4.58s\tremaining: 922ms\n",
      "8324:\tlearn: 0.0000000\ttotal: 4.58s\tremaining: 921ms\n",
      "8325:\tlearn: 0.0000000\ttotal: 4.58s\tremaining: 921ms\n",
      "8326:\tlearn: 0.0000000\ttotal: 4.58s\tremaining: 920ms\n",
      "8327:\tlearn: 0.0000000\ttotal: 4.58s\tremaining: 919ms\n",
      "8328:\tlearn: 0.0000000\ttotal: 4.58s\tremaining: 919ms\n",
      "8329:\tlearn: 0.0000000\ttotal: 4.58s\tremaining: 918ms\n",
      "8330:\tlearn: 0.0000000\ttotal: 4.58s\tremaining: 918ms\n",
      "8331:\tlearn: 0.0000000\ttotal: 4.58s\tremaining: 917ms\n",
      "8332:\tlearn: 0.0000000\ttotal: 4.58s\tremaining: 917ms\n",
      "8333:\tlearn: 0.0000000\ttotal: 4.58s\tremaining: 916ms\n",
      "8334:\tlearn: 0.0000000\ttotal: 4.58s\tremaining: 916ms\n",
      "8335:\tlearn: 0.0000000\ttotal: 4.58s\tremaining: 915ms\n",
      "8336:\tlearn: 0.0000000\ttotal: 4.58s\tremaining: 914ms\n",
      "8337:\tlearn: 0.0000000\ttotal: 4.58s\tremaining: 914ms\n",
      "8338:\tlearn: 0.0000000\ttotal: 4.58s\tremaining: 913ms\n",
      "8339:\tlearn: 0.0000000\ttotal: 4.58s\tremaining: 913ms\n",
      "8340:\tlearn: 0.0000000\ttotal: 4.59s\tremaining: 912ms\n",
      "8341:\tlearn: 0.0000000\ttotal: 4.59s\tremaining: 912ms\n",
      "8342:\tlearn: 0.0000000\ttotal: 4.59s\tremaining: 911ms\n",
      "8343:\tlearn: 0.0000000\ttotal: 4.59s\tremaining: 910ms\n",
      "8344:\tlearn: 0.0000000\ttotal: 4.59s\tremaining: 910ms\n",
      "8345:\tlearn: 0.0000000\ttotal: 4.59s\tremaining: 909ms\n",
      "8346:\tlearn: 0.0000000\ttotal: 4.59s\tremaining: 909ms\n",
      "8347:\tlearn: 0.0000000\ttotal: 4.59s\tremaining: 908ms\n",
      "8348:\tlearn: 0.0000000\ttotal: 4.59s\tremaining: 908ms\n",
      "8349:\tlearn: 0.0000000\ttotal: 4.59s\tremaining: 907ms\n",
      "8350:\tlearn: 0.0000000\ttotal: 4.59s\tremaining: 907ms\n",
      "8351:\tlearn: 0.0000000\ttotal: 4.59s\tremaining: 906ms\n",
      "8352:\tlearn: 0.0000000\ttotal: 4.59s\tremaining: 906ms\n",
      "8353:\tlearn: 0.0000000\ttotal: 4.59s\tremaining: 905ms\n",
      "8354:\tlearn: 0.0000000\ttotal: 4.59s\tremaining: 904ms\n",
      "8355:\tlearn: 0.0000000\ttotal: 4.59s\tremaining: 904ms\n",
      "8356:\tlearn: 0.0000000\ttotal: 4.59s\tremaining: 903ms\n",
      "8357:\tlearn: 0.0000000\ttotal: 4.59s\tremaining: 903ms\n",
      "8358:\tlearn: 0.0000000\ttotal: 4.59s\tremaining: 902ms\n",
      "8359:\tlearn: 0.0000000\ttotal: 4.59s\tremaining: 902ms\n",
      "8360:\tlearn: 0.0000000\ttotal: 4.6s\tremaining: 901ms\n",
      "8361:\tlearn: 0.0000000\ttotal: 4.6s\tremaining: 900ms\n",
      "8362:\tlearn: 0.0000000\ttotal: 4.6s\tremaining: 900ms\n",
      "8363:\tlearn: 0.0000000\ttotal: 4.6s\tremaining: 899ms\n",
      "8364:\tlearn: 0.0000000\ttotal: 4.6s\tremaining: 899ms\n",
      "8365:\tlearn: 0.0000000\ttotal: 4.6s\tremaining: 898ms\n",
      "8366:\tlearn: 0.0000000\ttotal: 4.6s\tremaining: 898ms\n",
      "8367:\tlearn: 0.0000000\ttotal: 4.6s\tremaining: 897ms\n",
      "8368:\tlearn: 0.0000000\ttotal: 4.6s\tremaining: 897ms\n",
      "8369:\tlearn: 0.0000000\ttotal: 4.6s\tremaining: 896ms\n",
      "8370:\tlearn: 0.0000000\ttotal: 4.6s\tremaining: 895ms\n",
      "8371:\tlearn: 0.0000000\ttotal: 4.6s\tremaining: 895ms\n",
      "8372:\tlearn: 0.0000000\ttotal: 4.6s\tremaining: 894ms\n",
      "8373:\tlearn: 0.0000000\ttotal: 4.6s\tremaining: 894ms\n",
      "8374:\tlearn: 0.0000000\ttotal: 4.6s\tremaining: 893ms\n",
      "8375:\tlearn: 0.0000000\ttotal: 4.6s\tremaining: 893ms\n",
      "8376:\tlearn: 0.0000000\ttotal: 4.6s\tremaining: 892ms\n",
      "8377:\tlearn: 0.0000000\ttotal: 4.61s\tremaining: 892ms\n",
      "8378:\tlearn: 0.0000000\ttotal: 4.61s\tremaining: 891ms\n",
      "8379:\tlearn: 0.0000000\ttotal: 4.61s\tremaining: 891ms\n",
      "8380:\tlearn: 0.0000000\ttotal: 4.61s\tremaining: 890ms\n",
      "8381:\tlearn: 0.0000000\ttotal: 4.61s\tremaining: 889ms\n",
      "8382:\tlearn: 0.0000000\ttotal: 4.61s\tremaining: 889ms\n",
      "8383:\tlearn: 0.0000000\ttotal: 4.61s\tremaining: 888ms\n",
      "8384:\tlearn: 0.0000000\ttotal: 4.61s\tremaining: 888ms\n",
      "8385:\tlearn: 0.0000000\ttotal: 4.61s\tremaining: 887ms\n",
      "8386:\tlearn: 0.0000000\ttotal: 4.61s\tremaining: 887ms\n",
      "8387:\tlearn: 0.0000000\ttotal: 4.61s\tremaining: 886ms\n",
      "8388:\tlearn: 0.0000000\ttotal: 4.61s\tremaining: 885ms\n",
      "8389:\tlearn: 0.0000000\ttotal: 4.61s\tremaining: 885ms\n",
      "8390:\tlearn: 0.0000000\ttotal: 4.61s\tremaining: 884ms\n",
      "8391:\tlearn: 0.0000000\ttotal: 4.61s\tremaining: 884ms\n",
      "8392:\tlearn: 0.0000000\ttotal: 4.61s\tremaining: 883ms\n",
      "8393:\tlearn: 0.0000000\ttotal: 4.61s\tremaining: 883ms\n",
      "8394:\tlearn: 0.0000000\ttotal: 4.61s\tremaining: 882ms\n",
      "8395:\tlearn: 0.0000000\ttotal: 4.61s\tremaining: 882ms\n",
      "8396:\tlearn: 0.0000000\ttotal: 4.62s\tremaining: 881ms\n",
      "8397:\tlearn: 0.0000000\ttotal: 4.62s\tremaining: 880ms\n",
      "8398:\tlearn: 0.0000000\ttotal: 4.62s\tremaining: 880ms\n",
      "8399:\tlearn: 0.0000000\ttotal: 4.62s\tremaining: 879ms\n",
      "8400:\tlearn: 0.0000000\ttotal: 4.62s\tremaining: 879ms\n",
      "8401:\tlearn: 0.0000000\ttotal: 4.62s\tremaining: 878ms\n",
      "8402:\tlearn: 0.0000000\ttotal: 4.62s\tremaining: 878ms\n",
      "8403:\tlearn: 0.0000000\ttotal: 4.62s\tremaining: 877ms\n",
      "8404:\tlearn: 0.0000000\ttotal: 4.62s\tremaining: 877ms\n",
      "8405:\tlearn: 0.0000000\ttotal: 4.62s\tremaining: 876ms\n",
      "8406:\tlearn: 0.0000000\ttotal: 4.62s\tremaining: 876ms\n",
      "8407:\tlearn: 0.0000000\ttotal: 4.62s\tremaining: 875ms\n",
      "8408:\tlearn: 0.0000000\ttotal: 4.62s\tremaining: 875ms\n",
      "8409:\tlearn: 0.0000000\ttotal: 4.62s\tremaining: 874ms\n",
      "8410:\tlearn: 0.0000000\ttotal: 4.62s\tremaining: 874ms\n",
      "8411:\tlearn: 0.0000000\ttotal: 4.62s\tremaining: 873ms\n",
      "8412:\tlearn: 0.0000000\ttotal: 4.62s\tremaining: 872ms\n",
      "8413:\tlearn: 0.0000000\ttotal: 4.63s\tremaining: 872ms\n",
      "8414:\tlearn: 0.0000000\ttotal: 4.63s\tremaining: 871ms\n",
      "8415:\tlearn: 0.0000000\ttotal: 4.63s\tremaining: 871ms\n",
      "8416:\tlearn: 0.0000000\ttotal: 4.63s\tremaining: 870ms\n",
      "8417:\tlearn: 0.0000000\ttotal: 4.63s\tremaining: 870ms\n",
      "8418:\tlearn: 0.0000000\ttotal: 4.63s\tremaining: 869ms\n",
      "8419:\tlearn: 0.0000000\ttotal: 4.63s\tremaining: 869ms\n",
      "8420:\tlearn: 0.0000000\ttotal: 4.63s\tremaining: 868ms\n",
      "8421:\tlearn: 0.0000000\ttotal: 4.63s\tremaining: 867ms\n",
      "8422:\tlearn: 0.0000000\ttotal: 4.63s\tremaining: 867ms\n",
      "8423:\tlearn: 0.0000000\ttotal: 4.63s\tremaining: 866ms\n",
      "8424:\tlearn: 0.0000000\ttotal: 4.63s\tremaining: 866ms\n",
      "8425:\tlearn: 0.0000000\ttotal: 4.63s\tremaining: 865ms\n",
      "8426:\tlearn: 0.0000000\ttotal: 4.63s\tremaining: 865ms\n",
      "8427:\tlearn: 0.0000000\ttotal: 4.63s\tremaining: 864ms\n",
      "8428:\tlearn: 0.0000000\ttotal: 4.63s\tremaining: 864ms\n",
      "8429:\tlearn: 0.0000000\ttotal: 4.63s\tremaining: 863ms\n",
      "8430:\tlearn: 0.0000000\ttotal: 4.63s\tremaining: 863ms\n",
      "8431:\tlearn: 0.0000000\ttotal: 4.63s\tremaining: 862ms\n",
      "8432:\tlearn: 0.0000000\ttotal: 4.64s\tremaining: 862ms\n",
      "8433:\tlearn: 0.0000000\ttotal: 4.64s\tremaining: 861ms\n",
      "8434:\tlearn: 0.0000000\ttotal: 4.64s\tremaining: 860ms\n",
      "8435:\tlearn: 0.0000000\ttotal: 4.64s\tremaining: 860ms\n",
      "8436:\tlearn: 0.0000000\ttotal: 4.64s\tremaining: 859ms\n",
      "8437:\tlearn: 0.0000000\ttotal: 4.64s\tremaining: 859ms\n",
      "8438:\tlearn: 0.0000000\ttotal: 4.64s\tremaining: 858ms\n",
      "8439:\tlearn: 0.0000000\ttotal: 4.64s\tremaining: 858ms\n",
      "8440:\tlearn: 0.0000000\ttotal: 4.64s\tremaining: 857ms\n",
      "8441:\tlearn: 0.0000000\ttotal: 4.64s\tremaining: 857ms\n",
      "8442:\tlearn: 0.0000000\ttotal: 4.64s\tremaining: 856ms\n",
      "8443:\tlearn: 0.0000000\ttotal: 4.64s\tremaining: 856ms\n",
      "8444:\tlearn: 0.0000000\ttotal: 4.64s\tremaining: 855ms\n",
      "8445:\tlearn: 0.0000000\ttotal: 4.64s\tremaining: 854ms\n",
      "8446:\tlearn: 0.0000000\ttotal: 4.64s\tremaining: 854ms\n",
      "8447:\tlearn: 0.0000000\ttotal: 4.64s\tremaining: 853ms\n",
      "8448:\tlearn: 0.0000000\ttotal: 4.64s\tremaining: 853ms\n",
      "8449:\tlearn: 0.0000000\ttotal: 4.65s\tremaining: 852ms\n",
      "8450:\tlearn: 0.0000000\ttotal: 4.65s\tremaining: 852ms\n",
      "8451:\tlearn: 0.0000000\ttotal: 4.65s\tremaining: 851ms\n",
      "8452:\tlearn: 0.0000000\ttotal: 4.65s\tremaining: 851ms\n",
      "8453:\tlearn: 0.0000000\ttotal: 4.65s\tremaining: 850ms\n",
      "8454:\tlearn: 0.0000000\ttotal: 4.65s\tremaining: 850ms\n",
      "8455:\tlearn: 0.0000000\ttotal: 4.65s\tremaining: 849ms\n",
      "8456:\tlearn: 0.0000000\ttotal: 4.65s\tremaining: 849ms\n",
      "8457:\tlearn: 0.0000000\ttotal: 4.65s\tremaining: 848ms\n",
      "8458:\tlearn: 0.0000000\ttotal: 4.65s\tremaining: 848ms\n",
      "8459:\tlearn: 0.0000000\ttotal: 4.65s\tremaining: 847ms\n",
      "8460:\tlearn: 0.0000000\ttotal: 4.65s\tremaining: 846ms\n",
      "8461:\tlearn: 0.0000000\ttotal: 4.65s\tremaining: 846ms\n",
      "8462:\tlearn: 0.0000000\ttotal: 4.65s\tremaining: 845ms\n",
      "8463:\tlearn: 0.0000000\ttotal: 4.66s\tremaining: 845ms\n",
      "8464:\tlearn: 0.0000000\ttotal: 4.66s\tremaining: 844ms\n",
      "8465:\tlearn: 0.0000000\ttotal: 4.66s\tremaining: 844ms\n",
      "8466:\tlearn: 0.0000000\ttotal: 4.66s\tremaining: 843ms\n",
      "8467:\tlearn: 0.0000000\ttotal: 4.66s\tremaining: 843ms\n",
      "8468:\tlearn: 0.0000000\ttotal: 4.66s\tremaining: 842ms\n",
      "8469:\tlearn: 0.0000000\ttotal: 4.66s\tremaining: 841ms\n",
      "8470:\tlearn: 0.0000000\ttotal: 4.66s\tremaining: 841ms\n",
      "8471:\tlearn: 0.0000000\ttotal: 4.66s\tremaining: 840ms\n",
      "8472:\tlearn: 0.0000000\ttotal: 4.66s\tremaining: 840ms\n",
      "8473:\tlearn: 0.0000000\ttotal: 4.66s\tremaining: 839ms\n",
      "8474:\tlearn: 0.0000000\ttotal: 4.66s\tremaining: 839ms\n",
      "8475:\tlearn: 0.0000000\ttotal: 4.66s\tremaining: 838ms\n",
      "8476:\tlearn: 0.0000000\ttotal: 4.66s\tremaining: 838ms\n",
      "8477:\tlearn: 0.0000000\ttotal: 4.66s\tremaining: 837ms\n",
      "8478:\tlearn: 0.0000000\ttotal: 4.66s\tremaining: 837ms\n",
      "8479:\tlearn: 0.0000000\ttotal: 4.67s\tremaining: 836ms\n",
      "8480:\tlearn: 0.0000000\ttotal: 4.67s\tremaining: 836ms\n",
      "8481:\tlearn: 0.0000000\ttotal: 4.67s\tremaining: 835ms\n",
      "8482:\tlearn: 0.0000000\ttotal: 4.67s\tremaining: 835ms\n",
      "8483:\tlearn: 0.0000000\ttotal: 4.67s\tremaining: 834ms\n",
      "8484:\tlearn: 0.0000000\ttotal: 4.67s\tremaining: 833ms\n",
      "8485:\tlearn: 0.0000000\ttotal: 4.67s\tremaining: 833ms\n",
      "8486:\tlearn: 0.0000000\ttotal: 4.67s\tremaining: 832ms\n",
      "8487:\tlearn: 0.0000000\ttotal: 4.67s\tremaining: 832ms\n",
      "8488:\tlearn: 0.0000000\ttotal: 4.67s\tremaining: 831ms\n",
      "8489:\tlearn: 0.0000000\ttotal: 4.67s\tremaining: 831ms\n",
      "8490:\tlearn: 0.0000000\ttotal: 4.67s\tremaining: 830ms\n",
      "8491:\tlearn: 0.0000000\ttotal: 4.67s\tremaining: 830ms\n",
      "8492:\tlearn: 0.0000000\ttotal: 4.67s\tremaining: 829ms\n",
      "8493:\tlearn: 0.0000000\ttotal: 4.67s\tremaining: 828ms\n",
      "8494:\tlearn: 0.0000000\ttotal: 4.67s\tremaining: 828ms\n",
      "8495:\tlearn: 0.0000000\ttotal: 4.67s\tremaining: 827ms\n",
      "8496:\tlearn: 0.0000000\ttotal: 4.67s\tremaining: 827ms\n",
      "8497:\tlearn: 0.0000000\ttotal: 4.67s\tremaining: 826ms\n",
      "8498:\tlearn: 0.0000000\ttotal: 4.68s\tremaining: 826ms\n",
      "8499:\tlearn: 0.0000000\ttotal: 4.68s\tremaining: 825ms\n",
      "8500:\tlearn: 0.0000000\ttotal: 4.68s\tremaining: 825ms\n",
      "8501:\tlearn: 0.0000000\ttotal: 4.68s\tremaining: 824ms\n",
      "8502:\tlearn: 0.0000000\ttotal: 4.68s\tremaining: 824ms\n",
      "8503:\tlearn: 0.0000000\ttotal: 4.68s\tremaining: 823ms\n",
      "8504:\tlearn: 0.0000000\ttotal: 4.68s\tremaining: 823ms\n",
      "8505:\tlearn: 0.0000000\ttotal: 4.68s\tremaining: 822ms\n",
      "8506:\tlearn: 0.0000000\ttotal: 4.68s\tremaining: 822ms\n",
      "8507:\tlearn: 0.0000000\ttotal: 4.68s\tremaining: 821ms\n",
      "8508:\tlearn: 0.0000000\ttotal: 4.68s\tremaining: 820ms\n",
      "8509:\tlearn: 0.0000000\ttotal: 4.68s\tremaining: 820ms\n",
      "8510:\tlearn: 0.0000000\ttotal: 4.68s\tremaining: 819ms\n",
      "8511:\tlearn: 0.0000000\ttotal: 4.68s\tremaining: 819ms\n",
      "8512:\tlearn: 0.0000000\ttotal: 4.68s\tremaining: 818ms\n",
      "8513:\tlearn: 0.0000000\ttotal: 4.68s\tremaining: 818ms\n",
      "8514:\tlearn: 0.0000000\ttotal: 4.68s\tremaining: 817ms\n",
      "8515:\tlearn: 0.0000000\ttotal: 4.68s\tremaining: 817ms\n",
      "8516:\tlearn: 0.0000000\ttotal: 4.69s\tremaining: 816ms\n",
      "8517:\tlearn: 0.0000000\ttotal: 4.69s\tremaining: 815ms\n",
      "8518:\tlearn: 0.0000000\ttotal: 4.69s\tremaining: 815ms\n",
      "8519:\tlearn: 0.0000000\ttotal: 4.69s\tremaining: 814ms\n",
      "8520:\tlearn: 0.0000000\ttotal: 4.69s\tremaining: 814ms\n",
      "8521:\tlearn: 0.0000000\ttotal: 4.69s\tremaining: 813ms\n",
      "8522:\tlearn: 0.0000000\ttotal: 4.69s\tremaining: 813ms\n",
      "8523:\tlearn: 0.0000000\ttotal: 4.69s\tremaining: 812ms\n",
      "8524:\tlearn: 0.0000000\ttotal: 4.69s\tremaining: 812ms\n",
      "8525:\tlearn: 0.0000000\ttotal: 4.69s\tremaining: 811ms\n",
      "8526:\tlearn: 0.0000000\ttotal: 4.69s\tremaining: 811ms\n",
      "8527:\tlearn: 0.0000000\ttotal: 4.69s\tremaining: 810ms\n",
      "8528:\tlearn: 0.0000000\ttotal: 4.69s\tremaining: 809ms\n",
      "8529:\tlearn: 0.0000000\ttotal: 4.69s\tremaining: 809ms\n",
      "8530:\tlearn: 0.0000000\ttotal: 4.69s\tremaining: 808ms\n",
      "8531:\tlearn: 0.0000000\ttotal: 4.7s\tremaining: 808ms\n",
      "8532:\tlearn: 0.0000000\ttotal: 4.7s\tremaining: 807ms\n",
      "8533:\tlearn: 0.0000000\ttotal: 4.7s\tremaining: 807ms\n",
      "8534:\tlearn: 0.0000000\ttotal: 4.7s\tremaining: 806ms\n",
      "8535:\tlearn: 0.0000000\ttotal: 4.7s\tremaining: 806ms\n",
      "8536:\tlearn: 0.0000000\ttotal: 4.7s\tremaining: 805ms\n",
      "8537:\tlearn: 0.0000000\ttotal: 4.7s\tremaining: 805ms\n",
      "8538:\tlearn: 0.0000000\ttotal: 4.7s\tremaining: 804ms\n",
      "8539:\tlearn: 0.0000000\ttotal: 4.7s\tremaining: 803ms\n",
      "8540:\tlearn: 0.0000000\ttotal: 4.7s\tremaining: 803ms\n",
      "8541:\tlearn: 0.0000000\ttotal: 4.7s\tremaining: 802ms\n",
      "8542:\tlearn: 0.0000000\ttotal: 4.7s\tremaining: 802ms\n",
      "8543:\tlearn: 0.0000000\ttotal: 4.7s\tremaining: 801ms\n",
      "8544:\tlearn: 0.0000000\ttotal: 4.7s\tremaining: 801ms\n",
      "8545:\tlearn: 0.0000000\ttotal: 4.7s\tremaining: 800ms\n",
      "8546:\tlearn: 0.0000000\ttotal: 4.7s\tremaining: 800ms\n",
      "8547:\tlearn: 0.0000000\ttotal: 4.71s\tremaining: 799ms\n",
      "8548:\tlearn: 0.0000000\ttotal: 4.71s\tremaining: 799ms\n",
      "8549:\tlearn: 0.0000000\ttotal: 4.71s\tremaining: 798ms\n",
      "8550:\tlearn: 0.0000000\ttotal: 4.71s\tremaining: 798ms\n",
      "8551:\tlearn: 0.0000000\ttotal: 4.71s\tremaining: 797ms\n",
      "8552:\tlearn: 0.0000000\ttotal: 4.71s\tremaining: 797ms\n",
      "8553:\tlearn: 0.0000000\ttotal: 4.71s\tremaining: 796ms\n",
      "8554:\tlearn: 0.0000000\ttotal: 4.71s\tremaining: 795ms\n",
      "8555:\tlearn: 0.0000000\ttotal: 4.71s\tremaining: 795ms\n",
      "8556:\tlearn: 0.0000000\ttotal: 4.71s\tremaining: 794ms\n",
      "8557:\tlearn: 0.0000000\ttotal: 4.71s\tremaining: 794ms\n",
      "8558:\tlearn: 0.0000000\ttotal: 4.71s\tremaining: 793ms\n",
      "8559:\tlearn: 0.0000000\ttotal: 4.71s\tremaining: 793ms\n",
      "8560:\tlearn: 0.0000000\ttotal: 4.71s\tremaining: 792ms\n",
      "8561:\tlearn: 0.0000000\ttotal: 4.71s\tremaining: 792ms\n",
      "8562:\tlearn: 0.0000000\ttotal: 4.71s\tremaining: 791ms\n",
      "8563:\tlearn: 0.0000000\ttotal: 4.71s\tremaining: 790ms\n",
      "8564:\tlearn: 0.0000000\ttotal: 4.71s\tremaining: 790ms\n",
      "8565:\tlearn: 0.0000000\ttotal: 4.71s\tremaining: 789ms\n",
      "8566:\tlearn: 0.0000000\ttotal: 4.71s\tremaining: 789ms\n",
      "8567:\tlearn: 0.0000000\ttotal: 4.71s\tremaining: 788ms\n",
      "8568:\tlearn: 0.0000000\ttotal: 4.72s\tremaining: 788ms\n",
      "8569:\tlearn: 0.0000000\ttotal: 4.72s\tremaining: 787ms\n",
      "8570:\tlearn: 0.0000000\ttotal: 4.72s\tremaining: 786ms\n",
      "8571:\tlearn: 0.0000000\ttotal: 4.72s\tremaining: 786ms\n",
      "8572:\tlearn: 0.0000000\ttotal: 4.72s\tremaining: 785ms\n",
      "8573:\tlearn: 0.0000000\ttotal: 4.72s\tremaining: 785ms\n",
      "8574:\tlearn: 0.0000000\ttotal: 4.72s\tremaining: 784ms\n",
      "8575:\tlearn: 0.0000000\ttotal: 4.72s\tremaining: 784ms\n",
      "8576:\tlearn: 0.0000000\ttotal: 4.72s\tremaining: 783ms\n",
      "8577:\tlearn: 0.0000000\ttotal: 4.72s\tremaining: 783ms\n",
      "8578:\tlearn: 0.0000000\ttotal: 4.72s\tremaining: 782ms\n",
      "8579:\tlearn: 0.0000000\ttotal: 4.72s\tremaining: 781ms\n",
      "8580:\tlearn: 0.0000000\ttotal: 4.72s\tremaining: 781ms\n",
      "8581:\tlearn: 0.0000000\ttotal: 4.72s\tremaining: 780ms\n",
      "8582:\tlearn: 0.0000000\ttotal: 4.72s\tremaining: 780ms\n",
      "8583:\tlearn: 0.0000000\ttotal: 4.72s\tremaining: 779ms\n",
      "8584:\tlearn: 0.0000000\ttotal: 4.72s\tremaining: 779ms\n",
      "8585:\tlearn: 0.0000000\ttotal: 4.72s\tremaining: 778ms\n",
      "8586:\tlearn: 0.0000000\ttotal: 4.72s\tremaining: 777ms\n",
      "8587:\tlearn: 0.0000000\ttotal: 4.72s\tremaining: 777ms\n",
      "8588:\tlearn: 0.0000000\ttotal: 4.72s\tremaining: 776ms\n",
      "8589:\tlearn: 0.0000000\ttotal: 4.72s\tremaining: 776ms\n",
      "8590:\tlearn: 0.0000000\ttotal: 4.73s\tremaining: 775ms\n",
      "8591:\tlearn: 0.0000000\ttotal: 4.73s\tremaining: 775ms\n",
      "8592:\tlearn: 0.0000000\ttotal: 4.73s\tremaining: 774ms\n",
      "8593:\tlearn: 0.0000000\ttotal: 4.73s\tremaining: 773ms\n",
      "8594:\tlearn: 0.0000000\ttotal: 4.73s\tremaining: 773ms\n",
      "8595:\tlearn: 0.0000000\ttotal: 4.73s\tremaining: 772ms\n",
      "8596:\tlearn: 0.0000000\ttotal: 4.73s\tremaining: 772ms\n",
      "8597:\tlearn: 0.0000000\ttotal: 4.73s\tremaining: 771ms\n",
      "8598:\tlearn: 0.0000000\ttotal: 4.73s\tremaining: 771ms\n",
      "8599:\tlearn: 0.0000000\ttotal: 4.73s\tremaining: 770ms\n",
      "8600:\tlearn: 0.0000000\ttotal: 4.73s\tremaining: 770ms\n",
      "8601:\tlearn: 0.0000000\ttotal: 4.73s\tremaining: 769ms\n",
      "8602:\tlearn: 0.0000000\ttotal: 4.73s\tremaining: 768ms\n",
      "8603:\tlearn: 0.0000000\ttotal: 4.73s\tremaining: 768ms\n",
      "8604:\tlearn: 0.0000000\ttotal: 4.73s\tremaining: 767ms\n",
      "8605:\tlearn: 0.0000000\ttotal: 4.73s\tremaining: 767ms\n",
      "8606:\tlearn: 0.0000000\ttotal: 4.73s\tremaining: 766ms\n",
      "8607:\tlearn: 0.0000000\ttotal: 4.73s\tremaining: 766ms\n",
      "8608:\tlearn: 0.0000000\ttotal: 4.74s\tremaining: 765ms\n",
      "8609:\tlearn: 0.0000000\ttotal: 4.74s\tremaining: 765ms\n",
      "8610:\tlearn: 0.0000000\ttotal: 4.74s\tremaining: 764ms\n",
      "8611:\tlearn: 0.0000000\ttotal: 4.74s\tremaining: 763ms\n",
      "8612:\tlearn: 0.0000000\ttotal: 4.74s\tremaining: 763ms\n",
      "8613:\tlearn: 0.0000000\ttotal: 4.74s\tremaining: 762ms\n",
      "8614:\tlearn: 0.0000000\ttotal: 4.74s\tremaining: 762ms\n",
      "8615:\tlearn: 0.0000000\ttotal: 4.74s\tremaining: 761ms\n",
      "8616:\tlearn: 0.0000000\ttotal: 4.74s\tremaining: 761ms\n",
      "8617:\tlearn: 0.0000000\ttotal: 4.74s\tremaining: 760ms\n",
      "8618:\tlearn: 0.0000000\ttotal: 4.74s\tremaining: 759ms\n",
      "8619:\tlearn: 0.0000000\ttotal: 4.74s\tremaining: 759ms\n",
      "8620:\tlearn: 0.0000000\ttotal: 4.74s\tremaining: 758ms\n",
      "8621:\tlearn: 0.0000000\ttotal: 4.74s\tremaining: 758ms\n",
      "8622:\tlearn: 0.0000000\ttotal: 4.74s\tremaining: 757ms\n",
      "8623:\tlearn: 0.0000000\ttotal: 4.74s\tremaining: 757ms\n",
      "8624:\tlearn: 0.0000000\ttotal: 4.74s\tremaining: 756ms\n",
      "8625:\tlearn: 0.0000000\ttotal: 4.74s\tremaining: 756ms\n",
      "8626:\tlearn: 0.0000000\ttotal: 4.74s\tremaining: 755ms\n",
      "8627:\tlearn: 0.0000000\ttotal: 4.74s\tremaining: 754ms\n",
      "8628:\tlearn: 0.0000000\ttotal: 4.74s\tremaining: 754ms\n",
      "8629:\tlearn: 0.0000000\ttotal: 4.75s\tremaining: 753ms\n",
      "8630:\tlearn: 0.0000000\ttotal: 4.75s\tremaining: 753ms\n",
      "8631:\tlearn: 0.0000000\ttotal: 4.75s\tremaining: 752ms\n",
      "8632:\tlearn: 0.0000000\ttotal: 4.75s\tremaining: 752ms\n",
      "8633:\tlearn: 0.0000000\ttotal: 4.75s\tremaining: 751ms\n",
      "8634:\tlearn: 0.0000000\ttotal: 4.75s\tremaining: 751ms\n",
      "8635:\tlearn: 0.0000000\ttotal: 4.75s\tremaining: 750ms\n",
      "8636:\tlearn: 0.0000000\ttotal: 4.75s\tremaining: 749ms\n",
      "8637:\tlearn: 0.0000000\ttotal: 4.75s\tremaining: 749ms\n",
      "8638:\tlearn: 0.0000000\ttotal: 4.75s\tremaining: 748ms\n",
      "8639:\tlearn: 0.0000000\ttotal: 4.75s\tremaining: 748ms\n",
      "8640:\tlearn: 0.0000000\ttotal: 4.75s\tremaining: 747ms\n",
      "8641:\tlearn: 0.0000000\ttotal: 4.75s\tremaining: 747ms\n",
      "8642:\tlearn: 0.0000000\ttotal: 4.75s\tremaining: 746ms\n",
      "8643:\tlearn: 0.0000000\ttotal: 4.75s\tremaining: 746ms\n",
      "8644:\tlearn: 0.0000000\ttotal: 4.75s\tremaining: 745ms\n",
      "8645:\tlearn: 0.0000000\ttotal: 4.75s\tremaining: 744ms\n",
      "8646:\tlearn: 0.0000000\ttotal: 4.75s\tremaining: 744ms\n",
      "8647:\tlearn: 0.0000000\ttotal: 4.75s\tremaining: 743ms\n",
      "8648:\tlearn: 0.0000000\ttotal: 4.75s\tremaining: 743ms\n",
      "8649:\tlearn: 0.0000000\ttotal: 4.75s\tremaining: 742ms\n",
      "8650:\tlearn: 0.0000000\ttotal: 4.75s\tremaining: 742ms\n",
      "8651:\tlearn: 0.0000000\ttotal: 4.76s\tremaining: 741ms\n",
      "8652:\tlearn: 0.0000000\ttotal: 4.76s\tremaining: 740ms\n",
      "8653:\tlearn: 0.0000000\ttotal: 4.76s\tremaining: 740ms\n",
      "8654:\tlearn: 0.0000000\ttotal: 4.76s\tremaining: 739ms\n",
      "8655:\tlearn: 0.0000000\ttotal: 4.76s\tremaining: 739ms\n",
      "8656:\tlearn: 0.0000000\ttotal: 4.76s\tremaining: 738ms\n",
      "8657:\tlearn: 0.0000000\ttotal: 4.76s\tremaining: 738ms\n",
      "8658:\tlearn: 0.0000000\ttotal: 4.76s\tremaining: 737ms\n",
      "8659:\tlearn: 0.0000000\ttotal: 4.76s\tremaining: 737ms\n",
      "8660:\tlearn: 0.0000000\ttotal: 4.76s\tremaining: 736ms\n",
      "8661:\tlearn: 0.0000000\ttotal: 4.76s\tremaining: 736ms\n",
      "8662:\tlearn: 0.0000000\ttotal: 4.76s\tremaining: 735ms\n",
      "8663:\tlearn: 0.0000000\ttotal: 4.76s\tremaining: 734ms\n",
      "8664:\tlearn: 0.0000000\ttotal: 4.76s\tremaining: 734ms\n",
      "8665:\tlearn: 0.0000000\ttotal: 4.76s\tremaining: 733ms\n",
      "8666:\tlearn: 0.0000000\ttotal: 4.76s\tremaining: 733ms\n",
      "8667:\tlearn: 0.0000000\ttotal: 4.76s\tremaining: 732ms\n",
      "8668:\tlearn: 0.0000000\ttotal: 4.76s\tremaining: 732ms\n",
      "8669:\tlearn: 0.0000000\ttotal: 4.76s\tremaining: 731ms\n",
      "8670:\tlearn: 0.0000000\ttotal: 4.76s\tremaining: 730ms\n",
      "8671:\tlearn: 0.0000000\ttotal: 4.77s\tremaining: 730ms\n",
      "8672:\tlearn: 0.0000000\ttotal: 4.77s\tremaining: 729ms\n",
      "8673:\tlearn: 0.0000000\ttotal: 4.77s\tremaining: 729ms\n",
      "8674:\tlearn: 0.0000000\ttotal: 4.77s\tremaining: 728ms\n",
      "8675:\tlearn: 0.0000000\ttotal: 4.77s\tremaining: 728ms\n",
      "8676:\tlearn: 0.0000000\ttotal: 4.77s\tremaining: 727ms\n",
      "8677:\tlearn: 0.0000000\ttotal: 4.77s\tremaining: 726ms\n",
      "8678:\tlearn: 0.0000000\ttotal: 4.77s\tremaining: 726ms\n",
      "8679:\tlearn: 0.0000000\ttotal: 4.77s\tremaining: 725ms\n",
      "8680:\tlearn: 0.0000000\ttotal: 4.77s\tremaining: 725ms\n",
      "8681:\tlearn: 0.0000000\ttotal: 4.77s\tremaining: 724ms\n",
      "8682:\tlearn: 0.0000000\ttotal: 4.77s\tremaining: 724ms\n",
      "8683:\tlearn: 0.0000000\ttotal: 4.77s\tremaining: 723ms\n",
      "8684:\tlearn: 0.0000000\ttotal: 4.77s\tremaining: 723ms\n",
      "8685:\tlearn: 0.0000000\ttotal: 4.77s\tremaining: 722ms\n",
      "8686:\tlearn: 0.0000000\ttotal: 4.77s\tremaining: 721ms\n",
      "8687:\tlearn: 0.0000000\ttotal: 4.77s\tremaining: 721ms\n",
      "8688:\tlearn: 0.0000000\ttotal: 4.77s\tremaining: 720ms\n",
      "8689:\tlearn: 0.0000000\ttotal: 4.78s\tremaining: 720ms\n",
      "8690:\tlearn: 0.0000000\ttotal: 4.78s\tremaining: 719ms\n",
      "8691:\tlearn: 0.0000000\ttotal: 4.78s\tremaining: 719ms\n",
      "8692:\tlearn: 0.0000000\ttotal: 4.78s\tremaining: 718ms\n",
      "8693:\tlearn: 0.0000000\ttotal: 4.78s\tremaining: 718ms\n",
      "8694:\tlearn: 0.0000000\ttotal: 4.78s\tremaining: 717ms\n",
      "8695:\tlearn: 0.0000000\ttotal: 4.78s\tremaining: 716ms\n",
      "8696:\tlearn: 0.0000000\ttotal: 4.78s\tremaining: 716ms\n",
      "8697:\tlearn: 0.0000000\ttotal: 4.78s\tremaining: 715ms\n",
      "8698:\tlearn: 0.0000000\ttotal: 4.78s\tremaining: 715ms\n",
      "8699:\tlearn: 0.0000000\ttotal: 4.78s\tremaining: 714ms\n",
      "8700:\tlearn: 0.0000000\ttotal: 4.78s\tremaining: 714ms\n",
      "8701:\tlearn: 0.0000000\ttotal: 4.78s\tremaining: 713ms\n",
      "8702:\tlearn: 0.0000000\ttotal: 4.78s\tremaining: 713ms\n",
      "8703:\tlearn: 0.0000000\ttotal: 4.78s\tremaining: 712ms\n",
      "8704:\tlearn: 0.0000000\ttotal: 4.78s\tremaining: 711ms\n",
      "8705:\tlearn: 0.0000000\ttotal: 4.78s\tremaining: 711ms\n",
      "8706:\tlearn: 0.0000000\ttotal: 4.78s\tremaining: 710ms\n",
      "8707:\tlearn: 0.0000000\ttotal: 4.78s\tremaining: 710ms\n",
      "8708:\tlearn: 0.0000000\ttotal: 4.78s\tremaining: 709ms\n",
      "8709:\tlearn: 0.0000000\ttotal: 4.78s\tremaining: 709ms\n",
      "8710:\tlearn: 0.0000000\ttotal: 4.78s\tremaining: 708ms\n",
      "8711:\tlearn: 0.0000000\ttotal: 4.79s\tremaining: 707ms\n",
      "8712:\tlearn: 0.0000000\ttotal: 4.79s\tremaining: 707ms\n",
      "8713:\tlearn: 0.0000000\ttotal: 4.79s\tremaining: 706ms\n",
      "8714:\tlearn: 0.0000000\ttotal: 4.79s\tremaining: 706ms\n",
      "8715:\tlearn: 0.0000000\ttotal: 4.79s\tremaining: 705ms\n",
      "8716:\tlearn: 0.0000000\ttotal: 4.79s\tremaining: 705ms\n",
      "8717:\tlearn: 0.0000000\ttotal: 4.79s\tremaining: 704ms\n",
      "8718:\tlearn: 0.0000000\ttotal: 4.79s\tremaining: 704ms\n",
      "8719:\tlearn: 0.0000000\ttotal: 4.79s\tremaining: 703ms\n",
      "8720:\tlearn: 0.0000000\ttotal: 4.79s\tremaining: 703ms\n",
      "8721:\tlearn: 0.0000000\ttotal: 4.79s\tremaining: 702ms\n",
      "8722:\tlearn: 0.0000000\ttotal: 4.79s\tremaining: 702ms\n",
      "8723:\tlearn: 0.0000000\ttotal: 4.79s\tremaining: 701ms\n",
      "8724:\tlearn: 0.0000000\ttotal: 4.79s\tremaining: 700ms\n",
      "8725:\tlearn: 0.0000000\ttotal: 4.79s\tremaining: 700ms\n",
      "8726:\tlearn: 0.0000000\ttotal: 4.79s\tremaining: 699ms\n",
      "8727:\tlearn: 0.0000000\ttotal: 4.79s\tremaining: 699ms\n",
      "8728:\tlearn: 0.0000000\ttotal: 4.79s\tremaining: 698ms\n",
      "8729:\tlearn: 0.0000000\ttotal: 4.8s\tremaining: 698ms\n",
      "8730:\tlearn: 0.0000000\ttotal: 4.8s\tremaining: 697ms\n",
      "8731:\tlearn: 0.0000000\ttotal: 4.8s\tremaining: 697ms\n",
      "8732:\tlearn: 0.0000000\ttotal: 4.8s\tremaining: 696ms\n",
      "8733:\tlearn: 0.0000000\ttotal: 4.8s\tremaining: 696ms\n",
      "8734:\tlearn: 0.0000000\ttotal: 4.8s\tremaining: 695ms\n",
      "8735:\tlearn: 0.0000000\ttotal: 4.8s\tremaining: 694ms\n",
      "8736:\tlearn: 0.0000000\ttotal: 4.8s\tremaining: 694ms\n",
      "8737:\tlearn: 0.0000000\ttotal: 4.8s\tremaining: 693ms\n",
      "8738:\tlearn: 0.0000000\ttotal: 4.8s\tremaining: 693ms\n",
      "8739:\tlearn: 0.0000000\ttotal: 4.8s\tremaining: 692ms\n",
      "8740:\tlearn: 0.0000000\ttotal: 4.8s\tremaining: 692ms\n",
      "8741:\tlearn: 0.0000000\ttotal: 4.8s\tremaining: 691ms\n",
      "8742:\tlearn: 0.0000000\ttotal: 4.8s\tremaining: 691ms\n",
      "8743:\tlearn: 0.0000000\ttotal: 4.8s\tremaining: 690ms\n",
      "8744:\tlearn: 0.0000000\ttotal: 4.8s\tremaining: 690ms\n",
      "8745:\tlearn: 0.0000000\ttotal: 4.8s\tremaining: 689ms\n",
      "8746:\tlearn: 0.0000000\ttotal: 4.81s\tremaining: 688ms\n",
      "8747:\tlearn: 0.0000000\ttotal: 4.81s\tremaining: 688ms\n",
      "8748:\tlearn: 0.0000000\ttotal: 4.81s\tremaining: 687ms\n",
      "8749:\tlearn: 0.0000000\ttotal: 4.81s\tremaining: 687ms\n",
      "8750:\tlearn: 0.0000000\ttotal: 4.81s\tremaining: 686ms\n",
      "8751:\tlearn: 0.0000000\ttotal: 4.81s\tremaining: 686ms\n",
      "8752:\tlearn: 0.0000000\ttotal: 4.81s\tremaining: 685ms\n",
      "8753:\tlearn: 0.0000000\ttotal: 4.81s\tremaining: 685ms\n",
      "8754:\tlearn: 0.0000000\ttotal: 4.81s\tremaining: 684ms\n",
      "8755:\tlearn: 0.0000000\ttotal: 4.81s\tremaining: 684ms\n",
      "8756:\tlearn: 0.0000000\ttotal: 4.81s\tremaining: 683ms\n",
      "8757:\tlearn: 0.0000000\ttotal: 4.81s\tremaining: 682ms\n",
      "8758:\tlearn: 0.0000000\ttotal: 4.81s\tremaining: 682ms\n",
      "8759:\tlearn: 0.0000000\ttotal: 4.81s\tremaining: 681ms\n",
      "8760:\tlearn: 0.0000000\ttotal: 4.81s\tremaining: 681ms\n",
      "8761:\tlearn: 0.0000000\ttotal: 4.81s\tremaining: 680ms\n",
      "8762:\tlearn: 0.0000000\ttotal: 4.81s\tremaining: 680ms\n",
      "8763:\tlearn: 0.0000000\ttotal: 4.81s\tremaining: 679ms\n",
      "8764:\tlearn: 0.0000000\ttotal: 4.82s\tremaining: 678ms\n",
      "8765:\tlearn: 0.0000000\ttotal: 4.82s\tremaining: 678ms\n",
      "8766:\tlearn: 0.0000000\ttotal: 4.82s\tremaining: 677ms\n",
      "8767:\tlearn: 0.0000000\ttotal: 4.82s\tremaining: 677ms\n",
      "8768:\tlearn: 0.0000000\ttotal: 4.82s\tremaining: 676ms\n",
      "8769:\tlearn: 0.0000000\ttotal: 4.82s\tremaining: 676ms\n",
      "8770:\tlearn: 0.0000000\ttotal: 4.82s\tremaining: 675ms\n",
      "8771:\tlearn: 0.0000000\ttotal: 4.82s\tremaining: 675ms\n",
      "8772:\tlearn: 0.0000000\ttotal: 4.82s\tremaining: 674ms\n",
      "8773:\tlearn: 0.0000000\ttotal: 4.82s\tremaining: 674ms\n",
      "8774:\tlearn: 0.0000000\ttotal: 4.82s\tremaining: 673ms\n",
      "8775:\tlearn: 0.0000000\ttotal: 4.82s\tremaining: 673ms\n",
      "8776:\tlearn: 0.0000000\ttotal: 4.82s\tremaining: 672ms\n",
      "8777:\tlearn: 0.0000000\ttotal: 4.82s\tremaining: 671ms\n",
      "8778:\tlearn: 0.0000000\ttotal: 4.82s\tremaining: 671ms\n",
      "8779:\tlearn: 0.0000000\ttotal: 4.82s\tremaining: 670ms\n",
      "8780:\tlearn: 0.0000000\ttotal: 4.82s\tremaining: 670ms\n",
      "8781:\tlearn: 0.0000000\ttotal: 4.82s\tremaining: 669ms\n",
      "8782:\tlearn: 0.0000000\ttotal: 4.83s\tremaining: 669ms\n",
      "8783:\tlearn: 0.0000000\ttotal: 4.83s\tremaining: 668ms\n",
      "8784:\tlearn: 0.0000000\ttotal: 4.83s\tremaining: 667ms\n",
      "8785:\tlearn: 0.0000000\ttotal: 4.83s\tremaining: 667ms\n",
      "8786:\tlearn: 0.0000000\ttotal: 4.83s\tremaining: 666ms\n",
      "8787:\tlearn: 0.0000000\ttotal: 4.83s\tremaining: 666ms\n",
      "8788:\tlearn: 0.0000000\ttotal: 4.83s\tremaining: 665ms\n",
      "8789:\tlearn: 0.0000000\ttotal: 4.83s\tremaining: 665ms\n",
      "8790:\tlearn: 0.0000000\ttotal: 4.83s\tremaining: 664ms\n",
      "8791:\tlearn: 0.0000000\ttotal: 4.83s\tremaining: 664ms\n",
      "8792:\tlearn: 0.0000000\ttotal: 4.83s\tremaining: 663ms\n",
      "8793:\tlearn: 0.0000000\ttotal: 4.83s\tremaining: 663ms\n",
      "8794:\tlearn: 0.0000000\ttotal: 4.83s\tremaining: 662ms\n",
      "8795:\tlearn: 0.0000000\ttotal: 4.83s\tremaining: 662ms\n",
      "8796:\tlearn: 0.0000000\ttotal: 4.83s\tremaining: 661ms\n",
      "8797:\tlearn: 0.0000000\ttotal: 4.83s\tremaining: 660ms\n",
      "8798:\tlearn: 0.0000000\ttotal: 4.83s\tremaining: 660ms\n",
      "8799:\tlearn: 0.0000000\ttotal: 4.83s\tremaining: 659ms\n",
      "8800:\tlearn: 0.0000000\ttotal: 4.83s\tremaining: 659ms\n",
      "8801:\tlearn: 0.0000000\ttotal: 4.83s\tremaining: 658ms\n",
      "8802:\tlearn: 0.0000000\ttotal: 4.84s\tremaining: 658ms\n",
      "8803:\tlearn: 0.0000000\ttotal: 4.84s\tremaining: 657ms\n",
      "8804:\tlearn: 0.0000000\ttotal: 4.84s\tremaining: 656ms\n",
      "8805:\tlearn: 0.0000000\ttotal: 4.84s\tremaining: 656ms\n",
      "8806:\tlearn: 0.0000000\ttotal: 4.84s\tremaining: 655ms\n",
      "8807:\tlearn: 0.0000000\ttotal: 4.84s\tremaining: 655ms\n",
      "8808:\tlearn: 0.0000000\ttotal: 4.84s\tremaining: 654ms\n",
      "8809:\tlearn: 0.0000000\ttotal: 4.84s\tremaining: 654ms\n",
      "8810:\tlearn: 0.0000000\ttotal: 4.84s\tremaining: 653ms\n",
      "8811:\tlearn: 0.0000000\ttotal: 4.84s\tremaining: 653ms\n",
      "8812:\tlearn: 0.0000000\ttotal: 4.84s\tremaining: 652ms\n",
      "8813:\tlearn: 0.0000000\ttotal: 4.84s\tremaining: 651ms\n",
      "8814:\tlearn: 0.0000000\ttotal: 4.84s\tremaining: 651ms\n",
      "8815:\tlearn: 0.0000000\ttotal: 4.84s\tremaining: 650ms\n",
      "8816:\tlearn: 0.0000000\ttotal: 4.84s\tremaining: 650ms\n",
      "8817:\tlearn: 0.0000000\ttotal: 4.84s\tremaining: 649ms\n",
      "8818:\tlearn: 0.0000000\ttotal: 4.84s\tremaining: 649ms\n",
      "8819:\tlearn: 0.0000000\ttotal: 4.84s\tremaining: 648ms\n",
      "8820:\tlearn: 0.0000000\ttotal: 4.84s\tremaining: 648ms\n",
      "8821:\tlearn: 0.0000000\ttotal: 4.84s\tremaining: 647ms\n",
      "8822:\tlearn: 0.0000000\ttotal: 4.85s\tremaining: 647ms\n",
      "8823:\tlearn: 0.0000000\ttotal: 4.85s\tremaining: 646ms\n",
      "8824:\tlearn: 0.0000000\ttotal: 4.85s\tremaining: 646ms\n",
      "8825:\tlearn: 0.0000000\ttotal: 4.85s\tremaining: 645ms\n",
      "8826:\tlearn: 0.0000000\ttotal: 4.85s\tremaining: 644ms\n",
      "8827:\tlearn: 0.0000000\ttotal: 4.85s\tremaining: 644ms\n",
      "8828:\tlearn: 0.0000000\ttotal: 4.85s\tremaining: 643ms\n",
      "8829:\tlearn: 0.0000000\ttotal: 4.85s\tremaining: 643ms\n",
      "8830:\tlearn: 0.0000000\ttotal: 4.85s\tremaining: 642ms\n",
      "8831:\tlearn: 0.0000000\ttotal: 4.85s\tremaining: 642ms\n",
      "8832:\tlearn: 0.0000000\ttotal: 4.85s\tremaining: 641ms\n",
      "8833:\tlearn: 0.0000000\ttotal: 4.85s\tremaining: 641ms\n",
      "8834:\tlearn: 0.0000000\ttotal: 4.85s\tremaining: 640ms\n",
      "8835:\tlearn: 0.0000000\ttotal: 4.85s\tremaining: 639ms\n",
      "8836:\tlearn: 0.0000000\ttotal: 4.85s\tremaining: 639ms\n",
      "8837:\tlearn: 0.0000000\ttotal: 4.86s\tremaining: 638ms\n",
      "8838:\tlearn: 0.0000000\ttotal: 4.86s\tremaining: 638ms\n",
      "8839:\tlearn: 0.0000000\ttotal: 4.86s\tremaining: 637ms\n",
      "8840:\tlearn: 0.0000000\ttotal: 4.86s\tremaining: 637ms\n",
      "8841:\tlearn: 0.0000000\ttotal: 4.86s\tremaining: 636ms\n",
      "8842:\tlearn: 0.0000000\ttotal: 4.86s\tremaining: 636ms\n",
      "8843:\tlearn: 0.0000000\ttotal: 4.86s\tremaining: 635ms\n",
      "8844:\tlearn: 0.0000000\ttotal: 4.86s\tremaining: 634ms\n",
      "8845:\tlearn: 0.0000000\ttotal: 4.86s\tremaining: 634ms\n",
      "8846:\tlearn: 0.0000000\ttotal: 4.86s\tremaining: 633ms\n",
      "8847:\tlearn: 0.0000000\ttotal: 4.86s\tremaining: 633ms\n",
      "8848:\tlearn: 0.0000000\ttotal: 4.86s\tremaining: 632ms\n",
      "8849:\tlearn: 0.0000000\ttotal: 4.86s\tremaining: 632ms\n",
      "8850:\tlearn: 0.0000000\ttotal: 4.86s\tremaining: 631ms\n",
      "8851:\tlearn: 0.0000000\ttotal: 4.86s\tremaining: 631ms\n",
      "8852:\tlearn: 0.0000000\ttotal: 4.86s\tremaining: 630ms\n",
      "8853:\tlearn: 0.0000000\ttotal: 4.86s\tremaining: 629ms\n",
      "8854:\tlearn: 0.0000000\ttotal: 4.86s\tremaining: 629ms\n",
      "8855:\tlearn: 0.0000000\ttotal: 4.86s\tremaining: 628ms\n",
      "8856:\tlearn: 0.0000000\ttotal: 4.86s\tremaining: 628ms\n",
      "8857:\tlearn: 0.0000000\ttotal: 4.87s\tremaining: 627ms\n",
      "8858:\tlearn: 0.0000000\ttotal: 4.87s\tremaining: 627ms\n",
      "8859:\tlearn: 0.0000000\ttotal: 4.87s\tremaining: 626ms\n",
      "8860:\tlearn: 0.0000000\ttotal: 4.87s\tremaining: 626ms\n",
      "8861:\tlearn: 0.0000000\ttotal: 4.87s\tremaining: 625ms\n",
      "8862:\tlearn: 0.0000000\ttotal: 4.87s\tremaining: 624ms\n",
      "8863:\tlearn: 0.0000000\ttotal: 4.87s\tremaining: 624ms\n",
      "8864:\tlearn: 0.0000000\ttotal: 4.87s\tremaining: 623ms\n",
      "8865:\tlearn: 0.0000000\ttotal: 4.87s\tremaining: 623ms\n",
      "8866:\tlearn: 0.0000000\ttotal: 4.87s\tremaining: 622ms\n",
      "8867:\tlearn: 0.0000000\ttotal: 4.87s\tremaining: 622ms\n",
      "8868:\tlearn: 0.0000000\ttotal: 4.87s\tremaining: 621ms\n",
      "8869:\tlearn: 0.0000000\ttotal: 4.87s\tremaining: 621ms\n",
      "8870:\tlearn: 0.0000000\ttotal: 4.87s\tremaining: 620ms\n",
      "8871:\tlearn: 0.0000000\ttotal: 4.87s\tremaining: 619ms\n",
      "8872:\tlearn: 0.0000000\ttotal: 4.87s\tremaining: 619ms\n",
      "8873:\tlearn: 0.0000000\ttotal: 4.87s\tremaining: 618ms\n",
      "8874:\tlearn: 0.0000000\ttotal: 4.88s\tremaining: 618ms\n",
      "8875:\tlearn: 0.0000000\ttotal: 4.88s\tremaining: 618ms\n",
      "8876:\tlearn: 0.0000000\ttotal: 4.88s\tremaining: 617ms\n",
      "8877:\tlearn: 0.0000000\ttotal: 4.88s\tremaining: 616ms\n",
      "8878:\tlearn: 0.0000000\ttotal: 4.88s\tremaining: 616ms\n",
      "8879:\tlearn: 0.0000000\ttotal: 4.88s\tremaining: 615ms\n",
      "8880:\tlearn: 0.0000000\ttotal: 4.88s\tremaining: 615ms\n",
      "8881:\tlearn: 0.0000000\ttotal: 4.88s\tremaining: 614ms\n",
      "8882:\tlearn: 0.0000000\ttotal: 4.88s\tremaining: 614ms\n",
      "8883:\tlearn: 0.0000000\ttotal: 4.88s\tremaining: 613ms\n",
      "8884:\tlearn: 0.0000000\ttotal: 4.88s\tremaining: 613ms\n",
      "8885:\tlearn: 0.0000000\ttotal: 4.88s\tremaining: 612ms\n",
      "8886:\tlearn: 0.0000000\ttotal: 4.88s\tremaining: 611ms\n",
      "8887:\tlearn: 0.0000000\ttotal: 4.88s\tremaining: 611ms\n",
      "8888:\tlearn: 0.0000000\ttotal: 4.88s\tremaining: 610ms\n",
      "8889:\tlearn: 0.0000000\ttotal: 4.88s\tremaining: 610ms\n",
      "8890:\tlearn: 0.0000000\ttotal: 4.88s\tremaining: 609ms\n",
      "8891:\tlearn: 0.0000000\ttotal: 4.88s\tremaining: 609ms\n",
      "8892:\tlearn: 0.0000000\ttotal: 4.88s\tremaining: 608ms\n",
      "8893:\tlearn: 0.0000000\ttotal: 4.88s\tremaining: 608ms\n",
      "8894:\tlearn: 0.0000000\ttotal: 4.88s\tremaining: 607ms\n",
      "8895:\tlearn: 0.0000000\ttotal: 4.89s\tremaining: 606ms\n",
      "8896:\tlearn: 0.0000000\ttotal: 4.89s\tremaining: 606ms\n",
      "8897:\tlearn: 0.0000000\ttotal: 4.89s\tremaining: 605ms\n",
      "8898:\tlearn: 0.0000000\ttotal: 4.89s\tremaining: 605ms\n",
      "8899:\tlearn: 0.0000000\ttotal: 4.89s\tremaining: 604ms\n",
      "8900:\tlearn: 0.0000000\ttotal: 4.89s\tremaining: 604ms\n",
      "8901:\tlearn: 0.0000000\ttotal: 4.89s\tremaining: 603ms\n",
      "8902:\tlearn: 0.0000000\ttotal: 4.89s\tremaining: 603ms\n",
      "8903:\tlearn: 0.0000000\ttotal: 4.89s\tremaining: 602ms\n",
      "8904:\tlearn: 0.0000000\ttotal: 4.89s\tremaining: 601ms\n",
      "8905:\tlearn: 0.0000000\ttotal: 4.89s\tremaining: 601ms\n",
      "8906:\tlearn: 0.0000000\ttotal: 4.89s\tremaining: 600ms\n",
      "8907:\tlearn: 0.0000000\ttotal: 4.89s\tremaining: 600ms\n",
      "8908:\tlearn: 0.0000000\ttotal: 4.89s\tremaining: 599ms\n",
      "8909:\tlearn: 0.0000000\ttotal: 4.89s\tremaining: 599ms\n",
      "8910:\tlearn: 0.0000000\ttotal: 4.89s\tremaining: 598ms\n",
      "8911:\tlearn: 0.0000000\ttotal: 4.89s\tremaining: 598ms\n",
      "8912:\tlearn: 0.0000000\ttotal: 4.89s\tremaining: 597ms\n",
      "8913:\tlearn: 0.0000000\ttotal: 4.9s\tremaining: 596ms\n",
      "8914:\tlearn: 0.0000000\ttotal: 4.9s\tremaining: 596ms\n",
      "8915:\tlearn: 0.0000000\ttotal: 4.9s\tremaining: 595ms\n",
      "8916:\tlearn: 0.0000000\ttotal: 4.9s\tremaining: 595ms\n",
      "8917:\tlearn: 0.0000000\ttotal: 4.9s\tremaining: 594ms\n",
      "8918:\tlearn: 0.0000000\ttotal: 4.9s\tremaining: 594ms\n",
      "8919:\tlearn: 0.0000000\ttotal: 4.9s\tremaining: 593ms\n",
      "8920:\tlearn: 0.0000000\ttotal: 4.9s\tremaining: 593ms\n",
      "8921:\tlearn: 0.0000000\ttotal: 4.9s\tremaining: 592ms\n",
      "8922:\tlearn: 0.0000000\ttotal: 4.9s\tremaining: 591ms\n",
      "8923:\tlearn: 0.0000000\ttotal: 4.9s\tremaining: 591ms\n",
      "8924:\tlearn: 0.0000000\ttotal: 4.9s\tremaining: 590ms\n",
      "8925:\tlearn: 0.0000000\ttotal: 4.9s\tremaining: 590ms\n",
      "8926:\tlearn: 0.0000000\ttotal: 4.9s\tremaining: 589ms\n",
      "8927:\tlearn: 0.0000000\ttotal: 4.9s\tremaining: 589ms\n",
      "8928:\tlearn: 0.0000000\ttotal: 4.9s\tremaining: 588ms\n",
      "8929:\tlearn: 0.0000000\ttotal: 4.9s\tremaining: 588ms\n",
      "8930:\tlearn: 0.0000000\ttotal: 4.9s\tremaining: 587ms\n",
      "8931:\tlearn: 0.0000000\ttotal: 4.91s\tremaining: 587ms\n",
      "8932:\tlearn: 0.0000000\ttotal: 4.91s\tremaining: 586ms\n",
      "8933:\tlearn: 0.0000000\ttotal: 4.91s\tremaining: 585ms\n",
      "8934:\tlearn: 0.0000000\ttotal: 4.91s\tremaining: 585ms\n",
      "8935:\tlearn: 0.0000000\ttotal: 4.91s\tremaining: 584ms\n",
      "8936:\tlearn: 0.0000000\ttotal: 4.91s\tremaining: 584ms\n",
      "8937:\tlearn: 0.0000000\ttotal: 4.91s\tremaining: 583ms\n",
      "8938:\tlearn: 0.0000000\ttotal: 4.91s\tremaining: 583ms\n",
      "8939:\tlearn: 0.0000000\ttotal: 4.91s\tremaining: 582ms\n",
      "8940:\tlearn: 0.0000000\ttotal: 4.91s\tremaining: 581ms\n",
      "8941:\tlearn: 0.0000000\ttotal: 4.91s\tremaining: 581ms\n",
      "8942:\tlearn: 0.0000000\ttotal: 4.91s\tremaining: 580ms\n",
      "8943:\tlearn: 0.0000000\ttotal: 4.91s\tremaining: 580ms\n",
      "8944:\tlearn: 0.0000000\ttotal: 4.91s\tremaining: 579ms\n",
      "8945:\tlearn: 0.0000000\ttotal: 4.91s\tremaining: 579ms\n",
      "8946:\tlearn: 0.0000000\ttotal: 4.91s\tremaining: 578ms\n",
      "8947:\tlearn: 0.0000000\ttotal: 4.91s\tremaining: 578ms\n",
      "8948:\tlearn: 0.0000000\ttotal: 4.91s\tremaining: 577ms\n",
      "8949:\tlearn: 0.0000000\ttotal: 4.91s\tremaining: 576ms\n",
      "8950:\tlearn: 0.0000000\ttotal: 4.91s\tremaining: 576ms\n",
      "8951:\tlearn: 0.0000000\ttotal: 4.91s\tremaining: 575ms\n",
      "8952:\tlearn: 0.0000000\ttotal: 4.92s\tremaining: 575ms\n",
      "8953:\tlearn: 0.0000000\ttotal: 4.92s\tremaining: 574ms\n",
      "8954:\tlearn: 0.0000000\ttotal: 4.92s\tremaining: 574ms\n",
      "8955:\tlearn: 0.0000000\ttotal: 4.92s\tremaining: 573ms\n",
      "8956:\tlearn: 0.0000000\ttotal: 4.92s\tremaining: 573ms\n",
      "8957:\tlearn: 0.0000000\ttotal: 4.92s\tremaining: 572ms\n",
      "8958:\tlearn: 0.0000000\ttotal: 4.92s\tremaining: 571ms\n",
      "8959:\tlearn: 0.0000000\ttotal: 4.92s\tremaining: 571ms\n",
      "8960:\tlearn: 0.0000000\ttotal: 4.92s\tremaining: 570ms\n",
      "8961:\tlearn: 0.0000000\ttotal: 4.92s\tremaining: 570ms\n",
      "8962:\tlearn: 0.0000000\ttotal: 4.92s\tremaining: 569ms\n",
      "8963:\tlearn: 0.0000000\ttotal: 4.92s\tremaining: 569ms\n",
      "8964:\tlearn: 0.0000000\ttotal: 4.92s\tremaining: 568ms\n",
      "8965:\tlearn: 0.0000000\ttotal: 4.92s\tremaining: 568ms\n",
      "8966:\tlearn: 0.0000000\ttotal: 4.92s\tremaining: 567ms\n",
      "8967:\tlearn: 0.0000000\ttotal: 4.92s\tremaining: 566ms\n",
      "8968:\tlearn: 0.0000000\ttotal: 4.92s\tremaining: 566ms\n",
      "8969:\tlearn: 0.0000000\ttotal: 4.92s\tremaining: 565ms\n",
      "8970:\tlearn: 0.0000000\ttotal: 4.92s\tremaining: 565ms\n",
      "8971:\tlearn: 0.0000000\ttotal: 4.92s\tremaining: 564ms\n",
      "8972:\tlearn: 0.0000000\ttotal: 4.92s\tremaining: 564ms\n",
      "8973:\tlearn: 0.0000000\ttotal: 4.92s\tremaining: 563ms\n",
      "8974:\tlearn: 0.0000000\ttotal: 4.92s\tremaining: 563ms\n",
      "8975:\tlearn: 0.0000000\ttotal: 4.93s\tremaining: 562ms\n",
      "8976:\tlearn: 0.0000000\ttotal: 4.93s\tremaining: 561ms\n",
      "8977:\tlearn: 0.0000000\ttotal: 4.93s\tremaining: 561ms\n",
      "8978:\tlearn: 0.0000000\ttotal: 4.93s\tremaining: 560ms\n",
      "8979:\tlearn: 0.0000000\ttotal: 4.93s\tremaining: 560ms\n",
      "8980:\tlearn: 0.0000000\ttotal: 4.93s\tremaining: 559ms\n",
      "8981:\tlearn: 0.0000000\ttotal: 4.93s\tremaining: 559ms\n",
      "8982:\tlearn: 0.0000000\ttotal: 4.93s\tremaining: 558ms\n",
      "8983:\tlearn: 0.0000000\ttotal: 4.93s\tremaining: 558ms\n",
      "8984:\tlearn: 0.0000000\ttotal: 4.93s\tremaining: 557ms\n",
      "8985:\tlearn: 0.0000000\ttotal: 4.93s\tremaining: 556ms\n",
      "8986:\tlearn: 0.0000000\ttotal: 4.93s\tremaining: 556ms\n",
      "8987:\tlearn: 0.0000000\ttotal: 4.93s\tremaining: 555ms\n",
      "8988:\tlearn: 0.0000000\ttotal: 4.93s\tremaining: 555ms\n",
      "8989:\tlearn: 0.0000000\ttotal: 4.93s\tremaining: 554ms\n",
      "8990:\tlearn: 0.0000000\ttotal: 4.93s\tremaining: 554ms\n",
      "8991:\tlearn: 0.0000000\ttotal: 4.93s\tremaining: 553ms\n",
      "8992:\tlearn: 0.0000000\ttotal: 4.93s\tremaining: 553ms\n",
      "8993:\tlearn: 0.0000000\ttotal: 4.93s\tremaining: 552ms\n",
      "8994:\tlearn: 0.0000000\ttotal: 4.94s\tremaining: 552ms\n",
      "8995:\tlearn: 0.0000000\ttotal: 4.94s\tremaining: 551ms\n",
      "8996:\tlearn: 0.0000000\ttotal: 4.94s\tremaining: 550ms\n",
      "8997:\tlearn: 0.0000000\ttotal: 4.94s\tremaining: 550ms\n",
      "8998:\tlearn: 0.0000000\ttotal: 4.94s\tremaining: 549ms\n",
      "8999:\tlearn: 0.0000000\ttotal: 4.94s\tremaining: 549ms\n",
      "9000:\tlearn: 0.0000000\ttotal: 4.94s\tremaining: 548ms\n",
      "9001:\tlearn: 0.0000000\ttotal: 4.94s\tremaining: 548ms\n",
      "9002:\tlearn: 0.0000000\ttotal: 4.94s\tremaining: 547ms\n",
      "9003:\tlearn: 0.0000000\ttotal: 4.94s\tremaining: 547ms\n",
      "9004:\tlearn: 0.0000000\ttotal: 4.94s\tremaining: 546ms\n",
      "9005:\tlearn: 0.0000000\ttotal: 4.94s\tremaining: 545ms\n",
      "9006:\tlearn: 0.0000000\ttotal: 4.94s\tremaining: 545ms\n",
      "9007:\tlearn: 0.0000000\ttotal: 4.94s\tremaining: 544ms\n",
      "9008:\tlearn: 0.0000000\ttotal: 4.94s\tremaining: 544ms\n",
      "9009:\tlearn: 0.0000000\ttotal: 4.94s\tremaining: 543ms\n",
      "9010:\tlearn: 0.0000000\ttotal: 4.94s\tremaining: 543ms\n",
      "9011:\tlearn: 0.0000000\ttotal: 4.94s\tremaining: 542ms\n",
      "9012:\tlearn: 0.0000000\ttotal: 4.95s\tremaining: 542ms\n",
      "9013:\tlearn: 0.0000000\ttotal: 4.95s\tremaining: 541ms\n",
      "9014:\tlearn: 0.0000000\ttotal: 4.95s\tremaining: 540ms\n",
      "9015:\tlearn: 0.0000000\ttotal: 4.95s\tremaining: 540ms\n",
      "9016:\tlearn: 0.0000000\ttotal: 4.95s\tremaining: 539ms\n",
      "9017:\tlearn: 0.0000000\ttotal: 4.95s\tremaining: 539ms\n",
      "9018:\tlearn: 0.0000000\ttotal: 4.95s\tremaining: 538ms\n",
      "9019:\tlearn: 0.0000000\ttotal: 4.95s\tremaining: 538ms\n",
      "9020:\tlearn: 0.0000000\ttotal: 4.95s\tremaining: 537ms\n",
      "9021:\tlearn: 0.0000000\ttotal: 4.95s\tremaining: 537ms\n",
      "9022:\tlearn: 0.0000000\ttotal: 4.95s\tremaining: 536ms\n",
      "9023:\tlearn: 0.0000000\ttotal: 4.95s\tremaining: 535ms\n",
      "9024:\tlearn: 0.0000000\ttotal: 4.95s\tremaining: 535ms\n",
      "9025:\tlearn: 0.0000000\ttotal: 4.95s\tremaining: 534ms\n",
      "9026:\tlearn: 0.0000000\ttotal: 4.95s\tremaining: 534ms\n",
      "9027:\tlearn: 0.0000000\ttotal: 4.95s\tremaining: 533ms\n",
      "9028:\tlearn: 0.0000000\ttotal: 4.95s\tremaining: 533ms\n",
      "9029:\tlearn: 0.0000000\ttotal: 4.95s\tremaining: 532ms\n",
      "9030:\tlearn: 0.0000000\ttotal: 4.95s\tremaining: 532ms\n",
      "9031:\tlearn: 0.0000000\ttotal: 4.95s\tremaining: 531ms\n",
      "9032:\tlearn: 0.0000000\ttotal: 4.96s\tremaining: 530ms\n",
      "9033:\tlearn: 0.0000000\ttotal: 4.96s\tremaining: 530ms\n",
      "9034:\tlearn: 0.0000000\ttotal: 4.96s\tremaining: 529ms\n",
      "9035:\tlearn: 0.0000000\ttotal: 4.96s\tremaining: 529ms\n",
      "9036:\tlearn: 0.0000000\ttotal: 4.96s\tremaining: 528ms\n",
      "9037:\tlearn: 0.0000000\ttotal: 4.96s\tremaining: 528ms\n",
      "9038:\tlearn: 0.0000000\ttotal: 4.96s\tremaining: 527ms\n",
      "9039:\tlearn: 0.0000000\ttotal: 4.96s\tremaining: 527ms\n",
      "9040:\tlearn: 0.0000000\ttotal: 4.96s\tremaining: 526ms\n",
      "9041:\tlearn: 0.0000000\ttotal: 4.96s\tremaining: 525ms\n",
      "9042:\tlearn: 0.0000000\ttotal: 4.96s\tremaining: 525ms\n",
      "9043:\tlearn: 0.0000000\ttotal: 4.96s\tremaining: 524ms\n",
      "9044:\tlearn: 0.0000000\ttotal: 4.96s\tremaining: 524ms\n",
      "9045:\tlearn: 0.0000000\ttotal: 4.96s\tremaining: 523ms\n",
      "9046:\tlearn: 0.0000000\ttotal: 4.96s\tremaining: 523ms\n",
      "9047:\tlearn: 0.0000000\ttotal: 4.96s\tremaining: 522ms\n",
      "9048:\tlearn: 0.0000000\ttotal: 4.96s\tremaining: 522ms\n",
      "9049:\tlearn: 0.0000000\ttotal: 4.96s\tremaining: 521ms\n",
      "9050:\tlearn: 0.0000000\ttotal: 4.96s\tremaining: 520ms\n",
      "9051:\tlearn: 0.0000000\ttotal: 4.96s\tremaining: 520ms\n",
      "9052:\tlearn: 0.0000000\ttotal: 4.96s\tremaining: 519ms\n",
      "9053:\tlearn: 0.0000000\ttotal: 4.96s\tremaining: 519ms\n",
      "9054:\tlearn: 0.0000000\ttotal: 4.96s\tremaining: 518ms\n",
      "9055:\tlearn: 0.0000000\ttotal: 4.97s\tremaining: 518ms\n",
      "9056:\tlearn: 0.0000000\ttotal: 4.97s\tremaining: 517ms\n",
      "9057:\tlearn: 0.0000000\ttotal: 4.97s\tremaining: 517ms\n",
      "9058:\tlearn: 0.0000000\ttotal: 4.97s\tremaining: 516ms\n",
      "9059:\tlearn: 0.0000000\ttotal: 4.97s\tremaining: 515ms\n",
      "9060:\tlearn: 0.0000000\ttotal: 4.97s\tremaining: 515ms\n",
      "9061:\tlearn: 0.0000000\ttotal: 4.97s\tremaining: 514ms\n",
      "9062:\tlearn: 0.0000000\ttotal: 4.97s\tremaining: 514ms\n",
      "9063:\tlearn: 0.0000000\ttotal: 4.97s\tremaining: 513ms\n",
      "9064:\tlearn: 0.0000000\ttotal: 4.97s\tremaining: 513ms\n",
      "9065:\tlearn: 0.0000000\ttotal: 4.97s\tremaining: 512ms\n",
      "9066:\tlearn: 0.0000000\ttotal: 4.97s\tremaining: 512ms\n",
      "9067:\tlearn: 0.0000000\ttotal: 4.97s\tremaining: 511ms\n",
      "9068:\tlearn: 0.0000000\ttotal: 4.97s\tremaining: 510ms\n",
      "9069:\tlearn: 0.0000000\ttotal: 4.97s\tremaining: 510ms\n",
      "9070:\tlearn: 0.0000000\ttotal: 4.97s\tremaining: 509ms\n",
      "9071:\tlearn: 0.0000000\ttotal: 4.97s\tremaining: 509ms\n",
      "9072:\tlearn: 0.0000000\ttotal: 4.97s\tremaining: 508ms\n",
      "9073:\tlearn: 0.0000000\ttotal: 4.98s\tremaining: 508ms\n",
      "9074:\tlearn: 0.0000000\ttotal: 4.98s\tremaining: 507ms\n",
      "9075:\tlearn: 0.0000000\ttotal: 4.98s\tremaining: 507ms\n",
      "9076:\tlearn: 0.0000000\ttotal: 4.98s\tremaining: 506ms\n",
      "9077:\tlearn: 0.0000000\ttotal: 4.98s\tremaining: 506ms\n",
      "9078:\tlearn: 0.0000000\ttotal: 4.98s\tremaining: 505ms\n",
      "9079:\tlearn: 0.0000000\ttotal: 4.98s\tremaining: 505ms\n",
      "9080:\tlearn: 0.0000000\ttotal: 4.98s\tremaining: 504ms\n",
      "9081:\tlearn: 0.0000000\ttotal: 4.98s\tremaining: 503ms\n",
      "9082:\tlearn: 0.0000000\ttotal: 4.98s\tremaining: 503ms\n",
      "9083:\tlearn: 0.0000000\ttotal: 4.98s\tremaining: 502ms\n",
      "9084:\tlearn: 0.0000000\ttotal: 4.98s\tremaining: 502ms\n",
      "9085:\tlearn: 0.0000000\ttotal: 4.98s\tremaining: 501ms\n",
      "9086:\tlearn: 0.0000000\ttotal: 4.98s\tremaining: 501ms\n",
      "9087:\tlearn: 0.0000000\ttotal: 4.98s\tremaining: 500ms\n",
      "9088:\tlearn: 0.0000000\ttotal: 4.98s\tremaining: 500ms\n",
      "9089:\tlearn: 0.0000000\ttotal: 4.98s\tremaining: 499ms\n",
      "9090:\tlearn: 0.0000000\ttotal: 4.99s\tremaining: 498ms\n",
      "9091:\tlearn: 0.0000000\ttotal: 4.99s\tremaining: 498ms\n",
      "9092:\tlearn: 0.0000000\ttotal: 4.99s\tremaining: 497ms\n",
      "9093:\tlearn: 0.0000000\ttotal: 4.99s\tremaining: 497ms\n",
      "9094:\tlearn: 0.0000000\ttotal: 4.99s\tremaining: 496ms\n",
      "9095:\tlearn: 0.0000000\ttotal: 4.99s\tremaining: 496ms\n",
      "9096:\tlearn: 0.0000000\ttotal: 4.99s\tremaining: 495ms\n",
      "9097:\tlearn: 0.0000000\ttotal: 4.99s\tremaining: 495ms\n",
      "9098:\tlearn: 0.0000000\ttotal: 4.99s\tremaining: 494ms\n",
      "9099:\tlearn: 0.0000000\ttotal: 4.99s\tremaining: 494ms\n",
      "9100:\tlearn: 0.0000000\ttotal: 4.99s\tremaining: 493ms\n",
      "9101:\tlearn: 0.0000000\ttotal: 4.99s\tremaining: 492ms\n",
      "9102:\tlearn: 0.0000000\ttotal: 4.99s\tremaining: 492ms\n",
      "9103:\tlearn: 0.0000000\ttotal: 4.99s\tremaining: 491ms\n",
      "9104:\tlearn: 0.0000000\ttotal: 4.99s\tremaining: 491ms\n",
      "9105:\tlearn: 0.0000000\ttotal: 4.99s\tremaining: 490ms\n",
      "9106:\tlearn: 0.0000000\ttotal: 4.99s\tremaining: 490ms\n",
      "9107:\tlearn: 0.0000000\ttotal: 4.99s\tremaining: 489ms\n",
      "9108:\tlearn: 0.0000000\ttotal: 5s\tremaining: 489ms\n",
      "9109:\tlearn: 0.0000000\ttotal: 5s\tremaining: 488ms\n",
      "9110:\tlearn: 0.0000000\ttotal: 5s\tremaining: 487ms\n",
      "9111:\tlearn: 0.0000000\ttotal: 5s\tremaining: 487ms\n",
      "9112:\tlearn: 0.0000000\ttotal: 5s\tremaining: 486ms\n",
      "9113:\tlearn: 0.0000000\ttotal: 5s\tremaining: 486ms\n",
      "9114:\tlearn: 0.0000000\ttotal: 5s\tremaining: 485ms\n",
      "9115:\tlearn: 0.0000000\ttotal: 5s\tremaining: 485ms\n",
      "9116:\tlearn: 0.0000000\ttotal: 5s\tremaining: 484ms\n",
      "9117:\tlearn: 0.0000000\ttotal: 5s\tremaining: 484ms\n",
      "9118:\tlearn: 0.0000000\ttotal: 5s\tremaining: 483ms\n",
      "9119:\tlearn: 0.0000000\ttotal: 5s\tremaining: 483ms\n",
      "9120:\tlearn: 0.0000000\ttotal: 5s\tremaining: 482ms\n",
      "9121:\tlearn: 0.0000000\ttotal: 5s\tremaining: 482ms\n",
      "9122:\tlearn: 0.0000000\ttotal: 5s\tremaining: 481ms\n",
      "9123:\tlearn: 0.0000000\ttotal: 5.01s\tremaining: 481ms\n",
      "9124:\tlearn: 0.0000000\ttotal: 5.01s\tremaining: 480ms\n",
      "9125:\tlearn: 0.0000000\ttotal: 5.01s\tremaining: 480ms\n",
      "9126:\tlearn: 0.0000000\ttotal: 5.01s\tremaining: 479ms\n",
      "9127:\tlearn: 0.0000000\ttotal: 5.01s\tremaining: 479ms\n",
      "9128:\tlearn: 0.0000000\ttotal: 5.01s\tremaining: 478ms\n",
      "9129:\tlearn: 0.0000000\ttotal: 5.01s\tremaining: 478ms\n",
      "9130:\tlearn: 0.0000000\ttotal: 5.01s\tremaining: 477ms\n",
      "9131:\tlearn: 0.0000000\ttotal: 5.01s\tremaining: 477ms\n",
      "9132:\tlearn: 0.0000000\ttotal: 5.01s\tremaining: 476ms\n",
      "9133:\tlearn: 0.0000000\ttotal: 5.01s\tremaining: 475ms\n",
      "9134:\tlearn: 0.0000000\ttotal: 5.01s\tremaining: 475ms\n",
      "9135:\tlearn: 0.0000000\ttotal: 5.01s\tremaining: 474ms\n",
      "9136:\tlearn: 0.0000000\ttotal: 5.01s\tremaining: 474ms\n",
      "9137:\tlearn: 0.0000000\ttotal: 5.02s\tremaining: 473ms\n",
      "9138:\tlearn: 0.0000000\ttotal: 5.02s\tremaining: 473ms\n",
      "9139:\tlearn: 0.0000000\ttotal: 5.02s\tremaining: 472ms\n",
      "9140:\tlearn: 0.0000000\ttotal: 5.02s\tremaining: 472ms\n",
      "9141:\tlearn: 0.0000000\ttotal: 5.02s\tremaining: 471ms\n",
      "9142:\tlearn: 0.0000000\ttotal: 5.02s\tremaining: 470ms\n",
      "9143:\tlearn: 0.0000000\ttotal: 5.02s\tremaining: 470ms\n",
      "9144:\tlearn: 0.0000000\ttotal: 5.02s\tremaining: 469ms\n",
      "9145:\tlearn: 0.0000000\ttotal: 5.02s\tremaining: 469ms\n",
      "9146:\tlearn: 0.0000000\ttotal: 5.02s\tremaining: 468ms\n",
      "9147:\tlearn: 0.0000000\ttotal: 5.02s\tremaining: 468ms\n",
      "9148:\tlearn: 0.0000000\ttotal: 5.02s\tremaining: 467ms\n",
      "9149:\tlearn: 0.0000000\ttotal: 5.02s\tremaining: 467ms\n",
      "9150:\tlearn: 0.0000000\ttotal: 5.02s\tremaining: 466ms\n",
      "9151:\tlearn: 0.0000000\ttotal: 5.02s\tremaining: 465ms\n",
      "9152:\tlearn: 0.0000000\ttotal: 5.02s\tremaining: 465ms\n",
      "9153:\tlearn: 0.0000000\ttotal: 5.02s\tremaining: 464ms\n",
      "9154:\tlearn: 0.0000000\ttotal: 5.02s\tremaining: 464ms\n",
      "9155:\tlearn: 0.0000000\ttotal: 5.03s\tremaining: 463ms\n",
      "9156:\tlearn: 0.0000000\ttotal: 5.03s\tremaining: 463ms\n",
      "9157:\tlearn: 0.0000000\ttotal: 5.03s\tremaining: 462ms\n",
      "9158:\tlearn: 0.0000000\ttotal: 5.03s\tremaining: 462ms\n",
      "9159:\tlearn: 0.0000000\ttotal: 5.03s\tremaining: 461ms\n",
      "9160:\tlearn: 0.0000000\ttotal: 5.03s\tremaining: 460ms\n",
      "9161:\tlearn: 0.0000000\ttotal: 5.03s\tremaining: 460ms\n",
      "9162:\tlearn: 0.0000000\ttotal: 5.03s\tremaining: 459ms\n",
      "9163:\tlearn: 0.0000000\ttotal: 5.03s\tremaining: 459ms\n",
      "9164:\tlearn: 0.0000000\ttotal: 5.03s\tremaining: 458ms\n",
      "9165:\tlearn: 0.0000000\ttotal: 5.03s\tremaining: 458ms\n",
      "9166:\tlearn: 0.0000000\ttotal: 5.03s\tremaining: 457ms\n",
      "9167:\tlearn: 0.0000000\ttotal: 5.03s\tremaining: 457ms\n",
      "9168:\tlearn: 0.0000000\ttotal: 5.03s\tremaining: 456ms\n",
      "9169:\tlearn: 0.0000000\ttotal: 5.03s\tremaining: 456ms\n",
      "9170:\tlearn: 0.0000000\ttotal: 5.03s\tremaining: 455ms\n",
      "9171:\tlearn: 0.0000000\ttotal: 5.03s\tremaining: 455ms\n",
      "9172:\tlearn: 0.0000000\ttotal: 5.04s\tremaining: 454ms\n",
      "9173:\tlearn: 0.0000000\ttotal: 5.04s\tremaining: 453ms\n",
      "9174:\tlearn: 0.0000000\ttotal: 5.04s\tremaining: 453ms\n",
      "9175:\tlearn: 0.0000000\ttotal: 5.04s\tremaining: 452ms\n",
      "9176:\tlearn: 0.0000000\ttotal: 5.04s\tremaining: 452ms\n",
      "9177:\tlearn: 0.0000000\ttotal: 5.04s\tremaining: 451ms\n",
      "9178:\tlearn: 0.0000000\ttotal: 5.04s\tremaining: 451ms\n",
      "9179:\tlearn: 0.0000000\ttotal: 5.04s\tremaining: 450ms\n",
      "9180:\tlearn: 0.0000000\ttotal: 5.04s\tremaining: 450ms\n",
      "9181:\tlearn: 0.0000000\ttotal: 5.04s\tremaining: 449ms\n",
      "9182:\tlearn: 0.0000000\ttotal: 5.04s\tremaining: 448ms\n",
      "9183:\tlearn: 0.0000000\ttotal: 5.04s\tremaining: 448ms\n",
      "9184:\tlearn: 0.0000000\ttotal: 5.04s\tremaining: 447ms\n",
      "9185:\tlearn: 0.0000000\ttotal: 5.04s\tremaining: 447ms\n",
      "9186:\tlearn: 0.0000000\ttotal: 5.04s\tremaining: 446ms\n",
      "9187:\tlearn: 0.0000000\ttotal: 5.04s\tremaining: 446ms\n",
      "9188:\tlearn: 0.0000000\ttotal: 5.04s\tremaining: 445ms\n",
      "9189:\tlearn: 0.0000000\ttotal: 5.04s\tremaining: 445ms\n",
      "9190:\tlearn: 0.0000000\ttotal: 5.04s\tremaining: 444ms\n",
      "9191:\tlearn: 0.0000000\ttotal: 5.04s\tremaining: 443ms\n",
      "9192:\tlearn: 0.0000000\ttotal: 5.04s\tremaining: 443ms\n",
      "9193:\tlearn: 0.0000000\ttotal: 5.05s\tremaining: 442ms\n",
      "9194:\tlearn: 0.0000000\ttotal: 5.05s\tremaining: 442ms\n",
      "9195:\tlearn: 0.0000000\ttotal: 5.05s\tremaining: 441ms\n",
      "9196:\tlearn: 0.0000000\ttotal: 5.05s\tremaining: 441ms\n",
      "9197:\tlearn: 0.0000000\ttotal: 5.05s\tremaining: 440ms\n",
      "9198:\tlearn: 0.0000000\ttotal: 5.05s\tremaining: 440ms\n",
      "9199:\tlearn: 0.0000000\ttotal: 5.05s\tremaining: 439ms\n",
      "9200:\tlearn: 0.0000000\ttotal: 5.05s\tremaining: 439ms\n",
      "9201:\tlearn: 0.0000000\ttotal: 5.05s\tremaining: 438ms\n",
      "9202:\tlearn: 0.0000000\ttotal: 5.05s\tremaining: 437ms\n",
      "9203:\tlearn: 0.0000000\ttotal: 5.05s\tremaining: 437ms\n",
      "9204:\tlearn: 0.0000000\ttotal: 5.05s\tremaining: 436ms\n",
      "9205:\tlearn: 0.0000000\ttotal: 5.05s\tremaining: 436ms\n",
      "9206:\tlearn: 0.0000000\ttotal: 5.05s\tremaining: 435ms\n",
      "9207:\tlearn: 0.0000000\ttotal: 5.05s\tremaining: 435ms\n",
      "9208:\tlearn: 0.0000000\ttotal: 5.05s\tremaining: 434ms\n",
      "9209:\tlearn: 0.0000000\ttotal: 5.05s\tremaining: 434ms\n",
      "9210:\tlearn: 0.0000000\ttotal: 5.05s\tremaining: 433ms\n",
      "9211:\tlearn: 0.0000000\ttotal: 5.06s\tremaining: 433ms\n",
      "9212:\tlearn: 0.0000000\ttotal: 5.06s\tremaining: 432ms\n",
      "9213:\tlearn: 0.0000000\ttotal: 5.06s\tremaining: 431ms\n",
      "9214:\tlearn: 0.0000000\ttotal: 5.06s\tremaining: 431ms\n",
      "9215:\tlearn: 0.0000000\ttotal: 5.06s\tremaining: 430ms\n",
      "9216:\tlearn: 0.0000000\ttotal: 5.06s\tremaining: 430ms\n",
      "9217:\tlearn: 0.0000000\ttotal: 5.06s\tremaining: 429ms\n",
      "9218:\tlearn: 0.0000000\ttotal: 5.06s\tremaining: 429ms\n",
      "9219:\tlearn: 0.0000000\ttotal: 5.06s\tremaining: 428ms\n",
      "9220:\tlearn: 0.0000000\ttotal: 5.06s\tremaining: 428ms\n",
      "9221:\tlearn: 0.0000000\ttotal: 5.06s\tremaining: 427ms\n",
      "9222:\tlearn: 0.0000000\ttotal: 5.06s\tremaining: 427ms\n",
      "9223:\tlearn: 0.0000000\ttotal: 5.06s\tremaining: 426ms\n",
      "9224:\tlearn: 0.0000000\ttotal: 5.06s\tremaining: 425ms\n",
      "9225:\tlearn: 0.0000000\ttotal: 5.06s\tremaining: 425ms\n",
      "9226:\tlearn: 0.0000000\ttotal: 5.07s\tremaining: 424ms\n",
      "9227:\tlearn: 0.0000000\ttotal: 5.07s\tremaining: 424ms\n",
      "9228:\tlearn: 0.0000000\ttotal: 5.07s\tremaining: 423ms\n",
      "9229:\tlearn: 0.0000000\ttotal: 5.07s\tremaining: 423ms\n",
      "9230:\tlearn: 0.0000000\ttotal: 5.07s\tremaining: 422ms\n",
      "9231:\tlearn: 0.0000000\ttotal: 5.07s\tremaining: 422ms\n",
      "9232:\tlearn: 0.0000000\ttotal: 5.07s\tremaining: 421ms\n",
      "9233:\tlearn: 0.0000000\ttotal: 5.07s\tremaining: 420ms\n",
      "9234:\tlearn: 0.0000000\ttotal: 5.07s\tremaining: 420ms\n",
      "9235:\tlearn: 0.0000000\ttotal: 5.07s\tremaining: 419ms\n",
      "9236:\tlearn: 0.0000000\ttotal: 5.07s\tremaining: 419ms\n",
      "9237:\tlearn: 0.0000000\ttotal: 5.07s\tremaining: 418ms\n",
      "9238:\tlearn: 0.0000000\ttotal: 5.07s\tremaining: 418ms\n",
      "9239:\tlearn: 0.0000000\ttotal: 5.07s\tremaining: 417ms\n",
      "9240:\tlearn: 0.0000000\ttotal: 5.07s\tremaining: 417ms\n",
      "9241:\tlearn: 0.0000000\ttotal: 5.07s\tremaining: 416ms\n",
      "9242:\tlearn: 0.0000000\ttotal: 5.07s\tremaining: 415ms\n",
      "9243:\tlearn: 0.0000000\ttotal: 5.07s\tremaining: 415ms\n",
      "9244:\tlearn: 0.0000000\ttotal: 5.07s\tremaining: 414ms\n",
      "9245:\tlearn: 0.0000000\ttotal: 5.07s\tremaining: 414ms\n",
      "9246:\tlearn: 0.0000000\ttotal: 5.08s\tremaining: 413ms\n",
      "9247:\tlearn: 0.0000000\ttotal: 5.08s\tremaining: 413ms\n",
      "9248:\tlearn: 0.0000000\ttotal: 5.08s\tremaining: 412ms\n",
      "9249:\tlearn: 0.0000000\ttotal: 5.08s\tremaining: 412ms\n",
      "9250:\tlearn: 0.0000000\ttotal: 5.08s\tremaining: 411ms\n",
      "9251:\tlearn: 0.0000000\ttotal: 5.08s\tremaining: 411ms\n",
      "9252:\tlearn: 0.0000000\ttotal: 5.08s\tremaining: 410ms\n",
      "9253:\tlearn: 0.0000000\ttotal: 5.08s\tremaining: 409ms\n",
      "9254:\tlearn: 0.0000000\ttotal: 5.08s\tremaining: 409ms\n",
      "9255:\tlearn: 0.0000000\ttotal: 5.08s\tremaining: 408ms\n",
      "9256:\tlearn: 0.0000000\ttotal: 5.08s\tremaining: 408ms\n",
      "9257:\tlearn: 0.0000000\ttotal: 5.08s\tremaining: 407ms\n",
      "9258:\tlearn: 0.0000000\ttotal: 5.08s\tremaining: 407ms\n",
      "9259:\tlearn: 0.0000000\ttotal: 5.08s\tremaining: 406ms\n",
      "9260:\tlearn: 0.0000000\ttotal: 5.08s\tremaining: 406ms\n",
      "9261:\tlearn: 0.0000000\ttotal: 5.08s\tremaining: 405ms\n",
      "9262:\tlearn: 0.0000000\ttotal: 5.08s\tremaining: 404ms\n",
      "9263:\tlearn: 0.0000000\ttotal: 5.08s\tremaining: 404ms\n",
      "9264:\tlearn: 0.0000000\ttotal: 5.08s\tremaining: 403ms\n",
      "9265:\tlearn: 0.0000000\ttotal: 5.08s\tremaining: 403ms\n",
      "9266:\tlearn: 0.0000000\ttotal: 5.08s\tremaining: 402ms\n",
      "9267:\tlearn: 0.0000000\ttotal: 5.08s\tremaining: 402ms\n",
      "9268:\tlearn: 0.0000000\ttotal: 5.08s\tremaining: 401ms\n",
      "9269:\tlearn: 0.0000000\ttotal: 5.09s\tremaining: 401ms\n",
      "9270:\tlearn: 0.0000000\ttotal: 5.09s\tremaining: 400ms\n",
      "9271:\tlearn: 0.0000000\ttotal: 5.09s\tremaining: 399ms\n",
      "9272:\tlearn: 0.0000000\ttotal: 5.09s\tremaining: 399ms\n",
      "9273:\tlearn: 0.0000000\ttotal: 5.09s\tremaining: 398ms\n",
      "9274:\tlearn: 0.0000000\ttotal: 5.09s\tremaining: 398ms\n",
      "9275:\tlearn: 0.0000000\ttotal: 5.09s\tremaining: 397ms\n",
      "9276:\tlearn: 0.0000000\ttotal: 5.09s\tremaining: 397ms\n",
      "9277:\tlearn: 0.0000000\ttotal: 5.09s\tremaining: 396ms\n",
      "9278:\tlearn: 0.0000000\ttotal: 5.09s\tremaining: 396ms\n",
      "9279:\tlearn: 0.0000000\ttotal: 5.09s\tremaining: 395ms\n",
      "9280:\tlearn: 0.0000000\ttotal: 5.09s\tremaining: 394ms\n",
      "9281:\tlearn: 0.0000000\ttotal: 5.09s\tremaining: 394ms\n",
      "9282:\tlearn: 0.0000000\ttotal: 5.09s\tremaining: 393ms\n",
      "9283:\tlearn: 0.0000000\ttotal: 5.09s\tremaining: 393ms\n",
      "9284:\tlearn: 0.0000000\ttotal: 5.09s\tremaining: 392ms\n",
      "9285:\tlearn: 0.0000000\ttotal: 5.09s\tremaining: 392ms\n",
      "9286:\tlearn: 0.0000000\ttotal: 5.09s\tremaining: 391ms\n",
      "9287:\tlearn: 0.0000000\ttotal: 5.09s\tremaining: 391ms\n",
      "9288:\tlearn: 0.0000000\ttotal: 5.09s\tremaining: 390ms\n",
      "9289:\tlearn: 0.0000000\ttotal: 5.09s\tremaining: 389ms\n",
      "9290:\tlearn: 0.0000000\ttotal: 5.1s\tremaining: 389ms\n",
      "9291:\tlearn: 0.0000000\ttotal: 5.1s\tremaining: 388ms\n",
      "9292:\tlearn: 0.0000000\ttotal: 5.1s\tremaining: 388ms\n",
      "9293:\tlearn: 0.0000000\ttotal: 5.1s\tremaining: 387ms\n",
      "9294:\tlearn: 0.0000000\ttotal: 5.1s\tremaining: 387ms\n",
      "9295:\tlearn: 0.0000000\ttotal: 5.1s\tremaining: 386ms\n",
      "9296:\tlearn: 0.0000000\ttotal: 5.1s\tremaining: 386ms\n",
      "9297:\tlearn: 0.0000000\ttotal: 5.1s\tremaining: 385ms\n",
      "9298:\tlearn: 0.0000000\ttotal: 5.1s\tremaining: 384ms\n",
      "9299:\tlearn: 0.0000000\ttotal: 5.1s\tremaining: 384ms\n",
      "9300:\tlearn: 0.0000000\ttotal: 5.1s\tremaining: 383ms\n",
      "9301:\tlearn: 0.0000000\ttotal: 5.1s\tremaining: 383ms\n",
      "9302:\tlearn: 0.0000000\ttotal: 5.1s\tremaining: 382ms\n",
      "9303:\tlearn: 0.0000000\ttotal: 5.1s\tremaining: 382ms\n",
      "9304:\tlearn: 0.0000000\ttotal: 5.1s\tremaining: 381ms\n",
      "9305:\tlearn: 0.0000000\ttotal: 5.1s\tremaining: 381ms\n",
      "9306:\tlearn: 0.0000000\ttotal: 5.1s\tremaining: 380ms\n",
      "9307:\tlearn: 0.0000000\ttotal: 5.11s\tremaining: 380ms\n",
      "9308:\tlearn: 0.0000000\ttotal: 5.11s\tremaining: 379ms\n",
      "9309:\tlearn: 0.0000000\ttotal: 5.11s\tremaining: 378ms\n",
      "9310:\tlearn: 0.0000000\ttotal: 5.11s\tremaining: 378ms\n",
      "9311:\tlearn: 0.0000000\ttotal: 5.11s\tremaining: 377ms\n",
      "9312:\tlearn: 0.0000000\ttotal: 5.11s\tremaining: 377ms\n",
      "9313:\tlearn: 0.0000000\ttotal: 5.11s\tremaining: 376ms\n",
      "9314:\tlearn: 0.0000000\ttotal: 5.11s\tremaining: 376ms\n",
      "9315:\tlearn: 0.0000000\ttotal: 5.11s\tremaining: 375ms\n",
      "9316:\tlearn: 0.0000000\ttotal: 5.11s\tremaining: 375ms\n",
      "9317:\tlearn: 0.0000000\ttotal: 5.11s\tremaining: 374ms\n",
      "9318:\tlearn: 0.0000000\ttotal: 5.11s\tremaining: 373ms\n",
      "9319:\tlearn: 0.0000000\ttotal: 5.11s\tremaining: 373ms\n",
      "9320:\tlearn: 0.0000000\ttotal: 5.11s\tremaining: 372ms\n",
      "9321:\tlearn: 0.0000000\ttotal: 5.11s\tremaining: 372ms\n",
      "9322:\tlearn: 0.0000000\ttotal: 5.11s\tremaining: 371ms\n",
      "9323:\tlearn: 0.0000000\ttotal: 5.11s\tremaining: 371ms\n",
      "9324:\tlearn: 0.0000000\ttotal: 5.11s\tremaining: 370ms\n",
      "9325:\tlearn: 0.0000000\ttotal: 5.11s\tremaining: 370ms\n",
      "9326:\tlearn: 0.0000000\ttotal: 5.11s\tremaining: 369ms\n",
      "9327:\tlearn: 0.0000000\ttotal: 5.11s\tremaining: 368ms\n",
      "9328:\tlearn: 0.0000000\ttotal: 5.12s\tremaining: 368ms\n",
      "9329:\tlearn: 0.0000000\ttotal: 5.12s\tremaining: 367ms\n",
      "9330:\tlearn: 0.0000000\ttotal: 5.12s\tremaining: 367ms\n",
      "9331:\tlearn: 0.0000000\ttotal: 5.12s\tremaining: 366ms\n",
      "9332:\tlearn: 0.0000000\ttotal: 5.12s\tremaining: 366ms\n",
      "9333:\tlearn: 0.0000000\ttotal: 5.12s\tremaining: 365ms\n",
      "9334:\tlearn: 0.0000000\ttotal: 5.12s\tremaining: 365ms\n",
      "9335:\tlearn: 0.0000000\ttotal: 5.12s\tremaining: 364ms\n",
      "9336:\tlearn: 0.0000000\ttotal: 5.12s\tremaining: 364ms\n",
      "9337:\tlearn: 0.0000000\ttotal: 5.12s\tremaining: 363ms\n",
      "9338:\tlearn: 0.0000000\ttotal: 5.12s\tremaining: 362ms\n",
      "9339:\tlearn: 0.0000000\ttotal: 5.12s\tremaining: 362ms\n",
      "9340:\tlearn: 0.0000000\ttotal: 5.12s\tremaining: 361ms\n",
      "9341:\tlearn: 0.0000000\ttotal: 5.12s\tremaining: 361ms\n",
      "9342:\tlearn: 0.0000000\ttotal: 5.12s\tremaining: 360ms\n",
      "9343:\tlearn: 0.0000000\ttotal: 5.12s\tremaining: 360ms\n",
      "9344:\tlearn: 0.0000000\ttotal: 5.12s\tremaining: 359ms\n",
      "9345:\tlearn: 0.0000000\ttotal: 5.12s\tremaining: 359ms\n",
      "9346:\tlearn: 0.0000000\ttotal: 5.12s\tremaining: 358ms\n",
      "9347:\tlearn: 0.0000000\ttotal: 5.12s\tremaining: 357ms\n",
      "9348:\tlearn: 0.0000000\ttotal: 5.12s\tremaining: 357ms\n",
      "9349:\tlearn: 0.0000000\ttotal: 5.13s\tremaining: 356ms\n",
      "9350:\tlearn: 0.0000000\ttotal: 5.13s\tremaining: 356ms\n",
      "9351:\tlearn: 0.0000000\ttotal: 5.13s\tremaining: 355ms\n",
      "9352:\tlearn: 0.0000000\ttotal: 5.13s\tremaining: 355ms\n",
      "9353:\tlearn: 0.0000000\ttotal: 5.13s\tremaining: 354ms\n",
      "9354:\tlearn: 0.0000000\ttotal: 5.13s\tremaining: 354ms\n",
      "9355:\tlearn: 0.0000000\ttotal: 5.13s\tremaining: 353ms\n",
      "9356:\tlearn: 0.0000000\ttotal: 5.13s\tremaining: 352ms\n",
      "9357:\tlearn: 0.0000000\ttotal: 5.13s\tremaining: 352ms\n",
      "9358:\tlearn: 0.0000000\ttotal: 5.13s\tremaining: 351ms\n",
      "9359:\tlearn: 0.0000000\ttotal: 5.13s\tremaining: 351ms\n",
      "9360:\tlearn: 0.0000000\ttotal: 5.13s\tremaining: 350ms\n",
      "9361:\tlearn: 0.0000000\ttotal: 5.13s\tremaining: 350ms\n",
      "9362:\tlearn: 0.0000000\ttotal: 5.13s\tremaining: 349ms\n",
      "9363:\tlearn: 0.0000000\ttotal: 5.13s\tremaining: 349ms\n",
      "9364:\tlearn: 0.0000000\ttotal: 5.13s\tremaining: 348ms\n",
      "9365:\tlearn: 0.0000000\ttotal: 5.13s\tremaining: 348ms\n",
      "9366:\tlearn: 0.0000000\ttotal: 5.13s\tremaining: 347ms\n",
      "9367:\tlearn: 0.0000000\ttotal: 5.13s\tremaining: 346ms\n",
      "9368:\tlearn: 0.0000000\ttotal: 5.13s\tremaining: 346ms\n",
      "9369:\tlearn: 0.0000000\ttotal: 5.13s\tremaining: 345ms\n",
      "9370:\tlearn: 0.0000000\ttotal: 5.14s\tremaining: 345ms\n",
      "9371:\tlearn: 0.0000000\ttotal: 5.14s\tremaining: 344ms\n",
      "9372:\tlearn: 0.0000000\ttotal: 5.14s\tremaining: 344ms\n",
      "9373:\tlearn: 0.0000000\ttotal: 5.14s\tremaining: 343ms\n",
      "9374:\tlearn: 0.0000000\ttotal: 5.14s\tremaining: 343ms\n",
      "9375:\tlearn: 0.0000000\ttotal: 5.14s\tremaining: 342ms\n",
      "9376:\tlearn: 0.0000000\ttotal: 5.14s\tremaining: 341ms\n",
      "9377:\tlearn: 0.0000000\ttotal: 5.14s\tremaining: 341ms\n",
      "9378:\tlearn: 0.0000000\ttotal: 5.14s\tremaining: 340ms\n",
      "9379:\tlearn: 0.0000000\ttotal: 5.14s\tremaining: 340ms\n",
      "9380:\tlearn: 0.0000000\ttotal: 5.14s\tremaining: 339ms\n",
      "9381:\tlearn: 0.0000000\ttotal: 5.14s\tremaining: 339ms\n",
      "9382:\tlearn: 0.0000000\ttotal: 5.14s\tremaining: 338ms\n",
      "9383:\tlearn: 0.0000000\ttotal: 5.14s\tremaining: 338ms\n",
      "9384:\tlearn: 0.0000000\ttotal: 5.14s\tremaining: 337ms\n",
      "9385:\tlearn: 0.0000000\ttotal: 5.14s\tremaining: 336ms\n",
      "9386:\tlearn: 0.0000000\ttotal: 5.14s\tremaining: 336ms\n",
      "9387:\tlearn: 0.0000000\ttotal: 5.14s\tremaining: 335ms\n",
      "9388:\tlearn: 0.0000000\ttotal: 5.14s\tremaining: 335ms\n",
      "9389:\tlearn: 0.0000000\ttotal: 5.14s\tremaining: 334ms\n",
      "9390:\tlearn: 0.0000000\ttotal: 5.14s\tremaining: 334ms\n",
      "9391:\tlearn: 0.0000000\ttotal: 5.14s\tremaining: 333ms\n",
      "9392:\tlearn: 0.0000000\ttotal: 5.15s\tremaining: 333ms\n",
      "9393:\tlearn: 0.0000000\ttotal: 5.15s\tremaining: 332ms\n",
      "9394:\tlearn: 0.0000000\ttotal: 5.15s\tremaining: 332ms\n",
      "9395:\tlearn: 0.0000000\ttotal: 5.15s\tremaining: 331ms\n",
      "9396:\tlearn: 0.0000000\ttotal: 5.15s\tremaining: 330ms\n",
      "9397:\tlearn: 0.0000000\ttotal: 5.15s\tremaining: 330ms\n",
      "9398:\tlearn: 0.0000000\ttotal: 5.15s\tremaining: 329ms\n",
      "9399:\tlearn: 0.0000000\ttotal: 5.15s\tremaining: 329ms\n",
      "9400:\tlearn: 0.0000000\ttotal: 5.15s\tremaining: 328ms\n",
      "9401:\tlearn: 0.0000000\ttotal: 5.15s\tremaining: 328ms\n",
      "9402:\tlearn: 0.0000000\ttotal: 5.15s\tremaining: 327ms\n",
      "9403:\tlearn: 0.0000000\ttotal: 5.15s\tremaining: 327ms\n",
      "9404:\tlearn: 0.0000000\ttotal: 5.15s\tremaining: 326ms\n",
      "9405:\tlearn: 0.0000000\ttotal: 5.15s\tremaining: 325ms\n",
      "9406:\tlearn: 0.0000000\ttotal: 5.15s\tremaining: 325ms\n",
      "9407:\tlearn: 0.0000000\ttotal: 5.15s\tremaining: 324ms\n",
      "9408:\tlearn: 0.0000000\ttotal: 5.15s\tremaining: 324ms\n",
      "9409:\tlearn: 0.0000000\ttotal: 5.15s\tremaining: 323ms\n",
      "9410:\tlearn: 0.0000000\ttotal: 5.16s\tremaining: 323ms\n",
      "9411:\tlearn: 0.0000000\ttotal: 5.16s\tremaining: 322ms\n",
      "9412:\tlearn: 0.0000000\ttotal: 5.16s\tremaining: 322ms\n",
      "9413:\tlearn: 0.0000000\ttotal: 5.16s\tremaining: 321ms\n",
      "9414:\tlearn: 0.0000000\ttotal: 5.16s\tremaining: 320ms\n",
      "9415:\tlearn: 0.0000000\ttotal: 5.16s\tremaining: 320ms\n",
      "9416:\tlearn: 0.0000000\ttotal: 5.16s\tremaining: 319ms\n",
      "9417:\tlearn: 0.0000000\ttotal: 5.16s\tremaining: 319ms\n",
      "9418:\tlearn: 0.0000000\ttotal: 5.16s\tremaining: 318ms\n",
      "9419:\tlearn: 0.0000000\ttotal: 5.16s\tremaining: 318ms\n",
      "9420:\tlearn: 0.0000000\ttotal: 5.16s\tremaining: 317ms\n",
      "9421:\tlearn: 0.0000000\ttotal: 5.16s\tremaining: 317ms\n",
      "9422:\tlearn: 0.0000000\ttotal: 5.16s\tremaining: 316ms\n",
      "9423:\tlearn: 0.0000000\ttotal: 5.16s\tremaining: 316ms\n",
      "9424:\tlearn: 0.0000000\ttotal: 5.16s\tremaining: 315ms\n",
      "9425:\tlearn: 0.0000000\ttotal: 5.16s\tremaining: 314ms\n",
      "9426:\tlearn: 0.0000000\ttotal: 5.16s\tremaining: 314ms\n",
      "9427:\tlearn: 0.0000000\ttotal: 5.16s\tremaining: 313ms\n",
      "9428:\tlearn: 0.0000000\ttotal: 5.16s\tremaining: 313ms\n",
      "9429:\tlearn: 0.0000000\ttotal: 5.16s\tremaining: 312ms\n",
      "9430:\tlearn: 0.0000000\ttotal: 5.17s\tremaining: 312ms\n",
      "9431:\tlearn: 0.0000000\ttotal: 5.17s\tremaining: 311ms\n",
      "9432:\tlearn: 0.0000000\ttotal: 5.17s\tremaining: 311ms\n",
      "9433:\tlearn: 0.0000000\ttotal: 5.17s\tremaining: 310ms\n",
      "9434:\tlearn: 0.0000000\ttotal: 5.17s\tremaining: 309ms\n",
      "9435:\tlearn: 0.0000000\ttotal: 5.17s\tremaining: 309ms\n",
      "9436:\tlearn: 0.0000000\ttotal: 5.17s\tremaining: 308ms\n",
      "9437:\tlearn: 0.0000000\ttotal: 5.17s\tremaining: 308ms\n",
      "9438:\tlearn: 0.0000000\ttotal: 5.17s\tremaining: 307ms\n",
      "9439:\tlearn: 0.0000000\ttotal: 5.17s\tremaining: 307ms\n",
      "9440:\tlearn: 0.0000000\ttotal: 5.17s\tremaining: 306ms\n",
      "9441:\tlearn: 0.0000000\ttotal: 5.17s\tremaining: 306ms\n",
      "9442:\tlearn: 0.0000000\ttotal: 5.17s\tremaining: 305ms\n",
      "9443:\tlearn: 0.0000000\ttotal: 5.17s\tremaining: 304ms\n",
      "9444:\tlearn: 0.0000000\ttotal: 5.17s\tremaining: 304ms\n",
      "9445:\tlearn: 0.0000000\ttotal: 5.17s\tremaining: 303ms\n",
      "9446:\tlearn: 0.0000000\ttotal: 5.17s\tremaining: 303ms\n",
      "9447:\tlearn: 0.0000000\ttotal: 5.17s\tremaining: 302ms\n",
      "9448:\tlearn: 0.0000000\ttotal: 5.17s\tremaining: 302ms\n",
      "9449:\tlearn: 0.0000000\ttotal: 5.17s\tremaining: 301ms\n",
      "9450:\tlearn: 0.0000000\ttotal: 5.17s\tremaining: 301ms\n",
      "9451:\tlearn: 0.0000000\ttotal: 5.18s\tremaining: 300ms\n",
      "9452:\tlearn: 0.0000000\ttotal: 5.18s\tremaining: 300ms\n",
      "9453:\tlearn: 0.0000000\ttotal: 5.18s\tremaining: 299ms\n",
      "9454:\tlearn: 0.0000000\ttotal: 5.18s\tremaining: 298ms\n",
      "9455:\tlearn: 0.0000000\ttotal: 5.18s\tremaining: 298ms\n",
      "9456:\tlearn: 0.0000000\ttotal: 5.18s\tremaining: 297ms\n",
      "9457:\tlearn: 0.0000000\ttotal: 5.18s\tremaining: 297ms\n",
      "9458:\tlearn: 0.0000000\ttotal: 5.18s\tremaining: 296ms\n",
      "9459:\tlearn: 0.0000000\ttotal: 5.18s\tremaining: 296ms\n",
      "9460:\tlearn: 0.0000000\ttotal: 5.18s\tremaining: 295ms\n",
      "9461:\tlearn: 0.0000000\ttotal: 5.18s\tremaining: 295ms\n",
      "9462:\tlearn: 0.0000000\ttotal: 5.18s\tremaining: 294ms\n",
      "9463:\tlearn: 0.0000000\ttotal: 5.18s\tremaining: 294ms\n",
      "9464:\tlearn: 0.0000000\ttotal: 5.18s\tremaining: 293ms\n",
      "9465:\tlearn: 0.0000000\ttotal: 5.18s\tremaining: 292ms\n",
      "9466:\tlearn: 0.0000000\ttotal: 5.18s\tremaining: 292ms\n",
      "9467:\tlearn: 0.0000000\ttotal: 5.18s\tremaining: 291ms\n",
      "9468:\tlearn: 0.0000000\ttotal: 5.18s\tremaining: 291ms\n",
      "9469:\tlearn: 0.0000000\ttotal: 5.18s\tremaining: 290ms\n",
      "9470:\tlearn: 0.0000000\ttotal: 5.19s\tremaining: 290ms\n",
      "9471:\tlearn: 0.0000000\ttotal: 5.19s\tremaining: 289ms\n",
      "9472:\tlearn: 0.0000000\ttotal: 5.19s\tremaining: 289ms\n",
      "9473:\tlearn: 0.0000000\ttotal: 5.19s\tremaining: 288ms\n",
      "9474:\tlearn: 0.0000000\ttotal: 5.19s\tremaining: 287ms\n",
      "9475:\tlearn: 0.0000000\ttotal: 5.19s\tremaining: 287ms\n",
      "9476:\tlearn: 0.0000000\ttotal: 5.19s\tremaining: 286ms\n",
      "9477:\tlearn: 0.0000000\ttotal: 5.19s\tremaining: 286ms\n",
      "9478:\tlearn: 0.0000000\ttotal: 5.19s\tremaining: 285ms\n",
      "9479:\tlearn: 0.0000000\ttotal: 5.19s\tremaining: 285ms\n",
      "9480:\tlearn: 0.0000000\ttotal: 5.19s\tremaining: 284ms\n",
      "9481:\tlearn: 0.0000000\ttotal: 5.19s\tremaining: 284ms\n",
      "9482:\tlearn: 0.0000000\ttotal: 5.19s\tremaining: 283ms\n",
      "9483:\tlearn: 0.0000000\ttotal: 5.19s\tremaining: 282ms\n",
      "9484:\tlearn: 0.0000000\ttotal: 5.19s\tremaining: 282ms\n",
      "9485:\tlearn: 0.0000000\ttotal: 5.19s\tremaining: 281ms\n",
      "9486:\tlearn: 0.0000000\ttotal: 5.19s\tremaining: 281ms\n",
      "9487:\tlearn: 0.0000000\ttotal: 5.19s\tremaining: 280ms\n",
      "9488:\tlearn: 0.0000000\ttotal: 5.2s\tremaining: 280ms\n",
      "9489:\tlearn: 0.0000000\ttotal: 5.2s\tremaining: 279ms\n",
      "9490:\tlearn: 0.0000000\ttotal: 5.2s\tremaining: 279ms\n",
      "9491:\tlearn: 0.0000000\ttotal: 5.2s\tremaining: 278ms\n",
      "9492:\tlearn: 0.0000000\ttotal: 5.2s\tremaining: 278ms\n",
      "9493:\tlearn: 0.0000000\ttotal: 5.2s\tremaining: 277ms\n",
      "9494:\tlearn: 0.0000000\ttotal: 5.2s\tremaining: 277ms\n",
      "9495:\tlearn: 0.0000000\ttotal: 5.2s\tremaining: 276ms\n",
      "9496:\tlearn: 0.0000000\ttotal: 5.2s\tremaining: 275ms\n",
      "9497:\tlearn: 0.0000000\ttotal: 5.2s\tremaining: 275ms\n",
      "9498:\tlearn: 0.0000000\ttotal: 5.2s\tremaining: 274ms\n",
      "9499:\tlearn: 0.0000000\ttotal: 5.2s\tremaining: 274ms\n",
      "9500:\tlearn: 0.0000000\ttotal: 5.2s\tremaining: 273ms\n",
      "9501:\tlearn: 0.0000000\ttotal: 5.2s\tremaining: 273ms\n",
      "9502:\tlearn: 0.0000000\ttotal: 5.2s\tremaining: 272ms\n",
      "9503:\tlearn: 0.0000000\ttotal: 5.2s\tremaining: 272ms\n",
      "9504:\tlearn: 0.0000000\ttotal: 5.2s\tremaining: 271ms\n",
      "9505:\tlearn: 0.0000000\ttotal: 5.2s\tremaining: 270ms\n",
      "9506:\tlearn: 0.0000000\ttotal: 5.2s\tremaining: 270ms\n",
      "9507:\tlearn: 0.0000000\ttotal: 5.2s\tremaining: 269ms\n",
      "9508:\tlearn: 0.0000000\ttotal: 5.21s\tremaining: 269ms\n",
      "9509:\tlearn: 0.0000000\ttotal: 5.21s\tremaining: 268ms\n",
      "9510:\tlearn: 0.0000000\ttotal: 5.21s\tremaining: 268ms\n",
      "9511:\tlearn: 0.0000000\ttotal: 5.21s\tremaining: 267ms\n",
      "9512:\tlearn: 0.0000000\ttotal: 5.21s\tremaining: 267ms\n",
      "9513:\tlearn: 0.0000000\ttotal: 5.21s\tremaining: 266ms\n",
      "9514:\tlearn: 0.0000000\ttotal: 5.21s\tremaining: 265ms\n",
      "9515:\tlearn: 0.0000000\ttotal: 5.21s\tremaining: 265ms\n",
      "9516:\tlearn: 0.0000000\ttotal: 5.21s\tremaining: 264ms\n",
      "9517:\tlearn: 0.0000000\ttotal: 5.21s\tremaining: 264ms\n",
      "9518:\tlearn: 0.0000000\ttotal: 5.21s\tremaining: 263ms\n",
      "9519:\tlearn: 0.0000000\ttotal: 5.21s\tremaining: 263ms\n",
      "9520:\tlearn: 0.0000000\ttotal: 5.21s\tremaining: 262ms\n",
      "9521:\tlearn: 0.0000000\ttotal: 5.21s\tremaining: 262ms\n",
      "9522:\tlearn: 0.0000000\ttotal: 5.21s\tremaining: 261ms\n",
      "9523:\tlearn: 0.0000000\ttotal: 5.21s\tremaining: 261ms\n",
      "9524:\tlearn: 0.0000000\ttotal: 5.21s\tremaining: 260ms\n",
      "9525:\tlearn: 0.0000000\ttotal: 5.21s\tremaining: 259ms\n",
      "9526:\tlearn: 0.0000000\ttotal: 5.21s\tremaining: 259ms\n",
      "9527:\tlearn: 0.0000000\ttotal: 5.21s\tremaining: 258ms\n",
      "9528:\tlearn: 0.0000000\ttotal: 5.22s\tremaining: 258ms\n",
      "9529:\tlearn: 0.0000000\ttotal: 5.22s\tremaining: 257ms\n",
      "9530:\tlearn: 0.0000000\ttotal: 5.22s\tremaining: 257ms\n",
      "9531:\tlearn: 0.0000000\ttotal: 5.22s\tremaining: 256ms\n",
      "9532:\tlearn: 0.0000000\ttotal: 5.22s\tremaining: 256ms\n",
      "9533:\tlearn: 0.0000000\ttotal: 5.22s\tremaining: 255ms\n",
      "9534:\tlearn: 0.0000000\ttotal: 5.22s\tremaining: 255ms\n",
      "9535:\tlearn: 0.0000000\ttotal: 5.22s\tremaining: 254ms\n",
      "9536:\tlearn: 0.0000000\ttotal: 5.22s\tremaining: 253ms\n",
      "9537:\tlearn: 0.0000000\ttotal: 5.22s\tremaining: 253ms\n",
      "9538:\tlearn: 0.0000000\ttotal: 5.22s\tremaining: 252ms\n",
      "9539:\tlearn: 0.0000000\ttotal: 5.22s\tremaining: 252ms\n",
      "9540:\tlearn: 0.0000000\ttotal: 5.22s\tremaining: 251ms\n",
      "9541:\tlearn: 0.0000000\ttotal: 5.22s\tremaining: 251ms\n",
      "9542:\tlearn: 0.0000000\ttotal: 5.22s\tremaining: 250ms\n",
      "9543:\tlearn: 0.0000000\ttotal: 5.22s\tremaining: 250ms\n",
      "9544:\tlearn: 0.0000000\ttotal: 5.22s\tremaining: 249ms\n",
      "9545:\tlearn: 0.0000000\ttotal: 5.22s\tremaining: 248ms\n",
      "9546:\tlearn: 0.0000000\ttotal: 5.22s\tremaining: 248ms\n",
      "9547:\tlearn: 0.0000000\ttotal: 5.22s\tremaining: 247ms\n",
      "9548:\tlearn: 0.0000000\ttotal: 5.22s\tremaining: 247ms\n",
      "9549:\tlearn: 0.0000000\ttotal: 5.23s\tremaining: 246ms\n",
      "9550:\tlearn: 0.0000000\ttotal: 5.23s\tremaining: 246ms\n",
      "9551:\tlearn: 0.0000000\ttotal: 5.23s\tremaining: 245ms\n",
      "9552:\tlearn: 0.0000000\ttotal: 5.23s\tremaining: 245ms\n",
      "9553:\tlearn: 0.0000000\ttotal: 5.23s\tremaining: 244ms\n",
      "9554:\tlearn: 0.0000000\ttotal: 5.23s\tremaining: 244ms\n",
      "9555:\tlearn: 0.0000000\ttotal: 5.23s\tremaining: 243ms\n",
      "9556:\tlearn: 0.0000000\ttotal: 5.23s\tremaining: 242ms\n",
      "9557:\tlearn: 0.0000000\ttotal: 5.23s\tremaining: 242ms\n",
      "9558:\tlearn: 0.0000000\ttotal: 5.23s\tremaining: 241ms\n",
      "9559:\tlearn: 0.0000000\ttotal: 5.23s\tremaining: 241ms\n",
      "9560:\tlearn: 0.0000000\ttotal: 5.23s\tremaining: 240ms\n",
      "9561:\tlearn: 0.0000000\ttotal: 5.23s\tremaining: 240ms\n",
      "9562:\tlearn: 0.0000000\ttotal: 5.23s\tremaining: 239ms\n",
      "9563:\tlearn: 0.0000000\ttotal: 5.23s\tremaining: 239ms\n",
      "9564:\tlearn: 0.0000000\ttotal: 5.23s\tremaining: 238ms\n",
      "9565:\tlearn: 0.0000000\ttotal: 5.23s\tremaining: 237ms\n",
      "9566:\tlearn: 0.0000000\ttotal: 5.24s\tremaining: 237ms\n",
      "9567:\tlearn: 0.0000000\ttotal: 5.24s\tremaining: 236ms\n",
      "9568:\tlearn: 0.0000000\ttotal: 5.24s\tremaining: 236ms\n",
      "9569:\tlearn: 0.0000000\ttotal: 5.24s\tremaining: 235ms\n",
      "9570:\tlearn: 0.0000000\ttotal: 5.24s\tremaining: 235ms\n",
      "9571:\tlearn: 0.0000000\ttotal: 5.24s\tremaining: 234ms\n",
      "9572:\tlearn: 0.0000000\ttotal: 5.24s\tremaining: 234ms\n",
      "9573:\tlearn: 0.0000000\ttotal: 5.24s\tremaining: 233ms\n",
      "9574:\tlearn: 0.0000000\ttotal: 5.24s\tremaining: 233ms\n",
      "9575:\tlearn: 0.0000000\ttotal: 5.24s\tremaining: 232ms\n",
      "9576:\tlearn: 0.0000000\ttotal: 5.24s\tremaining: 231ms\n",
      "9577:\tlearn: 0.0000000\ttotal: 5.24s\tremaining: 231ms\n",
      "9578:\tlearn: 0.0000000\ttotal: 5.24s\tremaining: 230ms\n",
      "9579:\tlearn: 0.0000000\ttotal: 5.24s\tremaining: 230ms\n",
      "9580:\tlearn: 0.0000000\ttotal: 5.24s\tremaining: 229ms\n",
      "9581:\tlearn: 0.0000000\ttotal: 5.24s\tremaining: 229ms\n",
      "9582:\tlearn: 0.0000000\ttotal: 5.24s\tremaining: 228ms\n",
      "9583:\tlearn: 0.0000000\ttotal: 5.24s\tremaining: 228ms\n",
      "9584:\tlearn: 0.0000000\ttotal: 5.24s\tremaining: 227ms\n",
      "9585:\tlearn: 0.0000000\ttotal: 5.25s\tremaining: 227ms\n",
      "9586:\tlearn: 0.0000000\ttotal: 5.25s\tremaining: 226ms\n",
      "9587:\tlearn: 0.0000000\ttotal: 5.25s\tremaining: 225ms\n",
      "9588:\tlearn: 0.0000000\ttotal: 5.25s\tremaining: 225ms\n",
      "9589:\tlearn: 0.0000000\ttotal: 5.25s\tremaining: 224ms\n",
      "9590:\tlearn: 0.0000000\ttotal: 5.25s\tremaining: 224ms\n",
      "9591:\tlearn: 0.0000000\ttotal: 5.25s\tremaining: 223ms\n",
      "9592:\tlearn: 0.0000000\ttotal: 5.25s\tremaining: 223ms\n",
      "9593:\tlearn: 0.0000000\ttotal: 5.25s\tremaining: 222ms\n",
      "9594:\tlearn: 0.0000000\ttotal: 5.25s\tremaining: 222ms\n",
      "9595:\tlearn: 0.0000000\ttotal: 5.25s\tremaining: 221ms\n",
      "9596:\tlearn: 0.0000000\ttotal: 5.25s\tremaining: 220ms\n",
      "9597:\tlearn: 0.0000000\ttotal: 5.25s\tremaining: 220ms\n",
      "9598:\tlearn: 0.0000000\ttotal: 5.25s\tremaining: 219ms\n",
      "9599:\tlearn: 0.0000000\ttotal: 5.25s\tremaining: 219ms\n",
      "9600:\tlearn: 0.0000000\ttotal: 5.25s\tremaining: 218ms\n",
      "9601:\tlearn: 0.0000000\ttotal: 5.25s\tremaining: 218ms\n",
      "9602:\tlearn: 0.0000000\ttotal: 5.25s\tremaining: 217ms\n",
      "9603:\tlearn: 0.0000000\ttotal: 5.25s\tremaining: 217ms\n",
      "9604:\tlearn: 0.0000000\ttotal: 5.25s\tremaining: 216ms\n",
      "9605:\tlearn: 0.0000000\ttotal: 5.25s\tremaining: 216ms\n",
      "9606:\tlearn: 0.0000000\ttotal: 5.25s\tremaining: 215ms\n",
      "9607:\tlearn: 0.0000000\ttotal: 5.26s\tremaining: 214ms\n",
      "9608:\tlearn: 0.0000000\ttotal: 5.26s\tremaining: 214ms\n",
      "9609:\tlearn: 0.0000000\ttotal: 5.26s\tremaining: 213ms\n",
      "9610:\tlearn: 0.0000000\ttotal: 5.26s\tremaining: 213ms\n",
      "9611:\tlearn: 0.0000000\ttotal: 5.26s\tremaining: 212ms\n",
      "9612:\tlearn: 0.0000000\ttotal: 5.26s\tremaining: 212ms\n",
      "9613:\tlearn: 0.0000000\ttotal: 5.26s\tremaining: 211ms\n",
      "9614:\tlearn: 0.0000000\ttotal: 5.26s\tremaining: 211ms\n",
      "9615:\tlearn: 0.0000000\ttotal: 5.26s\tremaining: 210ms\n",
      "9616:\tlearn: 0.0000000\ttotal: 5.26s\tremaining: 209ms\n",
      "9617:\tlearn: 0.0000000\ttotal: 5.26s\tremaining: 209ms\n",
      "9618:\tlearn: 0.0000000\ttotal: 5.26s\tremaining: 208ms\n",
      "9619:\tlearn: 0.0000000\ttotal: 5.26s\tremaining: 208ms\n",
      "9620:\tlearn: 0.0000000\ttotal: 5.26s\tremaining: 207ms\n",
      "9621:\tlearn: 0.0000000\ttotal: 5.26s\tremaining: 207ms\n",
      "9622:\tlearn: 0.0000000\ttotal: 5.26s\tremaining: 206ms\n",
      "9623:\tlearn: 0.0000000\ttotal: 5.26s\tremaining: 206ms\n",
      "9624:\tlearn: 0.0000000\ttotal: 5.26s\tremaining: 205ms\n",
      "9625:\tlearn: 0.0000000\ttotal: 5.26s\tremaining: 205ms\n",
      "9626:\tlearn: 0.0000000\ttotal: 5.26s\tremaining: 204ms\n",
      "9627:\tlearn: 0.0000000\ttotal: 5.26s\tremaining: 203ms\n",
      "9628:\tlearn: 0.0000000\ttotal: 5.27s\tremaining: 203ms\n",
      "9629:\tlearn: 0.0000000\ttotal: 5.27s\tremaining: 202ms\n",
      "9630:\tlearn: 0.0000000\ttotal: 5.27s\tremaining: 202ms\n",
      "9631:\tlearn: 0.0000000\ttotal: 5.27s\tremaining: 201ms\n",
      "9632:\tlearn: 0.0000000\ttotal: 5.27s\tremaining: 201ms\n",
      "9633:\tlearn: 0.0000000\ttotal: 5.27s\tremaining: 200ms\n",
      "9634:\tlearn: 0.0000000\ttotal: 5.27s\tremaining: 200ms\n",
      "9635:\tlearn: 0.0000000\ttotal: 5.27s\tremaining: 199ms\n",
      "9636:\tlearn: 0.0000000\ttotal: 5.27s\tremaining: 199ms\n",
      "9637:\tlearn: 0.0000000\ttotal: 5.27s\tremaining: 198ms\n",
      "9638:\tlearn: 0.0000000\ttotal: 5.27s\tremaining: 197ms\n",
      "9639:\tlearn: 0.0000000\ttotal: 5.27s\tremaining: 197ms\n",
      "9640:\tlearn: 0.0000000\ttotal: 5.27s\tremaining: 196ms\n",
      "9641:\tlearn: 0.0000000\ttotal: 5.27s\tremaining: 196ms\n",
      "9642:\tlearn: 0.0000000\ttotal: 5.27s\tremaining: 195ms\n",
      "9643:\tlearn: 0.0000000\ttotal: 5.27s\tremaining: 195ms\n",
      "9644:\tlearn: 0.0000000\ttotal: 5.27s\tremaining: 194ms\n",
      "9645:\tlearn: 0.0000000\ttotal: 5.27s\tremaining: 194ms\n",
      "9646:\tlearn: 0.0000000\ttotal: 5.27s\tremaining: 193ms\n",
      "9647:\tlearn: 0.0000000\ttotal: 5.28s\tremaining: 192ms\n",
      "9648:\tlearn: 0.0000000\ttotal: 5.28s\tremaining: 192ms\n",
      "9649:\tlearn: 0.0000000\ttotal: 5.28s\tremaining: 191ms\n",
      "9650:\tlearn: 0.0000000\ttotal: 5.28s\tremaining: 191ms\n",
      "9651:\tlearn: 0.0000000\ttotal: 5.28s\tremaining: 190ms\n",
      "9652:\tlearn: 0.0000000\ttotal: 5.28s\tremaining: 190ms\n",
      "9653:\tlearn: 0.0000000\ttotal: 5.28s\tremaining: 189ms\n",
      "9654:\tlearn: 0.0000000\ttotal: 5.28s\tremaining: 189ms\n",
      "9655:\tlearn: 0.0000000\ttotal: 5.28s\tremaining: 188ms\n",
      "9656:\tlearn: 0.0000000\ttotal: 5.28s\tremaining: 188ms\n",
      "9657:\tlearn: 0.0000000\ttotal: 5.28s\tremaining: 187ms\n",
      "9658:\tlearn: 0.0000000\ttotal: 5.28s\tremaining: 186ms\n",
      "9659:\tlearn: 0.0000000\ttotal: 5.28s\tremaining: 186ms\n",
      "9660:\tlearn: 0.0000000\ttotal: 5.28s\tremaining: 185ms\n",
      "9661:\tlearn: 0.0000000\ttotal: 5.28s\tremaining: 185ms\n",
      "9662:\tlearn: 0.0000000\ttotal: 5.28s\tremaining: 184ms\n",
      "9663:\tlearn: 0.0000000\ttotal: 5.28s\tremaining: 184ms\n",
      "9664:\tlearn: 0.0000000\ttotal: 5.28s\tremaining: 183ms\n",
      "9665:\tlearn: 0.0000000\ttotal: 5.28s\tremaining: 183ms\n",
      "9666:\tlearn: 0.0000000\ttotal: 5.28s\tremaining: 182ms\n",
      "9667:\tlearn: 0.0000000\ttotal: 5.28s\tremaining: 181ms\n",
      "9668:\tlearn: 0.0000000\ttotal: 5.29s\tremaining: 181ms\n",
      "9669:\tlearn: 0.0000000\ttotal: 5.29s\tremaining: 180ms\n",
      "9670:\tlearn: 0.0000000\ttotal: 5.29s\tremaining: 180ms\n",
      "9671:\tlearn: 0.0000000\ttotal: 5.29s\tremaining: 179ms\n",
      "9672:\tlearn: 0.0000000\ttotal: 5.29s\tremaining: 179ms\n",
      "9673:\tlearn: 0.0000000\ttotal: 5.29s\tremaining: 178ms\n",
      "9674:\tlearn: 0.0000000\ttotal: 5.29s\tremaining: 178ms\n",
      "9675:\tlearn: 0.0000000\ttotal: 5.29s\tremaining: 177ms\n",
      "9676:\tlearn: 0.0000000\ttotal: 5.29s\tremaining: 177ms\n",
      "9677:\tlearn: 0.0000000\ttotal: 5.29s\tremaining: 176ms\n",
      "9678:\tlearn: 0.0000000\ttotal: 5.29s\tremaining: 175ms\n",
      "9679:\tlearn: 0.0000000\ttotal: 5.29s\tremaining: 175ms\n",
      "9680:\tlearn: 0.0000000\ttotal: 5.29s\tremaining: 174ms\n",
      "9681:\tlearn: 0.0000000\ttotal: 5.29s\tremaining: 174ms\n",
      "9682:\tlearn: 0.0000000\ttotal: 5.29s\tremaining: 173ms\n",
      "9683:\tlearn: 0.0000000\ttotal: 5.29s\tremaining: 173ms\n",
      "9684:\tlearn: 0.0000000\ttotal: 5.29s\tremaining: 172ms\n",
      "9685:\tlearn: 0.0000000\ttotal: 5.29s\tremaining: 172ms\n",
      "9686:\tlearn: 0.0000000\ttotal: 5.29s\tremaining: 171ms\n",
      "9687:\tlearn: 0.0000000\ttotal: 5.29s\tremaining: 170ms\n",
      "9688:\tlearn: 0.0000000\ttotal: 5.29s\tremaining: 170ms\n",
      "9689:\tlearn: 0.0000000\ttotal: 5.29s\tremaining: 169ms\n",
      "9690:\tlearn: 0.0000000\ttotal: 5.29s\tremaining: 169ms\n",
      "9691:\tlearn: 0.0000000\ttotal: 5.3s\tremaining: 168ms\n",
      "9692:\tlearn: 0.0000000\ttotal: 5.3s\tremaining: 168ms\n",
      "9693:\tlearn: 0.0000000\ttotal: 5.3s\tremaining: 167ms\n",
      "9694:\tlearn: 0.0000000\ttotal: 5.3s\tremaining: 167ms\n",
      "9695:\tlearn: 0.0000000\ttotal: 5.3s\tremaining: 166ms\n",
      "9696:\tlearn: 0.0000000\ttotal: 5.3s\tremaining: 166ms\n",
      "9697:\tlearn: 0.0000000\ttotal: 5.3s\tremaining: 165ms\n",
      "9698:\tlearn: 0.0000000\ttotal: 5.3s\tremaining: 164ms\n",
      "9699:\tlearn: 0.0000000\ttotal: 5.3s\tremaining: 164ms\n",
      "9700:\tlearn: 0.0000000\ttotal: 5.3s\tremaining: 163ms\n",
      "9701:\tlearn: 0.0000000\ttotal: 5.3s\tremaining: 163ms\n",
      "9702:\tlearn: 0.0000000\ttotal: 5.3s\tremaining: 162ms\n",
      "9703:\tlearn: 0.0000000\ttotal: 5.3s\tremaining: 162ms\n",
      "9704:\tlearn: 0.0000000\ttotal: 5.3s\tremaining: 161ms\n",
      "9705:\tlearn: 0.0000000\ttotal: 5.3s\tremaining: 161ms\n",
      "9706:\tlearn: 0.0000000\ttotal: 5.3s\tremaining: 160ms\n",
      "9707:\tlearn: 0.0000000\ttotal: 5.3s\tremaining: 160ms\n",
      "9708:\tlearn: 0.0000000\ttotal: 5.3s\tremaining: 159ms\n",
      "9709:\tlearn: 0.0000000\ttotal: 5.3s\tremaining: 158ms\n",
      "9710:\tlearn: 0.0000000\ttotal: 5.3s\tremaining: 158ms\n",
      "9711:\tlearn: 0.0000000\ttotal: 5.3s\tremaining: 157ms\n",
      "9712:\tlearn: 0.0000000\ttotal: 5.31s\tremaining: 157ms\n",
      "9713:\tlearn: 0.0000000\ttotal: 5.31s\tremaining: 156ms\n",
      "9714:\tlearn: 0.0000000\ttotal: 5.31s\tremaining: 156ms\n",
      "9715:\tlearn: 0.0000000\ttotal: 5.31s\tremaining: 155ms\n",
      "9716:\tlearn: 0.0000000\ttotal: 5.31s\tremaining: 155ms\n",
      "9717:\tlearn: 0.0000000\ttotal: 5.31s\tremaining: 154ms\n",
      "9718:\tlearn: 0.0000000\ttotal: 5.31s\tremaining: 153ms\n",
      "9719:\tlearn: 0.0000000\ttotal: 5.31s\tremaining: 153ms\n",
      "9720:\tlearn: 0.0000000\ttotal: 5.31s\tremaining: 152ms\n",
      "9721:\tlearn: 0.0000000\ttotal: 5.31s\tremaining: 152ms\n",
      "9722:\tlearn: 0.0000000\ttotal: 5.31s\tremaining: 151ms\n",
      "9723:\tlearn: 0.0000000\ttotal: 5.31s\tremaining: 151ms\n",
      "9724:\tlearn: 0.0000000\ttotal: 5.31s\tremaining: 150ms\n",
      "9725:\tlearn: 0.0000000\ttotal: 5.31s\tremaining: 150ms\n",
      "9726:\tlearn: 0.0000000\ttotal: 5.31s\tremaining: 149ms\n",
      "9727:\tlearn: 0.0000000\ttotal: 5.31s\tremaining: 149ms\n",
      "9728:\tlearn: 0.0000000\ttotal: 5.31s\tremaining: 148ms\n",
      "9729:\tlearn: 0.0000000\ttotal: 5.32s\tremaining: 147ms\n",
      "9730:\tlearn: 0.0000000\ttotal: 5.32s\tremaining: 147ms\n",
      "9731:\tlearn: 0.0000000\ttotal: 5.32s\tremaining: 146ms\n",
      "9732:\tlearn: 0.0000000\ttotal: 5.32s\tremaining: 146ms\n",
      "9733:\tlearn: 0.0000000\ttotal: 5.32s\tremaining: 145ms\n",
      "9734:\tlearn: 0.0000000\ttotal: 5.32s\tremaining: 145ms\n",
      "9735:\tlearn: 0.0000000\ttotal: 5.32s\tremaining: 144ms\n",
      "9736:\tlearn: 0.0000000\ttotal: 5.32s\tremaining: 144ms\n",
      "9737:\tlearn: 0.0000000\ttotal: 5.32s\tremaining: 143ms\n",
      "9738:\tlearn: 0.0000000\ttotal: 5.32s\tremaining: 143ms\n",
      "9739:\tlearn: 0.0000000\ttotal: 5.32s\tremaining: 142ms\n",
      "9740:\tlearn: 0.0000000\ttotal: 5.32s\tremaining: 141ms\n",
      "9741:\tlearn: 0.0000000\ttotal: 5.32s\tremaining: 141ms\n",
      "9742:\tlearn: 0.0000000\ttotal: 5.32s\tremaining: 140ms\n",
      "9743:\tlearn: 0.0000000\ttotal: 5.32s\tremaining: 140ms\n",
      "9744:\tlearn: 0.0000000\ttotal: 5.32s\tremaining: 139ms\n",
      "9745:\tlearn: 0.0000000\ttotal: 5.32s\tremaining: 139ms\n",
      "9746:\tlearn: 0.0000000\ttotal: 5.32s\tremaining: 138ms\n",
      "9747:\tlearn: 0.0000000\ttotal: 5.32s\tremaining: 138ms\n",
      "9748:\tlearn: 0.0000000\ttotal: 5.32s\tremaining: 137ms\n",
      "9749:\tlearn: 0.0000000\ttotal: 5.32s\tremaining: 137ms\n",
      "9750:\tlearn: 0.0000000\ttotal: 5.32s\tremaining: 136ms\n",
      "9751:\tlearn: 0.0000000\ttotal: 5.33s\tremaining: 135ms\n",
      "9752:\tlearn: 0.0000000\ttotal: 5.33s\tremaining: 135ms\n",
      "9753:\tlearn: 0.0000000\ttotal: 5.33s\tremaining: 134ms\n",
      "9754:\tlearn: 0.0000000\ttotal: 5.33s\tremaining: 134ms\n",
      "9755:\tlearn: 0.0000000\ttotal: 5.33s\tremaining: 133ms\n",
      "9756:\tlearn: 0.0000000\ttotal: 5.33s\tremaining: 133ms\n",
      "9757:\tlearn: 0.0000000\ttotal: 5.33s\tremaining: 132ms\n",
      "9758:\tlearn: 0.0000000\ttotal: 5.33s\tremaining: 132ms\n",
      "9759:\tlearn: 0.0000000\ttotal: 5.33s\tremaining: 131ms\n",
      "9760:\tlearn: 0.0000000\ttotal: 5.33s\tremaining: 131ms\n",
      "9761:\tlearn: 0.0000000\ttotal: 5.33s\tremaining: 130ms\n",
      "9762:\tlearn: 0.0000000\ttotal: 5.33s\tremaining: 129ms\n",
      "9763:\tlearn: 0.0000000\ttotal: 5.33s\tremaining: 129ms\n",
      "9764:\tlearn: 0.0000000\ttotal: 5.33s\tremaining: 128ms\n",
      "9765:\tlearn: 0.0000000\ttotal: 5.33s\tremaining: 128ms\n",
      "9766:\tlearn: 0.0000000\ttotal: 5.33s\tremaining: 127ms\n",
      "9767:\tlearn: 0.0000000\ttotal: 5.33s\tremaining: 127ms\n",
      "9768:\tlearn: 0.0000000\ttotal: 5.33s\tremaining: 126ms\n",
      "9769:\tlearn: 0.0000000\ttotal: 5.33s\tremaining: 126ms\n",
      "9770:\tlearn: 0.0000000\ttotal: 5.33s\tremaining: 125ms\n",
      "9771:\tlearn: 0.0000000\ttotal: 5.33s\tremaining: 124ms\n",
      "9772:\tlearn: 0.0000000\ttotal: 5.33s\tremaining: 124ms\n",
      "9773:\tlearn: 0.0000000\ttotal: 5.34s\tremaining: 123ms\n",
      "9774:\tlearn: 0.0000000\ttotal: 5.34s\tremaining: 123ms\n",
      "9775:\tlearn: 0.0000000\ttotal: 5.34s\tremaining: 122ms\n",
      "9776:\tlearn: 0.0000000\ttotal: 5.34s\tremaining: 122ms\n",
      "9777:\tlearn: 0.0000000\ttotal: 5.34s\tremaining: 121ms\n",
      "9778:\tlearn: 0.0000000\ttotal: 5.34s\tremaining: 121ms\n",
      "9779:\tlearn: 0.0000000\ttotal: 5.34s\tremaining: 120ms\n",
      "9780:\tlearn: 0.0000000\ttotal: 5.34s\tremaining: 120ms\n",
      "9781:\tlearn: 0.0000000\ttotal: 5.34s\tremaining: 119ms\n",
      "9782:\tlearn: 0.0000000\ttotal: 5.34s\tremaining: 118ms\n",
      "9783:\tlearn: 0.0000000\ttotal: 5.34s\tremaining: 118ms\n",
      "9784:\tlearn: 0.0000000\ttotal: 5.34s\tremaining: 117ms\n",
      "9785:\tlearn: 0.0000000\ttotal: 5.34s\tremaining: 117ms\n",
      "9786:\tlearn: 0.0000000\ttotal: 5.34s\tremaining: 116ms\n",
      "9787:\tlearn: 0.0000000\ttotal: 5.34s\tremaining: 116ms\n",
      "9788:\tlearn: 0.0000000\ttotal: 5.34s\tremaining: 115ms\n",
      "9789:\tlearn: 0.0000000\ttotal: 5.34s\tremaining: 115ms\n",
      "9790:\tlearn: 0.0000000\ttotal: 5.35s\tremaining: 114ms\n",
      "9791:\tlearn: 0.0000000\ttotal: 5.35s\tremaining: 114ms\n",
      "9792:\tlearn: 0.0000000\ttotal: 5.35s\tremaining: 113ms\n",
      "9793:\tlearn: 0.0000000\ttotal: 5.35s\tremaining: 112ms\n",
      "9794:\tlearn: 0.0000000\ttotal: 5.35s\tremaining: 112ms\n",
      "9795:\tlearn: 0.0000000\ttotal: 5.35s\tremaining: 111ms\n",
      "9796:\tlearn: 0.0000000\ttotal: 5.35s\tremaining: 111ms\n",
      "9797:\tlearn: 0.0000000\ttotal: 5.35s\tremaining: 110ms\n",
      "9798:\tlearn: 0.0000000\ttotal: 5.35s\tremaining: 110ms\n",
      "9799:\tlearn: 0.0000000\ttotal: 5.35s\tremaining: 109ms\n",
      "9800:\tlearn: 0.0000000\ttotal: 5.35s\tremaining: 109ms\n",
      "9801:\tlearn: 0.0000000\ttotal: 5.35s\tremaining: 108ms\n",
      "9802:\tlearn: 0.0000000\ttotal: 5.35s\tremaining: 108ms\n",
      "9803:\tlearn: 0.0000000\ttotal: 5.35s\tremaining: 107ms\n",
      "9804:\tlearn: 0.0000000\ttotal: 5.35s\tremaining: 106ms\n",
      "9805:\tlearn: 0.0000000\ttotal: 5.35s\tremaining: 106ms\n",
      "9806:\tlearn: 0.0000000\ttotal: 5.35s\tremaining: 105ms\n",
      "9807:\tlearn: 0.0000000\ttotal: 5.35s\tremaining: 105ms\n",
      "9808:\tlearn: 0.0000000\ttotal: 5.36s\tremaining: 104ms\n",
      "9809:\tlearn: 0.0000000\ttotal: 5.36s\tremaining: 104ms\n",
      "9810:\tlearn: 0.0000000\ttotal: 5.36s\tremaining: 103ms\n",
      "9811:\tlearn: 0.0000000\ttotal: 5.36s\tremaining: 103ms\n",
      "9812:\tlearn: 0.0000000\ttotal: 5.36s\tremaining: 102ms\n",
      "9813:\tlearn: 0.0000000\ttotal: 5.36s\tremaining: 102ms\n",
      "9814:\tlearn: 0.0000000\ttotal: 5.36s\tremaining: 101ms\n",
      "9815:\tlearn: 0.0000000\ttotal: 5.36s\tremaining: 100ms\n",
      "9816:\tlearn: 0.0000000\ttotal: 5.36s\tremaining: 99.9ms\n",
      "9817:\tlearn: 0.0000000\ttotal: 5.36s\tremaining: 99.4ms\n",
      "9818:\tlearn: 0.0000000\ttotal: 5.36s\tremaining: 98.8ms\n",
      "9819:\tlearn: 0.0000000\ttotal: 5.36s\tremaining: 98.3ms\n",
      "9820:\tlearn: 0.0000000\ttotal: 5.36s\tremaining: 97.7ms\n",
      "9821:\tlearn: 0.0000000\ttotal: 5.36s\tremaining: 97.2ms\n",
      "9822:\tlearn: 0.0000000\ttotal: 5.36s\tremaining: 96.6ms\n",
      "9823:\tlearn: 0.0000000\ttotal: 5.36s\tremaining: 96.1ms\n",
      "9824:\tlearn: 0.0000000\ttotal: 5.36s\tremaining: 95.5ms\n",
      "9825:\tlearn: 0.0000000\ttotal: 5.36s\tremaining: 95ms\n",
      "9826:\tlearn: 0.0000000\ttotal: 5.36s\tremaining: 94.4ms\n",
      "9827:\tlearn: 0.0000000\ttotal: 5.37s\tremaining: 93.9ms\n",
      "9828:\tlearn: 0.0000000\ttotal: 5.37s\tremaining: 93.4ms\n",
      "9829:\tlearn: 0.0000000\ttotal: 5.37s\tremaining: 92.8ms\n",
      "9830:\tlearn: 0.0000000\ttotal: 5.37s\tremaining: 92.3ms\n",
      "9831:\tlearn: 0.0000000\ttotal: 5.37s\tremaining: 91.7ms\n",
      "9832:\tlearn: 0.0000000\ttotal: 5.37s\tremaining: 91.2ms\n",
      "9833:\tlearn: 0.0000000\ttotal: 5.37s\tremaining: 90.6ms\n",
      "9834:\tlearn: 0.0000000\ttotal: 5.37s\tremaining: 90.1ms\n",
      "9835:\tlearn: 0.0000000\ttotal: 5.37s\tremaining: 89.5ms\n",
      "9836:\tlearn: 0.0000000\ttotal: 5.37s\tremaining: 89ms\n",
      "9837:\tlearn: 0.0000000\ttotal: 5.37s\tremaining: 88.4ms\n",
      "9838:\tlearn: 0.0000000\ttotal: 5.37s\tremaining: 87.9ms\n",
      "9839:\tlearn: 0.0000000\ttotal: 5.37s\tremaining: 87.4ms\n",
      "9840:\tlearn: 0.0000000\ttotal: 5.37s\tremaining: 86.8ms\n",
      "9841:\tlearn: 0.0000000\ttotal: 5.37s\tremaining: 86.3ms\n",
      "9842:\tlearn: 0.0000000\ttotal: 5.37s\tremaining: 85.7ms\n",
      "9843:\tlearn: 0.0000000\ttotal: 5.37s\tremaining: 85.2ms\n",
      "9844:\tlearn: 0.0000000\ttotal: 5.37s\tremaining: 84.6ms\n",
      "9845:\tlearn: 0.0000000\ttotal: 5.37s\tremaining: 84.1ms\n",
      "9846:\tlearn: 0.0000000\ttotal: 5.38s\tremaining: 83.5ms\n",
      "9847:\tlearn: 0.0000000\ttotal: 5.38s\tremaining: 83ms\n",
      "9848:\tlearn: 0.0000000\ttotal: 5.38s\tremaining: 82.4ms\n",
      "9849:\tlearn: 0.0000000\ttotal: 5.38s\tremaining: 81.9ms\n",
      "9850:\tlearn: 0.0000000\ttotal: 5.38s\tremaining: 81.3ms\n",
      "9851:\tlearn: 0.0000000\ttotal: 5.38s\tremaining: 80.8ms\n",
      "9852:\tlearn: 0.0000000\ttotal: 5.38s\tremaining: 80.2ms\n",
      "9853:\tlearn: 0.0000000\ttotal: 5.38s\tremaining: 79.7ms\n",
      "9854:\tlearn: 0.0000000\ttotal: 5.38s\tremaining: 79.1ms\n",
      "9855:\tlearn: 0.0000000\ttotal: 5.38s\tremaining: 78.6ms\n",
      "9856:\tlearn: 0.0000000\ttotal: 5.38s\tremaining: 78.1ms\n",
      "9857:\tlearn: 0.0000000\ttotal: 5.38s\tremaining: 77.5ms\n",
      "9858:\tlearn: 0.0000000\ttotal: 5.38s\tremaining: 77ms\n",
      "9859:\tlearn: 0.0000000\ttotal: 5.4s\tremaining: 76.7ms\n",
      "9860:\tlearn: 0.0000000\ttotal: 5.4s\tremaining: 76.2ms\n",
      "9861:\tlearn: 0.0000000\ttotal: 5.41s\tremaining: 75.6ms\n",
      "9862:\tlearn: 0.0000000\ttotal: 5.41s\tremaining: 75.1ms\n",
      "9863:\tlearn: 0.0000000\ttotal: 5.41s\tremaining: 74.6ms\n",
      "9864:\tlearn: 0.0000000\ttotal: 5.41s\tremaining: 74ms\n",
      "9865:\tlearn: 0.0000000\ttotal: 5.41s\tremaining: 73.5ms\n",
      "9866:\tlearn: 0.0000000\ttotal: 5.41s\tremaining: 73ms\n",
      "9867:\tlearn: 0.0000000\ttotal: 5.42s\tremaining: 72.4ms\n",
      "9868:\tlearn: 0.0000000\ttotal: 5.42s\tremaining: 71.9ms\n",
      "9869:\tlearn: 0.0000000\ttotal: 5.42s\tremaining: 71.4ms\n",
      "9870:\tlearn: 0.0000000\ttotal: 5.42s\tremaining: 70.8ms\n",
      "9871:\tlearn: 0.0000000\ttotal: 5.42s\tremaining: 70.3ms\n",
      "9872:\tlearn: 0.0000000\ttotal: 5.42s\tremaining: 69.7ms\n",
      "9873:\tlearn: 0.0000000\ttotal: 5.42s\tremaining: 69.2ms\n",
      "9874:\tlearn: 0.0000000\ttotal: 5.42s\tremaining: 68.6ms\n",
      "9875:\tlearn: 0.0000000\ttotal: 5.42s\tremaining: 68.1ms\n",
      "9876:\tlearn: 0.0000000\ttotal: 5.42s\tremaining: 67.5ms\n",
      "9877:\tlearn: 0.0000000\ttotal: 5.42s\tremaining: 67ms\n",
      "9878:\tlearn: 0.0000000\ttotal: 5.42s\tremaining: 66.5ms\n",
      "9879:\tlearn: 0.0000000\ttotal: 5.43s\tremaining: 65.9ms\n",
      "9880:\tlearn: 0.0000000\ttotal: 5.43s\tremaining: 65.4ms\n",
      "9881:\tlearn: 0.0000000\ttotal: 5.43s\tremaining: 64.8ms\n",
      "9882:\tlearn: 0.0000000\ttotal: 5.43s\tremaining: 64.3ms\n",
      "9883:\tlearn: 0.0000000\ttotal: 5.43s\tremaining: 63.7ms\n",
      "9884:\tlearn: 0.0000000\ttotal: 5.43s\tremaining: 63.2ms\n",
      "9885:\tlearn: 0.0000000\ttotal: 5.43s\tremaining: 62.6ms\n",
      "9886:\tlearn: 0.0000000\ttotal: 5.43s\tremaining: 62.1ms\n",
      "9887:\tlearn: 0.0000000\ttotal: 5.43s\tremaining: 61.5ms\n",
      "9888:\tlearn: 0.0000000\ttotal: 5.43s\tremaining: 61ms\n",
      "9889:\tlearn: 0.0000000\ttotal: 5.43s\tremaining: 60.4ms\n",
      "9890:\tlearn: 0.0000000\ttotal: 5.43s\tremaining: 59.9ms\n",
      "9891:\tlearn: 0.0000000\ttotal: 5.43s\tremaining: 59.3ms\n",
      "9892:\tlearn: 0.0000000\ttotal: 5.43s\tremaining: 58.8ms\n",
      "9893:\tlearn: 0.0000000\ttotal: 5.43s\tremaining: 58.2ms\n",
      "9894:\tlearn: 0.0000000\ttotal: 5.43s\tremaining: 57.7ms\n",
      "9895:\tlearn: 0.0000000\ttotal: 5.43s\tremaining: 57.1ms\n",
      "9896:\tlearn: 0.0000000\ttotal: 5.44s\tremaining: 56.6ms\n",
      "9897:\tlearn: 0.0000000\ttotal: 5.44s\tremaining: 56ms\n",
      "9898:\tlearn: 0.0000000\ttotal: 5.44s\tremaining: 55.5ms\n",
      "9899:\tlearn: 0.0000000\ttotal: 5.44s\tremaining: 54.9ms\n",
      "9900:\tlearn: 0.0000000\ttotal: 5.44s\tremaining: 54.4ms\n",
      "9901:\tlearn: 0.0000000\ttotal: 5.44s\tremaining: 53.8ms\n",
      "9902:\tlearn: 0.0000000\ttotal: 5.44s\tremaining: 53.3ms\n",
      "9903:\tlearn: 0.0000000\ttotal: 5.44s\tremaining: 52.7ms\n",
      "9904:\tlearn: 0.0000000\ttotal: 5.44s\tremaining: 52.2ms\n",
      "9905:\tlearn: 0.0000000\ttotal: 5.44s\tremaining: 51.6ms\n",
      "9906:\tlearn: 0.0000000\ttotal: 5.44s\tremaining: 51.1ms\n",
      "9907:\tlearn: 0.0000000\ttotal: 5.44s\tremaining: 50.5ms\n",
      "9908:\tlearn: 0.0000000\ttotal: 5.44s\tremaining: 50ms\n",
      "9909:\tlearn: 0.0000000\ttotal: 5.44s\tremaining: 49.4ms\n",
      "9910:\tlearn: 0.0000000\ttotal: 5.44s\tremaining: 48.9ms\n",
      "9911:\tlearn: 0.0000000\ttotal: 5.44s\tremaining: 48.3ms\n",
      "9912:\tlearn: 0.0000000\ttotal: 5.44s\tremaining: 47.8ms\n",
      "9913:\tlearn: 0.0000000\ttotal: 5.44s\tremaining: 47.2ms\n",
      "9914:\tlearn: 0.0000000\ttotal: 5.45s\tremaining: 46.7ms\n",
      "9915:\tlearn: 0.0000000\ttotal: 5.45s\tremaining: 46.1ms\n",
      "9916:\tlearn: 0.0000000\ttotal: 5.45s\tremaining: 45.6ms\n",
      "9917:\tlearn: 0.0000000\ttotal: 5.45s\tremaining: 45ms\n",
      "9918:\tlearn: 0.0000000\ttotal: 5.45s\tremaining: 44.5ms\n",
      "9919:\tlearn: 0.0000000\ttotal: 5.45s\tremaining: 43.9ms\n",
      "9920:\tlearn: 0.0000000\ttotal: 5.45s\tremaining: 43.4ms\n",
      "9921:\tlearn: 0.0000000\ttotal: 5.45s\tremaining: 42.8ms\n",
      "9922:\tlearn: 0.0000000\ttotal: 5.45s\tremaining: 42.3ms\n",
      "9923:\tlearn: 0.0000000\ttotal: 5.45s\tremaining: 41.7ms\n",
      "9924:\tlearn: 0.0000000\ttotal: 5.45s\tremaining: 41.2ms\n",
      "9925:\tlearn: 0.0000000\ttotal: 5.45s\tremaining: 40.6ms\n",
      "9926:\tlearn: 0.0000000\ttotal: 5.45s\tremaining: 40.1ms\n",
      "9927:\tlearn: 0.0000000\ttotal: 5.45s\tremaining: 39.5ms\n",
      "9928:\tlearn: 0.0000000\ttotal: 5.45s\tremaining: 39ms\n",
      "9929:\tlearn: 0.0000000\ttotal: 5.45s\tremaining: 38.4ms\n",
      "9930:\tlearn: 0.0000000\ttotal: 5.45s\tremaining: 37.9ms\n",
      "9931:\tlearn: 0.0000000\ttotal: 5.45s\tremaining: 37.3ms\n",
      "9932:\tlearn: 0.0000000\ttotal: 5.45s\tremaining: 36.8ms\n",
      "9933:\tlearn: 0.0000000\ttotal: 5.45s\tremaining: 36.2ms\n",
      "9934:\tlearn: 0.0000000\ttotal: 5.45s\tremaining: 35.7ms\n",
      "9935:\tlearn: 0.0000000\ttotal: 5.45s\tremaining: 35.1ms\n",
      "9936:\tlearn: 0.0000000\ttotal: 5.46s\tremaining: 34.6ms\n",
      "9937:\tlearn: 0.0000000\ttotal: 5.46s\tremaining: 34ms\n",
      "9938:\tlearn: 0.0000000\ttotal: 5.46s\tremaining: 33.5ms\n",
      "9939:\tlearn: 0.0000000\ttotal: 5.46s\tremaining: 32.9ms\n",
      "9940:\tlearn: 0.0000000\ttotal: 5.46s\tremaining: 32.4ms\n",
      "9941:\tlearn: 0.0000000\ttotal: 5.46s\tremaining: 31.8ms\n",
      "9942:\tlearn: 0.0000000\ttotal: 5.46s\tremaining: 31.3ms\n",
      "9943:\tlearn: 0.0000000\ttotal: 5.46s\tremaining: 30.7ms\n",
      "9944:\tlearn: 0.0000000\ttotal: 5.46s\tremaining: 30.2ms\n",
      "9945:\tlearn: 0.0000000\ttotal: 5.46s\tremaining: 29.6ms\n",
      "9946:\tlearn: 0.0000000\ttotal: 5.46s\tremaining: 29.1ms\n",
      "9947:\tlearn: 0.0000000\ttotal: 5.46s\tremaining: 28.5ms\n",
      "9948:\tlearn: 0.0000000\ttotal: 5.46s\tremaining: 28ms\n",
      "9949:\tlearn: 0.0000000\ttotal: 5.46s\tremaining: 27.4ms\n",
      "9950:\tlearn: 0.0000000\ttotal: 5.46s\tremaining: 26.9ms\n",
      "9951:\tlearn: 0.0000000\ttotal: 5.46s\tremaining: 26.3ms\n",
      "9952:\tlearn: 0.0000000\ttotal: 5.46s\tremaining: 25.8ms\n",
      "9953:\tlearn: 0.0000000\ttotal: 5.46s\tremaining: 25.2ms\n",
      "9954:\tlearn: 0.0000000\ttotal: 5.46s\tremaining: 24.7ms\n",
      "9955:\tlearn: 0.0000000\ttotal: 5.46s\tremaining: 24.2ms\n",
      "9956:\tlearn: 0.0000000\ttotal: 5.46s\tremaining: 23.6ms\n",
      "9957:\tlearn: 0.0000000\ttotal: 5.46s\tremaining: 23.1ms\n",
      "9958:\tlearn: 0.0000000\ttotal: 5.47s\tremaining: 22.5ms\n",
      "9959:\tlearn: 0.0000000\ttotal: 5.47s\tremaining: 22ms\n",
      "9960:\tlearn: 0.0000000\ttotal: 5.47s\tremaining: 21.4ms\n",
      "9961:\tlearn: 0.0000000\ttotal: 5.47s\tremaining: 20.9ms\n",
      "9962:\tlearn: 0.0000000\ttotal: 5.47s\tremaining: 20.3ms\n",
      "9963:\tlearn: 0.0000000\ttotal: 5.47s\tremaining: 19.8ms\n",
      "9964:\tlearn: 0.0000000\ttotal: 5.47s\tremaining: 19.2ms\n",
      "9965:\tlearn: 0.0000000\ttotal: 5.47s\tremaining: 18.7ms\n",
      "9966:\tlearn: 0.0000000\ttotal: 5.47s\tremaining: 18.1ms\n",
      "9967:\tlearn: 0.0000000\ttotal: 5.47s\tremaining: 17.6ms\n",
      "9968:\tlearn: 0.0000000\ttotal: 5.47s\tremaining: 17ms\n",
      "9969:\tlearn: 0.0000000\ttotal: 5.47s\tremaining: 16.5ms\n",
      "9970:\tlearn: 0.0000000\ttotal: 5.47s\tremaining: 15.9ms\n",
      "9971:\tlearn: 0.0000000\ttotal: 5.47s\tremaining: 15.4ms\n",
      "9972:\tlearn: 0.0000000\ttotal: 5.47s\tremaining: 14.8ms\n",
      "9973:\tlearn: 0.0000000\ttotal: 5.47s\tremaining: 14.3ms\n",
      "9974:\tlearn: 0.0000000\ttotal: 5.47s\tremaining: 13.7ms\n",
      "9975:\tlearn: 0.0000000\ttotal: 5.47s\tremaining: 13.2ms\n",
      "9976:\tlearn: 0.0000000\ttotal: 5.47s\tremaining: 12.6ms\n",
      "9977:\tlearn: 0.0000000\ttotal: 5.48s\tremaining: 12.1ms\n",
      "9978:\tlearn: 0.0000000\ttotal: 5.48s\tremaining: 11.5ms\n",
      "9979:\tlearn: 0.0000000\ttotal: 5.48s\tremaining: 11ms\n",
      "9980:\tlearn: 0.0000000\ttotal: 5.48s\tremaining: 10.4ms\n",
      "9981:\tlearn: 0.0000000\ttotal: 5.48s\tremaining: 9.88ms\n",
      "9982:\tlearn: 0.0000000\ttotal: 5.48s\tremaining: 9.33ms\n",
      "9983:\tlearn: 0.0000000\ttotal: 5.48s\tremaining: 8.78ms\n",
      "9984:\tlearn: 0.0000000\ttotal: 5.48s\tremaining: 8.23ms\n",
      "9985:\tlearn: 0.0000000\ttotal: 5.48s\tremaining: 7.68ms\n",
      "9986:\tlearn: 0.0000000\ttotal: 5.48s\tremaining: 7.13ms\n",
      "9987:\tlearn: 0.0000000\ttotal: 5.48s\tremaining: 6.58ms\n",
      "9988:\tlearn: 0.0000000\ttotal: 5.48s\tremaining: 6.04ms\n",
      "9989:\tlearn: 0.0000000\ttotal: 5.48s\tremaining: 5.49ms\n",
      "9990:\tlearn: 0.0000000\ttotal: 5.48s\tremaining: 4.94ms\n",
      "9991:\tlearn: 0.0000000\ttotal: 5.48s\tremaining: 4.39ms\n",
      "9992:\tlearn: 0.0000000\ttotal: 5.48s\tremaining: 3.84ms\n",
      "9993:\tlearn: 0.0000000\ttotal: 5.48s\tremaining: 3.29ms\n",
      "9994:\tlearn: 0.0000000\ttotal: 5.48s\tremaining: 2.74ms\n",
      "9995:\tlearn: 0.0000000\ttotal: 5.48s\tremaining: 2.19ms\n",
      "9996:\tlearn: 0.0000000\ttotal: 5.48s\tremaining: 1.65ms\n",
      "9997:\tlearn: 0.0000000\ttotal: 5.49s\tremaining: 1.1ms\n",
      "9998:\tlearn: 0.0000000\ttotal: 5.49s\tremaining: 548us\n",
      "9999:\tlearn: 0.0000000\ttotal: 5.49s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "199.39882798249386"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply catboost to df_train\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, y_train, X_test, y_test = df_train[['NBEATS', 'NHITS', 'TFT']], df_train['y'], df_test[['NBEATS', 'NHITS', 'TFT']], df_test['y']\n",
    "\n",
    "model = CatBoostRegressor(iterations=10000,\n",
    "                            learning_rate=0.1,\n",
    "                            loss_function='RMSE',\n",
    "                            verbose=True)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.120864987049973"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3154746187540376"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MQLoss()(torch.tensor(y_pred), torch.tensor(y_test.values)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1 y_test.values                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'y_test'</span> is not defined\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1 y_test.values                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'y_test'\u001b[0m is not defined\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1 </span>y_test = torch.tensor(np.array([<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>,<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>,<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span>,<span style=\"color: #0000ff; text-decoration-color: #0000ff\">4</span>]))                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>y_pred = torch.tensor(np.array([<span style=\"color: #0000ff; text-decoration-color: #0000ff\">4</span>,<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span>,<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>,<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>]))                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3 MQLoss()(y_test, y_pred).item()                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">c:\\Users\\szymo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\neuralforecast\\losses\\p</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">ytorch.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">587</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__call__</span>                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 584 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>sq = torch.maximum(-error, torch.zeros_like(error))                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 585 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>s1_q = torch.maximum(error, torch.zeros_like(error))                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 586 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>losses = (<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> / <span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.quantiles)) * (                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 587 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.quantiles * sq + (<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> - <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.quantiles) * s1_q                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 588 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 589 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 590 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> y_hat.ndim == <span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span>:  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># BaseWindows</span>                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">RuntimeError: </span>The size of tensor a <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">)</span> must match the size of tensor b <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">)</span> at non-singleton dimension <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m3\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1 \u001b[0my_test = torch.tensor(np.array([\u001b[94m1\u001b[0m,\u001b[94m2\u001b[0m,\u001b[94m3\u001b[0m,\u001b[94m4\u001b[0m]))                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0my_pred = torch.tensor(np.array([\u001b[94m4\u001b[0m,\u001b[94m3\u001b[0m,\u001b[94m2\u001b[0m,\u001b[94m1\u001b[0m]))                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3 MQLoss()(y_test, y_pred).item()                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m4 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mc:\\Users\\szymo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\neuralforecast\\losses\\p\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mytorch.py\u001b[0m:\u001b[94m587\u001b[0m in \u001b[92m__call__\u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 584 \u001b[0m\u001b[2m│   │   \u001b[0msq = torch.maximum(-error, torch.zeros_like(error))                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 585 \u001b[0m\u001b[2m│   │   \u001b[0ms1_q = torch.maximum(error, torch.zeros_like(error))                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 586 \u001b[0m\u001b[2m│   │   \u001b[0mlosses = (\u001b[94m1\u001b[0m / \u001b[96mlen\u001b[0m(\u001b[96mself\u001b[0m.quantiles)) * (                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 587 \u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.quantiles * sq + (\u001b[94m1\u001b[0m - \u001b[96mself\u001b[0m.quantiles) * s1_q                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 588 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 589 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 590 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m y_hat.ndim == \u001b[94m3\u001b[0m:  \u001b[2m# BaseWindows\u001b[0m                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mRuntimeError: \u001b[0mThe size of tensor a \u001b[1m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1m)\u001b[0m must match the size of tensor b \u001b[1m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1m)\u001b[0m at non-singleton dimension \u001b[1;36m1\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_test = torch.tensor(np.array([1,2,3,4]))\n",
    "y_pred = torch.tensor(np.array([4,3,2,1]))\n",
    "MQLoss()(y_test, y_pred).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55    0.001011\n",
       "56    0.006401\n",
       "57    0.000000\n",
       "58    0.003258\n",
       "59         NaN\n",
       "Name: target_1, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_all['target_1'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t1 = [ 0.0088,  0.0078,  0.0074,  0.0059,  0.0065,  0.0191,  0.0188,  0.0173,\n",
    "#          0.0174,  0.0159,  0.0045,  0.0024,  0.0010, -0.0010,  0.0023,  0.0332,\n",
    "#          0.0329,  0.0307,  0.0250,  0.0275,  0.0208,  0.0209,  0.0192,  0.0189,\n",
    "#          0.0197,  0.0148,  0.0139,  0.0135,  0.0146,  0.0135,  0.0100,  0.0104,\n",
    "#          0.0084,  0.0084,  0.0090,  0.0051,  0.0056,  0.0049,  0.0031,  0.0036]\n",
    "t1 = [ 0.0088,  0.0078,  0.0074,  0.0059,  0.0065, 10]\n",
    "# t2 = [-0.0034,  0.0087,  0.0142, -0.0190,  0.0183,  0.0535,  0.0059, -0.0879,\n",
    "#         -0.0229,  0.0020, -0.0016, -0.0118, -0.0227,  0.0301,  0.0305, -0.0008,\n",
    "#         -0.0205,  0.0030,  0.0014,  0.0210, -0.0056, -0.0217,  0.0025, -0.0195,\n",
    "#          0.0144, -0.0096, -0.0197, -0.0304,  0.0038,  0.0093,  0.0119,  0.0342,\n",
    "#         -0.0494,  0.0221,  0.0049,  0.0281,  0.0108, -0.0023,  0.0142,  0.0000]\n",
    "t2 = [-0.0034,  0.0087,  0.0142, -0.0190,  0.018, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0088, 0.0078, 0.0074, 0.0059, 0.0065, 10]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1 # MQLoss()(t1, t2).item()</span>                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">print</span>(t1)                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3 MQLoss()(torch.tensor(t1), torch.tensor(t2)).item()                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">c:\\Users\\szymo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\neuralforecast\\losses\\p</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">ytorch.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">587</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__call__</span>                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 584 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>sq = torch.maximum(-error, torch.zeros_like(error))                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 585 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>s1_q = torch.maximum(error, torch.zeros_like(error))                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 586 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>losses = (<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> / <span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.quantiles)) * (                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 587 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.quantiles * sq + (<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> - <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.quantiles) * s1_q                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 588 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 589 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 590 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> y_hat.ndim == <span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span>:  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># BaseWindows</span>                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">RuntimeError: </span>The size of tensor a <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">)</span> must match the size of tensor b <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span><span style=\"font-weight: bold\">)</span> at non-singleton dimension <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m3\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1 \u001b[0m\u001b[2m# MQLoss()(t1, t2).item()\u001b[0m                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m\u001b[96mprint\u001b[0m(t1)                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3 MQLoss()(torch.tensor(t1), torch.tensor(t2)).item()                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m4 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mc:\\Users\\szymo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\neuralforecast\\losses\\p\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mytorch.py\u001b[0m:\u001b[94m587\u001b[0m in \u001b[92m__call__\u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 584 \u001b[0m\u001b[2m│   │   \u001b[0msq = torch.maximum(-error, torch.zeros_like(error))                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 585 \u001b[0m\u001b[2m│   │   \u001b[0ms1_q = torch.maximum(error, torch.zeros_like(error))                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 586 \u001b[0m\u001b[2m│   │   \u001b[0mlosses = (\u001b[94m1\u001b[0m / \u001b[96mlen\u001b[0m(\u001b[96mself\u001b[0m.quantiles)) * (                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 587 \u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.quantiles * sq + (\u001b[94m1\u001b[0m - \u001b[96mself\u001b[0m.quantiles) * s1_q                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 588 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 589 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 590 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m y_hat.ndim == \u001b[94m3\u001b[0m:  \u001b[2m# BaseWindows\u001b[0m                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mRuntimeError: \u001b[0mThe size of tensor a \u001b[1m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1m)\u001b[0m must match the size of tensor b \u001b[1m(\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1m)\u001b[0m at non-singleton dimension \u001b[1;36m1\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MQLoss()(t1, t2).item()\n",
    "print(t1)\n",
    "MQLoss()(torch.tensor(t1), torch.tensor(t2)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1 MQLoss(torch.tensor(t1), torch.tensor(t2)).item                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">c:\\Users\\szymo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1695</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__getattr__</span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1692 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>modules = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__dict__</span>[<span style=\"color: #808000; text-decoration-color: #808000\">'_modules'</span>]                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1693 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> name <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> modules:                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1694 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> modules[name]                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1695 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">AttributeError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">f\"'{</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">type</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>).<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__name__</span><span style=\"color: #808000; text-decoration-color: #808000\">}' object has no attribute '{</span>name<span style=\"color: #808000; text-decoration-color: #808000\">}'\"</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1696 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1697 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__setattr__</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, name: <span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>, value: Union[Tensor, <span style=\"color: #808000; text-decoration-color: #808000\">'Module'</span>]) -&gt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1698 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">remove_from</span>(*dicts_or_sets):                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">AttributeError: </span><span style=\"color: #008000; text-decoration-color: #008000\">'MQLoss'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'item'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1 MQLoss(torch.tensor(t1), torch.tensor(t2)).item                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mc:\\Users\\szymo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33m.py\u001b[0m:\u001b[94m1695\u001b[0m in \u001b[92m__getattr__\u001b[0m                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1692 \u001b[0m\u001b[2m│   │   │   \u001b[0mmodules = \u001b[96mself\u001b[0m.\u001b[91m__dict__\u001b[0m[\u001b[33m'\u001b[0m\u001b[33m_modules\u001b[0m\u001b[33m'\u001b[0m]                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1693 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m name \u001b[95min\u001b[0m modules:                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1694 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mreturn\u001b[0m modules[name]                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1695 \u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mAttributeError\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m'\u001b[0m\u001b[33m{\u001b[0m\u001b[96mtype\u001b[0m(\u001b[96mself\u001b[0m).\u001b[91m__name__\u001b[0m\u001b[33m}\u001b[0m\u001b[33m'\u001b[0m\u001b[33m object has no attribute \u001b[0m\u001b[33m'\u001b[0m\u001b[33m{\u001b[0mname\u001b[33m}\u001b[0m\u001b[33m'\u001b[0m\u001b[33m\"\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1696 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1697 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m__setattr__\u001b[0m(\u001b[96mself\u001b[0m, name: \u001b[96mstr\u001b[0m, value: Union[Tensor, \u001b[33m'\u001b[0m\u001b[33mModule\u001b[0m\u001b[33m'\u001b[0m]) -> \u001b[94mNone\u001b[0m:             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1698 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mremove_from\u001b[0m(*dicts_or_sets):                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mAttributeError: \u001b[0m\u001b[32m'MQLoss'\u001b[0m object has no attribute \u001b[32m'item'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MQLoss(torch.tensor(t1), torch.tensor(t2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d == f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
